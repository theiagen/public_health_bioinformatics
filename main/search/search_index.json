{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#purpose-workflows","title":"Purpose &amp; Workflows","text":"<p>The PHB repository contains workflows for the characterization, genomic epidemiology, and sharing of pathogen genomes of public health concern. Workflows are available for viruses, bacteria, and fungi.</p> <p>All workflows in the PHB repository end with <code>_PHB</code> in order to differentiate them from earlier versions and from the original tools they incorporate.</p> <p>Explore our workflows</p> <ul> <li> <p></p>Terra Users<p></p> <p>Learn how to use our workflows on Terra!</p><p></p> </li> <li> <p></p>v3.1.1 Release Notes<p></p> <p>Learn about the latest changes to our workflows!</p><p></p> </li> <li> <p></p>Command-line Users<p></p> <p>Learn how to use our workflows on the command-line!</p><p></p> </li> </ul> <p>Our Open Source Philosophy</p> <p>PHB source code is publicly available on GitHub and available under GNU Affero General Public License v3.0!</p> <p>All workflows can be imported directly to Terra via the Dockstore PHB collection! </p> <p>You can also use our workflows on the command-line. Please see our guide on how to get started here!</p> <p>When undertaking genomic analysis using the command-line, via Terra, or other data visualization platforms, it is essential to consider the necessary and appropriate workflows and resources for your analysis. To help you make these choices, take a look at the relationship between the most commonly used Theiagen workflows.</p> <p>Analysis Approaches for Genomic Data</p> General Workflow RelationshipsAvailable Standalone Workflows <p></p> <p>This diagram shows the available workflows in the PHB repository, represented by circles, that are available for analysis of genomic data. Workflows are grouped into boxes that represent the major types of analysis that they perform. The arrows between the boxes represent the relationships between the workflows, showing which workflows may be used consecutively, while the large arrow underlying everything indicates the general process of analysis.</p> <p></p> <p>This diagram shows the available standalone workflows in the PHB repository, represented by circles, that are available for analysis of genomic data. Workflows are grouped by colors that represent the major types of analysis that they perform. These workflows can be used independently of the major workflow groupings as either supplements or alternatives.</p>"},{"location":"#phb-development-is-a-cycle","title":"PHB development is a cycle","text":"<p>We continuously work to improve our codebase and usability of our workflows by the public health community, so changes from version to version are expected. This documentation page reflects the state of the repository at the version stated in the header.</p>"},{"location":"#contributing-to-the-phb-repository","title":"Contributing to the PHB Repository","text":"<p>We warmly welcome contributions to this repository! Our code style guide may be found here for convenience of formatting and our documentation style guide may be found here.</p> <p>If you would like to submit suggested code changes to our workflows, you may add or modify the WDL files and submit pull requests to the PHB GitHub repository.</p> <p>You can expect a careful review of every PR and feedback as needed before merging, just like we do for PRs submitted by the Theiagen team. Our PR template can help prepare you for the review process. As always, reach out with any questions! We love recieving feedback and contributions from the community. When your PR is merged, we'll add your name to the contributors list below!</p>"},{"location":"#authorship-responsibility","title":"Authorship &amp; Responsibility","text":""},{"location":"#authorship","title":"Authorship","text":"<p>(Ordered by contribution [# of lines changed] as of 2025-09-08)</p> <ul> <li>Sage Wright (@sage-wright) - Conceptualization, Software, Validation, Supervision </li> <li>In\u00eas Mendes (@cimendes) - Software, Validation </li> <li>Curtis Kapsak (@kapsakcj) - Conceptualization, Software, Validation </li> <li>Theron James (@MrTheronJ) - Software, Validation </li> <li>Zachary Konkel (@xonq) - Software, Validation </li> <li>Michal Babinski (@Michal-Babins) - Software, Validation </li> <li>Andrew Hale (@awh082834) - Software, Validation </li> <li>Michelle Scribner (@michellescribner) - Software, Validation </li> <li>Kevin Libuit (@kevinlibuit) - Conceptualization, Project Administration, Software, Validation, Supervision </li> <li>Andrew Lang (@AndrewLangVt) - Software, Supervision </li> <li>Kelsey Kropp (@kelseykropp) - Validation </li> <li>Sushmita Sridhar (@ss43) - Validation </li> <li>Deborah Young (@theiadeb) - Validation </li> <li>Joel Sevinsky (@sevinsky) - Conceptualization, Project Administration, Supervision </li> </ul>"},{"location":"#external-contributors","title":"External Contributors","text":"<p>We would like to gratefully acknowledge the following individuals from the public health community for their contributions to the PHB repository:</p> <ul> <li>Frank Ambrosio (@frankambrosio3)*</li> <li>James Otieno (@jrotieno)*</li> <li>Robert Petit (@rpetit3)*</li> <li>Fraser Combe (@fraser-combe)*</li> <li>Andrew Page (@andrewjpage)*</li> <li>Emma Doughty (@emmadoughty)*</li> <li>Nate Matteson (@watronfire)</li> <li>Ash O'Farrel (@aofarrel)</li> <li>Sam Baird (@sam-baird)</li> <li>Holly Halstead (@HNHalstead)</li> <li>Emily Smith (@emily-smith1)*</li> </ul> <p>* Former member of Theiagen</p>"},{"location":"#on-the-shoulder-of-giants","title":"On the Shoulder of Giants","text":"<p>The PHB repository would not be possible without its predecessors. We would like to acknowledge the following repositories, individuals, and contributors for their influence on the development of these workflows:</p> <p>The PHB repository originated from collaborative work with Andrew Lang, PhD &amp; his Genomic Analysis WDL workflows. The workflows and task development were influenced by The Broad's Viral Pipes repository. The TheiaCoV workflows for viral genomic characterization were influenced by UPHL's Cecret &amp; StaPH-B's Monroe (now deprecated) workflows. The TheiaProk workflows for bacterial genomic characterization were influenced by Robert Petit's bactopia. Most importantly, the PHB user community drove the development of these workflows and we are grateful for their feedback and contributions.</p> <p>If you would like to provide feedback, please raise a GitHub issue or contact us at support@theiagen.com.</p>"},{"location":"#maintaining-phb-pipelines","title":"Maintaining PHB Pipelines","text":"<p>Theiagen Genomics has committed to maintaining these workflows for the forseeable future. These workflows are written using a standard workflow language (WDL) and uses Docker images based on the StaPH-B Docker Builds. New versions that include bug fixes and additional features are released on a quarterly bases, with urgent bug fixes released as needed. Each version is accompanied by detailed release notes to lower the barrier of pipeline upkeep from the public health community at large.</p>"},{"location":"#point-of-contact","title":"Point of Contact","text":"<p>If you have any questions or concerns, please raise a GitHub issue or email Theiagen's general support at support@theiagen.com.</p>"},{"location":"#conflict-of-interest","title":"Conflict of Interest","text":"<p>The authors declare no conflict of interest.</p>"},{"location":"#citation","title":"Citation","text":"<p>Please cite this paper if publishing work using any workflows:</p> <p>Libuit, Kevin G., Emma L. Doughty, James R. Otieno, Frank Ambrosio, Curtis J. Kapsak, Emily A. Smith, Sage M. Wright, et al. 2023. \"Accelerating Bioinformatics Implementation in Public Health.\" Microbial Genomics 9 (7). https://doi.org/10.1099/mgen.0.001051.</p> <p>Alternatively, please cite this paper if using the TheiaEuk workflow:</p> <p>Ambrosio, Frank, Michelle Scribner, Sage Wright, James Otieno, Emma Doughty, Andrew Gorzalski, Danielle Siao, et al. 2023. \"TheiaEuk: A Species-Agnostic Bioinformatics Workflow for Fungal Genomic Characterization.\" Frontiers in Public Health 11. https://doi.org/10.3389/fpubh.2023.1198213.</p>"},{"location":"#about-theiagen","title":"About Theiagen","text":"<p>Theiagen develops bioinformatics solutions for public health labs, and then trains and supports scientists to use these. If you would like to work with Theiagen, please\u00a0get in contact.</p>"},{"location":"assets/new_workflow_template/","title":"Workflow Name","text":""},{"location":"assets/new_workflow_template/#workflow-name","title":"Workflow Name","text":""},{"location":"assets/new_workflow_template/#quick-facts","title":"Quick Facts","text":"<p>Use the following render_tsv_table macro call that is provided in code below to generate the quick facts table, replacing the fields marked with <code>&lt;&gt;</code> with the appropriate values. Please note that the macro result is seen on the web browser, not the macro call itself.</p> Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore"},{"location":"assets/new_workflow_template/#workflow_name_on_terra","title":"Workflow_Name_On_Terra","text":"<p>Please provide a description of the workflow in complete sentences.</p> <p>Workflow Name Diagram</p> <p>If a workflow diagram is available, add it here. If not, remove this caption admonition. See the page for TheiaCoV for an example.</p>"},{"location":"assets/new_workflow_template/#inputs","title":"Inputs","text":"<p>Any additional information regarding the inputs, such as suggestions or guidelines should be found before the table. See the page for Snippy_Streamline for an example.</p> <p>Add your inputs anywhere in the <code>assets/tables/all_inputs.tsv</code> table. If your workflow has the same type of input as a different workflow, check the inputs table to see if that input already exists. If so, add your workflow name to the comma-delimited list for that input in the appropriate column.</p> <p>Use the following macro call to generate the inputs table. Adjust the fields marked with <code>&lt;&gt;</code> with the appropriate values.  Please note that the macro result is seen on the web browser, not the macro call itself.</p> Terra Task Name Variable Type Description Default Value Terra Status"},{"location":"assets/new_workflow_template/#workflow-tasks","title":"Workflow Tasks","text":"<p>Feel free to separate this section into subsections, like \"Read QC\" and \"Alignment\" if there are multiple tasks per subsection for easier navigation and readability. See the page for TheiaMeta for an example.</p> <p>If your workflow uses a task that is modular and can be used in other contexts, please add that information to the <code>docs/common_text</code> directory in a new page (see a template in the <code>/common_text/template_task.md</code> file) and use the following macro call to include it here. Adjust the fields marked with <code>&lt;&gt;</code> with the appropriate values. Please note that the macro result is seen on the web browser, not the macro call itself.</p> <code>&lt;tool_name&gt;</code>: &lt;brief description&gt; <p>Provide sufficient information about your task here so that users can understand how to use the task, what actions it performs, and any important considerations or requirements. Use admonitions as appropriate to highlight important information, tips, or technical details.</p> <p>Be sure any links within this file are written relative to the destination file. For example, if this file is in <code>docs/common_text/</code> but is being included in <code>docs/workflows/standalone/</code> and you want to link to a file in <code>docs/assets/figures/</code>, the link should be written as <code>[link_name](../../assets/figures/link_destination.md)</code>.</p> <p>If your task is used slighly differently in different contexts, you can provide conditionals inside of comments.</p> <p>To include any conditional information in the destination page, add the <code>condition=\"condition_name\"</code> parameter to the <code>include_md</code> macro call on the destination page. Please note that the <code>if: &lt;condition_name&gt;</code> and <code>endif</code> syntax within the markdown comment (<code>&lt;!-- --&gt;</code>) is required for a conditional statement to work. </p> <p>Here is an example:</p> <p><code>&lt;!-- if: &lt;condition_name&gt; --&gt;</code></p> <p>Conditional Content</p> <p>This is content that is only shown if &lt;condition_name&gt; is provided. See the <code>kraken_task.md</code> common_text file for examples on conditional usage. </p> <p><code>&lt;!-- endif --&gt;</code></p> <p> Technical Details</p> <p>This section is required for all tasks. If the Software Source Code, Software Documentation, and/or Original Publication(s) fields are not applicable, they may be removed.</p> Links Task .wdl Software Source Code Software Documentation Original Publication(s)"},{"location":"assets/new_workflow_template/#outputs","title":"Outputs","text":"<p>Add your outputs to the <code>assets/tables/all_outputs.tsv</code> table. Location doesn't matter. If your workflow has the same type of output as a different workflow, check the output table to see if that output already exists. If so, add your workflow name to the comma-delimited list in the appropriate column.</p> <p>Use the following macro call to generate the outputs table. Adjust the fields marked with <code>&lt;&gt;</code> with the appropriate values. Please note that the macro result is seen on the web browser, not the macro call itself.</p> Variable Type Description <p>Any additional information regarding the outputs, such as interpretation suggestions or more details, should be found after the table. See the page for Kraken2 for an example.</p>"},{"location":"assets/new_workflow_template/#references","title":"References","text":"<p>Include this section if applicable.</p> <p>reference1</p> <p>reference2</p>"},{"location":"common_text/abricate_abaum_task/","title":"Abricate abaum task","text":"<code>abricate_abaum</code>: Plasmid Identification <p>Acinetobacter plasmids are not included in the PlasmidFinder database (see the above section on Plasmid Identification). Instead, the AcinetobacterPlasmidTyping database contains variants of the plasmid rep gene for A. baumannii plasmid identification. When matched with &gt;/= 95 % identity, this represents a typing scheme for Acinetobacter baumannii plasmids.</p> <p>The bioinformatics software for querying sample assemblies against the AcinetobacterPlasmidTyping database is ABRicate. By default, a 95% minimum identity threshold is set in order for successful classification.</p> <p>abricate_abaum Technical Details</p> Links Task task_abricate.wdl Software Source Code AcinetobacterPlasmidTyping Database on GitHubABRicate on GitHub Software Documentation AcinetobacterPlasmidTyping Database on GitHubABRicate on GitHub Original Publication(s) AcinetobacterPlasmidTyping database: Detection and Typing of Plasmids in\u00a0Acinetobacter baumannii\u00a0Using\u00a0rep\u00a0Genes Encoding Replication Initiation Proteins"},{"location":"common_text/abricate_bacterial_task/","title":"Abricate bacterial task","text":"<code>ABRicate</code>: AMR Genotyping (optional) <p>To activate this task, set <code>call_abricate</code> to <code>true</code>.</p> <p>The <code>abricate</code> module, if enabled, will run ABRicate with the database defined in <code>abricate_db</code> to perform mass screening of contigs for antimicrobial resistance or virulence genes. It comes bundled with multiple databases: NCBI, CARD, ARG-ANNOT, Resfinder, MEGARES, EcOH, PlasmidFinder, Ecoli_VF and VFDB. It only detects acquired resistance genes,\u00a0NOT\u00a0point mutations.</p> <p>By default, the \"vfdb\" database is used. The virulence factor database (VFDB) is a comprehensive resource for bacterial pathogen virulence factors.</p> <p>ABRicate Technical Details</p> Links Task task_abricate.wdl Software Source Code VFDB DatabaseABRicate on GitHub Software Documentation VFDB DatabaseABRicate on GitHub Original Publication(s) VFDB database: VFDB 2019: a comparative pathogenomic platform with an interactive web interface"},{"location":"common_text/abricate_flu_task/","title":"Abricate flu task","text":"<code>abricate</code> <p>ABRicate assigns types and subtype/lineages for flu samples using a version of the INSaFLU (\"INSide the FLU\") database described here. </p> <p>ABRicate typically works by screening contigs for the presence of acquired resistance genes, but when using the INSaFLU database, the algorithm works by assigning contigs to the most closely corresponding viral segment in the INSaFLU database, which is used to call the flu type and subtype.</p> <p>ABRicate Technical Details</p> Links Task task_abricate.wdl (abricate_flu subtask) Software Source Code ABRicate on GitHub Software Documentation ABRicate on GitHub Original Publication(s) INSaFLU database: INSaFLU: an automated open web-based bioinformatics suite \"from-reads\" for influenza whole-genome-sequencing-based surveillance"},{"location":"common_text/abricate_vibrio_task/","title":"Abricate vibrio task","text":"<code>abricate_vibrio</code>: Vibrio Characterization <p>The <code>abricate_vibrio</code> task is used to perform general characterization of Vibrio genomes using a database of target sequences that are traditionally used in PCR methods. The sequences included in the database are as follows:</p> Resistence Gene Database Sequence Name Sequence Role Purpose in Database toxR Transcriptional activator Species marker where presence identifies V. cholerae ompW Outer Membrane Protein Species marker where presence identifies V. cholerae ctxA Cholera toxin Indicates cholera toxin production tcpA_classical Toxin co-pilus A allele, associated with the Classical biotype Used to infer identity as Classical biotype tcpA_ElTor Toxin co-pilus A allele, associated with the El Tor biotype Used to infer identity as El Tor biotype wbeN O antigen encoding region Used to infer identity as O1 serogroup wbfR O antigen encoding region Used to infer identity as O139 serogroup <p>This database was developed via communication with Dr. Christine Lee, of the National Listeria, Yersinia, Vibrio and Enterobacterales Reference Laboratory within the Enteric Diseases Laboratory Branch at CDC. It is identical to the database used in the <code>srst2</code> task except it is formatted for ABRicate.</p> <p>This task works by using the ABRicate tool, which uses BLAST to compare the assembled genome to the target sequences in the database and then reporting the details of the genes that pass quality thresholds. The presence or absence of specific genes are used to verify the species, identify cholera toxin production, and designation both the biotype and serogroup of the sample. See the table above for the genes used for each of these purposes.</p> <p>abricate_vibrio Technical Details</p> Links Task task_abricate.wdl Software Source Code ABRicate on GitHub Software Documentation ABRicate on GitHub"},{"location":"common_text/agrvate_task/","title":"Agrvate task","text":"<code>AgrVATE</code>: Sequence Typing <p>This tool identifies the accessory gene regulator (agr) locus type and reports possible variants in the agr operon. The agr system is a major regulator of virulence phenotypes in Staphylococcus aureus. Many S. aureus strains often have nonfunctional agr activity due to various loss-of-function mutations in the agr operon. This may be associated with increased disease severity, making its detection clinically significant.</p> <p>AgrVATE workings by using BLAST to compare a database of unique agr-group-specific k-mers against the provided assembly. The agr operon is then extracted using in-silico PCR computational methods. If an agr-group is assigned, variants are called using an Agr-group specific reference operon in order to detect possible non-functional agr. If the agr-group was untypeable, the sequence is searched for potential non-canonical agrD.</p> <p>AgrVATE Technical Details</p> Links Task task_agrvate.wdl Software Source Code AgrVATE on GitHub Software Documentation AgrVATE on GitHub Original Publication(s) Species-Wide Phylogenomics of the Staphylococcus aureus Agr Operon Revealed Convergent Evolution of Frameshift Mutations"},{"location":"common_text/amr_search_task/","title":"Amr search task","text":"<code>amr_search</code>: Antimicrobial resistance profiling <code>amr_search</code>: Antimicrobial Resistance Profiling (optional) <p>To activate this task, set <code>run_amr_search</code> to be <code>true</code>.</p> <pre><code>This task performs _in silico_ antimicrobial resistance (AMR) profiling for supported species using AMRsearch, the primary tool used by [Pathogenwatch](https://pathogen.watch/) to genotype and infer antimicrobial resistance (AMR) phenotypes from assembled microbial genomes.\n\nAMRsearch screens against Pathogenwatch's library of curated genotypes and inferred phenotypes, developed in collaboration with community experts. Resistance phenotypes are determined based on both _resistance genes_ and _mutations_, and the system accounts for interactions between multiple SNPs, genes, and suppressors. Predictions follow **S/I/R classification** (_Sensitive_, _Intermediate_, _Resistant_).\n\nCurrently, only a subset of species are supported by this task.\n\n??? toggle \"Supported Species\"\n    The following table shows the species name and the associated NCBI Code. If you are running AMR Search as part of TheiaProk and TheiaEuk, these codes will be automatically determined based on the GAMBIT predicted taxon, or the user-provided `expected_taxon` input.\n\n    | Species                      | NCBI Code |\n    |------------------------------|-----------|\n    | _Neisseria gonorrhoeae_      | 485       |\n    | _Staphylococcus aureus_      | 1280      |\n    | _Salmonella_ Typhi           | 90370     |\n    | _Streptococcus pneumoniae_   | 1313      |\n    | _Klebisiella_                | 570       |\n    | _Escherichia_                | 561       |\n    | _Mycobacterium tuberculosis_ | 1773      |\n    | _Candida auris_              | 498019    |\n    | _Vibrio cholerae_            | 666       |\n    | _Campylobacter_              | 194       |\n\n**Outputs:**\n\n- **JSON Output**: Contains the complete AMR profile, including detailed resistance state, detected resistance genes/mutations, and supporting BLAST results.\n- **CSV &amp; PDF Tables**: An incorporated Python script, `parse_amr_json.py`, extracts and formats results into a CSV file and PDF summary table for easier visualization.\n\n!!! techdetails \"amr_search Technical Details\"    \n    |  | Links |\n    | --- | --- |\n    | Task | [task_amr_search.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/gene_typing/drug_resistance/task_amr_search.wdl) |\n    | Software Source Code | [AMRsearch on GitHub](https://github.com/pathogenwatch-oss/amr-search) |\n    | Software Documentation | [AMRsearch on GitHub](https://github.com/pathogenwatch-oss/amr-search) |\n    | Original Publication(s) | [PAARSNP: rapid genotypic resistance prediction for _Neisseria gonorrhoeae_](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7545138/) |\n</code></pre>"},{"location":"common_text/amrfinderplus_task/","title":"Amrfinderplus task","text":"<code>AMRFinderPlus</code>: AMR Genotyping <p>NCBI's AMRFinderPlus is the default antimicrobial resistance (AMR) detection tool used in TheiaProk. ResFinder may be used alternatively and if so, AMRFinderPlus is not run. </p> <p>AMRFinderPlus identifies acquired antimicrobial resistance (AMR) genes, virulence genes, and stress genes.  Such AMR genes confer resistance to antibiotics, metals, biocides, heat, or acid. For some taxa (see here), AMRFinderPlus will provide taxa-specific results including filtering out genes that are almost ubiquitous in the taxa (intrinsic genes) and identifying resistance-associated point mutations.  In TheiaProk, the taxon used by AMRFinderPlus is specified based on the <code>gambit_predicted_taxon</code> or a user-provided <code>expected_taxon</code>. AMRFinderPlus also has the ability to utilize a GFF and protein FASTA file which can be enabled via <code>amrfinder_use_gff</code> allowing for more accurate calls.</p> <p>You can check if a gene or point mutation is in the AMRFinderPlus database with the Reference Gene Catalog, find the sequences of reference genes in the Bacterial Antimicrobial Resistance Reference Gene Database BioProject, and search the query Hidden Markov Models (HMMs) used by AMRFinderPlus to identify AMR genes and some stress and virulence proteins in the Reference HMM Catalog. The AMRFinderPlus database is updated frequently. You can ensure you are using the most up-to-date version by specifying the Docker image in the optional workflow input.</p> AMRFinderPlus results can be used to confirm taxonomic assignment in A. baumannii <p>The blaOXA-51-like genes, also known as oxaAB, are considered intrinsic to Acinetobacter baumannii but are not found in other Acinetobacter species. Identification of a blaOXA-51-like gene with this tool is therefore considered to confirm the species' identity as A. baumannii.</p> <p>AMRFinderPlus Technical Details</p> Links Task task_amrfinderplus.wdl Software Source Code NCBI's AMRFinderPlus on GitHub Software Documentation https://github.com/ncbi/amr/wiki Original Publication(s) AMRFinderPlus and the Reference Gene Catalog facilitate examination of the genomic links among antimicrobial resistance, stress response, and virulence"},{"location":"common_text/arln_stats_task/","title":"Arln stats task","text":"<code>arln_stats</code>: Quality Assessment for ARLN (optional) <p>To activate this task, set <code>call_arln_stats</code> to <code>true</code>.</p> <p>The <code>arln_stats</code> task will provide the user with Antimicrobial Resistance Laboratory Network (ARLN)-compliant statistics used for PASS/FAIL assessment, such as assembly ratio, percent GC statistics, and the percent Q30 of raw and cleaned reads.</p> <p>The Q30 statistics are calculated via a Python script (q30.py) that is incorporated within this task's Docker image. The assembly ratio statistic is obtained by parsing an included NCBI Assembly Stats text file that is created by the CDC to aggregate NCBI prokaryotic assembly data. The file is sorted by taxon and has statistics for each taxon (see toggle below). This data is used to obtain and calculate the assembly ratio of samples passed through <code>arln_stats</code>, much the same as CDC's Phoenix pipeline.</p> NCBI Assembly Stats Explained <p>This aggregated data file is produced by the CDC and the columns are as follows: </p> <ul> <li>Species</li> <li>Assembly_Size_Min</li> <li>Assembly_Size_Max</li> <li>Assembly_vMedian</li> <li>Assembly_Size_Mean</li> <li>Assembly_Size_StDev</li> <li>Assembly_count</li> <li>GC_Min</li> <li>GC_Max</li> <li>GC_Median</li> <li>GC_Mean</li> <li>GC_Stdev</li> <li>GC_count</li> <li>CDS_Min</li> <li>CDS_Max</li> <li>CDS_Median</li> <li>CDS_Mean</li> <li>CDS_Stdev</li> <li>CDS_count</li> <li>Consensus_TAXID</li> </ul> <p>arln_stats Technical Details</p> Links Task task_arln_stats.wdl"},{"location":"common_text/artic_consensus_task/","title":"Artic consensus task","text":"<code>artic_consensus</code>: Alignment, Primer Trimming, Variant Detection, and Consensus <p>This task runs the <code>Artic minion</code> command which is a pipeline with a number of stages, described in detail in the ARTIC documentation. Briefly, these stages are as follows:</p> <p>Input reads are aligned to the appropriate reference and only mapped reads are retained. Alignment post-processing occurs, where primers are removed and various trimming steps are undertaken. Variants are detected, and a consensus assembly file is generated.</p> <p>Please note that the Medaka model is set by default to <code>\"r941_min_high_g360\"</code> which may not be suitable for your sequencing data. Please be sure to change this parameter if needed.</p> <p>Read-trimming is performed on raw read data generated on the ClearLabs instrument and thus not a required step in the TheiaCoV_ClearLabs workflow.</p> <p>Artic Consensus Technical Details</p> Links Task task_artic_consensus.wdl Software Source Code ARTIC on GitHub Software Documentation ARTIC Documentation"},{"location":"common_text/artic_guppyplex_task/","title":"Artic guppyplex task","text":"<code>artic_guppyplex</code>: Read Filtering <p>Reads are filtered by length with <code>artic_guppyplex</code>, which is a part of the <code>ARTIC</code> protocol. Since TheiaCoV was developed primarily for amplicon-based viral sequencing, this task is included to remove chimeric reads that are either too short or too long.</p> <p>artic_guppyplex Technical Details</p> Links Task task_artic_guppyplex.wdl Software Source Code ARTIC on GitHub Software Documentation ARTIC Documentation"},{"location":"common_text/assembly_metrics_task/","title":"Assembly metrics task","text":"<code>assembly_metrics</code>: Mapping Statistics <p>The <code>assembly_metrics</code> task generates mapping statistics from a BAM file. It uses samtools to generate a summary of the mapping statistics, which includes coverage, depth, average base quality, average mapping quality, and other relevant metrics.</p> <pre><code>This task is run twice: once on the untrimmed reads and, if primer trimming is enabled, once on the primer-trimmed reads. This allows for a comparison of mapping statistics before and after primer trimming, which can be useful for assessing the impact of primer trimming on the quality of the alignment and subsequent analyses.\n</code></pre> <pre><code>!!! techdetails \"`assembly_metrics` Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_assembly_metrics.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/basic_statistics/task_assembly_metrics.wdl) |\n    | Software Source Code | [samtools on GitHub](https://github.com/samtools/samtools) |\n    | Software Documentation | [samtools](https://www.htslib.org/doc/samtools.html) |\n    | Original Publication(s) | [The Sequence Alignment/Map format and SAMtools](https://doi.org/10.1093/bioinformatics/btp352)&lt;br&gt;[Twelve Years of SAMtools and BCFtools](https://doi.org/10.1093/gigascience/giab008) |\n</code></pre>"},{"location":"common_text/bakta_task/","title":"Bakta task","text":"<code>Bakta</code>: Assembly Annotation (alternative) <p>To activate this task, set <code>genome_annotation</code> to <code>\"bakta\"</code>.</p> <p><code>Bakta</code> is intended for the annotation of bacterial genomes and plasmids and is used to identify and describe regions of interest within the genome.</p> <p>In addition to the standard annotation outputs, <code>Bakta</code> also provides a plot summarizing the annotation results, which can be useful for visualizing genome features.</p> <p>Bakta Database Options</p> <p>Our implementation of <code>Bakta</code> supports three database configurations:</p> <ul> <li>Light: Optimized for faster performance and lower resource usage, with a focused set of core reference data for most bacterial genome annotations. Recommended for quick annotations or limited computational resources. Specify \"light\" for the <code>bakta_db</code> input.</li> <li>Full (default): Comprehensive with extensive reference annotations, suitable for detailed and accurate annotations. Specify \"full\" for the <code>bakta_db</code> input.</li> <li>Custom: Allows users to provide a Bakta-compatible database stored in Google Cloud Storage Bucket. This file must be a .tar.gz archive containing a properly formatted Bakta database with a valid version.json. Please see the Bakta database documentation for detailed formatting requirements. Example: <code>\"bakta_db\": \"gs://my-bucket/custom_bakta_db.tar.gz\"</code></li> </ul> <p>Bakta Technical Details</p> Links Task task_bakta.wdl Software Source Code Bakta on GitHub Software Documentation Bakta on GitHub Original Publication(s) Bakta: rapid and standardized annotation of bacterial genomes via alignment-free sequence identification"},{"location":"common_text/bandage_task/","title":"Bandage task","text":"<code>Bandage</code>: Graph Visualization <p>Bandage creates de novo assembly graphs containing the assembled contigs and the connections between those contigs. These graphs are useful for visualizing the assembly structure, identifying potential misassemblies, and understanding the relationships between contigs.</p> <p>Bandage Technical Details</p> Links WDL Task task_bandage_plot.wdl Software Source Code Bandage on GitHub Software Documentation Bandage Documentation Original Publication(s) Bandage: interactive visualization of de novo genome assemblies"},{"location":"common_text/bbduk_task/","title":"Bbduk task","text":"<code>BBDuk</code>: Adapter Trimming and PhiX Removal <p>Adapters are manufactured oligonucleotide sequences attached to DNA fragments during the library preparation process. In Illumina sequencing, these adapter sequences are required for attaching reads to flow cells. You can read more about Illumina adapters here. For genome analysis, it's important to remove these sequences since they're not actually from your sample. If you don't remove them, the downstream analysis may be affected.</p> <p>The <code>bbduk</code> task removes adapters from sequence reads. To do this:</p> <ul> <li>Repair from the BBTools package reorders reads in paired fastq files to ensure the forward and reverse reads of a pair are in the same position in the two fastq files (it re-pairs).</li> <li>BBDuk  (\"Bestus Bioinformaticus\" Decontamination Using Kmers) is then used to trim the adapters and filter out all reads that have a 31-mer match to PhiX, which is commonly added to Illumina sequencing runs to monitor and/or improve overall run quality.</li> </ul> <p>BBDuk Technical Details</p> Links Task task_bbduk.wdl Software Source Code BBMap on SourceForge Software Documentation BBDuk Guide (archived)"},{"location":"common_text/bcftools_consensus_task/","title":"Bcftools consensus task","text":"<code>bcftools_consensus</code> <pre><code>The `bcftools_consensus` task generates a consensus genome assembly by applying variants from the `clair3` task to a masked reference genome. It uses bcftools to filter variants based on the `min_depth` and `min_allele_freq` input parameter, left aligns and normalizes indels, indexes the VCF file, and generates a consensus genome in FASTA format. Reference bases are substituted with filtered variants where applicable, preserved in regions without variant calls, and replaced with \"N\"s in areas masked by the `mask_low_coverage` task.\n\n??? dna \"`min_depth` input parameter\"\n    This parameter accepts an integer value to set the minimum read depth for variant calling and subsequent consensus sequence generation. The default value is `10`.\n\n??? dna \"`min_allele_freq` input parameter\"\n    This parameter accepts a float value to set the minimum allele frequency for variant calling and subsequent consensus sequence generation. The default value is `0.6`.\n</code></pre> <pre><code>!!! techdetails \"`bcftools_consensus` Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_bcftools_consensus.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/assembly/task_bcftools_consensus.wdl) |\n    | Software Source Code | [bcftools on GitHub](https://github.com/samtools/bcftools) |\n    | Software Documentation | [bcftools Manual Page](https://samtools.github.io/bcftools/bcftools.html) |\n    | Original Publication(s) | [Twelve Years of SAMtools and BCFtools](https://doi.org/10.1093/gigascience/giab008) |\n</code></pre>"},{"location":"common_text/busco_task/","title":"Busco task","text":"<code>BUSCO</code>: Assembly Quality Assessment <p>BUSCO (Benchmarking Universal Single-Copy Orthologue) attempts to quantify the completeness and contamination of an assembly to generate quality assessment metrics. It uses taxa-specific databases containing genes that are all expected to occur in the given taxa, each in a single copy. BUSCO examines the presence or absence of these genes, whether they are fragmented, and whether they are duplicated (suggestive that additional copies came from contaminants).</p> <p>BUSCO notation </p> <p>Here is an example of BUSCO notation: <code>C:99.1%[S:98.9%,D:0.2%],F:0.0%,M:0.9%,n:440</code>. There are several abbreviations used in this output:</p> <ul> <li>Complete (C) - genes are considered \"complete\" when their lengths are within two standard deviations of the BUSCO group mean length.</li> <li>Single-copy (S) - genes that are complete and have only one copy.</li> <li>Duplicated (D) - genes that are complete and have more than one copy.</li> <li>Fragmented (F) - genes that are only partially recovered.</li> <li>Missing (M) - genes that were not recovered at all.</li> <li>Number of genes examined (n) - the number of genes examined.</li> </ul> <p>A high equity assembly will use the appropriate database for the taxa, have high complete (C) and single-copy (S) percentages, and low duplicated (D), fragmented (F) and missing (M) percentages. </p> <p>BUSCO Technical Details</p> Links Task task_busco.wdl Software Source Code BUSCO on GitLab Software Documentation https://busco.ezlab.org/ Orginal publication BUSCO: assessing genome assembly and annotation completeness with single-copy orthologs"},{"location":"common_text/bwa_task/","title":"Bwa task","text":"<code>bwa</code>: Read alignment to the assembly <p>If a reference is not provided, BWA (Burrow-Wheeler Aligner) is used to align the clean reads to the Pilon-polished assembly_fasta.</p> <code>bwa</code>: Read Alignment to the Assembly <p>BWA (Burrow-Wheeler Aligner) is used to align the cleaned read files to generated assembly file in order to generate an alignment. The resulting BAM file is directly passed to the Pilon task to polish the assembly for errors.</p> <code>bwa</code>: Read Alignment to the Reference <p>BWA (Burrow-Wheeler Aligner) is used to align the cleaned read files to a reference genome, either  determined by the user or provided by the organism-specific parameters section (see above). The resulting BAM file is used for primer trimming, variant calling, and consensus generation in downstream tasks.</p> <code>bwa</code> Details <p>This task aligns the cleaned short reads (Illumina) to the reference genome provided by the user.</p> <code>bwa</code> <p>The <code>bwa</code> task is a wrapper for the BWA alignment tool. It utilizes the BWA-MEM algorithm to map cleaned reads to the reference genome, either selected by the <code>skani</code> task or provided by the user input <code>reference_fasta</code>. This creates a BAM file which is then sorted using the command <code>samtools sort</code>.</p> <pre><code>!!! techdetails \"BWA Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_bwa.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/alignment/task_bwa.wdl) |\n    | Software Source Code | [BWA on GitHub](https://github.com/lh3/bwa) |\n    | Software Documentation | [BWA Documentation](https://bio-bwa.sourceforge.net/) |\n    | Original Publication(s) | [Fast and accurate short read alignment with Burrows-Wheeler transform](https://doi.org/10.1093/bioinformatics/btp324) |\n</code></pre>"},{"location":"common_text/cauris_cladetyper/","title":"Cauris cladetyper","text":"Cladetyping: clade determination <pre><code>The Cauris_Cladetyper Workflow for _Candidozyma auris_ employs GAMBIT for taxonomic identification, comparing whole genome sequencing data against reference databases to accurately classify _Candidozyma auris_ isolates.\n</code></pre> <pre><code>A custom GAMBIT database is created using six clade-specific _Candidozyma auris_ reference genomes. Sequences undergo genomic signature comparison against this database, which then enables assignment to one of the six _Candidozyma auris_ clades (Clade I to Clade VI) based on sequence similarity and phylogenetic relationships. This integrated approach ensures precise clade assignments, crucial for understanding the genetic diversity and epidemiology of _Candidozyma auris_.\n\nSee more information on the reference information for the six clades below:\n\n| Clade | Genome Accession | Assembly Name | Strain | BioSample Accession |\n|---|---|---|---|---|\n| Clade I | GCA_002759435.3 | Cand_auris_B8441_V3 | B8441 | SAMN05379624 |\n| Clade II | GCA_003013715.2 | ASM301371v2 | B11220 | SAMN05379608 |\n| Clade III | GCA_002775015.1 | Cand_auris_B11221_V1 | B11221 | SAMN05379609 |\n| Clade IV | GCA_003014415.1 | Cand_auris_B11243 | B11243 | SAMN05379619 |\n| Clade V | GCA_016809505.1 | ASM1680950v1 | IFRC2087 | SAMN11570381 |\n| Clade VI | GCA_032714025.1 | ASM3271402v1 | F1580 | SAMN36753179 |\n\n!!! warning \"Clade VI annotation\"\n\n    Clade VI does not have an available reference genome annotation at the time of adding the reference genome into Cladetyping. While Clade VI assignment is functional, downstream variant calling is not currently possible without an annotation. Users may provide a close relative annotation, such as Clade IV, though it is unknown if Clade VI variants can reliably be called with respect to such a reference.\n\n!!! techdetails \"Cauris_Cladetyper Technical Details\"\n\n    |  | Links |\n    | --- | --- |\n    | Task | [task_cauris_cladetyper.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/species_typing/candidozyma/task_cauris_cladetyper.wdl) |\n    | Software Source Code | [GAMBIT on GitHub](https://github.com/jlumpe/gambit) |\n    | Software Documentation | [GAMBIT Overview](https://theiagen.notion.site/GAMBIT-7c1376b861d0486abfbc316480046bdc?pvs=4) |\n    | Original Publication(s) | [GAMBIT (Genomic Approximation Method for Bacterial Identification and Tracking): A methodology to rapidly leverage whole genome sequencing of bacterial isolates for clinical identification](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0277575) &lt;br&gt; [TheiaEuk: a species-agnostic bioinformatics workflow for fungal genomic characterization](https://doi.org/10.3389/fpubh.2023.1198213) |\n</code></pre>"},{"location":"common_text/centroid_task/","title":"Centroid task","text":"Centroid"},{"location":"common_text/centroid_task/#centroid","title":"Centroid","text":"<p>Centroid selects the most central genome among a list of assemblies by computing pairwise mash distances. In <code>Snippy_Streamline</code>, this centroid assembly is then used to find a closely related reference genome that can be used to generate the tree.  In order to use <code>Centroid</code>, should complete the <code>samplenames</code> input. </p> <p><code>centroid</code> Technical Details</p> Links Task task_centroid.wdl Software Source Code https://github.com/theiagen/centroid Software Documentation https://github.com/theiagen/centroid"},{"location":"common_text/cg_pipeline_task/","title":"Cg pipeline task","text":"<code>CG-Pipeline</code>: Assessment of Read Quality, and Estimation of Genome Coverage <p>The<code>cg_pipeline</code> task generates metrics about read quality and estimates the coverage of the genome using the <code>run_assembly_readMetrics.pl</code> script from CG-Pipeline. The genome coverage estimates are calculated using both using raw and cleaned reads, using either a user-provided <code>genome_size</code> or the estimated genome length generated by QUAST.</p> <p>CG-Pipeline Technical Details</p> <p>The <code>cg_pipeline</code> task is run twice in this workflow, once with raw reads, and once with clean reads.</p> Links Task task_cg_pipeline.wdl Software Source Code CG-Pipeline on GitHub Software Documentation CG-Pipeline on GitHub Original Publication(s) A computational genomics pipeline for prokaryotic sequencing projects"},{"location":"common_text/checkv_task/","title":"Checkv task","text":"<code>checkv</code> <p>CheckV is a fully automated command-line pipeline for assessing the quality of viral genomes, including identification of host contamination for integrated proviruses, estimating completeness for genome fragments, and identification of closed genomes.</p> <p>By default, CheckV reports results on a contig-by-contig basis. The <code>checkv</code> task additionally reports both \"weighted_contamination\" and \"weighted_completeness\", which are average percents calculated across the total assembly that are weighted by contig length.</p> <p>CheckV Technical Details</p> Links Task task_checkv.wdl Software Source Code CheckV on Bitbucket Software Documentation CheckV Documentation Original Publication(s) CheckV assesses the quality and completeness of metagenome-assembled viral genomes"},{"location":"common_text/clair3_task/","title":"Clair3 task","text":"<code>clair3</code> <p><code>Clair3</code> performs deep learning-based variant detection using a multi-stage approach. The process begins with pileup-based calling for initial variant identification, followed by full-alignment analysis for comprehensive variant detection. Results are merged into a final high-confidence call set.</p> <pre><code>The variant calling pipeline employs specialized neural networks trained on ONT data to accurately identify:\n- Single nucleotide variants (SNVs)\n- Small insertions and deletions (indels)\n- Structural variants\n\n??? dna \"`clair3_model` input parameter\"\n    This parameter specifies the clair3 model to use for variant calling. The default is set to `\"r1041_e82_400bps_sup_v500\"`, but users may select from other available models that `clair3` was trained on, which may yield better results depending on the basecaller and data type. The following models are available:\n\n    - `\"ont\"`\n    - `\"ont_guppy2\"`\n    - `\"ont_guppy5\"`\n    - `\"r941_prom_sup_g5014\"`\n    - `\"r941_prom_hac_g360+g422\"`\n    - `\"r941_prom_hac_g238\"`\n    - `\"r1041_e82_400bps_sup_v500\"`\n    - `\"r1041_e82_400bps_hac_v500\"`\n    - `\"r1041_e82_400bps_sup_v410\"`\n    - `\"r1041_e82_400bps_hac_v410\"`\n\n???+ warning \"Default Parameters and Filtering\"\n    In this workflow, `clair3` is run with nearly all default parameters. Note that the VCF file produced by the `clair3` task is **unfiltered** and does not represent the final set of variants that will be included in the final consensus genome. A filtered vcf file is generated by the `bcftools_consensus` task. The filtering parameters are as follows:\n\n    - The `min_map_quality` parameter is applied before calling variants.\n    - The `min_depth` and `min_allele_freq` parameters are applied after variant calling during consensus genome construction.\n</code></pre> <pre><code>!!! techdetails \"Clair3 Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_clair3.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/variant_calling/task_clair3.wdl) |\n    | Software Source Code | [Clair3 on GitHub](https://github.com/HKU-BAL/Clair3) |\n    | Software Documentation | [Clair3 Documentation](https://github.com/HKU-BAL/Clair3?tab=readme-ov-file#usage) |\n    | Original Publication(s) | [Symphonizing pileup and full-alignment for deep learning-based long-read variant calling](https://doi.org/10.1101/2021.12.29.474431) |\n</code></pre>"},{"location":"common_text/clockwork_task/","title":"Clockwork task","text":"<code>Clockwork</code>: Read Decontamination for Illumina PE only <p>Clockwork decontaminates paired-end Mycobacterium tuberculosis data by removing all non-TB reads. At a high level, the sample is processed by aligning the reads with BWA to the H37Rv reference genome, and retaining only reads that have been mapped. This greatly improves the quality of any called variants and ensures that any variants called by TBProfiler are of suitable reliability.</p> <p>Clockwork Technical Details</p> Links Task task_clockwork.wdl Software Source Code Clockwork on GitHub Software Documentation Clockwork Wiki Original Publication(s) Clockwork tool: Minos: variant adjudication and joint genotyping of cohorts of bacterial genome"},{"location":"common_text/concatenate_illumina_lanes_task/","title":"Concatenate illumina lanes task","text":"<code>concatenate_illumina_lanes</code>: Concatenate Multi-Lane Illumina FASTQs <p>The <code>concatenate_illumina_lanes</code> task concatenates Illumina FASTQ files from multiple lanes into a single file. This task only runs if the <code>read1_lane2</code> input file has been provided. All read1 lanes are concatenated together and are used in subsequent tasks, as are the read2 lanes if applicable. These concatenated files are also provided as output.</p> <p>Concatenate Illumina Lanes Technical Details</p> <p>The <code>concatenate_illumina_lanes</code> task is run before any downstream steps take place.</p> Links Subworkflow wf_concatenate_illumina_lanes.wdl"},{"location":"common_text/consensus_qc_task/","title":"Consensus qc task","text":"<code>consensus_qc</code>: Assembly Statistics <p>The consensus_qc task generates a summary of genomic statistics from a consensus genome. This includes the total number of bases, \"N\" bases, degenerate bases, and an estimate of the percent coverage to the reference genome.</p> <p><code>consensus_qc</code> Technical Details</p> Links Task task_consensus_qc.wdl"},{"location":"common_text/data_summary_task/","title":"Data summary task","text":"Data summary (optional) <p>##### Data Summary (optional)</p> <p>!!! tip \"Command-line incompatible\"         This task is not compatible with command-line use, even with modifications. It is engineered to run on Terra. To run this workflow on the command line, you must leave the <code>data_summary_*</code> and <code>sample_names</code> optional variables blank to prevent this task from running.</p> <pre><code>If you fill out the `data_summary_*` and `sample_names` optional variables, you can use the optional `summarize_data` task. The task takes a comma-separated list of column names from the Terra data table, which should each contain a list of comma-separated items. For example, `\"amrfinderplus_virulence_genes,amrfinderplus_stress_genes\"` (with quotes, comma separated, no spaces) for these output columns from running TheiaProk. The task checks whether those comma-separated items are present in each row of the data table (sample), then creates a CSV file of these results. The CSV file indicates presence (TRUE) or absence (empty) for each item. By default, the task does not add a Phandango coloring tag to group items from the same column, but you can turn this on by setting `phandango_coloring` to `true`.\n\n??? toggle \"**Example output CSV**\"\n\n    ```text linenums=\"1\"\n    Sample_Name,aph(3')-IIa,blaCTX-M-65,blaOXA-193,tet(O)\n    sample1,TRUE,,TRUE,TRUE\n    sample2,,,FALSE,TRUE\n    sample3,,,FALSE,\n    ```\n\n??? toggle \"**Example use of Phandango coloring**\"\n\n    Data summary produced using the `phandango_coloring` option, visualized alongside Newick tree at &lt;http://jameshadfield.github.io/phandango/#/main&gt;\n\n    !!! caption \"Example phandango_coloring output\"\n        ![Phandango coloring example](../../assets/figures/example_phandango_coloring.png)\n\n!!! techdetails \"Data summary technical details\"\n\n    |  | Links |\n    | --- | --- |\n    | Task | [task_summarize_data.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/utilities/data_handling/task_summarize_data.wdl) |\n</code></pre>"},{"location":"common_text/digger_denovo_wf/","title":"Digger denovo wf","text":"<code>digger_denovo</code>: De novo Assembly <p>De novo  assembly is the process or product of attempting to reconstruct a genome from scratch (without prior knowledge of the genome) using sequence reads. Assembly of fungal genomes from short-reads will produce multiple contigs per chromosome rather than a single contiguous sequence for each chromosome.</p> <p>In TheiaProk and TheiaEuk Illumina workflows, de novo assembly is performed for samples that have sufficient read quantity and quality using digger_denovo, a subworkflow based off of Shovill pipeline. The name \"digger\" is a nod to Shovill and SPAdes.</p> De novo Assembly <p><code>assembler</code> with <code>skesa</code> (default), <code>spades</code>, or <code>megahit</code></p> <p>To activate a particular assembler, set the <code>assembler</code> input parameter to either <code>skesa</code> (default), <code>spades</code>, or <code>megahit</code>.</p> <p>These tasks are mutually exclusive.</p> <code>SKESA</code>: De novo Assembly (default) <p>This task is activated by default.</p> <p><code>SKESA</code> (Strategic K-mer Extension for Scrupulous Assemblies) is a de novo assembler that is fairly conservative and introduces breaks in the genome at repeat regions. This leads to higher sequence quality but more fragmented assemblies, which, depending on the final analysis goal, can be either highly preferred or detrimental. Designed for Illumina reads and haploid genomes, SKESA is the default assembler in the <code>digger_denovo</code> subworkflow.</p> <p>SKESA Technical Details</p> Links Task task_skesa.wdl Software Source Code SKESA on GitHub Software Documentation SKESA on GitHub Original Publication(s) SKESA: strategic k-mer externsion for scrupulous assemblies <code>SPAdes</code>: De novo Assembly (alternative) <p>To activate this task, set <code>assembler</code> to <code>spades</code>.</p> <p><code>SPAdes</code> (St. Petersburg genome assembler) is a de novo assembly tool that uses de Bruijn graphs to assemble genomes from Illumina short reads.</p> <p>In TheiaProk, SPAdes is run in <code>--isolate</code> mode, which is the recommended flag for high-coverage isolate and multi-cell Illumina data, which is typical of most bacterial sequencing projects. This method is optimized for improving assembly quality and decreasing runtime.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>MetaviralSPAdes Technical Details</p> Links Task task_spades.wdl Software Source Code SPAdes on GitHub Software Documentation SPAdes Manual Original Publication(s) TheiaProk: SPAdes: A New Genome Assembly Algorithm and Its Applications to Single-Cell SequencingTheiaViral: MetaviralSPAdes: assembly of viruses from metagenomic data <code>MEGAHIT</code>: De novo Assembly (alternative) <p>To activate this task, set <code>assembler</code> to <code>megahit</code>.</p> <p>The MEGAHIT assembler is a fast and memory-efficient de novo assembler that can handle large datasets. While optimized for metagenomics, MEGAHIT also performs well on single-genome assemblies, making it a versatile choice for various assembly tasks.</p> <p>MEGAHIT uses a multiple k-mer strategy that can be beneficial for assembling genomes with varying coverage levels, which is common in metagenomic samples. It constructs succinct de Bruijn graphs to efficiently represent the assembly process, allowing it to handle large and complex datasets with reduced memory usage.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>MEGAHIT Technical Details</p> Links Task task_megahit.wdl Software Source Code MEGAHIT on GitHub Software Documentation MEGAHIT on GitHub Original Publication(s) MEGAHIT: an ultra-fast single-node solution for large and complex metagenomics assembly via succinct de Bruijn graph Assembly Polishing (optional) <p>To activate assembly polishing, set <code>call_pilon</code> to <code>true</code>.</p> <code>bwa</code>: Read Alignment to the Assembly <p>BWA (Burrow-Wheeler Aligner) is used to align the cleaned read files to generated assembly file in order to generate an alignment. The resulting BAM file is directly passed to the Pilon task to polish the assembly for errors.</p> <p>BWA Technical Details</p> Links Task task_bwa.wdl Software Source Code BWA on GitHub Software Documentation BWA Documentation Original Publication(s) Fast and accurate short read alignment with Burrows-Wheeler transform <code>Pilon</code>: Assembly Polishing <p><code>Pilon</code> is a tool that uses read alignments to correct errors in an assembly.</p> <p>The <code>bwa</code>-generated alignment of the read data to the assembly is used to identify inconsistences between the reads and the assembly in order to correct them. <code>Pilon</code> will attempt to fix individual base errors and small indels using the read data. This can improve the overall quality of the assembly, especially when the assembler has made mistakes due to sequencing errors or low coverage regions.</p> <p>The default parameters were set to mimic the parameters used by Shovill: <code>--fix bases --minq 60 --minqual 3 --mindepth 0.25</code>. These can be modified by the user.</p> <p>Pilon Technical Details</p> Links Task task_pilon.wdl Software Source Code Pilon on GitHub Software Documentation Pilon Wiki Original Publication(s) Pilon: An Integrated Tool for Comprehensive Microbial Variant Detection and Genome Assembly Improvement Contig Filtering (optional) <code>Filter Contigs</code>: Contig Quality Control <p>To deactivate contig filtering, set <code>run_filter_contigs</code> to <code>false</code>.</p> <p>This task filters the created contigs based on a default minimum length threshold of 200 bp and a minimum coverage of 2.0. It also eliminates homopolymer contigs (contigs of any length that consist of a single nucleotide).</p> <p>Options are available to skip any of these filters by setting the respective parameters to <code>false</code>: <code>filter_contigs_skip_length_filter</code>, <code>filter_contigs_skip_coverage_filter</code>, and <code>filter_contigs_skip_homopolymer_filter</code>. The minimum length and coverage thresholds can be adjusted using the <code>filter_contigs_min_length</code> and <code>filter_contigs_min_coverage</code> parameters, respectively.</p> <p>This ensures high-quality assemblies by retaining only contigs that meet specified criteria. Detailed metrics on contig counts and sequence lengths before and after filtering are provided in the output.</p> <p>Filter Contigs Technical Details</p> Links WDL Task task_filter_contigs.wdl <p>Digger-Denovo Technical Details</p> Links Subworkflow wf_digger_denovo.wdl"},{"location":"common_text/dnaapler_task/","title":"Dnaapler task","text":"<code>Dnaapler</code>: Final Assembly Orientation <p>Dnaapler reorients contigs to start at specific reference points. Dnaapler supports the following modes, which can be indicated by filling the <code>dnaapler_mode</code> input variable with the desired mode. The default is <code>all</code>, which reorients contigs to start with <code>dnaA</code>, <code>terL</code>, <code>repA</code>, or <code>COG1474</code>.</p> <ul> <li>all: Reorients contigs to start with <code>dnaA</code>, <code>terL</code>, <code>repA</code>, or <code>COG1474</code> (Default)</li> <li>chromosome: Reorients to begin with the <code>dnaA</code> chromosomal replication initiator gene, commonly used for bacterial chromosome assemblies.</li> <li>plasmid: Reorients to start with the <code>repA</code> plasmid replication initiation gene, ideal for plasmid assemblie</li> <li>phage: Reorients to start with the <code>terL</code> large terminase subunit gene, used for bacteriophage assemblies</li> <li>archaea: Reorients to start with the <code>COG1474</code> archaeal Orc1/cdc6 gene, relevant for archaeal assemblies</li> <li>custom: Reorients based on a user-specified gene in amino acid FASTA format for experimental or unique workflows</li> <li>mystery: Reorients to start with a random CDS for exploratory purposes</li> <li>largest: Reorients to start with the largest CDS in the assembly, often useful for poorly annotated genomes</li> <li>nearest: Reorients to start with the first CDS nearest to the sequence start, resolving CDS breakpoints</li> <li>bulk: Processes multiple contigs to start with the desired start gene (<code>dnaA</code>, <code>terL</code>, <code>repA</code>, or custom)</li> </ul> <p>Dnaapler Technical Details</p> Links WDL Task task_dnaapler.wdl Software Source Code Dnaapler on GitHub Software Documentation Dnaapler Documentation Original Publication(s) Dnaapler: a tool to reorient circular microbial genomes"},{"location":"common_text/ectyper_task/","title":"Ectyper task","text":"<code>ECTyper</code>: Serotyping <p>ECTyper is a serotyping module for E. coli. ECTyper provides species identification and quality control for E. coli, allowing for complete reports on serotyping, Shiga toxin typing, and pathotyping. Pathotype is identified using an ECTyper internal typing database that looks at toxin and pathotype signature marker sequences. Pathotypes are distinct categories defined by specific virulence factors used to group E. coli specimens based on pathogenicity. </p> <p>ECTyper Technical Details</p> Links Task task_ectyper.wdl Software Source Code ECTyper on GitHub Software Documentation ECTyper on GitHub Orginal publication ECTyper: in silico Escherichia coli serotype and species prediction from raw and assembled whole-genome sequence data"},{"location":"common_text/emmtyper_task/","title":"Emmtyper task","text":"<code>emmtyper</code>: Sequence Typing <p>The Streptococcus pyogenes M protein (encoded by emm) is used for sequencing typing and disease surveillence as it is a major virulence factor. There are over 275 emm types.</p> <p><code>emmtyper</code> uses BLAST to compare the genome assembly to the CDC-curated trimmed emm type database (by default). An in silico PCR method is also available. The BLAST results are then processed to distinguish between emm and emm-like alleles to derive the isolates' M-type. The predicted emm-type is reported in addition to any possible emm-like alleles and the functional emm cluster.</p> <p>emm-typing-tool Technical Details</p> Links Task task_emmtyper.wdl Software Source Code emmtyper on GitHub Software Documentation emmtyper on GitHub Original Publication(s) emm typing scheme: A systematic and functional classification of Streptococcus pyogenes that serves as a new tool for molecular typing and vaccine development"},{"location":"common_text/emmtypingtool_task/","title":"Emmtypingtool task","text":"<code>emm-typing-tool</code>: Sequence Typing for Illumina_PE only <p>The Streptococcus pyogenes M protein (encoded by emm) is used for sequencing typing and disease surveillence as it is a major virulence factor. There are over 275 emm types.</p> <p><code>emm-typing-tool</code> maps the reads to a CDC-curated emm type database using bowtie2 to identify any emm genes. Alleles with 100% coverage and over 90% identity are selected, and the allele with the highest percent identity is generally reported (see the decision tree for the nuances).</p> <p>emm-typing-tool Technical Details</p> Links Task task_emmtypingtool.wdl Software Source Code emm-typing-tool on GitHub Software Documentation emm-typing-tool on GitHub Original Publication(s) emm typing scheme: A systematic and functional classification of Streptococcus pyogenes that serves as a new tool for molecular typing and vaccine development"},{"location":"common_text/fasta_utilities_task/","title":"Fasta utilities task","text":"<code>fasta_utilities</code> <p>The <code>fasta_utilities</code> task utilizes samtools to index a reference fasta file.</p> <pre><code>This reference is selected by the `skani` task or provided by the user input `reference_fasta`. This indexed reference genome is used for downstream variant calling and consensus generation tasks.\n</code></pre> <pre><code>!!! techdetails \"`fasta_utilities` Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_fasta_utilities.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/utilities/data_handling/task_fasta_utilities.wdl) |\n    | Software Source Code | [samtools on GitHub](https://github.com/samtools/samtools) |\n    | Software Documentation | [samtools](https://www.htslib.org/doc/samtools.html) |\n    | Original Publication(s) | [The Sequence Alignment/Map format and SAMtools](https://doi.org/10.1093/bioinformatics/btp352)&lt;br&gt;[Twelve Years of SAMtools and BCFtools](https://doi.org/10.1093/gigascience/giab008) |\n</code></pre>"},{"location":"common_text/fastp_task/","title":"Fastp task","text":"<code>fastp</code>: Read Trimming (alternative) <p>To activate this task, set <code>read_processing</code> to <code>\"fastp\"</code>.</p> <p><code>fastp</code> trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>fastp</code> also has additional default parameters and features that are not a part of <code>trimmomatic</code>'s default configuration.</p> <code>fastp</code> default read-trimming parameters Parameter Explanation -g enables polyG tail trimming -5 20 enables read end-trimming -3 20 enables read end-trimming --detect_adapter_for_pe enables adapter-trimming only for paired-end reads <p>Additional arguments can be passed using the <code>fastp_args</code> optional parameter.</p> <p>Trimmomatic and fastp Technical Details</p> Links Task task_fastp.wdl Software Source Code fastp on GitHub Software Documentation fastp on GitHub Original Publication(s) fastp: an ultra-fast all-in-one FASTQ preprocessor"},{"location":"common_text/fastq_scan_task/","title":"Fastq scan task","text":"<code>fastq-scan</code>: Read Quantification (default) <p>Read quantification is available via <code>fastq-scan</code> by default.</p> <p><code>fastq-scan</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <code>fastq-scan</code>: Read Quantification <p><code>fastq-scan</code> quantifies the reads in the FASTQ files. This task is run once with raw reads as input and once with dehosted reads as input. If QC has been performed correctly, you should expect fewer dehosted (or \"clean\") reads than raw reads.</p> <pre><code>!!! techdetails \"`fastq-scan` Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_fastq_scan.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/basic_statistics/task_fastq_scan.wdl)|\n    | Software Source Code | [fastq-scan on GitHub](https://github.com/rpetit3/fastq-scan) |\n    | Software Documentation | [fastq-scan on GitHub](https://github.com/rpetit3/fastq-scan/blob/master/README.md) |\n</code></pre>"},{"location":"common_text/fastqc_task/","title":"Fastqc task","text":"<code>FastQC</code>: Read Quantification (alternative) <p>To activate this task, set <code>read_qc</code> to <code>\"fastqc\"</code>.</p> <p><code>FastQC</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>This tool also provides a graphical visualization of the read quality.</p> <p><code>FastQC</code> Technical Details</p> Links Task task_fastqc.wdl Software Source Code FastQC on Github Software Documentation FastQC Website"},{"location":"common_text/filter_contigs_task/","title":"Filter contigs task","text":"<code>Filter Contigs</code>: Filter contigs below a threshold length and remove homopolymer contigs <p>This task filters the created contigs based on a user-defined minimum length threshold (default of 1000) and eliminates homopolymer contigs (contigs of any length that consist of a single nucleotide).</p> <code>Filter Contigs</code>: Contig Quality Control <p>To deactivate contig filtering, set <code>run_filter_contigs</code> to <code>false</code>.</p> <p>This task filters the created contigs based on a default minimum length threshold of 200 bp and a minimum coverage of 2.0. It also eliminates homopolymer contigs (contigs of any length that consist of a single nucleotide).</p> <p>Options are available to skip any of these filters by setting the respective parameters to <code>false</code>: <code>filter_contigs_skip_length_filter</code>, <code>filter_contigs_skip_coverage_filter</code>, and <code>filter_contigs_skip_homopolymer_filter</code>. The minimum length and coverage thresholds can be adjusted using the <code>filter_contigs_min_length</code> and <code>filter_contigs_min_coverage</code> parameters, respectively.</p> <pre><code>This ensures high-quality assemblies by retaining only contigs that meet specified criteria. Detailed metrics on contig counts and sequence lengths before and after filtering are provided in the output.\n\n!!! techdetails \"Filter Contigs Technical Details\" \n    |  | Links |\n    | --- | --- |\n    | WDL Task | [task_filter_contigs.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/read_filtering/task_filter_contigs.wdl) |\n</code></pre>"},{"location":"common_text/flu_antiviral_substitutions_wf/","title":"Flu antiviral substitutions wf","text":"<code>flu_antiviral_substitutions</code> <p>This subworkflow determines if any antiviral mutations are present in the HA, NA, and MP segments of H1N1 or H3N2 flu sample, or any in non-subtype-specific PA, PB1, and PB2 segments.</p> <p>These mutations are identified by generating a multiple sequence alignment (MSA) between each individual flu segment and the respective reference genome using MAFFT. Amino acid mutations are then called from the MSA. The resulting mutations are compared against a list of known amino-acid substitutions associated with antiviral resistance and any matches are reported. </p> <p>This list of amino-acid substitutions includes both substitutions reported in the scientific literature and those inferred to potentially cause antiviral resistance based on analogous antiviral mutations in other flu subtypes. A table with the explanation for each amino-acid substitution in the antiviral resistance task is available here.</p> <p>The list of known amino-acid substitutions associated with resistance can be expanded via optional user input <code>antiviral_aa_subs</code> in the format \"<code>NA:V95A,HA:I97V</code>\", i.e. <code>Protein:AAPositionAA</code>. </p> Currently, the default mutations considered confer resistance to the following antivirals <ul> <li>A_315675</li> <li>Amantadine</li> <li>Compound_367</li> <li>Favipiravir</li> <li>Fludase</li> <li>L_742_001</li> <li>Laninamivir</li> <li>Oseltamivir (tamiflu)</li> <li>Peramivir</li> <li>Pimodivir</li> <li>Rimantadine</li> <li>Xofluza</li> <li>Zanamivir</li> </ul> <p>Antiviral Substitutions Technical Details</p> Links Sub-workflow wf_influenza_antiviral_substitutions.wdl Tasks task_mafft.wdltask_flu_antiviral_subs.wdl Original Publication(s) MAFFT Multiple Sequence Alignment Software Version 7: Improvements in Performance and UsabilityNext-Generation Sequencing: An Eye-Opener for the Surveillance of Antiviral Resistance in Influenza"},{"location":"common_text/flye_denovo_wf/","title":"Flye denovo wf","text":"<code>Flye</code>: De novo Assembly <p><code>flye_denovo</code> is a sub-workflow that performs de novo assembly using Flye for ONT data and supports additional polishing and visualization steps.</p> <p>Ensure correct medaka model is selected if performing medaka polishing</p> <p>In order to obtain the best results, the appropriate model must be set to match the sequencer's basecaller model; this string takes the format of {pore}_{device}_{caller variant}_{caller_version}. See also https://github.com/nanoporetech/medaka?tab=readme-ov-file#models. If <code>flye</code> is being run on legacy data the medaka model will likely be <code>r941_min_hac_g507</code>. Recently generated data will likely be suited by the default model of <code>r1041_e82_400bps_sup_v5.0.0</code>.</p> <p>The detailed steps and tasks are as follows:</p> <code>Porechop</code>: Read Trimming (optional; off by default) <p>Porechop is a tool for finding and removing adapters from ONT data. Adapters on the ends of reads are trimmed, and when a read has an adapter in the middle, the read is split into two.</p> <p>Porechop Technical Details</p> Links WDL Task task_porechop.wdl Software Source Code Porechop on GitHub Software Documentation https://github.com/rrwick/Porechop#porechop <code>Flye</code>: De novo Assembly <p>Flye is a de novo assembler for long read data using repeat graphs. Compared to de Bruijn graphs, which require exact k-mer matches, repeat graphs can use approximate matches which better tolerates the error rate of ONT data.</p> <code>flye_read_type</code> input parameter <p>This input parameter specifies the type of sequencing reads being used for assembly. This parameter significantly impacts the assembly process and should match the characteristics of your input data. Below are the available options:</p> Parameter Explanation <code>--nano-hq</code> (default) Optimized for ONT high-quality reads, such as Guppy5+ SUP or Q20 (&lt;5% error). Recommended for ONT reads processed with Guppy5 or newer <code>--nano-raw</code> For ONT regular reads, pre-Guppy5 (&lt;20% error) <code>--nano-corr</code> ONT reads corrected with other methods (&lt;3% error) <code>--pacbio-raw</code> PacBio regular CLR reads (&lt;20% error) <code>--pacbio-corr</code> PacBio reads corrected with other methods (&lt;3% error) <code>--pacbio-hifi</code> PacBio HiFi reads (&lt;1% error) <p>Refer to the Flye documentation for detailed guidance on selecting the appropriate <code>flye_read_type</code> based on your sequencing data and additional optional paramaters.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>Flye Technical Details</p> Links WDL Task task_flye.wdl Software Source Code Flye on GitHub Software Documentation Flye Documentation Original Publication(s) Assembly of long, error-prone reads using repeat graphs <code>Bandage</code>: Graph Visualization <p>Bandage creates de novo assembly graphs containing the assembled contigs and the connections between those contigs. These graphs are useful for visualizing the assembly structure, identifying potential misassemblies, and understanding the relationships between contigs.</p> <p>Bandage Technical Details</p> Links WDL Task task_bandage_plot.wdl Software Source Code Bandage on GitHub Software Documentation Bandage Documentation Original Publication(s) Bandage: interactive visualization of de novo genome assemblies <code>Polypolish</code>: Hybrid Assembly Polishing for ONT and Illumina data <p>If short reads are provided with the optional <code>illumina_read1</code> and <code>illumina_read2</code> inputs, Polypolish will use those short-reads to correct errors in the long-read assemblies. Uniquely, Polypolish uses the short-read alignments where each read is aligned to all possible locations, meaning that even repeat regions will have error correction.</p> <p>Polypolish Technical Details</p> Links Task task_polypolish.wdl Software Source Code Polypolish on GitHub Software Documentation Polypolish Documentation Original Publication(s) Polypolish: short-read polishing of long-read bacterial genome assembliesHow low can you go? Short-read polishing of Oxford Nanopore bacterial genome assemblies <code>Medaka</code>: Polishing of Flye assembly (default; optional) <p>Polishing is optional and can be skipped by setting the <code>skip_polishing</code> variable to true. If polishing is skipped, then neither Medaka or Racon will run.</p> <p>Medaka is the default assembly polisher used in TheiaProk. Racon may be used alternatively, and if so, Medaka will not run. Medaka uses the raw reads to polish the assembly and generate a consensus sequence. </p> <p>Importantly, Medaka requires knowing the model that was used to generate the read data. There are several ways to provide this information:</p> <ul> <li>Automatic Model Selection: Automatically determines the most appropriate Medaka model based on the input data, ensuring optimal polishing results without manual intervention. </li> <li>User-Specified Model Override: Allows users to specify a particular <code>Medaka model</code> if automatic selection does not yield the desired outcome or for specialized use cases.</li> <li>Default Model: If both automatic model selection fails and no user-specified model is provided, Medaka defaults to the predefined fallback model <code>r1041_e82_400bps_sup_v5.0.0</code>. </li> </ul> <p>Medaka Model Resolution Process</p> <p>Medaka's automatic model selection uses the <code>medaka tools resolve_model</code> command to identify the appropriate model for polishing. This process relies on metadata embedded in the input file, which is typically generated by the basecaller. If the automatic selection fails to identify a suitable model, Medaka gracefully falls back to the default model to maintain workflow continuity. Users should verify the chosen model and consider specifying a model override if necessary.</p> <p>Medaka Technical Details</p> Links WDL Task task_medaka.wdl Software Source Code Medaka on GitHub Software Documentation Medaka Documentation <code>Racon</code>: Polishing of Flye assembly (alternative; optional) <p>Polishing is optional and can be skipped by setting the <code>skip_polishing</code> variable to true. If polishing is skipped, then neither Medaka or Racon will run.</p> <p><code>Racon</code> is an alternative to using <code>medaka</code> for assembly polishing, and can be run by setting the <code>polisher</code> input to \"racon\".  Racon is a consensus algorithm designed for refining raw de novo DNA assemblies generated from long, uncorrected sequencing reads.</p> <p>Racon Technical Details</p> Links WDL Task task_racon.wdl Software Source Code Racon on GitHub Software Documentation Racon Documentation Original Publication(s) Fast and accurate de novo genome assembly from long uncorrected reads <code>Filter Contigs</code>: Filter contigs below a threshold length and remove homopolymer contigs <p>This task filters the created contigs based on a user-defined minimum length threshold (default of 1000) and eliminates homopolymer contigs (contigs of any length that consist of a single nucleotide).</p> <p>This ensures high-quality assemblies by retaining only contigs that meet specified criteria. Detailed metrics on contig counts and sequence lengths before and after filtering are provided in the output.</p> <p>Filter Contigs Technical Details</p> Links WDL Task task_filter_contigs.wdl <code>Dnaapler</code>: Final Assembly Orientation <p>Dnaapler reorients contigs to start at specific reference points. Dnaapler supports the following modes, which can be indicated by filling the <code>dnaapler_mode</code> input variable with the desired mode. The default is <code>all</code>, which reorients contigs to start with <code>dnaA</code>, <code>terL</code>, <code>repA</code>, or <code>COG1474</code>.</p> <ul> <li>all: Reorients contigs to start with <code>dnaA</code>, <code>terL</code>, <code>repA</code>, or <code>COG1474</code> (Default)</li> <li>chromosome: Reorients to begin with the <code>dnaA</code> chromosomal replication initiator gene, commonly used for bacterial chromosome assemblies.</li> <li>plasmid: Reorients to start with the <code>repA</code> plasmid replication initiation gene, ideal for plasmid assemblie</li> <li>phage: Reorients to start with the <code>terL</code> large terminase subunit gene, used for bacteriophage assemblies</li> <li>archaea: Reorients to start with the <code>COG1474</code> archaeal Orc1/cdc6 gene, relevant for archaeal assemblies</li> <li>custom: Reorients based on a user-specified gene in amino acid FASTA format for experimental or unique workflows</li> <li>mystery: Reorients to start with a random CDS for exploratory purposes</li> <li>largest: Reorients to start with the largest CDS in the assembly, often useful for poorly annotated genomes</li> <li>nearest: Reorients to start with the first CDS nearest to the sequence start, resolving CDS breakpoints</li> <li>bulk: Processes multiple contigs to start with the desired start gene (<code>dnaA</code>, <code>terL</code>, <code>repA</code>, or custom)</li> </ul> <p>Dnaapler Technical Details</p> Links WDL Task task_dnaapler.wdl Software Source Code Dnaapler on GitHub Software Documentation Dnaapler Documentation Original Publication(s) Dnaapler: a tool to reorient circular microbial genomes <p>Flye-Denovo Technical Details</p> Links Subworkflow wf_flye_denovo.wdl"},{"location":"common_text/flye_task/","title":"Flye task","text":"<code>flye</code> <p>Flye is a de novo assembler for long read data using repeat graphs. Compared to de Bruijn graphs, which require exact k-mer matches, repeat graphs can use approximate matches which better tolerates the error rate of ONT data.</p> <pre><code>It can be enabled by setting the `call_raven` parameter to `false`. The `flye` task is used as a fallback option if the `raven` task fails during execution (see task `raven` for more details).\n</code></pre> <pre><code>??? dna \"`flye_read_type` input parameter\" \n    This input parameter specifies the type of sequencing reads being used for assembly. This parameter significantly impacts the assembly process and should match the characteristics of your input data. Below are the available options:\n\n    | **Parameter** | **Explanation** |\n    | --- | --- |\n    | `--nano-hq` (default) | Optimized for ONT high-quality reads, such as Guppy5+ SUP or Q20 (&lt;5% error). Recommended for ONT reads processed with Guppy5 or newer |\n    | `--nano-raw` | For ONT regular reads, pre-Guppy5 (&lt;20% error) |\n    | `--nano-corr` | ONT reads corrected with other methods (&lt;3% error) |\n    | `--pacbio-raw` | PacBio regular CLR reads (&lt;20% error) |\n    | `--pacbio-corr` | PacBio reads corrected with other methods (&lt;3% error) |\n    | `--pacbio-hifi` | PacBio HiFi reads (&lt;1% error) |\n\n    Refer to the Flye documentation for detailed guidance on selecting the appropriate `flye_read_type` based on your sequencing data and additional optional paramaters.\n\n???+ warning \"Non-deterministic output(s)\"\n    This task may yield non-deterministic outputs.\n\n!!! techdetails \"Flye Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | WDL Task | [task_flye.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/assembly/task_flye.wdl) |\n    | Software Source Code | [Flye on GitHub](https://github.com/fenderglass/Flye) |\n    | Software Documentation | [Flye Documentation](https://github.com/fenderglass/Flye/blob/flye/docs/USAGE.md) |\n    | Original Publication(s) | [Assembly of long, error-prone reads using repeat graphs](https://www.nature.com/articles/s41587-019-0072-8) |\n</code></pre>"},{"location":"common_text/gambit_task/","title":"Gambit task","text":"<code>GAMBIT</code>: Taxon Assignment <p><code>GAMBIT</code> determines the taxon of the genome assembly using a k-mer based approach to match the assembly sequence to the closest complete genome in a database, thereby predicting its identity. Sometimes, GAMBIT can confidently designate the organism to the species level. Other times, it is more conservative and assigns it to a higher taxonomic rank.</p> <p>For additional details regarding the GAMBIT tool and a list of available GAMBIT databases for analysis, please consult the GAMBIT tool documentation.</p> <p>GAMBIT Technical Details</p> Links Task task_gambit.wdl Software Source Code GAMBIT on GitHub Software Documentation GAMBIT ReadTheDocs Original Publication(s) GAMBIT (Genomic Approximation Method for Bacterial Identification and Tracking): A methodology to rapidly leverage whole genome sequencing of bacterial isolates for clinical identification"},{"location":"common_text/gamma_task/","title":"Gamma task","text":"<code>GAMMA</code>: AMR Genotyping (optional) <p>To activate this task, set <code>call_gamma</code> to <code>true</code>.</p> <p>GAMMA (Gene Allele Mutation Microbial Assessment) is a protein identity based tool that identifies gene matches in microbial genomic data. GAMMA will also translate and annotate each match providing mutational and truncation information for identified matches. This is done much like AMRFinder, however, GAMMA uses BLAT as opposed to BLAST allowing for faster calls with comparable accuracy.  </p> <p>GAMMA utilizes a multifasta database of the coding sequences of genes specified by the user. This allows for GAMMA to search for AMR, hypervirulence, plasmid markers, or any prokaryotic database. The default for <code>task_gamma.wdl</code> is the GAMMA-provided ResFinder Database. GAMMA will then return gene matches with mutation and truncation information as a <code>.gamma</code> file which can be accompanied with a GFF output utilizing the <code>--gff</code> flag.</p> <p>GAMMA also allows for the usage of only nucleotide sequences rather than translated sequences. Using GAMMA-S, enabled with the boolean <code>run_gammas</code>, will find the best matches from a multifasta database without translating sequences. </p> <p>GAMMA Technical Details</p> Links Task task_gamma.wdl Software Source Code GAMMA on GitHub Software Documentation GAMMA on GitHub Original Publication(s) GAMMA: a tool for the rapid identification, classification and annotation of translated gene matches from sequencing data"},{"location":"common_text/gene_coverage_task/","title":"Gene coverage task","text":"<code>gene_coverage</code> <p>This task calculates the percent of a region (typically genes) covered above a minimum depth using <code>samtools</code> and basic arithmetic. By default, this task runs for SARS-CoV-2 and Mpox, but if a BED file is provided with regions of interest, this task can run for other organisms as well.</p> <p>Gene Coverage Technical Details</p> Links Task task_gene_coverage.wdl Software Source Code SAMtools on GitHub Software Documentation SAMTools Manual Original Publication(s) Twelve years of SAMtools and BCFtools"},{"location":"common_text/genoflu_task/","title":"Genoflu task","text":"<code>genoflu</code> <p>This task determines the whole-genome genotype of a H5N1 (currently only for the 2.3.4.4b clade of H5N1) flu sample by comparing each segment of the sample against a curated database of H5N1 references. Each segment is assigned a type, and the whole-genome genotype is assigned based on the combination of segment types, according to the GenoFLU reference table.</p> <p>GenoFLU Technical Details</p> Links Task task_genoflu.wdl Software Source Code GenoFLU on GitHub Software Documentation GenoFLU on GitHub Original Publication(s) H5N1 highly pathogenic avian influenza clade 2.3.4.4b in wild and domestic birds: Introductions into the United States and reassortments, December 2021-April 2022"},{"location":"common_text/genotyphi_task/","title":"Genotyphi task","text":"<code>genotyphi</code>: Salmonella Typhi Characterization for Illumina and ONT only <p><code>genotyphi</code> is activated upon the identification of the \"Typhi\" serotype by SISTR or SeqSero2 (via either the <code>seqsero2_predicted_serotype</code>, or the <code>sistr_predicted_serotype</code>). <code>genotyphi</code> divides the Salmonella enterica serovar Typhi population into detailed lineages, clades, and subclades. It also detects mutations in the quinolone-resistance determining regions, acquired antimicrobial resistance genes, plasmid replicons, and subtypes of the IncHI1 plasmid which is associated with multidrug resistance.</p> <p>This task uses Mykrobe in order to perform k-mer based genotyping with a genotyping scheme specific to Salmonella Typhi, and then parses that output using the <code>genotyphi</code> tool. This scheme divides the Salmonella Typhi population into genotypes based on unique SNV markers.</p> <p>genotyphi Technical Details</p> Links Task task_genotyphi.wdl Software Source Code genotyphi on GitHub Software Documentation genotyphi on GitHub Orginal publication(s) An extended genotyping framework for Salmonella enterica serovar Typhi, the cause of human typhoidFive Years of GenoTyphi: Updates to the Global Salmonella Typhi Genotyping FrameworkTyphi Mykrobe: fast and accurate lineage identification and antimicrobial resistance genotyping directly from sequence reads for the typhoid fever agent Salmonella Typhi"},{"location":"common_text/gubbins_task/","title":"Gubbins task","text":"Gubbins (optional) <pre><code>**_Most optional inputs are hidden in Snippy_Streamline for simplification of the workflow. If you would like to use Gubbins with additional options, please use the `Snippy_Tree` workflow._**\n\n!!! tip \"\"\n    In Snippy Streamline, the nucleotide substitution model used by gubbins will always be GTR+GAMMA.\n</code></pre> <pre><code>**G**enealogies **U**nbiased **B**y recom**B**inations **I**n **N**ucleotide **S**equences (Gubbins) identifies and masks genomic regions that are predicted to have arisen via recombination. It works by iteratively identifying loci containing elevated densities of SNPs and constructing phylogenies based on the putative single nucleotide variants outside these regions (for more details, see [here](https://github.com/nickjcroucher/gubbins/blob/v3.3/docs/gubbins_manual.md#description-of-the-algorithm)). By default, these phylogenies are constructed using RaxML and a GTR-GAMMA nucleotide substitution model, which will be the most suitable model for most bacterial phylogenetics, though this can be modified with the `tree_builder` and `nuc_subst_model` inputs.\n\nGubbins is the industry standard for masking recombination from bacterial genomes when building phylogenies, but limitations to recombination removal exist. Gubbins cannot distinguish recombination from high densities of SNPs that may result from assembly or alignment errors, mutational hotspots, or regions of the genome with relaxed selection. The tool is also intended only to find recombinant regions that are short relative to the length of the genome, so large regions of recombination may not be masked. These factors should be considered when interpreting resulting phylogenetic trees, but overwhelmingly Gubbins improves our ability to understand ancestral relationships between bacterial genomes.\n</code></pre> <pre><code>There are few optional inputs for Gubbins that can be modified by the user:\n\n- `iterations`: Gubbins works by iteratively identifying loci containing elevated densities of SNPs, while constructing phylogenies based on the putative single nucleotide variants outside these regions. It may take many iterations for Gubbins to converge on an alignment that it considers free of recombination, especially for phylogenies that contain large numbers of genomes. By default, Gubbins is limited to 5 iterations though this may be increased by the user with the `iterations`optional input (incurring increased computing time and cost, and possibly requiring increased memory allocation).\n- `nuc_subst_model`, `tree_builder` and `tree_args`:  When Gubbins constructs phylogenies, it can use a number of phylogenetic inference tools, each with [different nucleotide substitution models](https://github.com/nickjcroucher/gubbins/blob/master/docs/gubbins_manual.md#nucleotide-substitution-model-options) and [tree-building models](https://github.com/nickjcroucher/gubbins/blob/master/docs/gubbins_manual.md#tree-building-options). By default, the `Snippy_Tree` workflow uses a GTRGAMMA substitution model and RaxML for tree building (typically suitable for bacterial genomes), but these can be modified by the user depending on the genome sequences being used with the `nuc_subst_model` and `tree_builder` optional inputs, respectively. The nucleotide substitution models that are available depend on the tree building algorithm being used (see [here](https://github.com/nickjcroucher/gubbins/blob/v3.3/docs/gubbins_manual.md#nucleotide-substitution-model-options)). Additional options for generating the phylogenetic trees in Gubbins can be specified with the `tree_args` optional input, providing an input string that is consistent with the option formats of the Gubbins command.\n- `filter_percent`: By default, Gubbins removes genomes from the multiple sequence alignment if  more than 25 % of the genome is represented by gaps. The percentage of gaps can be modified by the user using the `filter_percent` optional input.\n</code></pre> <pre><code>!!! techdetails \"Gubbins Technical Details\"\n\n    |  | Links |\n    | --- | --- |\n    | Task | [task_gubbins.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/phylogenetic_inference/task_gubbins.wdl) |\n    | Software Source Code | [Gubbins on GitHub](https://github.com/nickjcroucher/gubbins) |\n    | Software Documentation | [Gubbins v3.3 manual](https://github.com/nickjcroucher/gubbins/blob/v3.3/docs/gubbins_manual.md) |\n    | Original Publication(s) | [Rapid phylogenetic analysis of large samples of recombinant bacterial whole genome sequences using Gubbins](https://academic.oup.com/nar/article/43/3/e15/2410982) |\n</code></pre>"},{"location":"common_text/gubbins_task/#gubbins-optional","title":"Gubbins (optional)","text":"<p>Turn on Gubbins with <code>use_gubbins</code></p> <p>Gubbins runs when the <code>use_gubbins</code> option is set to <code>true</code> (default=true).</p>"},{"location":"common_text/hicap_task/","title":"Hicap task","text":"<code>hicap</code>: Serotyping <p><code>hicap</code> identifies the\u00a0cap\u00a0locus serotype in\u00a0Haemophilus influenzae\u00a0assemblies. As described in the <code>hicap</code> documentation:</p> <p>The\u00a0cap\u00a0locus of\u00a0H. influenzae\u00a0is categorised into 6 different groups based on serology (a-f). There are three functionally distinct regions of the\u00a0cap\u00a0locus, designated\u00a0<code>region I</code>,\u00a0<code>region II</code>, and\u00a0<code>region III</code>. Genes within\u00a0<code>region I</code>\u00a0(<code>bexABCD</code>) and\u00a0<code>region III</code>\u00a0(<code>hcsAB</code>) are associated with transport and post-translation modification. The\u00a0<code>region II</code>\u00a0genes encode serotype-specific proteins, with each serotype (a-f) having a distinct set of genes.\u00a0cap\u00a0loci are often subject to structural changes (e.g. duplication, deletion) making the process of\u00a0in silico\u00a0typing and characterisation of loci difficult.</p> <p>hicap Technical Details</p> Links Task task_hicap.wdl Software Source Code hicap on GitHub Software Documentation hicap on GitHub Original Publication(s) hicap: In Silico Serotyping of the Haemophilus influenzae Capsule Locus"},{"location":"common_text/host_decontaminate_wf/","title":"Host decontaminate wf","text":"<code>host_decontaminate</code>: Host Read Decontamination <p>Host genetic data is frequently incidentally sequenced alongside pathogens, which can negatively affect the quality of downstream analysis. Host Decontaminate attempts to remove host reads by aligning to a reference host genome acquired on-the-fly. The reference host genome can be acquired via NCBI Taxonomy-compatible taxon input or assembly accession. Host Decontaminate maps inputted reads to the host genome using <code>minimap2</code>, reports mapping statistics to this host genome, and outputs the unaligned dehosted reads. </p> <p>The detailed steps and tasks are as follows:</p> Taxonomic Identification <p>The <code>ncbi_identify</code> task uses <code>NCBI Datasets</code> to search the NCBI Viral Genome Database and acquire taxonomic metadata from a user's inputted taxonomy and desired taxonomic rank. This task will always return a taxon ID, name, and rank, and it facilitates multiple downstream functions, including read classification and targeted read extraction. This task also generates a comprehensive summary file of all successful hits to the input <code>taxon</code>, which includes each taxon's accession number, completeness status, genome length, source, and other relevant metadata. Based on this summary, the task also calculates the average expected genome size for the input <code>taxon</code>.</p> <code>taxon</code> input parameter <p>This parameter accepts either a NCBI taxon ID (e.g. <code>11292</code>) or an organism name (e.g. <code>Lyssavirus rabies</code>).</p> <code>rank</code> a.k.a <code>read_extraction_rank</code> input parameter <p>Valid options include: <code>\"species\"</code>, <code>\"genus\"</code>, <code>\"family\"</code>, <code>\"order\"</code>, <code>\"class\"</code>, <code>\"phylum\"</code>, <code>\"kingdom\"</code>, or <code>\"domain\"</code>. By default it is set to <code>\"family\"</code>. This parameter filters metadata to report information only at the taxonomic <code>rank</code> specified by the user, regardless of the taxonomic rank implied by the original input <code>taxon</code>.</p> Important <ul> <li>The <code>rank</code> parameter must specify a taxonomic rank that is equal to or above the input taxon's taxonomic rank.</li> </ul> <p>Examples:</p> <ul> <li>If your input <code>taxon</code> is <code>Lyssavirus rabies</code> (species level) with <code>rank</code> set to <code>family</code>, the task will return information for the family of <code>Lyssavirus rabies</code>: taxon ID for Rhabdoviridae (11270), name \"Rhabdoviridae\", and rank \"family\".</li> <li>If your input <code>taxon</code> is <code>Lyssavirus</code> (genus level) with <code>rank</code> set to <code>species</code>, the task will fail because it cannot determine species information from an inputted genus.</li> </ul> <p>NCBI Datasets Technical Details</p> Links Task task_identify_taxon_id.wdl Software Source Code NCBI Datasets on GitHub Software Documentation NCBI Datasets Documentation on NCBI Original Publication(s) Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets Download Accession <p>The <code>NCBI Datasets</code> task downloads specified assemblies from NCBI using either the virus or genome (for all other genome types) package as appropriate.</p> <p>This task uses the accession ID output from the <code>skani</code> task to download the the most closely related reference genome to the input assembly. The downloaded reference is then used for downstream analysis, including variant calling and consensus generation.</p> <p>NCBI Datasets Technical Details</p> Links Task task_ncbi_datasets.wdl Software Source Code NCBI Datasets on GitHub Software Documentation NCBI Datasets Documentation on NCBI Original Publication(s) Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets Map Reads to Host <p><code>minimap2</code> is a popular aligner that is used to align reads (or assemblies) to an assembly file. In minimap2, \"modes\" are a group of preset options.</p> <p>The mode used in this task is <code>map-ont</code> which is the default mode for long reads and indicates that long reads of ~10% error rates should be aligned to the reference genome. The output file is in SAM format.</p> <p>For more information regarding modes and the available options for <code>minimap2</code>, please see the minimap2 manpage</p> <p>minimap2 Technical Details</p> Links Task task_minimap2.wdl Software Source Code minimap2 on GitHub Software Documentation minimap2 Original Publication(s) Minimap2: pairwise alignment for nucleotide sequences Extract Unaligned Reads <p>The <code>bam_to_unaligned_fastq</code> task will extract a FASTQ file of reads that failed to align, while removing unpaired reads. </p> <p><code>parse_mapping</code> Technical Details</p> Links Task task_parse_mapping.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <code>assembly_metrics</code>: Mapping Statistics <p>The <code>assembly_metrics</code> task generates mapping statistics from a BAM file. It uses samtools to generate a summary of the mapping statistics, which includes coverage, depth, average base quality, average mapping quality, and other relevant metrics.</p> <p><code>assembly_metrics</code> Technical Details</p> Links Task task_assembly_metrics.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <p>Host Decontaminate Technical Details</p> Links Subworkflow wf_host_decontaminate.wdl"},{"location":"common_text/iqtree2_task/","title":"Iqtree2 task","text":"IQTree2"},{"location":"common_text/iqtree2_task/#iqtree2","title":"IQTree2","text":"<p>IQTree2 is used to build the final phylogeny. It uses the alignment generated in the previous steps of the workflow. The contents of this alignment will depend on whether any sites were masked with recombination.</p> <p>The phylogeny is generated using the maximum-likelihood method and a specified nucleotide substitution model. By default, the Snippy_Tree workflow will run Model Finder to determine the most appropriate nucleotide substitution model for your data, but you may specify the nucleotide substitution model yourself using the <code>iqtree2_model</code> optional input (see here for available models).</p> <p>IQTree will perform assessments of the tree using the Shimodaira\u2013Hasegawa approximate likelihood-ratio test (SH-aLRT test), and ultrafast bootstrapping with UFBoot2, a quicker but less biased alternative to standard bootstrapping. A clade should not typically be trusted if it has less than 80% support from the SH-aLRT test and less than 95% support with ultrafast bootstrapping.</p> <p>Nucleotide substitution model</p> <p>When <code>core_genome</code>= <code>true</code>, the default nucleotide substitution model is set to the General Time Reverside model with Gamma distribution (GTR+G). </p> <p>When the user sets <code>core_genome</code>= <code>false</code>, the default nucleotide substitution model is set to the General Time Reversible model with invariant sites and Gamma distribution (<code>GTR+I+G</code>).</p> <p>IQTree2 technical details</p> Links Task task_iqtree2.wdl Software Source Code IQ-TREE on GitHub Software Documentation IQTree documentation for the latest version (not necessarily the version used in this workflow) Original Publication(s) IQ-TREE 2: New Models and Efficient Methods for Phylogenetic Inference in the Genomic EraNew Algorithms and Methods to Estimate Maximum-Likelihood Phylogenies: Assessing the Performance of PhyML 3.0Ultrafast Approximation for Phylogenetic Bootstrap UFBoot2: Improving the Ultrafast Bootstrap ApproximationModelFinder: fast model selection for accurate phylogenetic estimates"},{"location":"common_text/irma_task/","title":"Irma task","text":"<code>irma</code>: Assembly and Characterization <code>irma</code> <pre><code>Cleaned reads are assembled using `irma` which stands for Iterative Refinement Meta-Assembler. IRMA first sorts reads to Flu genome segments using LABEL, then iteratively maps read to collection of reference sequences (in this case for Influenza virus) and iteratively edits the references to account for high population diversity and mutational rates that are characteristic of Influenza genomes. Assemblies produced by `irma` will be ordered from largest to smallest assembled flu segment. `irma` also performs typing and subtyping as part of the assembly process. Note: IRMA does not differentiate between Flu B Victoria and Yamagata lineages. For determining this information, please review the `abricate` task outputs which will provide this information.\n</code></pre> <pre><code>Due to the segmented nature of the Influenza genome and the various downstream bioinformatics tools that require the genome assembly, the IRMA task &amp; TheiaCoV workflows output various genome assembly files. Briefly they are:\n\n- `assembly_fasta` - The full genome assembly in FASTA format, with 1 FASTA entry per genome segment. There should be 8 segments in total, but depending on the quality and depth of sequence data, some segments may not be assembled and nor present in this output file.\n- `irma_assembly_fasta_concatenated` - The full genome assembly in FASTA format, but with all segments concatenated into a single FASTA entry. This is not your typical FASTA file and is purposely created to be used with a custom Nextclade dataset for the H5N1 B3.13 genotype that is based on a concatenated reference genome.\n- `irma_&lt;segment-abbreviation&gt;_segment_fasta` - Individual FASTA files that only contain the sequence for 1 segment, for example the HA segment. There are 8 of these in total.\n\nGeneral statistics about the assembly are generated with the `consensus_qc` task ([task_assembly_metrics.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/basic_statistics/task_assembly_metrics.wdl)).\n</code></pre> <pre><code>!!! techdetails \"IRMA Technical Details\" \n    |  | Links |\n    | --- | --- |\n    | Task | [task_irma.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/assembly/task_irma.wdl) |\n    | Software Documentation | [IRMA website](https://wonder.cdc.gov/amd/flu/irma/) |\n    | Original Publication(s) | [Viral deep sequencing needs an adaptive approach: IRMA, the iterative refinement meta-assembler](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-016-3030-6) |\n</code></pre>"},{"location":"common_text/ivar_consensus_task/","title":"Ivar consensus task","text":"<code>ivar_consensus</code>: Consensus Assembly <p>iVar's <code>consensus</code> tool generates a reference-based consensus assembly. Several parameters can be set that determine the stringency of the consensus assembly, including minimum quality, minimum allele frequency, and minimum depth.</p> <pre><code>For TheiaCoV, the following default parameters are used:\n\n- minimum quality: 20\n- minimum depth: 100\n- minimum allele frequency: 0.6\n</code></pre> <pre><code>This task is functional for segmented viruses by iteratively executing iVar on a contig-by-contig basis and concantenating resulting consensus contigs.\n\n??? dna \"`min_depth` input parameter\"\n    This parameter accepts an integer value to set the minimum read depth for variant calling and subsequent consensus sequence generation. The default value is `10`.\n\n??? dna \"`min_map_quality` input parameter\"\n    This parameter accepts an integer value to set the minimum mapping quality for variant calling and subsequent consensus sequence generation. The default value is `20`.\n\n??? dna \"`min_allele_freq` input parameter\"\n    This parameter accepts a float value to set the minimum allele frequency for variant calling and subsequent consensus sequence generation. The default value is `0.6`.\n</code></pre> <pre><code>!!! techdetails \"iVar Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_ivar_consensus.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/assembly/task_ivar_consensus.wdl) |\n    | Software Source Code | [Ivar on GitHub](https://andersen-lab.github.io/ivar/html/) |\n    | Software Documentation | [Ivar Documentation](https://andersen-lab.github.io/ivar/html/manualpage.html) |\n    | Original Publication(s) | [An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar](http://dx.doi.org/10.1186/s13059-018-1618-7) |\n</code></pre>"},{"location":"common_text/ivar_consensus_wf/","title":"Ivar consensus wf","text":"<code>ivar_consensus</code>: Alignment, Consensus, Variant Detection, and Assembly Statistics <p><code>iVar Consensus</code> is a sub-workflow within TheiaCoV that performs reference-based consensus assembly using the iVar tool by Nathan Grubaugh from the Andersen lab.</p> <code>bwa</code>: Read Alignment to the Reference <p>BWA (Burrow-Wheeler Aligner) is used to align the cleaned read files to a reference genome, either  determined by the user or provided by the organism-specific parameters section (see above). The resulting BAM file is used for primer trimming, variant calling, and consensus generation in downstream tasks.</p> <p>BWA Technical Details</p> Links Task task_bwa.wdl Software Source Code BWA on GitHub Software Documentation BWA Documentation Original Publication(s) Fast and accurate short read alignment with Burrows-Wheeler transform <code>ivar_trim</code>: Primer Trimming (optional) <p>To deactivate this task, set <code>trim_primers</code> to <code>false</code>.</p> <p>Using the user-provided (or, more rarely, a organism-specific parameters-determined) <code>primer_bed</code> file, iVar soft-clips primer sequences from an aligned and sorted BAM file and then trims the reads based on a quality threshold of 20 using a sliding window approach. If the resulting read is greater than 30 bp, the read is written to a a new BAM file consisting of only trimmed reads (or reads that did not have a primer identified).</p> <p>iVar Trim Technical Details</p> Links Task task_ivar_primer_trim.wdl Software Source Code iVar on GitHub Software Documentation iVar on GitHub Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar <code>assembly_metrics</code>: Mapping Statistics <p>The <code>assembly_metrics</code> task generates mapping statistics from a BAM file. It uses samtools to generate a summary of the mapping statistics, which includes coverage, depth, average base quality, average mapping quality, and other relevant metrics.</p> <p>This task is run twice: once on the untrimmed reads and, if primer trimming is enabled, once on the primer-trimmed reads. This allows for a comparison of mapping statistics before and after primer trimming, which can be useful for assessing the impact of primer trimming on the quality of the alignment and subsequent analyses.</p> <p><code>assembly_metrics</code> Technical Details</p> Links Task task_assembly_metrics.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <code>ivar_consensus</code>: Consensus Assembly <p>iVar's <code>consensus</code> tool generates a reference-based consensus assembly. Several parameters can be set that determine the stringency of the consensus assembly, including minimum quality, minimum allele frequency, and minimum depth.</p> <p>For TheiaCoV, the following default parameters are used:</p> <ul> <li>minimum quality: 20</li> <li>minimum depth: 100</li> <li>minimum allele frequency: 0.6</li> </ul> <p>iVar Technical Details</p> Links Task task_ivar_consensus.wdl Software Source Code Ivar on GitHub Software Documentation Ivar Documentation Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar <code>ivar_variants</code>: Variant Calling <p>iVar uses the outputs of <code>samtools mpileup</code> to call single nucleotide variants (SNVs) and insertions/deletions (indels). Several key parameters can be set to determine the stringency of variant calling, including minimum quality, minimum allele frequency, and minimum depth.</p> <p>This task returns a VCF file containing all called variants, the number of detected variants, and the proportion of those variants with allele frequencies between 0.6 and 0.9 (also known as intermediate variants).</p> <p>For TheiaCoV, the following default parameters are used:</p> <ul> <li>minimum quality: 20</li> <li>minimum depth: 100</li> <li>minimum allele frequency: 0.06</li> </ul> <p>iVar Technical Details</p> Links Task task_ivar_variant_call.wdl Software Source Code Ivar on GitHub Software Documentation Ivar Documentation Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar <p>iVar Consensus Technical Details</p> Links Subworkflow wf_ivar_consensus.wdl"},{"location":"common_text/ivar_trim_task/","title":"Ivar trim task","text":"<code>ivar_trim</code>: Primer Trimming (optional) <p>To deactivate this task, set <code>trim_primers</code> to <code>false</code>.</p> <p>Using the user-provided (or, more rarely, a organism-specific parameters-determined) <code>primer_bed</code> file, iVar soft-clips primer sequences from an aligned and sorted BAM file and then trims the reads based on a quality threshold of 20 using a sliding window approach. If the resulting read is greater than 30 bp, the read is written to a a new BAM file consisting of only trimmed reads (or reads that did not have a primer identified).</p> <p>iVar Trim Technical Details</p> Links Task task_ivar_primer_trim.wdl Software Source Code iVar on GitHub Software Documentation iVar on GitHub Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar"},{"location":"common_text/ivar_variants_task/","title":"Ivar variants task","text":"<code>ivar_variants</code>: Variant Calling <p>iVar uses the outputs of <code>samtools mpileup</code> to call single nucleotide variants (SNVs) and insertions/deletions (indels). Several key parameters can be set to determine the stringency of variant calling, including minimum quality, minimum allele frequency, and minimum depth.</p> <p>This task returns a VCF file containing all called variants, the number of detected variants, and the proportion of those variants with allele frequencies between 0.6 and 0.9 (also known as intermediate variants).</p> <pre><code>For TheiaCoV, the following default parameters are used:\n\n- minimum quality: 20\n- minimum depth: 100\n- minimum allele frequency: 0.06\n</code></pre> <pre><code>??? dna \"`min_depth` input parameter\"\n    This parameter accepts an integer value to set the minimum read depth for variant calling and subsequent consensus sequence generation. The default value is `10`.\n\n??? dna \"`min_map_quality` input parameter\"\n    This parameter accepts an integer value to set the minimum mapping quality for variant calling and subsequent consensus sequence generation. The default value is `20`.\n\n??? dna \"`min_allele_freq` input parameter\"\n    This parameter accepts a float value to set the minimum allele frequency for variant calling and subsequent consensus sequence generation. The default value is `0.6`.\n</code></pre> <pre><code>!!! techdetails \"iVar Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_ivar_variant_call.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/gene_typing/variant_detection/task_ivar_variant_call.wdl) |\n    | Software Source Code | [Ivar on GitHub](https://andersen-lab.github.io/ivar/html/) |\n    | Software Documentation | [Ivar Documentation](https://andersen-lab.github.io/ivar/html/manualpage.html) |\n    | Original Publication(s) | [An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar](http://dx.doi.org/10.1186/s13059-018-1618-7) |\n</code></pre>"},{"location":"common_text/kaptive_task/","title":"Kaptive task","text":"<code>Kaptive</code>: Capsule and Lipooligosaccharide Outer Core Typing <p>The cell-surface capsular polysaccharide (CPS) of Acinetobacter baumannii can be used as an epidemiological marker. CPS varies in its composition and structure and is a key determinant in virulence and a target for non-antibiotic therapeutics. Specificity for non-antibiotic therapeutics (e.g. phage therapy) bear particular significance given the extent of antibiotic resistance found in this ESKAPE pathogen. </p> <p>Biosynthesis and export of CPS is encoded by genes clustering at the K locus (KL). Additional genes associated with CPS biosynthesis and export are sometimes found in other chromosomal locations. The full combination of these genes is summarized as a \"K type\", described as a \"predicted serotype associated with the best match locus\". You can read more about this in the Kaptive Wiki.</p> <p>Previously, serotyping of A. baumannii focused on a major immunogenic polysaccharide which was considered the O antigen for the species. This serotyping approach appears to no longer be used and the serotyping scheme has not been updated in over 20 years. Nonetheless, the O-antigen polysaccharide is attached to lipooligosaccharide, and the outer core (OC) of this lipooligosaccharide varies. Biosynthesis of the outer core lipooligosaccharide is encoded by a cluster of genes at the outer core (OC) locus.</p> <p>Variation in the KL and OCL can be characterized with the Kaptive tool and its associated databases of numbered A. baumannii K and OC locus variants. Kaptive takes in a genome assembly file (fasta), and assigns the K and OC locus to their numbered variants, provides a K type, and a description of genes in the K or OC loci and elsewhere in the chromosome, alongside metrics for quality of locus match. A description of how Kaptive works, explanations of the full output reports, and resources for interpreting outputs are available on the Kaptive Wiki page.</p> <p>Kaptive Technical Details</p> Links Task task_kaptive.wdl Software Source Code Kaptive on GitHub Software Documentation Kaptive on GitHub Orginal Publication(s) Identification of Acinetobacter baumannii loci for capsular polysaccharide (KL) and lipooligosaccharide outer core (OCL) synthesis in genome assemblies using curated reference databases compatible with KaptiveAn update to the database for Acinetobacter baumannii capsular polysaccharide locus typing extends the extensive and diverse repertoire of genes found at and outside the K locus"},{"location":"common_text/kleborate_task/","title":"Kleborate task","text":"<code>Kleborate</code>: Species Identification, MLST, Serotyping, AMR and Virulence Characterization <p>Kleborate is a tool to identify the Klebsiella species, MLST sequence type, serotype, virulence factors (ICE_Kp_ and plasmid associated), and AMR genes and mutations. Serotyping is based on the capsular (K antigen) and lipopolysaccharide (LPS) (O antigen) genes. The acquired resistance genes identified by Kleborate can be found in the Kleborate documentation here, along with other useful information regarding all of Kleborate's modules.</p> <p><code>Kaptive</code> can be run as well by setting the optional input variable <code>kleborate_skip_kaptive</code> to <code>false</code> in order to recieve the K antigen and O antigen locus typing via wzi alleles.</p> <p>Kleborate Technical Details</p> Links Task task_kleborate.wdl Software Source Code Kleborate on GitHub Software Documentation Kleborate Documentation on ReadTheDocs Original publication A genomic surveillance framework and genotyping tool for Klebsiella pneumoniae and its related species complexIdentification of Klebsiella capsule synthesis loci from whole genome data"},{"location":"common_text/kmerfinder_task/","title":"Kmerfinder task","text":"<code>KmerFinder</code>: Taxon Assignment (optional) <p>To activate this task, set <code>call_kmerfinder</code> to <code>true</code>.</p> <p>KmerFinder predicts prokaryotic species based on the number of overlapping (co-occurring)\u00a0k-mers, i.e., 16-mers, between the query genome and genomes in a reference database. These k-mers are selected with the prefix of <code>ATGAC</code> in order to focus on coding regions of genomes. A prediction is made by identifying which species in the training data has the highest number of 16-mers in common with the query. This match is made regardless of position. Ties will result in an alphabetical sorting of tied species and the return of the first species in the alphabetical list. </p> <p>This is a simpler approach than other k-mer based tools such as GAMBIT, which uses a 11-mer approach while implementing thresholds to its classification algorithm allowing it to re-assess at a higher level of classification if need be.</p> <p>KmerFinder Technical Details</p> Links Task task_kmerfinder.wdl Software Source Code KmerFinder BitBucket Software Documentation CGE KmerFinder Documentation Original Publication(s) Benchmarking of Methods for Genomic Taxonomy"},{"location":"common_text/kraken2_task/","title":"Kraken2 task","text":"<code>Kraken2</code>: Read Identification (optional) <p>To activate this task, set <code>call_kraken</code> to <code>true</code> and provide a value for <code>kraken_db</code>.</p> <code>Kraken2</code>: Read Identification Kraken2 <pre><code>`Kraken2` is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.\n</code></pre> <pre><code>Kraken2 is run on both the raw and clean reads.\n</code></pre> <pre><code>Kraken2 is run on the raw read data.\n</code></pre> <pre><code>This task runs on cleaned reads passed from the `read_QC_trim` subworkflow and outputs a Kraken2 report detailing taxonomic classifications. It also separates classified reads from unclassified ones.\n</code></pre> <pre><code>!!! info \"Database-dependent\"\n    This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at `gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz`.\n</code></pre> <pre><code>As an alternative to `MIDAS` (see above), the `Kraken2` task can also be turned on through setting the `call_kraken` input variable as `true` for the identification of reads to detect contamination with non-target taxa.\n</code></pre> <pre><code>A database must be provided if this optional module is activated, through the kraken_db optional input. A list of suggested databases can be found on [Kraken2 standalone documentation](../standalone/kraken2.md#databases).\n</code></pre> <pre><code>This workflow is database dependent, and one is required to run this task. Please see above for a list of suggested databases to provide through the `kraken2_db` input variable.\n</code></pre> <pre><code>Kraken2 is run on the set of raw reads, provided as input, as well as the set of clean reads that are resulted from the `read_QC_trim` workflow\n\nThe Kraken2 software is database-dependent and **taxonomic assignments are highly sensitive to the database used**. An appropriate database should contain the expected organism(s) (e.g. _Escherichia coli_) and other taxa that may be present in the reads (e.g. _Citrobacter freundii_, a common contaminant).\n</code></pre> <pre><code>!!! techdetails \"Kraken2 Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_kraken2.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/taxon_id/contamination/task_kraken2.wdl) |\n    | Software Source Code | [Kraken2 on GitHub](https://github.com/DerrickWood/kraken2/)  |\n    | Software Documentation | [Kraken2 Documentation](https://github.com/DerrickWood/kraken2/blob/master/docs/MANUAL.markdown) |\n    | Original Publication(s) | [Improved metagenomic analysis with Kraken 2](https://link.springer.com/article/10.1186/s13059-019-1891-0) |\n</code></pre>"},{"location":"common_text/krakentools_task/","title":"Krakentools task","text":"<code>krakentools</code>: Read Extraction <p>The <code>task_krakentools.wdl</code> task extracts reads from the Kraken2 output file. It uses the KrakenTools package to extract reads classified at any user-specified taxon ID.</p> <pre><code>??? dna \"`extract_unclassified` input parameter\"\n    This parameter determines whether unclassified reads should also be extracted and combined with the `taxon`-specific extracted reads. By default, this is set to `false`, meaning that only reads classified to the specified input `taxon` will be extracted.\n\n???+ warning \"Important\"\n    This task will extract reads classified to the input `taxon` and **all of its descendant taxa**. The `rank` input parameter controls the extraction of reads classified at the specified `rank` and all suboridante taxonomic levels. See task `ncbi_identify` under the **Taxonomic Identification** section for more details on the `rank` input parameter.\n</code></pre> <pre><code>!!! techdetails \"KrakenTools Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_krakentools.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/taxon_id/task_krakentools.wdl) |\n    | Software Source Code | [KrakenTools on GitHub](https://github.com/jenniferlu717/KrakenTools) |\n    | Software Documentation | [KrakenTools](https://github.com/jenniferlu717/KrakenTools/blob/master/README.md) |\n    | Original Publication(s) | [Metagenome analysis using the Kraken software suite](https://doi.org/10.1126/scitranslmed.aap9489) |\n</code></pre>"},{"location":"common_text/ksnp_task/","title":"Ksnp task","text":"kSNP3 Details kSNP4 Details <pre><code>This workflow is run on a set of assembly files to produce both pan-genome and core-genome phylogenies. This also results in alignment files which are used by downstream tasks.\n</code></pre> <pre><code>!!! techdetails \"kSNP3 Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_ksnp3.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/phylogenetic_inference/task_ksnp3.wdl) |\n    | Software Source Code | [kSNP on SourceForge via the WayBack Machine](https://web.archive.org/web/20221006234124/https://sourceforge.net/projects/ksnp/files/)  |\n    | Software Documentation | [kSNP on SourceForge via the WayBack Machine](https://web.archive.org/web/20221006234124/https://sourceforge.net/projects/ksnp/files/) |\n    | Original Publication(s) | [kSNP3.0: SNP detection and phylogenetic analysis of genomes without genome alignment or reference genome](https://doi.org/10.1093/bioinformatics/btv271) |\n</code></pre> <p>!!! techdetails \"kSNP4 Technical Details\"         |  | Links |         | --- | --- |         | Task | task_ksnp4.wdl |         | Software Source Code | kSNP4 on SourceForge  |         | Software Documentation | kSNP4 on SourceForge  |         | Original Publication(s) | Building Phylogenetic Trees from Genome Sequences With kSNP4 |</p>"},{"location":"common_text/legsta_task/","title":"Legsta task","text":"<code>Legsta</code>: Sequence-based typing <p>Legsta performs a sequence-based typing (SBT) of Legionella pneumophila, with the intention of being used for outbreak investigations. This tool outputs the allele number for seven genes (flaA, pilE, asd, mip, mompS, proA, and neuA), and combines the identified alleles to determine the overall SBT of the sample. Over 2,794 SBTs are able to be identified using this tool. Alleles with no in silico products are denoted with <code>-</code>s and novel alleles are listed with <code>?</code>s.</p> <p>Legsta Technical Details</p> Links Task task_legsta.wdl Software Source Code Legsta on GitHub Software Documentation Legsta on GitHub"},{"location":"common_text/lissero_task/","title":"Lissero task","text":"<code>LisSero</code>: Serogroup Prediction <p>LisSero performs serogroup prediction for Listeria monocytogenes based on the presence or absence of five genes, lmo1118, lmo0737, ORF2110, ORF2819, and Prs. LisSero does not predict somatic (O) or flagellar (H) biosynthesis.</p> <p>LisSero uses BLAST to query the sample against a built-in database to determine the most likely serogroup. </p> Serogroup Decision Tree <p>The following decision tree is used to determine the serogroup for the sample. </p><pre><code>if not Prs:\n    stop\nelif lmo0737 and not (ORF2819 or ORF2110):\n    if lmo1118:\n        Serogroup 1/2c, 3c\n    else:\n        Serogroup 1/2a, 3a\nelif ORF2819 and not (lmo0737 or lmo1118):\n    if ORF2110:\n        Serogroup 4b, 4d, 4e\n    else:\n        Serogroup 1/2b, 3b, 7\nelif lmo0737 and ORF2819 and ORF2110:\n    Serogroup 4b, 4d, 4e*\nelse:\n    Nontypable\n</code></pre><p></p> <p>LisSero Technical Details</p> Links Task task_lissero.wdl Software Source Code LisSero on GitHub Software Documentation LisSero on GitHub"},{"location":"common_text/medaka_task/","title":"Medaka task","text":"<code>Medaka</code>: Polishing of Flye assembly (default; optional) <p>Polishing is optional and can be skipped by setting the <code>skip_polishing</code> variable to true. If polishing is skipped, then neither Medaka or Racon will run.</p> <p>Medaka is the default assembly polisher used in TheiaProk. Racon may be used alternatively, and if so, Medaka will not run. Medaka uses the raw reads to polish the assembly and generate a consensus sequence. </p> <p>Importantly, Medaka requires knowing the model that was used to generate the read data. There are several ways to provide this information:</p> <ul> <li>Automatic Model Selection: Automatically determines the most appropriate Medaka model based on the input data, ensuring optimal polishing results without manual intervention. </li> <li>User-Specified Model Override: Allows users to specify a particular <code>Medaka model</code> if automatic selection does not yield the desired outcome or for specialized use cases.</li> <li>Default Model: If both automatic model selection fails and no user-specified model is provided, Medaka defaults to the predefined fallback model <code>r1041_e82_400bps_sup_v5.0.0</code>. </li> </ul> <p>Medaka Model Resolution Process</p> <p>Medaka's automatic model selection uses the <code>medaka tools resolve_model</code> command to identify the appropriate model for polishing. This process relies on metadata embedded in the input file, which is typically generated by the basecaller. If the automatic selection fails to identify a suitable model, Medaka gracefully falls back to the default model to maintain workflow continuity. Users should verify the chosen model and consider specifying a model override if necessary.</p> <p>Medaka Technical Details</p> Links WDL Task task_medaka.wdl Software Source Code Medaka on GitHub Software Documentation Medaka Documentation"},{"location":"common_text/megahit_task/","title":"Megahit task","text":"<code>megahit</code> <code>MEGAHIT</code>: De novo Assembly (alternative) <p>To activate this task, set <code>assembler</code> to <code>megahit</code>.</p> <pre><code>The [MEGAHIT assembler](https://github.com/voutcn/megahit) is a fast and memory-efficient _de novo_ assembler that can handle large datasets. While optimized for metagenomics, MEGAHIT also performs well on single-genome assemblies, making it a versatile choice for various assembly tasks.\n\nMEGAHIT uses a multiple k-mer strategy that can be beneficial for assembling genomes with varying coverage levels, which is common in metagenomic samples. It constructs succinct de Bruijn graphs to efficiently represent the assembly process, allowing it to handle large and complex datasets with reduced memory usage.\n</code></pre> <pre><code>This task is optional, turned off by default, and will only be called if MetaviralSPAdes fails. It can be enabled by setting the `skip_metaviralspades` parameter to `true`. The `megahit` task is used as a fallback option if the `spades` task fails during execution (see task `spades` for more details).\n</code></pre> <pre><code>???+ warning \"Non-deterministic output(s)\"\n    This task may yield non-deterministic outputs.\n\n!!! techdetails \"MEGAHIT Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_megahit.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/assembly/task_megahit.wdl) |\n    | Software Source Code | [MEGAHIT on GitHub](https://github.com/voutcn/megahit) |\n    | Software Documentation | [MEGAHIT on GitHub](https://github.com/voutcn/megahit/blob/master/README.md) |\n    | Original Publication(s) | [MEGAHIT: an ultra-fast single-node solution for large and complex metagenomics assembly via succinct de Bruijn graph](https://doi.org/10.1093/bioinformatics/btv033) |\n</code></pre>"},{"location":"common_text/meningotype_task/","title":"Meningotype task","text":"<code>meningotype</code>: Neisseria meningitidis Serotyping <p>This tool performs in silico typing of N. meningitidis. It performs the following functions: serogrouping, finetyping of porA and fetA, porB sequencing typing, and Bexsero Antigen Sequencing Typing (BAST) (fHbp, NHBA, NadA, and PorA). These results are all parsed and provided to the user as outputs.</p> <p>The allele database is extracted from PubMLST's N. meningitidis database. This tool works by using BLAST to compare the sample sequence against the database entries.</p> <p>meningotype Technical Details</p> Links Task task_meningotype.wdl Software Source Code meningotype on GitHub Software Documentation meningotype on GitHub"},{"location":"common_text/metabuli_task/","title":"Metabuli task","text":"<code>metabuli</code> <p>The <code>metabuli</code> task is used to classify and extract reads against a reference database. Metabuli uses a novel k-mer structure, called metamer, to analyze both amino acid (AA) and DNA sequences. It leverages AA conservation for sensitive homology detection and DNA mutations for specific differentiation between closely related taxa.</p> <code>cpu</code> / <code>memory</code> input parameters <p>Increasing the memory and cpus allocated to Metabuli can substantially increase throughput.</p> <pre><code>??? dna \"`extract_unclassified` input parameter\"\n    This parameter determines whether unclassified reads should also be extracted and combined with the `taxon`-specific extracted reads. By default, this is set to `false`, meaning that only reads classified to the specified input `taxon` will be extracted.\n\n???+ warning \"Descendant taxa reads are extracted\"\n    This task will extract reads classified to the input `taxon` and **all of its descendant taxa**. The `rank` input parameter controls the extraction of reads classified at the specified `rank` and all subordiante taxonomic levels. See task `ncbi_identify` under the **Taxonomic Identification** section above for more details on the `rank` input parameter.\n</code></pre> <pre><code>!!! techdetails \"Metabuli Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_metabuli.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/taxon_id/contamination/task_metabuli.wdl) |\n    | Software Source Code | [Metabuli on GitHub](https://github.com/steineggerlab/Metabuli) |\n    | Software Documentation | [Metabuli Documentation](https://github.com/steineggerlab/Metabuli/blob/master/README.md) |\n    | Original Publication(s) | [Metabuli: sensitive and specific metagenomic classification via joint analysis of amino acid and DNA](https://doi.org/10.1038/s41592-024-02273-y) |\n</code></pre>"},{"location":"common_text/midas_task/","title":"Midas task","text":"<code>MIDAS</code>: Read Identification (optional) <p>To activate this task, set <code>call_midas</code> to <code>true</code>.</p> <p>The <code>MIDAS</code> task is for the identification of reads to detect contamination with non-target taxa.</p> <p>The MIDAS tool was originally designed for metagenomic sequencing data but has been co-opted for use with bacterial isolate WGS methods. It can be used to detect contamination present in raw sequencing data by estimating bacterial species abundance in bacterial isolate WGS data. If a secondary genus is detected above a relative frequency of 0.01 (1%), then the sample should fail QC and be investigated further for potential contamination.</p> <p>This task is similar to those used in commercial software, BioNumerics, for estimating secondary species abundance.</p> How are the MIDAS output columns determined? <p>Example MIDAS report in the <code>midas_report</code> column:</p> species_id count_reads coverage relative_abundance Salmonella_enterica_58156 3309 89.88006645 0.855888033 Salmonella_enterica_58266 501 11.60606061 0.110519371 Salmonella_enterica_53987 99 2.232896237 0.021262881 Citrobacter_youngae_61659 46 0.995216227 0.009477003 Escherichia_coli_58110 5 0.123668877 0.001177644 <p>MIDAS report column descriptions:</p> <ul> <li>species_id: species identifier</li> <li>count_reads: number of reads mapped to marker genes</li> <li>coverage: estimated genome-coverage (i.e. read-depth) of species in metagenome</li> <li>relative_abundance: estimated relative abundance of species in metagenome</li> </ul> <p>The value in the <code>midas_primary_genus</code> column is derived by ordering the rows in order of \"relative_abundance\" and identifying the genus of top species in the \"species_id\" column (Salmonella). The value in the <code>midas_secondary_genus</code> column is derived from the genus of the second-most prevalent genus in the \"species_id\" column (Citrobacter). The <code>midas_secondary_genus_abundance</code> column is the \"relative_abundance\" of the second-most prevalent genus (0.009477003). The <code>midas_secondary_genus_coverage</code> is the \"coverage\" of the second-most prevalent genus (0.995216227).</p> <p>MIDAS Reference Database Overview</p> <p>The MIDAS reference database is a comprehensive tool for identifying bacterial species in metagenomic and bacterial isolate WGS data. It includes several layers of genomic data, helping detect species abundance and potential contaminants.</p> <p>Key Components of the MIDAS Database</p> <ol> <li> <p>Species Groups: </p> <ul> <li>MIDAS clusters bacterial genomes based on 96.5% sequence identity, forming over 5,950 species groups from 31,007 genomes. These groups align with the gold-standard species definition (95% ANI), ensuring highly accurate species identification.</li> </ul> </li> <li> <p>Genomic Data Structure:</p> <ul> <li>Marker Genes: Contains 15 universal single-copy genes used to estimate species abundance.</li> <li>Representative Genome: Each species group has a selected representative genome, which minimizes genetic variation and aids in accurate SNP identification.</li> <li>Pan-genome: The database includes clusters of non-redundant genes, with options for multi-level clustering (e.g., 99%, 95%, 90% identity), enabling MIDAS to identify gene content within strains at various clustering thresholds.</li> </ul> </li> <li> <p>Taxonomic Annotation: </p> <ul> <li>Genomes are annotated based on consensus Latin names. Discrepancies in name assignments may occur due to factors like unclassified genomes or genus-level ambiguities.</li> </ul> </li> </ol> <p>Using the Default MIDAS Database</p> <p>TheiaProk and TheiaEuk use the pre-loaded MIDAS database in Terra (see input table for current version) by default for bacterial species detection in metagenomic data, requiring no additional setup.</p> <p>Create a Custom MIDAS Database</p> <p>Users can also build their own custom MIDAS database if they want to include specific genomes or configurations. This custom database can replace the default MIDAS database used in Terra. To build a custom MIDAS database, follow the MIDAS GitHub guide on building a custom database. Once the database is built, users can upload it to a Google Cloud Storage bucket or Terra workkspace and provide the link to the database in the <code>midas_db</code> input variable.</p> <p>MIDAS Technical Details</p> Links Task task_midas.wdl Software Source Code MIDAS on GitHub Software Documentation MIDAS on GitHub Original Publication(s) An integrated metagenomics pipeline for strain profiling reveals novel patterns of bacterial transmission and biogeography"},{"location":"common_text/minimap2_task/","title":"Minimap2 task","text":"<code>minimap2</code>: Read Alignment Details <pre><code>`minimap2` is a popular aligner that is used to align reads (or assemblies) to an assembly file. In minimap2, \"modes\" are a group of preset options.\n</code></pre> <pre><code>The mode used in this task is `map-ont` with additional long-read-specific parameters (the `-L --cs --MD` flags) to align ONT reads to the reference genome. These specialized parameters are essential for proper handling of long read error profiles, generation of detailed alignment information, and improved mapping accuracy for long reads.\n\n`map-ont` is the default mode for long reads and it indicates that long reads of ~10% error rates should be aligned to the reference genome. The output file is in SAM format.\n</code></pre> <pre><code>The mode used in this task is `map-ont` which is the default mode for long reads and indicates that long reads of ~10% error rates should be aligned to the reference genome. The output file is in SAM format.\n</code></pre> <pre><code>The mode used in this task is `asm20` which is intended for \"long assembly to reference mapping\". The `asm20` mode indicates the following parameters should be used: `-k19 -w10 -U50,500 --rmq -r100k -g10k -A1 -B4 -O6,26 -E2,1 -s200 -z200 -N50`. The output file is in PAF format.\n</code></pre> <pre><code>The mode used in this task is `sr` which is intended for \"short single-end reads without splicing\". The `sr` mode indicates the following parameters should be used: `-k21 -w11 --sr --frag=yes -A2 -B8 -O12,32 -E2,1 -b0 -r100 -p.5 -N20 -f1000,5000 -n2 -m20 -s40 -g100 -2K50m --heap-sort=yes --secondary=no`. The output file is in SAM format.\n</code></pre> <pre><code>For more information regarding modes and the available options for `minimap2`, please see the [minimap2 manpage](https://lh3.github.io/minimap2/minimap2.html)\n\n!!! techdetails \"minimap2 Technical Details\"\n    | | Links |\n    |---|---|\n    | Task | [task_minimap2.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/alignment/task_minimap2.wdl) |\n    | Software Source Code | [minimap2 on GitHub](https://github.com/lh3/minimap2) |\n    | Software Documentation | [minimap2](https://lh3.github.io/minimap2) |\n    | Original Publication(s) | [Minimap2: pairwise alignment for nucleotide sequences](https://academic.oup.com/bioinformatics/article/34/18/3094/4994778) |\n</code></pre>"},{"location":"common_text/mummer_ani_task/","title":"Mummer ani task","text":"<code>MUMmer_ANI</code>: Taxon Assignment using Average Nucleotide Identity (optional) <p>To activate this task, set <code>call_ani</code> to <code>true</code>.</p> <p>Average Nucleotide Identity (ANI) is a useful approach for taxonomic identification. The higher the percentage ANI of a query sequence to a given reference genome, the more likely the sequence is the same taxa as the reference. </p> <p>ANI is calculated in TheiaProk using a perl script written by Lee Katz (ani-m.pl). This uses MUMmer to rapidly align entire query assemblies to one or more reference genomes. By default, TheiaProk uses a set of 43 reference genomes in RGDv2, a database containing genomes of enteric pathogens commonly sequenced by CDC EDLB &amp; PulseNet participating laboratories. The user may also provide their own reference genome. After genome alignment with MUMmer, ani-m.pl calculates the average nucleotide identity and percent bases aligned between 2 genomes (query and reference genomes)</p> <p>The default database of reference genomes used is called \"Reference Genome Database version 2\" AKA \"RGDv2\". This database is composed of 43 enteric bacteria representing 32 species and is intended for identification of enteric pathogens and common contaminants. It contains six Campylobacter spp., three Escherichia/Shigella spp., one Grimontia hollisae, six Listeria spp., one Photobacterium damselae, two Salmonella spp., and thirteen Vibrio spp. </p> <p>2 Thresholds are utilized to prevent false positive hits. The <code>ani_top_species_match</code> will only report a genus &amp; species match if both thresholds are surpassed. Both of these thresholds are set to match those used in BioNumerics for PulseNet organisms.</p> <ol> <li><code>ani_threshold</code> default value of 80.0</li> <li><code>percent_bases_aligned_threshold</code> default value of 70.0</li> </ol> <p>For more information on RGDv2 database of reference genomes, please see the publication here.</p> <p>MUMmer_ANI Technical Details</p> Links Task task_mummer_ani.wdl Software Source Code ani-m on GitHubMUMmer on GitHub Software Documentation ani-m on GitHubMUMmer on SourceForge Original Publication(s) MUMmer4: MUMmer4: A fast and versatile genome alignment systemRGDv2 database: Rapid identification of enteric bacteria from whole genome sequences using average nucleotide identity metrics"},{"location":"common_text/nanoplot_task/","title":"Nanoplot task","text":"<code>NanoPlot</code>: Read Quantification <p>NanoPlot is used for the determination of mean quality scores, read lengths, and number of reads. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <pre><code>While this task currently is run _outside_ of the `read_QC_trim_ont` workflow, it is being included here as it calculates statistics on the read data. This is done so that the actual assembly genome lengths can be used (if an estimated genome length is not provided by the user) to ensure the estimated coverage statistics are accurate.\n</code></pre> <pre><code>!!! techdetails \"NanoPlot Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_nanoplot.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/basic_statistics/task_nanoplot.wdl) |\n    | Software Source Code | [NanoPlot on GitHub](https://github.com/wdecoster/NanoPlot) |\n    | Software Documentation | [NanoPlot Documentation](https://github.com/wdecoster/NanoPlot/blob/master/README.md) |\n    | Original Publication(s) | [NanoPack2: population-scale evaluation of long-read sequencing data](https://academic.oup.com/bioinformatics/article/39/5/btad311/7160911) |\n</code></pre>"},{"location":"common_text/nanoq_task/","title":"Nanoq task","text":"<code>Nanoq</code>: Read Filtering <p>Reads are filtered by length and quality using <code>nanoq</code>. By default, sequences with less than 500 basepairs and quality scores lower than 10 are filtered out to improve assembly accuracy. These defaults are able to be modified by the user.</p> <p>Nanoq Technical Details</p> Links Task task_nanoq.wdl Software Source Code Nanoq on GitHub Software Documentation Nanoq Documentation Original Publication(s) Nanoq: ultra-fast quality control for nanopore reads"},{"location":"common_text/ncbi_datasets_task/","title":"Ncbi datasets task","text":"NCBI Datasets <pre><code>##### NCBI Datasets\n</code></pre> <pre><code>The [`NCBI Datasets`](https://www.ncbi.nlm.nih.gov/datasets/) task downloads specified assemblies from NCBI using either the [virus](https://www.ncbi.nlm.nih.gov/datasets/docs/v2/reference-docs/data-packages/virus-genome/) or [genome](https://www.ncbi.nlm.nih.gov/datasets/docs/v2/reference-docs/data-packages/genome/) (for all other genome types) package as appropriate.\n</code></pre> <pre><code>This task uses the accession ID output from the `skani` task to download the the most closely related reference genome to the input assembly. The downloaded reference is then used for downstream analysis, including variant calling and consensus generation.\n</code></pre> <pre><code>!!! dna \"`include_gbff` behavior\"\n    If `include_gbff` is set to `true`, the gbff file will be used as the reference for `Snippy_Variants` and `Snippy_Tree`. If `include_gbff` is set to `false`, the fasta file will be used as the reference for `Snippy_Variants` and `Snippy_Tree`. Tree topology should not differ, though annotations may.\n</code></pre> <pre><code>!!! techdetails \"NCBI Datasets Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_ncbi_datasets.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/utilities/data_import/task_ncbi_datasets.wdl) |\n    | Software Source Code | [NCBI Datasets on GitHub](https://github.com/ncbi/datasets) |\n    | Software Documentation | [NCBI Datasets Documentation on NCBI](https://www.ncbi.nlm.nih.gov/datasets/docs/v2/) |\n    | Original Publication(s) | [Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets](https://doi.org/10.1038/s41597-024-03571-y) |\n</code></pre>"},{"location":"common_text/ncbi_identify_task/","title":"Ncbi identify task","text":"<code>ncbi_identify</code> <p>The <code>ncbi_identify</code> task uses <code>NCBI Datasets</code> to search the NCBI Viral Genome Database and acquire taxonomic metadata from a user's inputted taxonomy and desired taxonomic rank. This task will always return a taxon ID, name, and rank, and it facilitates multiple downstream functions, including read classification and targeted read extraction. This task also generates a comprehensive summary file of all successful hits to the input <code>taxon</code>, which includes each taxon's accession number, completeness status, genome length, source, and other relevant metadata. Based on this summary, the task also calculates the average expected genome size for the input <code>taxon</code>.</p> <code>taxon</code> input parameter <p>This parameter accepts either a NCBI taxon ID (e.g. <code>11292</code>) or an organism name (e.g. <code>Lyssavirus rabies</code>).</p> <code>rank</code> a.k.a <code>read_extraction_rank</code> input parameter <p>Valid options include: <code>\"species\"</code>, <code>\"genus\"</code>, <code>\"family\"</code>, <code>\"order\"</code>, <code>\"class\"</code>, <code>\"phylum\"</code>, <code>\"kingdom\"</code>, or <code>\"domain\"</code>. By default it is set to <code>\"family\"</code>. This parameter filters metadata to report information only at the taxonomic <code>rank</code> specified by the user, regardless of the taxonomic rank implied by the original input <code>taxon</code>.</p> Important <ul> <li>The <code>rank</code> parameter must specify a taxonomic rank that is equal to or above the input taxon's taxonomic rank.</li> </ul> <p>Examples:</p> <ul> <li>If your input <code>taxon</code> is <code>Lyssavirus rabies</code> (species level) with <code>rank</code> set to <code>family</code>, the task will return information for the family of <code>Lyssavirus rabies</code>: taxon ID for Rhabdoviridae (11270), name \"Rhabdoviridae\", and rank \"family\".</li> <li>If your input <code>taxon</code> is <code>Lyssavirus</code> (genus level) with <code>rank</code> set to <code>species</code>, the task will fail because it cannot determine species information from an inputted genus.</li> </ul> <p>NCBI Datasets Technical Details</p> Links Task task_identify_taxon_id.wdl Software Source Code NCBI Datasets on GitHub Software Documentation NCBI Datasets Documentation on NCBI Original Publication(s) Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets"},{"location":"common_text/ncbi_scrub_task/","title":"Ncbi scrub task","text":"<code>HRRT</code>: Human Host Sequence Removal <p>All reads of human origin are removed, including their mates, by using NCBI's human read removal tool (HRRT). </p> <p>HRRT is based on the SRA Taxonomy Analysis Tool and employs a k-mer database constructed of k-mers from Eukaryota derived from all human RefSeq records with any k-mers found in non-Eukaryota RefSeq records subtracted from the database.</p> <p>NCBI-Scrub Technical Details</p> Links Task task_ncbi_scrub.wdl Software Source Code HRRT on GitHub Software Documentation HRRT on NCBI"},{"location":"common_text/nextclade_task/","title":"Nextclade task","text":"<code>nextclade</code> <p>Nextclade is an open-source project used to analyze viral genomes, particularly for clade assignment and mutation calling. Simply, Nextclade works by aligning viral genomes to a reference genome, calling variants between the two sequences, and then assigning clades based on those identified mutations. </p> <p>Clade assignment is performed via phylogenetic placement. Phylogenetic placement compares the mutations of the provided sequence to the mutations of each node found in a reference tree, where the root of that tree is the reference genome. The node that is most similar to the sample is used to both assign a clade designation and calculate where the sample should be placed in the phylogenetic tree.</p> <pre><code>Theiagen has implemented a full genome-based [Nextclade dataset](https://github.com/theiagen/rabies) for *L. rabies* with subclade classification resolution.\n</code></pre> <pre><code>!!! techdetails \"Nextclade Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_nextclade.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/taxon_id/task_nextclade.wdl) |\n    | Software Source Code | &lt;https://github.com/nextstrain/nextclade&gt; |\n    | Software Documentation | [Nextclade](https://docs.nextstrain.org/projects/nextclade/en/stable/) |\n    | Original Publication(s) | [Nextclade: clade assignment, mutation calling and quality control for viral genomes.](https://doi.org/10.21105/joss.03773) |\n</code></pre>"},{"location":"common_text/ngmaster_task/","title":"Ngmaster task","text":"<code>ngmaster</code>: Neisseria gonorrhoeae Sequence Typing <p>NG-MAST is currently the most widely used method for epidemiological surveillance of\u00a0Neisseria gonorrhoea. This tool is targeted at clinical and research microbiology laboratories that have performed WGS of\u00a0N. gonorrhoeae isolates and wish to understand the molecular context of their data in comparison to previously published epidemiological studies. As WGS becomes more routinely performed,\u00a0NGMASTER\u00a0has been developed to completely replace PCR-based NG-MAST, reducing time and labor costs.</p> <p>NG-STAR offers a standardized method of classifying seven well-characterized genes associated antimicrobial resistance in N. gonorrhoeae (penA, mtrR, porB, ponA, gyrA, parC and 23S rRNA) to three classes of antibiotics (cephalosporins, macrolides and fluoroquinolones).</p> <p>ngmaster combines two tools: NG-MAST (in silico multi-antigen sequencing typing) and NG-STAR (sequencing typing for antimicrobial resistance) and returns the results from both tools.</p> <p>ngmaster Technical Details</p> Links Task task_ngmaster.wdl Software Source Code ngmaster on GitHub Software Documentation ngmaster on GitHub Original Publication(s) NGMASTER: in silico multi-antigen sequence typing for Neisseria gonorrhoeae"},{"location":"common_text/pangolin_task/","title":"Pangolin task","text":"<code>pangolin</code> <p>Pangolin (Phylogenetic Assignment of Named Global Outbreak Lineages) was developed to implement a dynamic nomenclature for designating SARS-CoV-2 lineage assignments and is used by researchers and public health agencies worldwide to track the spread and transmission of SARS-CoV-2.</p> <p>Pangolin aligns input sequences against an early SARS-CoV-2 reference and generates a unique hash for the alignment. The hash is checked against a designation cache to see if it matches any previously identified lineages, and is checked via scorpio (Serious Constellations of Reoccuring Phylogenetically-Independent Origin) to determine if the hash matches any variant of concern (VOC) constellations, which are groups of functionally meaningful mutations that can independently evolve. Following a QC check, an inference pipeline is run: either pangoLEARN or UShER (which is the default inference model). The final lineage report is then generated.</p> <p>Pangolin Technical Details</p> Links Task task_pangolin.wdl Software Source Code Pangolin on GitHub Software Documentation Pangolin on cov-lineages.org Original Publication(s) A dynamic nomenclature proposal for SARS-CoV-2 lineages to assist genomic epidemiology"},{"location":"common_text/parse_mapping_task/","title":"Parse mapping task","text":"<code>parse_mapping</code> <pre><code>The `sam_to_sorted_bam` sub-task converts the output SAM file from the `minimap2` task and converts it to a BAM file. It then sorts the BAM file by coordinate, and creates a BAM index file.\n\n??? dna \"`min_map_quality` input parameter\"\n    This parameter accepts an integer value to set the minimum mapping quality for variant calling and subsequent consensus sequence generation. The default value is `20`.\n</code></pre> <pre><code>The `bam_to_unaligned_fastq` task will extract a FASTQ file of reads that failed to align, while removing unpaired reads.\n</code></pre> <pre><code>The `mask_low_coverage` sub-task is used to mask low coverage regions in the `reference_fasta` file to improve the accuracy of the final consensus genome. Coverage thresholds are defined by the `min_depth` parameter, which specifies the minimum read depth required for a base to be retained. Bases falling below this threshold are replaced with \"N\"s to clearly mark low confidence regions. The masked reference is then combined with variants from the `clair3` task to produce the final consensus genome.\n\n??? dna \"`min_depth` input parameter\"\n    This parameter accepts an integer value to set the minimum read depth for variant calling and subsequent consensus sequence generation. The default value is `10`.\n</code></pre> <pre><code>!!! techdetails \"`parse_mapping` Technical Details\"\n    | | Links |\n    |---|---|\n    | Task | [task_parse_mapping.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/utilities/data_handling/task_parse_mapping.wdl) |\n    | Software Source Code | [samtools on GitHub](https://github.com/samtools/samtools) |\n    | Software Documentation | [samtools](https://www.htslib.org/doc/samtools.html) |\n    | Original Publication(s) | [The Sequence Alignment/Map format and SAMtools](https://doi.org/10.1093/bioinformatics/btp352)&lt;br&gt;[Twelve Years of SAMtools and BCFtools](https://doi.org/10.1093/gigascience/giab008) |\n</code></pre>"},{"location":"common_text/pasty_task/","title":"Pasty task","text":"<code>pasty</code>: Serotyping <p><code>pasty</code> is a tool for in silico serogrouping of Pseudomonas aeruginosa isolates. <code>pasty</code> was developed by Robert Petit, based on the PAst tool from the Centre for Genomic Epidemiology.</p> <p><code>pasty</code> uses the <code>camlhmp</code> tool to identify the serogroup. It uses BLAST to compare an input asssembly against a set of O-antigens. The serogroup can be predicted based off of those results.</p> <p>pasty Technical Details</p> Links Task task_pasty.wdl Software Source Code pasty on GitHub Software Documentation pasty on GitHub Original Publication(s) Application of Whole-Genome Sequencing Data for O-Specific Antigen Analysis and In Silico Serotyping of Pseudomonas aeruginosa Isolates."},{"location":"common_text/pbptyper_task/","title":"Pbptyper task","text":"<code>PBPtyper</code>: Penicillin-Binding Protein Genotyping <p>The Penicillin-binding proteins (PBP) are responsible for the minimum inhibitory concentration (MIC) phenotypes for beta-lactam antibiotics, which are the drugs of choice for treating pneumococcal infections. In Streptococcus pneumoniae, these PBP genes (PBP1a, PBP2b, and PBP2x) can be identified and typed with PBPTyper to help predict beta-lactam resistance levels in S. pneumoniae, which can be invaluable in disease surveillance.</p> <p>pbptyper uses BLAST and average nucleotide identity (ANI) to identify the closest matching PBP types from a database of known PBP types and uses the PBP typing scheme described by the linked publication below.</p> <p>pbptyper Technical Details</p> Links Task task_pbptyper.wdl Software Source Code pbptyper on GitHub Software Documentation pbptyper on GitHub Original Publication(s) PBP typing method: Penicillin-Binding Protein Transpeptidase Signatures for Tracking and Predicting \u03b2-Lactam Resistance Levels in Streptococcus pneumoniae"},{"location":"common_text/phylocompare_task/","title":"Phylocompare task","text":"<code>phylocompare</code> <p>PhyloCompare will clean two phylogenies and validate if the distance between these two phylogenies' topologies is less than an inputted <code>max_distance</code> float (0 by default). Phylogenies are cleaned by converting 0 branch length nodes into polytomies, and any detected polytomies are reported as a flag. Polytomies may arbitrarily yield a non-0 distance, though if a 0 distance is reported with a polytomy then it indicates that the polytomy did not confound distance calculation.</p> <p>For unrooted phylogenies, PhyloCompare calculates the Lin-Rajan-Moret distance, and for rooted phylogenies, PhyloCompare calculates the matching cluster distance. The Robinson-Foulds distance is also calculated, though it is disregarded in validation (see citations for criticism).</p> <p>PhyloCompare Technical Details</p> Links Task task_phylocompare.wdl Software Source Code https://github.com/theiagen/theiaphylo Software Documentation TheiaPhylo"},{"location":"common_text/pilon_task/","title":"Pilon task","text":"<code>Pilon</code>: Assembly Polishing <p><code>Pilon</code> is a tool that uses read alignments to correct errors in an assembly.</p> <pre><code>The `bwa`-generated alignment of the read data to the assembly is used to identify inconsistences between the reads and the assembly in order to correct them. `Pilon` will attempt to fix individual base errors and small indels using the read data. This can improve the overall quality of the assembly, especially when the assembler has made mistakes due to sequencing errors or low coverage regions.\n\nThe default parameters were set to mimic the parameters used by [Shovill](https://github.com/tseemann/shovill): `--fix bases --minq 60 --minqual 3 --mindepth 0.25`. These can be modified by the user.\n</code></pre> <pre><code>It is used to polish the assembly produced by metaSPAdes. The input to Pilon is the sorted BAM file produced by `samtools`, and the original draft assembly produced by `metaspades`.\n</code></pre> <pre><code>!!! techdetails \"Pilon Technical Details\"\n    | | Links |\n    |---|---|\n    | Task | [task_pilon.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/read_filtering/task_pilon.wdl) |\n    | Software Source Code | [Pilon on GitHub](https://github.com/broadinstitute/pilon) |\n    | Software Documentation | [Pilon Wiki](https://github.com/broadinstitute/pilon/wiki) |\n    | Original Publication(s) | [Pilon: An Integrated Tool for Comprehensive Microbial Variant Detection and Genome Assembly Improvement](https://doi.org/10.1371/journal.pone.0112963) |\n</code></pre>"},{"location":"common_text/plasmidfinder_task/","title":"Plasmidfinder task","text":"<code>PlasmidFinder</code>: Plasmid Identification (optional) <p>To activate this task, set <code>call_plasmidfinder</code> to <code>true</code>.</p> <p><code>PlasmidFinder</code>, from the Center for Genomic Epidemiology, detects plasmids in total or partially sequenced genomes and identifies the closest plasmid type in the database for typing purposes.</p> What are plasmids? <p>Plasmids are double-stranded circular or linear DNA molecules that are capable of replication independently of the chromosome and may be transferred between different species and clones. Many plasmids contain resistance or virulence genes, though some do not clearly confer an advantage to their host bacterium.</p> <p>PlasmidFinder Technical Details</p> Links Task task_plasmidfinder.wdl Software Source Code PlasmidFinder Tool on BitBucketPlasmidFinder Database on BitBucket Software Documentation PlasmidFinder on BitBucket Original Publication(s) In Silico Detection and Typing of Plasmids using PlasmidFinder and Plasmid Multilocus Sequence Typing"},{"location":"common_text/polypolish_task/","title":"Polypolish task","text":"<code>Polypolish</code>: Hybrid Assembly Polishing for ONT and Illumina data <p>If short reads are provided with the optional <code>illumina_read1</code> and <code>illumina_read2</code> inputs, Polypolish will use those short-reads to correct errors in the long-read assemblies. Uniquely, Polypolish uses the short-read alignments where each read is aligned to all possible locations, meaning that even repeat regions will have error correction.</p> <p>Polypolish Technical Details</p> Links Task task_polypolish.wdl Software Source Code Polypolish on GitHub Software Documentation Polypolish Documentation Original Publication(s) Polypolish: short-read polishing of long-read bacterial genome assembliesHow low can you go? Short-read polishing of Oxford Nanopore bacterial genome assemblies"},{"location":"common_text/poppunk_task/","title":"Poppunk task","text":"<code>PopPUNK</code>: Global Pneumococcal Sequence Cluster Typing <p>Global Pneumococcal Sequence Clusters (GPSC) define and name pneumococcal strains. Each GPSC is an international definition of a pneumococcal lineage and can capture all variations across the entire genome, leading to better vaccine development due to increased disease surveillance. GPSC designation is undertaken using the PopPUNK (Population Partitioning Using Nucleotide K-mers) software and the GPSC database.</p> <p>PopPUNK works by using variable-length k-mers to distinguish between sample divergences in shared genomic content. Clusters are assigned based on the resulting pairwise distance distributions. </p> <p>Interpreting GPSC results</p> <ul> <li>In the\u00a0<code>*_external_clusters.csv</code> novel clusters are assigned NA. For isolates that are assigned a novel cluster and pass QC, you can email\u00a0globalpneumoseq@gmail.com\u00a0to have these novel clusters added to the database.</li> <li>Unsampled diversity in the pneumococcal population may represent missing variation that links two GPS clusters. When this is discovered, GPSCs are merged and the merge history is indicated. For example, if GPSC23 and GPSC362 merged, the GPSC would be reported as GPSC23, with a merge history of GPSC23;362.</li> </ul> <p>PopPUNK Technical Details</p> Links Task task_poppunk_streppneumo.wdl Software Source Code PopPUNK on GitHubGlobal Pneumococcal Sequencing ProjectGPSC Database Software Documentation PopPUNK DocumentationGPS Training Documentation Original Publication(s) PopPUNK tool: Fast and flexible bacterial genomic epidemiology with PopPUNKGPSC database: International genomic definition of pneumococcal lineages, to contextualise disease, antibiotic resistance and vaccine impact"},{"location":"common_text/porechop_task/","title":"Porechop task","text":"<code>porechop</code> <pre><code>Read trimming is optional and can be enabled by setting the `run_porchop` input variable to true.\n</code></pre> <pre><code>Porechop is a tool for finding and removing adapters from ONT data. Adapters on the ends of reads are trimmed, and when a read has an adapter in the middle, the read is split into two.\n</code></pre> <pre><code>The `porechop` task is optional and is turned off by default. It can be enabled by setting the `call_porechop` parameter to `true`.\n</code></pre> <pre><code>!!! techdetails \"Porechop Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | WDL Task | [task_porechop.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/read_filtering/task_porechop.wdl) |\n    | Software Source Code | [Porechop on GitHub](https://github.com/rrwick/Porechop) |\n    | Software Documentation | [https://github.com/rrwick/Porechop#porechop](https://github.com/rrwick/Porechop#porechop) |\n</code></pre>"},{"location":"common_text/primer_trim_task/","title":"Primer trim task","text":"<code>primer_trim</code> Details <p>This task trims the primer sequences from the aligned bam file with iVar. The optional input, <code>keep_noprimer_reads</code>, does not have to be modified.</p> <p>Primer Trim Technical Details</p> Links Task task_ivar_primer_trim.wdl Software Source Code https://github.com/andersen-lab/ivar Software Documentation https://andersen-lab.github.io/ivar/html/manualpage.html Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar"},{"location":"common_text/prokka_task/","title":"Prokka task","text":"<code>Prokka</code>: Assembly Annotation (default) <p>Assembly annotation is available via <code>Prokka</code> as default.</p> <p><code>Prokka</code> is a prokaryotic genome annotation tool used to identify and describe features of interest within the genome sequence. Prokka annotates the genome by querying three core databases: ISfinder, NCBI's Bacterial Antimicrobial Resistance Reference Gene Database, and UniProtKB (SwissProt). Additional databases can be used or specified, with instructions on how to do so located in the Prokka README.</p> <p>The most versatile output from Prokka is likely the GFF3 file, as it contains all of the generated information, though other file formats are available for the instances when a reduction of the GFF3 is useful.</p> <p>Prokka Technical Details</p> Links Task task_prokka.wdl Software Source Code Prokka on GitHub Software Documentation Prokka on GitHub Original Publication(s) Prokka: rapid prokaryotic genome annotation"},{"location":"common_text/qc_check_task/","title":"Qc check task","text":"<code>qc_check</code>: Check QC Metrics Against User-Defined Thresholds (optional) <p>To activate this task, provide a <code>qc_check_table</code> as input.</p> <p>The <code>qc_check</code> task compares generated QC metrics against user-defined thresholds for each metric. This task will run if the user provides a <code>qc_check_table</code> TSV file. If all QC metrics meet the threshold, the <code>qc_check</code> output variable will read <code>QC_PASS</code>. Otherwise, the output will read <code>QC_NA</code> if the task could not proceed or <code>QC_ALERT</code> followed by a string indicating what metric failed.</p> <pre><code>The `qc_check` task applies quality thresholds according to the specified organism, which should match the _standardized_ `organism` input in the TheiaCoV workflows.\n</code></pre> <pre><code>The `qc_check` task applies quality thresholds according to the sample taxa. The sample taxa is taken from the `gambit_predicted_taxon` value inferred by the GAMBIT module OR can be manually provided by the user using the `expected_taxon` workflow input.\n</code></pre> <pre><code>??? toggle \"Formatting the _qc_check_table.tsv_\"\n    - The first column of the qc_check_table lists the `organism` that the task will assess and the header of this column must be \"**taxon**\".\n</code></pre> <pre><code>    - Any genus or species can be included as a row of the qc_check_table. However, these taxa must **uniquely** match the sample taxa, meaning that the file can include multiple species from the same genus (Vibrio_cholerae and Vibrio_vulnificus), but not both a genus row and species within that genus (Vibrio and Vibrio cholerae). **The taxa should be formatted with the first letter capitalized and underscores in lieu of spaces.**\n</code></pre> <pre><code>    - Each subsequent column indicates a QC metric and lists a threshold for each organism that will be checked. **The column names must exactly match expected values, so we highly recommend copy and pasting the header from the template file below as a starting place.**\n\n??? toggle \"Template _qc_check_table.tsv_ files\"\n</code></pre> <pre><code>    - TheiaCoV_Illumina_PE: [TheiaCoV_Illumina_PE_qc_check_template.tsv](../../assets/files/TheiaCoV_Illumina_PE_qc_check_template.tsv)\n</code></pre> <pre><code>    - TheiaProk_Illumina_PE: [theiaprok_illumina_pe_qc_check_template.tsv](../../assets/files/TheiaProk_Illumina_PE_qc_check_template.tsv)\n    - TheiaProk_FASTA: [theiaprok_fasta_qc_check_template.tsv](../../assets/files/TheiaProk_FASTA_qc_check_template.tsv)\n</code></pre> <pre><code>    - TheiaEuk_Illumina_PE_PHB: [theiaeuk_qc_check_template.tsv](../../assets/files/TheiaEuk_qc_check_template.tsv)\n</code></pre> <pre><code>    !!! warning \"Example Purposes Only\"\n        The QC threshold values shown in the file above are for example purposes only and should not be presumed to be sufficient for every dataset.\n\n!!! techdetails \"qc_check Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_qc_check_phb.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/comparisons/task_qc_check_phb.wdl) |\n</code></pre>"},{"location":"common_text/quasitools_task/","title":"Quasitools task","text":"<code>quasitools</code> <p><code>quasitools</code> performs genomic characterization for HIV by using the HyDRA module for identifying drug resistance mutations in HIV-1 samples based on the Stanford HIV Drug Resistance Database and the 2009 WHO list for Surveillance of Transmitted HIVDR; see also the papers linked below.</p> <p>The HyDRA module in quasitools maps the sample sequence against an annotated HIV-1 reference and performs variant calling. Those variants are compared to the databases described above, and any matches are reported, along with the complete list of variants. </p> <p>quasitools Technical Details</p> Links Task task_quasitools.wdl Software Source Code quasitools on GitHub Software Documentation quasitools HyDRA README Original Publication(s) quasitools preprint: quasitools: A Collection of Tools for Viral Quasispecies AnalysisWHO 2009 Database: Drug resistance mutations for surveillance of transmitted HIV-1 drug-resistance: 2009 updateStanford Database: Human immunodeficiency virus reverse transcriptase and protease sequence database"},{"location":"common_text/quast_task/","title":"Quast task","text":"<code>quast</code>: Assembly Quality Assessment <p>QUAST stands for QUality ASsessment Tool. It evaluates genome/metagenome assemblies by computing various metrics without a reference being necessary. It includes useful metrics such as number of contigs, length of the largest contig and N50.</p> <p>QUAST Technical Details</p> Links Task task_quast.wdl Software Source Code QUAST on GitHub Software Documentation QUAST Manual on SourceForge Original Publication(s) QUAST: quality assessment tool for genome assemblies"},{"location":"common_text/racon_task/","title":"Racon task","text":"<code>Racon</code>: Polishing of Flye assembly (alternative; optional) <p>Polishing is optional and can be skipped by setting the <code>skip_polishing</code> variable to true. If polishing is skipped, then neither Medaka or Racon will run.</p> <p><code>Racon</code> is an alternative to using <code>medaka</code> for assembly polishing, and can be run by setting the <code>polisher</code> input to \"racon\".  Racon is a consensus algorithm designed for refining raw de novo DNA assemblies generated from long, uncorrected sequencing reads.</p> <p>Racon Technical Details</p> Links WDL Task task_racon.wdl Software Source Code Racon on GitHub Software Documentation Racon Documentation Original Publication(s) Fast and accurate de novo genome assembly from long uncorrected reads"},{"location":"common_text/rasusa_task/","title":"Rasusa task","text":"<code>Rasusa</code>: Read subsampling (optional, on by default) <code>Rasusa</code>: Read Subsampling <pre><code>To deactivate this task, set `call_rasusa` to `false`.\n</code></pre> <pre><code>`Rasusa` is a tool to randomly subsample sequencing reads to a specified coverage without assuming that all reads are of equal length, making it especially suitable for long-read data while still being applicable to short-read data.\n</code></pre> <pre><code>The `Rasusa` task performs subsampling on the input raw reads. By default, it subsamples reads to a target depth of 250X, using the estimated genome length either generated by the `ncbi_identify` task or provided directly by the user. Disabled by default, users can enable it by setting the `skip_rasusa` variable to `false`. The target subsampling depth can also be adjusted by modifying the `coverage` variable.\n\n??? dna \"`coverage` input parameter\"\n    This parameter specifies the target coverage for subsampling. The default value is `250`, but users can adjust it as needed.\n</code></pre> <pre><code>The `Rasusa` task performs subsampling on the input raw reads. By default, this task will subsample TheiaProk_ONT reads to a depth of 150X using an estimated genome length of 5 million basepairs (0.7 Mb higher than the average bacterial genome length), and TheiaEuk_ONT reads using an estimated genome length of 50 million basepairs. The estimated genome length can be changed by the user by providing a different value for the `genome_length` input parameter. The target subsampling depth can also be adjusted by modifying the `subsample_coverage` variable.\n</code></pre> <pre><code>For TheiaEuk_Illumina_PE, the estimated genome length is determined by the `read_screen` task. Please note that the user can prevent the task from being launched by setting the `call_rasusa` variable to false.\n</code></pre> <pre><code>???+ warning \"Non-deterministic output(s)\"\n    This task may yield non-deterministic outputs since it performs _random_ subsampling. To ensure reproducibility, set a a value for the `rasusa_seed` optional input variable.\n\n!!! techdetails \"Rasusa Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_rasusa.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/utilities/task_rasusa.wdl) |\n    | Software Source Code | [Rasusa on GitHub](https://github.com/mbhall88/rasusa) |\n    | Software Documentation | [Rasusa on GitHub](https://github.com/mbhall88/rasusa) |\n    | Original Publication(s) | [Rasusa: Randomly subsample sequencing reads to a specified coverage](https://doi.org/10.21105/joss.03941) |\n</code></pre>"},{"location":"common_text/raven_task/","title":"Raven task","text":"<code>raven</code> <p>The <code>raven</code> task is used to create a de novo assembly from cleaned reads. Raven is an overlap-layout-consensus based assembler that accelerates the overlap step, constructs an assembly graph from reads pre-processed with pile-o-grams, applies a novel and robust graph simplification method based on graph drawings, and polishes unambiguous graph paths using Racon. </p> <pre><code>Based on internal benchmarking against Flye and results reported by [Cook et al. (2024)](https://pmc.ncbi.nlm.nih.gov/articles/PMC11092197/), Raven is faster, produces more contiguous assemblies, and yields more complete genomes within TheiaViral according to CheckV quality assessment (see task `checkv` for technical details).\n\n??? dna \"`call_raven` input parameter\"\n    This parameter controls whether or not the `raven` task is called by the workflow. By default, `call_raven` is set to `true` because Raven is used as the primary assembler. Raven is generally recommended for most users, but it might not perform optimally on all datasets. If users encounter issues with Raven, they can set the `call_raven` variable to `false` to bypass the `raven` task and instead *de novo* assemble using Flye (see task `flye` for details). Additionally, if the Raven task fails during execution, the workflow will automatically fall back to using Flye for *de novo* assembly.\n</code></pre> <pre><code>???+ warning \"Error traceback\"\n    Raven may fail with cryptic \"segmentation fault\" (segfault) errors or by failing to output an output file. It is difficult to traceback the source of these issues, though increasing the `memory` parameter may resolve some errors.\n\n???+ warning \"Non-deterministic output(s)\"\n    This task may yield non-deterministic outputs.\n\n!!! techdetails \"Raven Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_raven.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/assembly/task_raven.wdl) |\n    | Software Source Code | [Raven on GitHub](https://github.com/lbcb-sci/raven)\n    | Software Documentation | [Raven Documentation](https://github.com/lbcb-sci/raven/blob/master/README.md)\n    | Original Publication(s) | [Time- and memory-efficient genome assembly with Raven](https://doi.org/10.1038/s43588-021-00073-4) |\n</code></pre>"},{"location":"common_text/read_qc_trim_illumina_wf/","title":"Read qc trim illumina wf","text":"<code>read_QC_trim</code>: Read Quality Trimming, Adapter Removal, Quantification, and Identification <p><code>read_QC_trim</code> is a sub-workflow that removes low-quality reads, low-quality regions of reads, and sequencing adapters to improve data quality. It uses a number of tasks, described below. The differences between the PE and SE versions of the <code>read_QC_trim</code> sub-workflow lie in the default parameters, the use of two or one input read file(s), and the different output files.</p> <pre><code>??? task \"`HRRT`: Human Host Sequence Removal\"\n    All reads of human origin **are removed**, including their mates, by using NCBI's [**human read removal tool (HRRT)**](https://github.com/ncbi/sra-human-scrubber).\n\n    HRRT is based on the [SRA Taxonomy Analysis Tool](https://doi.org/10.1186/s13059-021-02490-0) and employs a k-mer database constructed of k-mers from Eukaryota derived from all human RefSeq records with any k-mers found in non-Eukaryota RefSeq records subtracted from the database.\n\n    !!! techdetails \"NCBI-Scrub Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Task | [task_ncbi_scrub.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/read_filtering/task_ncbi_scrub.wdl) |\n        | Software Source Code | [HRRT on GitHub](https://github.com/ncbi/sra-human-scrubber) |\n        | Software Documentation |  [HRRT on NCBI](https://ncbiinsights.ncbi.nlm.nih.gov/2023/02/02/scrubbing-human-sequences-sra-submissions/) |\n</code></pre> <pre><code>!!! dna \"\"\n    By default, `read_processing` is set to `\"trimmomatic\"`. To use `fastp` instead, set `read_processing` to `\"fastp\"`. These tasks are mutually exclusive.\n\n    ??? task \"`Trimmomatic`: Read Trimming (default)\"\n        Read proccessing is available via `Trimmomatic` by default.\n\n        Trimmomatic trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with `trim_window_size`), cutting once the average quality within the window falls below the `trim_quality_trim_score` (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below `trim_minlen` (default of 75 for paired-end, 25 for single-end).\n\n        !!! techdetails \"`Trimmomatic` Technical Details\"\n            |  | Links |\n            | --- | --- |\n            | Task | [task_trimmomatic.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/read_filtering/task_trimmomatic.wdl) |\n            | Software Source Code | [Trimmomatic on GitHub](https://github.com/usadellab/Trimmomatic) |\n            | Software Documentation | [Trimmomatic Website](http://www.usadellab.org/cms/?page=trimmomatic) |\n            | Original Publication(s) | [Trimmomatic: a flexible trimmer for Illumina sequence data](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4103590/) |\n\n\n    ??? task \"`fastp`: Read Trimming (alternative)\"\n        To activate this task, set `read_processing` to `\"fastp\"`.\n\n        `fastp` trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with `trim_window_size`), cutting once the average quality within the window falls below the `trim_quality_trim_score` (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below `trim_minlen` (default of 75 for paired-end, 25 for single-end).\n\n        `fastp` also has additional default parameters and features that are not a part of `trimmomatic`'s default configuration.\n\n        ??? toggle \"`fastp` default read-trimming parameters\"\n            | Parameter | Explanation |\n            | --- | --- |\n            | -g | enables polyG tail trimming |\n            | -5 20 | enables read end-trimming |\n            | -3 20 | enables read end-trimming |\n            | --detect_adapter_for_pe | enables adapter-trimming **only for paired-end reads** |\n\n            Additional arguments can be passed using the `fastp_args` optional parameter.\n\n        !!! techdetails \"Trimmomatic and fastp Technical Details\"\n            |  | Links |\n            | --- | --- |\n            | Task | [task_fastp.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/read_filtering/task_fastp.wdl) |\n            | Software Source Code | [fastp on GitHub](https://github.com/OpenGene/fastp) |\n            | Software Documentation | [fastp on GitHub](https://github.com/OpenGene/fastp) |\n            | Original Publication(s) | [fastp: an ultra-fast all-in-one FASTQ preprocessor](https://academic.oup.com/bioinformatics/article/34/17/i884/5093234?login=false) |\n\n\n??? task \"`BBDuk`: Adapter Trimming and PhiX Removal\"\n    Adapters are manufactured oligonucleotide sequences attached to DNA fragments during the library preparation process. In Illumina sequencing, these adapter sequences are required for attaching reads to flow cells. You can read more about [Illumina adapters here](https://emea.support.illumina.com/bulletins/2020/06/illumina-adapter-portfolio.html). For genome analysis, it's important to remove these sequences since they're not actually from your sample. If you don't remove them, the downstream analysis may be affected.\n\n    The `bbduk` task removes adapters from sequence reads. To do this:\n\n    - [Repair](https://archive.jgi.doe.gov/data-and-tools/software-tools/bbtools/bb-tools-user-guide/repair-guide/) from the [BBTools](https://archive.jgi.doe.gov/data-and-tools/software-tools/bbtools/) package reorders reads in paired fastq files to ensure the forward and reverse reads of a pair are in the same position in the two fastq files (it _re-pairs_).\n    - [BBDuk](https://archive.jgi.doe.gov/data-and-tools/software-tools/bbtools/bb-tools-user-guide/bbduk-guide/)  (*\"Bestus Bioinformaticus\" Decontamination Using Kmers*) is then used to trim the adapters and filter out all reads that have a 31-mer match to [PhiX](https://emea.illumina.com/products/by-type/sequencing-kits/cluster-gen-sequencing-reagents/phix-control-v3.html), which is commonly added to Illumina sequencing runs to monitor and/or improve overall run quality.\n\n    !!! techdetails \"BBDuk Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Task | [task_bbduk.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/read_filtering/task_bbduk.wdl) |\n        | Software Source Code | [BBMap on SourceForge](https://sourceforge.net/projects/bbmap/) |\n        | Software Documentation | [BBDuk Guide (archived)](https://archive.jgi.doe.gov/data-and-tools/software-tools/bbtools/bb-tools-user-guide/bbduk-guide/) |\n\n\n!!! dna \"\"\n    By default, `read_qc` is set to `\"fastq_scan\"`. To use `fastqc` instead, set `read_qc` to `\"fastqc\"`. These tasks are mutually exclusive.\n\n    ??? task \"`fastq-scan`: Read Quantification (default)\"\n        Read quantification is available via `fastq-scan` by default.\n\n        `fastq-scan` quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect **fewer** clean reads than raw reads.\n\n        !!! techdetails \"`fastq-scan` Technical Details\"\n            |  | Links |\n            | --- | --- |\n            | Task | [task_fastq_scan.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/basic_statistics/task_fastq_scan.wdl)|\n            | Software Source Code | [fastq-scan on GitHub](https://github.com/rpetit3/fastq-scan) |\n            | Software Documentation | [fastq-scan on GitHub](https://github.com/rpetit3/fastq-scan/blob/master/README.md) |\n\n\n    ??? task \"`FastQC`: Read Quantification (alternative)\"\n        To activate this task, set `read_qc` to `\"fastqc\"`.\n\n        `FastQC` quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect **fewer** clean reads than raw reads.\n\n        This tool also provides a graphical visualization of the read quality.\n\n        !!! techdetails \"`FastQC` Technical Details\"\n            |  | Links |\n            | --- | --- |\n            | Task | [task_fastqc.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/basic_statistics/task_fastqc.wdl) |\n            | Software Source Code | [FastQC on Github](https://github.com/s-andrews/FastQC) |\n            | Software Documentation | [FastQC Website](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) |\n</code></pre> <pre><code>??? task \"`MIDAS`: Read Identification (optional)\"\n    To activate this task, set `call_midas` to `true`.\n\n    The `MIDAS` task is for the identification of reads to detect contamination with non-target taxa.\n\n    The MIDAS tool was originally designed for metagenomic sequencing data but has been co-opted for use with bacterial isolate WGS methods. It can be used to detect contamination present in raw sequencing data by estimating bacterial species abundance in bacterial isolate WGS data. If a secondary genus is detected above a relative frequency of 0.01 (1%), then the sample should fail QC and be investigated further for potential contamination.\n\n    This task is similar to those used in commercial software, BioNumerics, for estimating secondary species abundance.\n\n    ??? toggle \"How are the MIDAS output columns determined?\"\n\n        Example MIDAS report in the `midas_report` column:\n\n        | species_id | count_reads | coverage | relative_abundance |\n        | --- | --- | --- | --- |\n        | Salmonella_enterica_58156 | 3309 | 89.88006645 | 0.855888033 |\n        | Salmonella_enterica_58266 | 501 | 11.60606061 | 0.110519371 |\n        | Salmonella_enterica_53987 | 99 | 2.232896237 | 0.021262881 |\n        | Citrobacter_youngae_61659 | 46 | 0.995216227 | 0.009477003 |\n        | Escherichia_coli_58110 | 5 | 0.123668877 | 0.001177644 |\n\n        MIDAS report column descriptions:\n\n        - species_id: species identifier\n        - count_reads: number of reads mapped to marker genes\n        - coverage: estimated genome-coverage (i.e. read-depth) of species in metagenome\n        - relative_abundance: estimated relative abundance of species in metagenome\n\n        The value in the `midas_primary_genus` column is derived by ordering the rows in order of \"relative_abundance\" and identifying the genus of top species in the \"species_id\" column (Salmonella). The value in the `midas_secondary_genus` column is derived from the genus of the second-most prevalent genus in the \"species_id\" column (Citrobacter). The `midas_secondary_genus_abundance` column is the \"relative_abundance\" of the second-most prevalent genus (0.009477003). The `midas_secondary_genus_coverage` is the \"coverage\" of the second-most prevalent genus (0.995216227).\n\n    **MIDAS Reference Database Overview**\n\n    The **MIDAS reference database** is a comprehensive tool for identifying bacterial species in metagenomic and bacterial isolate WGS data. It includes several layers of genomic data, helping detect species abundance and potential contaminants.\n\n    !!! dna \"Key Components of the MIDAS Database\"\n        1. **Species Groups**: \n            - MIDAS clusters bacterial genomes based on 96.5% sequence identity, forming over 5,950 species groups from 31,007 genomes. These groups align with the gold-standard species definition (95% ANI), ensuring highly accurate species identification.\n\n        2. **Genomic Data Structure**:\n            - _Marker Genes_: Contains 15 universal single-copy genes used to estimate species abundance.\n            - _Representative Genome_: Each species group has a selected representative genome, which minimizes genetic variation and aids in accurate SNP identification.\n            - _Pan-genome_: The database includes clusters of non-redundant genes, with options for multi-level clustering (e.g., 99%, 95%, 90% identity), enabling MIDAS to identify gene content within strains at various clustering thresholds.\n\n        3. **Taxonomic Annotation**: \n            - Genomes are annotated based on consensus Latin names. Discrepancies in name assignments may occur due to factors like unclassified genomes or genus-level ambiguities.\n\n    ---\n\n    **Using the Default MIDAS Database**\n\n    TheiaProk and TheiaEuk use the pre-loaded MIDAS database in Terra (see input table for current version) by default for bacterial species detection in metagenomic data, requiring no additional setup.\n\n    !!! tip \"Create a Custom MIDAS Database\"\n        Users can also build their own custom MIDAS database if they want to include specific genomes or configurations. This custom database can replace the default MIDAS database used in Terra. To build a custom MIDAS database, follow the [MIDAS GitHub guide on building a custom database](https://github.com/snayfach/MIDAS/blob/master/docs/build_db.md). Once the database is built, users can upload it to a Google Cloud Storage bucket or Terra workkspace and provide the link to the database in the `midas_db` input variable.\n\n    ---\n\n    !!! techdetails \"MIDAS Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Task | [task_midas.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/taxon_id/contamination/task_midas.wdl) |\n        | Software Source Code | [MIDAS on GitHub](https://github.com/snayfach/MIDAS)\n        | Software Documentation | [MIDAS on GitHub](https://github.com/snayfach/MIDAS)\n        | Original Publication(s) | [An integrated metagenomics pipeline for strain profiling reveals novel patterns of bacterial transmission and biogeography](https://pubmed.ncbi.nlm.nih.gov/27803195) |\n</code></pre> <pre><code>??? task \"`Kraken2`: Read Identification (optional)\"\n    To activate this task, set `call_kraken` to `true` and provide a value for `kraken_db`.\n\n    `Kraken2` is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.\n\n\n\n\n    !!! info \"Database-dependent\"\n        This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at `gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz`.\n\n    As an alternative to `MIDAS` (see above), the `Kraken2` task can also be turned on through setting the `call_kraken` input variable as `true` for the identification of reads to detect contamination with non-target taxa.\n\n    A database must be provided if this optional module is activated, through the kraken_db optional input. A list of suggested databases can be found on [Kraken2 standalone documentation](../standalone/kraken2.md#databases).\n\n\n\n    !!! techdetails \"Kraken2 Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Task | [task_kraken2.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/taxon_id/contamination/task_kraken2.wdl) |\n        | Software Source Code | [Kraken2 on GitHub](https://github.com/DerrickWood/kraken2/)  |\n        | Software Documentation | [Kraken2 Documentation](https://github.com/DerrickWood/kraken2/blob/master/docs/MANUAL.markdown) |\n        | Original Publication(s) | [Improved metagenomic analysis with Kraken 2](https://link.springer.com/article/10.1186/s13059-019-1891-0) |\n</code></pre> <pre><code>??? task \"`Kraken2`: Read Identification\"\n\n    `Kraken2` is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.\n\n    Kraken2 is run on both the raw and clean reads.\n\n\n\n    !!! info \"Database-dependent\"\n        This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at `gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz`.\n\n\n\n\n\n    !!! techdetails \"Kraken2 Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Task | [task_kraken2.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/taxon_id/contamination/task_kraken2.wdl) |\n        | Software Source Code | [Kraken2 on GitHub](https://github.com/DerrickWood/kraken2/)  |\n        | Software Documentation | [Kraken2 Documentation](https://github.com/DerrickWood/kraken2/blob/master/docs/MANUAL.markdown) |\n        | Original Publication(s) | [Improved metagenomic analysis with Kraken 2](https://link.springer.com/article/10.1186/s13059-019-1891-0) |\n</code></pre> <pre><code>??? task \"`host_decontaminate`: Host Read Decontamination\"\n\n    Host genetic data is frequently incidentally sequenced alongside pathogens, which can negatively affect the quality of downstream analysis. Host Decontaminate attempts to remove host reads by aligning to a reference host genome acquired on-the-fly. The reference host genome can be acquired via [NCBI Taxonomy-compatible](https://www.ncbi.nlm.nih.gov/taxonomy) taxon input or assembly accession. Host Decontaminate maps inputted reads to the host genome using `minimap2`, reports mapping statistics to this host genome, and outputs the unaligned dehosted reads.\n\n    The detailed steps and tasks are as follows:\n\n    ??? toggle \"Taxonomic Identification\"\n\n        The `ncbi_identify` task uses [`NCBI Datasets`](https://www.ncbi.nlm.nih.gov/datasets/docs/v2/reference-docs/data-packages/taxonomy/) to search the NCBI Viral Genome Database and acquire taxonomic metadata from a user's inputted taxonomy and desired taxonomic rank. This task will always return a taxon ID, name, and rank, and it facilitates multiple downstream functions, including **read classification and targeted read extraction**. This task also generates a comprehensive summary file of all successful hits to the input `taxon`, which includes each taxon's accession number, completeness status, genome length, source, and other relevant metadata. Based on this summary, the task also calculates the average expected genome size for the input `taxon`.\n\n        ??? dna \"`taxon` input parameter\"\n            This parameter accepts either a NCBI taxon ID (e.g. `11292`) or an organism name (e.g. `Lyssavirus rabies`).\n\n        ??? dna \"`rank` a.k.a `read_extraction_rank` input parameter\"\n            Valid options include: `\"species\"`, `\"genus\"`, `\"family\"`, `\"order\"`, `\"class\"`, `\"phylum\"`, `\"kingdom\"`, or `\"domain\"`. By default it is set to `\"family\"`. This parameter filters metadata to report information only at the taxonomic `rank` specified by the user, regardless of the taxonomic rank implied by the original input `taxon`.\n\n        ???+ warning \"Important\"\n            - The `rank` parameter **must** specify a taxonomic rank that is ==equal to or above== the input taxon's taxonomic rank.\n\n            **Examples:**\n\n            - If your input `taxon` is `Lyssavirus rabies` (species level) with `rank` set to `family`, the task will return information for the family of `Lyssavirus rabies`: taxon ID for Rhabdoviridae (11270), name \"Rhabdoviridae\", and rank \"family\".\n            - If your input `taxon` is `Lyssavirus` (genus level) with `rank` set to `species`, the task will fail because it cannot determine species information from an inputted genus.\n\n        !!! techdetails \"NCBI Datasets Technical Details\"\n            |  | Links |\n            | --- | --- |\n            | Task | [task_identify_taxon_id.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/taxon_id/task_identify_taxon_id.wdl) |\n            | Software Source Code | [NCBI Datasets on GitHub](https://github.com/ncbi/datasets) |\n            | Software Documentation | [NCBI Datasets Documentation on NCBI](https://www.ncbi.nlm.nih.gov/datasets/docs/v2/) |\n            | Original Publication(s) | [Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets](https://doi.org/10.1038/s41597-024-03571-y) |\n\n\n    ??? toggle \"Download Accession\"\n\n        The [`NCBI Datasets`](https://www.ncbi.nlm.nih.gov/datasets/) task downloads specified assemblies from NCBI using either the [virus](https://www.ncbi.nlm.nih.gov/datasets/docs/v2/reference-docs/data-packages/virus-genome/) or [genome](https://www.ncbi.nlm.nih.gov/datasets/docs/v2/reference-docs/data-packages/genome/) (for all other genome types) package as appropriate.\n\n        This task uses the accession ID output from the `skani` task to download the the most closely related reference genome to the input assembly. The downloaded reference is then used for downstream analysis, including variant calling and consensus generation.\n\n        !!! techdetails \"NCBI Datasets Technical Details\"\n            |  | Links |\n            | --- | --- |\n            | Task | [task_ncbi_datasets.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/utilities/data_import/task_ncbi_datasets.wdl) |\n            | Software Source Code | [NCBI Datasets on GitHub](https://github.com/ncbi/datasets) |\n            | Software Documentation | [NCBI Datasets Documentation on NCBI](https://www.ncbi.nlm.nih.gov/datasets/docs/v2/) |\n            | Original Publication(s) | [Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets](https://doi.org/10.1038/s41597-024-03571-y) |\n\n    ??? toggle \"Map Reads to Host\"\n\n        `minimap2` is a popular aligner that is used to align reads (or assemblies) to an assembly file. In minimap2, \"modes\" are a group of preset options.\n\n\n        The mode used in this task is `map-ont` which is the default mode for long reads and indicates that long reads of ~10% error rates should be aligned to the reference genome. The output file is in SAM format.\n\n\n\n        For more information regarding modes and the available options for `minimap2`, please see the [minimap2 manpage](https://lh3.github.io/minimap2/minimap2.html)\n\n        !!! techdetails \"minimap2 Technical Details\"\n            | | Links |\n            |---|---|\n            | Task | [task_minimap2.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/alignment/task_minimap2.wdl) |\n            | Software Source Code | [minimap2 on GitHub](https://github.com/lh3/minimap2) |\n            | Software Documentation | [minimap2](https://lh3.github.io/minimap2) |\n            | Original Publication(s) | [Minimap2: pairwise alignment for nucleotide sequences](https://academic.oup.com/bioinformatics/article/34/18/3094/4994778) |\n\n\n    ??? toggle \"Extract Unaligned Reads\"\n\n\n        The `bam_to_unaligned_fastq` task will extract a FASTQ file of reads that failed to align, while removing unpaired reads.\n\n\n        !!! techdetails \"`parse_mapping` Technical Details\"\n            | | Links |\n            |---|---|\n            | Task | [task_parse_mapping.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/utilities/data_handling/task_parse_mapping.wdl) |\n            | Software Source Code | [samtools on GitHub](https://github.com/samtools/samtools) |\n            | Software Documentation | [samtools](https://www.htslib.org/doc/samtools.html) |\n            | Original Publication(s) | [The Sequence Alignment/Map format and SAMtools](https://doi.org/10.1093/bioinformatics/btp352)&lt;br&gt;[Twelve Years of SAMtools and BCFtools](https://doi.org/10.1093/gigascience/giab008) |\n\n    ??? task \"`assembly_metrics`: Mapping Statistics\"\n        The `assembly_metrics` task generates mapping statistics from a BAM file. It uses samtools to generate a summary of the mapping statistics, which includes coverage, depth, average base quality, average mapping quality, and other relevant metrics.\n\n\n        !!! techdetails \"`assembly_metrics` Technical Details\"\n            |  | Links |\n            | --- | --- |\n            | Task | [task_assembly_metrics.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/basic_statistics/task_assembly_metrics.wdl) |\n            | Software Source Code | [samtools on GitHub](https://github.com/samtools/samtools) |\n            | Software Documentation | [samtools](https://www.htslib.org/doc/samtools.html) |\n            | Original Publication(s) | [The Sequence Alignment/Map format and SAMtools](https://doi.org/10.1093/bioinformatics/btp352)&lt;br&gt;[Twelve Years of SAMtools and BCFtools](https://doi.org/10.1093/gigascience/giab008) |\n\n\n    !!! techdetails \"Host Decontaminate Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Subworkflow | [wf_host_decontaminate.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_host_decontaminate.wdl) |\n\n??? task \"`Kraken2`: Read Identification\"\n\n    `Kraken2` is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.\n\n\n\n    This task runs on cleaned reads passed from the `read_QC_trim` subworkflow and outputs a Kraken2 report detailing taxonomic classifications. It also separates classified reads from unclassified ones.\n\n    !!! info \"Database-dependent\"\n        This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at `gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz`.\n\n\n\n\n\n    !!! techdetails \"Kraken2 Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Task | [task_kraken2.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/taxon_id/contamination/task_kraken2.wdl) |\n        | Software Source Code | [Kraken2 on GitHub](https://github.com/DerrickWood/kraken2/)  |\n        | Software Documentation | [Kraken2 Documentation](https://github.com/DerrickWood/kraken2/blob/master/docs/MANUAL.markdown) |\n        | Original Publication(s) | [Improved metagenomic analysis with Kraken 2](https://link.springer.com/article/10.1186/s13059-019-1891-0) |\n\n\n??? task \"`krakentools`: Read Extraction\"\n\n    The `task_krakentools.wdl` task extracts reads from the Kraken2 output file. It uses the [KrakenTools](https://github.com/jenniferlu717/KrakenTools) package to extract reads classified at any user-specified taxon ID.\n\n    ??? dna \"`extract_unclassified` input parameter\"\n        This parameter determines whether unclassified reads should also be extracted and combined with the `taxon`-specific extracted reads. By default, this is set to `false`, meaning that only reads classified to the specified input `taxon` will be extracted.\n\n    ???+ warning \"Important\"\n        This task will extract reads classified to the input `taxon` and **all of its descendant taxa**. The `rank` input parameter controls the extraction of reads classified at the specified `rank` and all suboridante taxonomic levels. See task `ncbi_identify` under the **Taxonomic Identification** section for more details on the `rank` input parameter.\n\n    !!! techdetails \"KrakenTools Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Task | [task_krakentools.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/taxon_id/task_krakentools.wdl) |\n        | Software Source Code | [KrakenTools on GitHub](https://github.com/jenniferlu717/KrakenTools) |\n        | Software Documentation | [KrakenTools](https://github.com/jenniferlu717/KrakenTools/blob/master/README.md) |\n        | Original Publication(s) | [Metagenome analysis using the Kraken software suite](https://doi.org/10.1126/scitranslmed.aap9489) |\n</code></pre> <pre><code>!!! techdetails \"read_QC_trim Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Subworkflow | [wf_read_QC_trim_pe.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_read_QC_trim_pe.wdl)&lt;br&gt;[wf_read_QC_trim_se.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_read_QC_trim_se.wdl) |\n</code></pre>"},{"location":"common_text/read_qc_trim_ont_wf/","title":"Read qc trim ont wf","text":"<code>read_QC_trim_ont</code>: Read Quality Trimming, Quantification, and Identification <p><code>read_QC_trim_ont</code> is a sub-workflow that filters low-quality reads and trims low-quality regions of reads. It uses several tasks, described below.</p> <pre><code>??? task \"`HRRT`: Human Host Sequence Removal\"\n    All reads of human origin **are removed**, including their mates, by using NCBI's [**human read removal tool (HRRT)**](https://github.com/ncbi/sra-human-scrubber).\n\n    HRRT is based on the [SRA Taxonomy Analysis Tool](https://doi.org/10.1186/s13059-021-02490-0) and employs a k-mer database constructed of k-mers from Eukaryota derived from all human RefSeq records with any k-mers found in non-Eukaryota RefSeq records subtracted from the database.\n\n    !!! techdetails \"NCBI-Scrub Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Task | [task_ncbi_scrub.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/read_filtering/task_ncbi_scrub.wdl) |\n        | Software Source Code | [HRRT on GitHub](https://github.com/ncbi/sra-human-scrubber) |\n        | Software Documentation |  [HRRT on NCBI](https://ncbiinsights.ncbi.nlm.nih.gov/2023/02/02/scrubbing-human-sequences-sra-submissions/) |\n\n\n??? task \"`artic_guppyplex`: Read Filtering\"\n    Reads are filtered by length with `artic_guppyplex`, which is a part of the [`ARTIC` protocol](https://artic.network/fieldbioinformatics/fieldbioinformatics-sop.html). Since TheiaCoV was developed primarily for amplicon-based viral sequencing, this task is included to remove chimeric reads that are either too short or too long.\n\n    !!! techdetails \"artic_guppyplex Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Task | [task_artic_guppyplex.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/read_filtering/task_artic_guppyplex.wdl) |\n        | Software Source Code | [ARTIC on GitHub](https://github.com/artic-network/fieldbioinformatics/) |\n        | Software Documentation | [ARTIC Documentation](https://artic.readthedocs.io/en/latest/?badge=latest) |\n\n\n??? task \"`Kraken2`: Read Identification\"\n\n    `Kraken2` is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.\n\n    Kraken2 is run on both the raw and clean reads.\n\n\n\n    !!! info \"Database-dependent\"\n        This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at `gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz`.\n\n\n\n\n\n    !!! techdetails \"Kraken2 Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Task | [task_kraken2.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/taxon_id/contamination/task_kraken2.wdl) |\n        | Software Source Code | [Kraken2 on GitHub](https://github.com/DerrickWood/kraken2/)  |\n        | Software Documentation | [Kraken2 Documentation](https://github.com/DerrickWood/kraken2/blob/master/docs/MANUAL.markdown) |\n        | Original Publication(s) | [Improved metagenomic analysis with Kraken 2](https://link.springer.com/article/10.1186/s13059-019-1891-0) |\n</code></pre> <pre><code>!!! dna \"A note on estimated genome length\"\n\n    By default, the estimated genome length is set to 5 Mb, which is around 0.7 Mb higher than the average bacterial genome length, according to [the information of thousands of NCBI bacterial assemblies collated here](https://github.com/CDCgov/phoenix/blob/717d19c19338373fc0f89eba30757fe5cfb3e18a/assets/databases/NCBI_Assembly_stats_20240124.txt). This estimate can be overwritten by the user and is used by `Rasusa`.\n</code></pre> <pre><code>??? task \"`Rasusa`: Read Subsampling\"\n\n\n    `Rasusa` is a tool to randomly subsample sequencing reads to a specified coverage without assuming that all reads are of equal length, making it especially suitable for long-read data while still being applicable to short-read data.\n\n\n    The `Rasusa` task performs subsampling on the input raw reads. By default, this task will subsample TheiaProk_ONT reads to a depth of 150X using an estimated genome length of 5 million basepairs (0.7 Mb higher than the average bacterial genome length), and TheiaEuk_ONT reads using an estimated genome length of 50 million basepairs. The estimated genome length can be changed by the user by providing a different value for the `genome_length` input parameter. The target subsampling depth can also be adjusted by modifying the `subsample_coverage` variable.\n\n\n    ???+ warning \"Non-deterministic output(s)\"\n        This task may yield non-deterministic outputs since it performs _random_ subsampling. To ensure reproducibility, set a a value for the `rasusa_seed` optional input variable.\n\n    !!! techdetails \"Rasusa Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Task | [task_rasusa.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/utilities/task_rasusa.wdl) |\n        | Software Source Code | [Rasusa on GitHub](https://github.com/mbhall88/rasusa) |\n        | Software Documentation | [Rasusa on GitHub](https://github.com/mbhall88/rasusa) |\n        | Original Publication(s) | [Rasusa: Randomly subsample sequencing reads to a specified coverage](https://doi.org/10.21105/joss.03941) |\n\n\n??? task \"`Nanoq`: Read Filtering\"\n\n    Reads are filtered by length and quality using `nanoq`. By default, sequences with less than 500 basepairs and quality scores lower than 10 are filtered out to improve assembly accuracy. These defaults are able to be modified by the user.\n\n    !!! techdetails \"Nanoq Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Task | [task_nanoq.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/read_filtering/task_nanoq.wdl) |\n        | Software Source Code | [Nanoq on GitHub](https://github.com/esteinig/nanoq) |\n        | Software Documentation | [Nanoq Documentation](https://github.com/esteinig/nanoq/blob/master/README.md) |\n        | Original Publication(s) | [Nanoq: ultra-fast quality control for nanopore reads](https://doi.org/10.21105/joss.02991)\n\n\n??? task \"`Kraken2`: Read Identification (optional)\"\n    To activate this task, set `call_kraken` to `true` and provide a value for `kraken_db`.\n\n    `Kraken2` is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.\n\n\n    Kraken2 is run on the raw read data.\n\n\n    !!! info \"Database-dependent\"\n        This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at `gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz`.\n\n\n    A database must be provided if this optional module is activated, through the kraken_db optional input. A list of suggested databases can be found on [Kraken2 standalone documentation](../standalone/kraken2.md#databases).\n\n\n\n    !!! techdetails \"Kraken2 Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Task | [task_kraken2.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/taxon_id/contamination/task_kraken2.wdl) |\n        | Software Source Code | [Kraken2 on GitHub](https://github.com/DerrickWood/kraken2/)  |\n        | Software Documentation | [Kraken2 Documentation](https://github.com/DerrickWood/kraken2/blob/master/docs/MANUAL.markdown) |\n        | Original Publication(s) | [Improved metagenomic analysis with Kraken 2](https://link.springer.com/article/10.1186/s13059-019-1891-0) |\n</code></pre> <pre><code>??? task \"`NanoPlot`: Read Quantification\"\n\n    NanoPlot is used for the determination of mean quality scores, read lengths, and number of reads. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect **fewer** clean reads than raw reads.\n\n    While this task currently is run _outside_ of the `read_QC_trim_ont` workflow, it is being included here as it calculates statistics on the read data. This is done so that the actual assembly genome lengths can be used (if an estimated genome length is not provided by the user) to ensure the estimated coverage statistics are accurate.\n\n    !!! techdetails \"NanoPlot Technical Details\"\n        |  | Links |\n        | --- | --- |\n        | Task | [task_nanoplot.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/basic_statistics/task_nanoplot.wdl) |\n        | Software Source Code | [NanoPlot on GitHub](https://github.com/wdecoster/NanoPlot) |\n        | Software Documentation | [NanoPlot Documentation](https://github.com/wdecoster/NanoPlot/blob/master/README.md) |\n        | Original Publication(s) | [NanoPack2: population-scale evaluation of long-read sequencing data](https://academic.oup.com/bioinformatics/article/39/5/btad311/7160911) |\n\n!!! techdetails \"read_QC_trim_ont Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Subworkflow | [wf_read_QC_trim_ont.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_read_QC_trim_ont.wdl) |\n</code></pre>"},{"location":"common_text/read_screen_task/","title":"Read screen task","text":"<code>screen</code>: Total Raw Read Quantification and Genome Size Estimation <p>The <code>screen</code> task ensures the quantity of sequence data is sufficient to undertake genomic analysis. It uses <code>fastq-scan</code> and bash commands for quantification of reads and base pairs, and mash sketching to estimate the genome size and its coverage. At each step, the results are assessed relative to pass/fail criteria and thresholds that may be defined by optional user inputs. Samples are run through all threshold checks, regardless of failures, and the workflow will terminate after the <code>screen</code> task if any thresholds are not met:</p> <ol> <li>Total number of reads: A sample will fail the read screening task if its total number of reads is less than or equal to <code>min_reads</code>.</li> <li>The proportion of basepairs reads in the forward and reverse read files: A sample will fail the read screening if fewer than <code>min_proportion</code> basepairs are in either the reads1 or read2 files.</li> <li>Number of basepairs: A sample will fail the read screening if there are fewer than <code>min_basepairs</code> basepairs</li> <li>Estimated genome size:  A sample will fail the read screening if the estimated genome size is smaller than <code>min_genome_size</code> or bigger than <code>max_genome_size</code>.</li> <li>Estimated genome coverage: A sample will fail the read screening if the estimated genome coverage is less than the <code>min_coverage</code>.</li> </ol> <pre><code>Read screening is undertaken on both the raw and cleaned reads. The task may be skipped by setting the `skip_screen` variable to true.\n\nDefault values vary between the PE, SE, and ONT workflows. The rationale for these default values can be found below. If two default values are shown, the first is for Illumina workflows and the second is for ONT.\n</code></pre> <pre><code>Read screening is performed only on the cleaned reads. The task may be skipped by setting the `skip_screen` variable to `true`. Default values vary between the ONT and PE workflow. The rationale for these default values can be found below:\n\n??? toggle \"Default Thresholds and Rationales\"\n    | Variable  | Description | Default Value | Rationale |\n    | --- | --- | --- | --- |\n    | `min_reads` | A sample will fail the read screening task if its total number of reads is less than or equal to `min_reads` | 50 | Minimum number of base pairs for 10x coverage of the Hepatitis delta (of the *Deltavirus* genus) virus divided by 300 (longest Illumina read length) |\n    | `min_basepairs` | A sample will fail the read screening if there are fewer than `min_basepairs` basepairs | 15000 | Greater than 10x coverage of the Hepatitis delta (of the *Deltavirus* genus) virus |\n    | `min_genome_size` | A sample will fail the read screening if the estimated genome size is smaller than `min_genome_size` | 1500 |  Based on the Hepatitis delta (of the *Deltavirus* genus) genome- the smallest viral genome as of 2024-04-11 (1,700 bp) |\n    | `max_genome_size` | A sample will fail the read screening if the estimated genome size is smaller than `max_genome_size` |2673870 | Based on the *Pandoravirus salinus* genome, the biggest viral genome, (2,673,870 bp) with 2 Mbp added |\n    | `min_coverage` | A sample will fail the read screening if the estimated genome coverage is less than the `min_coverage` | 10 | A bare-minimum coverage for genome characterization. Higher coverage would be required for high-quality phylogenetics. |\n    | `min_proportion` | A sample will fail the read screening if fewer than `min_proportion` basepairs are in either the reads1 or read2 files | 40 | Greater than 50% reads are in the read1 file; others are in the read2 file. (PE workflow only) |\n</code></pre> <pre><code>| Variable  | Default Value | Rationale |\n| --- | --- | --- |\n| `skip_screen` | false | Set to true to skip the read screen from running |\n| `min_reads` | 57 | Calculated from the minimum number of base pairs required for 10x coverage of the Hepatitis delta (of the _Deltavirus_ genus) genome, the samllest known viral genome as of 2024-04-11 (1,700 bp), divided by 300 (the longest Illumina read length) |\n| `min_basepairs` | 17000 | Should be greater than 10x coverage of Hepatitis delta (of the _Deltavirus_ genus), the smallest known viral genome (1,700 bp) |\n| `min_genome_length` | 1700 | Based on the Hepatitis delta (of the _Deltavirus_ genus) genome, the smallest viral genome as of 2024-04-11 (1,700 bp) |\n| `max_genome_length` | 2673870 | Based on the _Pandoravirus salinus_ genome, the largest known viral genome (2,473,870 bp), plus an additional 200 kbp to cater for potential extra genomic material |\n| `min_coverage` | 10 | A bare-minimum average per base coverage across the genome required for genome characterization A Higher coverage would be required for high-quality phylogenetics. |\n| `min_proportion` | 40 | Neither read1 nor read2 files should have less than 40% of the total number of reads. For paired-end data only. |\n</code></pre> <pre><code>| Variable  | Default Value | Rationale |\n| --- | --- | --- |\n| `skip_screen` | false | Set to true to skip the read screen from running |\n| `min_reads` | 7472 or 5000 | Calculated from the minimum number of base pairs required for 20x coverage of the Nasuia deltocephalinicola genome, the smallest known bacterial genome as of 2019-08-07 (112,091 bp), divided by 300 (the longest Illumina read length) or 5000 (estimate of ONT read length) |\n| `min_basepairs` | 2241820 | Should be greater than 20x coverage of Nasuia deltocephalinicola, the smallest known bacterial genome (112,091 bp) |\n| `min_genome_length` | 100000 | Based on the Nasuia deltocephalinicola genome, the smallest known bacterial genome (112,091 bp) |\n| `max_genome_length` | 18040666 | Based on the Minicystis rosea genome, the largest known bacterial genome (16,040,666 bp), plus an additional 2 Mbp to cater for potential extra genomic material |\n| `min_coverage` | 10 or 5 | A bare-minimum average per base coverage across the genome required for genome characterization. Higher coverage would be required for high-quality phylogenetics. |\n| `min_proportion` | 40 | Neither read1 nor read2 files should have less than 40% of the total number of reads. For paired-end data only. |\n</code></pre> <pre><code>| Variable  | Rationale |\n| --- | --- | --- |\n| `skip_screen` | false | Set to true to skip the read screen from running. If you set this value to true, please provide a value for the theiaeuk_illumina_pe `genome_length` optional input, OR set the theiaeuk_illumina_pe `call_rasusa` optional input to false. Otherwise RASUSA will attempt to downsample to an expected genome size of 0 bp, and the workflow will fail. |\n| `min_reads` | 3000 | Calculated from the minimum number of base pairs required for 20x coverage of the _Hansenula polymorpha_ genome, the smallest fungal genome as of 2015-04-02 (8.97 Mbp), divided by 300 (the longest Illumina read length) |\n| `min_basepairs` | 45000000 | Should be greater than 10x coverage of _Hansenula polymorpha_, the smallest fungal genome as of 2015-04-02 (8.97 Mbp)  |\n| `min_genome_length` | 9000000 | Based on the _Hansenula polymorpha_  genome - the smallest fungal genome as of 2015-04-02 (8.97 Mbp) |\n| `max_genome_length` | 178000000 | Based on the _Cenococcum geophilum_  genome, the largest pathogenic fungal genome (177.57 Mbp), plus an additional 2 Mbp to cater for potential extra genomic material |\n| `min_coverage` | 10 | A bare-minimum average per base coverage across the genome required for genome characterization. Higher coverage would be required for high-quality phylogenetics.|\n| `min_proportion` | 40 | Neither read1 nor read2 files should have less than 40% of the total number of reads. For paired-end data only. |\n</code></pre> <pre><code>!!! techdetails \"Screen Technical Details\"\n</code></pre> <pre><code>    There is a single WDL task for read screening. The `screen` task is run twice, once for raw reads and once for clean reads.\n</code></pre> <pre><code>    |  | Links |\n    | --- | --- |\n    | Task | [task_screen.wdl (PE sub-task)](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/comparisons/task_screen.wdl#L3)&lt;br&gt;[task_screen.wdl (SE sub-task)](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/quality_control/comparisons/task_screen.wdl#L147) |\n</code></pre>"},{"location":"common_text/referenceseeker_task/","title":"Referenceseeker task","text":"ReferenceSeeker Details (Optional)"},{"location":"common_text/referenceseeker_task/#referenceseeker","title":"ReferenceSeeker","text":"<p><code>ReferenceSeeker</code> uses your draft assembly to identify closely related bacterial, viral, fungal, or plasmid genome assemblies in RefSeq.</p> <p>Databases that can be used with ReferenceSeeker are as follows, and can be used by pasting the GSURI in double quotation marks <code>\" \"</code> into the <code>referenceseeker_db</code> optional input:</p> <ul> <li>archea:  <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-archaea-refseq-205.v20210406.tar.gz</code></li> <li>bacterial (default): <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-bacteria-refseq-205.v20210406.tar.gz</code></li> <li>fungi: <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-fungi-refseq-205.v20210406.tar.gz</code></li> <li>plasmids: <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-plasmids-refseq-205.v20210406.tar.gz</code></li> <li>viral: <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-viral-refseq-205.v20210406.tar.gz</code></li> </ul> <p>For ReferenceSeeker to identify a genome, it must meet user-specified thresholds for sequence coverage (<code>referenceseeker_conserved_dna_threshold</code>; default &gt;= 0.69) and identity (<code>referenceseeker_ani_threshold</code>; default &gt;= 0.95 ). </p> <p>A list of closely related genomes is provided in <code>referenceseeker_tsv</code>. The reference genome that ranks highest according to ANI and conserved DNA values is considered the closest match and will be downloaded, with information about this provided in the <code>assembly_fetch_referenceseeker_top_hit_ncbi_accession</code> output.</p> <p>ReferenceSeeker Technical Details</p> Links Task task_referenceseeker.wdl Software Source Code ReferenceSeeker on GitHub Software Documentation ReferenceSeeker on GitHub Original Publication(s) ReferenceSeeker: rapid determination of appropriate reference genomes"},{"location":"common_text/resfinder_task/","title":"Resfinder task","text":"<code>ResFinder</code>: AMR Genotyping and XDR Shigella Prediction (optional) <p>To activate this task, set <code>call_resfinder</code> to <code>true</code>.</p> <p>AMR Genotyping</p> <p>The <code>ResFinder</code> task is an optional task that can be used in conjunction with AMRFinderPlus for detection and identification of AMR genes and resistance-associated mutations. This task runs the Centre for Genomic Epidemiology (CGE) ResFinder tool to identify acquired antimicrobial resistance. The default thresholds for calling AMR genes are 90% identity and 50% coverage of the reference genes (expressed as a fraction in workflow inputs: 0.9 and 0.5). These are the same thresholds utilized in BioNumerics for calling AMR genes.</p> <p>This task can also run the CGE PointFinder tool if the <code>call_pointfinder</code> variable is set with to <code>true</code>. The databases underlying the task are different to those used by AMRFinderPlus.</p> PointFinder-supported organisms <p>The following organisms are currently supported by PointFinder for mutational-based predicted resistance. If GAMBIT (see above) predicted the sample to be an organism not on this list, PointFinder will be skipped.</p> <ul> <li>Campylobacter coli &amp; C. jejuni</li> <li>Enterococcus faecalis</li> <li>Enterococcus faecium</li> <li>Escherichia coli &amp; Shigella spp.</li> <li>Helicobacter pylori</li> <li>Neisseria gonorrhoeae</li> <li>Klebsiella</li> <li>Mycobacterium tuberculosis</li> <li>Salmonella spp.</li> <li>Staphylococcus aureus</li> </ul> <p>XDR Shigella prediction</p> <p>The <code>ResFinder</code> Task also has the ability to predict whether or not a sample meets the CDC's definition for extensively drug-resistant (XDR) Shigella. </p> <p>CDC defines XDR Shigella bacteria as strains that are resistant to all commonly recommended empiric and alternative antibiotics \u2014 azithromycin, ciprofloxacin, ceftriaxone, trimethoprim-sulfamethoxazole (TMP-SMX), and ampicillin. See also the Increase in Extensively Drug-Resistance Shigellosis in the United State CDC Health Network Alert where this definition can be found.</p> Criteria for XDR Shigella Prediction <p>A sample is required to meet all 7 criteria in order to be predicted as <code>XDR Shigella</code> </p> <ol> <li>The GAMBIT task in the workflow must identify the sample as <code>Shigella</code> OR the user must input the word <code>Shigella</code> somewhere within the input String variable called <code>expected_taxon</code>. This requirement serves as the identification of a sample to be of the Shigella genus.</li> <li>Resfinder or PointFinder predicted resistance to Ampicillin</li> <li>Resfinder or PointFinder predicted resistance to Azithromycin</li> <li>Resfinder or PointFinder predicted resistance to Ciprofloxacin</li> <li>Resfinder or PointFinder predicted resistance to Ceftriazone</li> <li>Resfinder or PointFinder predicted resistance to Trimethoprim</li> <li>Resfinder or PointFinder predicted resistance to Sulfamethoxazole</li> </ol> <p>There are 3 potential outputs for the <code>resfinder_predicted_xdr_shigella</code> output string:</p> <ul> <li><code>Not Shigella based on gambit_predicted_taxon or user input</code></li> <li><code>Not XDR Shigella</code>\u00a0for samples identified as Shigella by GAMBIT or user input BUT does ResFinder did not predict resistance to all 6 drugs in XDR definition</li> <li><code>XDR Shigella</code>\u00a0meaning the sample was identified as Shigella and ResFinder/PointFinder did predict resistance to ceftriazone, azithromycin, ciprofloxacin, trimethoprim, sulfamethoxazole, and ampicillin.</li> </ul> <p>ResFinder Technical Details</p> Links Task task_resfinder.wdl Software Source Code ResFinder Tool on BitBucketResFinder Database on BitBucketPointFinder Database on BitBucket Software Documentation ResFinder on BitBucket Original Publication(s) ResFinder tool: ResFinder 4.0 for predictions of phenotypes from genotypesResFinder database: Identification of acquired antimicrobial resistance genes"},{"location":"common_text/root_phylo_task/","title":"Root phylo task","text":"<code>root_phylo</code> <p>Root_Phylo returns a rooted phylogeny from inputted outgroup(s) or by finding the midpoint root. Outgroups must be tip names (case-sensitive) that exist within the tree, and multiple outgroups must be comma-delimited. Up to two outgroup tips can be supplied, and the most-recent common ancestor (MRCA) of the these outgroups will be used as the rooting branch. It is important to note that rooting on the MRCA of two outgroups is relative to the topology of the tree prior to rooting - if one of the samples is at that base of the phylogeny prior to rooting, then a random tip will be selected to allow for rooting upon the MRCA of the two inputted outgroups.</p> <p>Root_Phylo Technical Details</p> Links Task task_root_phylo.wdl Software Source Code https://github.com/theiagen/theiaphylo Software Documentation TheiaPhylo"},{"location":"common_text/seqsero2_task/","title":"Seqsero2 task","text":"<code>SeqSero2</code>: Serotyping <p>SeqSero2 is a tool for Salmonella serotype prediction. In the TheiaProk Illumina workflows, SeqSero2 takes in raw sequencing reads and performs targeted assembly of serotype determinant alleles, which can be used to predict serotypes including contamination between serotypes. For the TheiaProk ONT and FASTA workflows, SeqSero2 uses the genome assembly as input.</p> <p>If reads are provided, SeqSero2 performs allele micro-assembly by default. This occurs through targeted assembly of serotype determinant alleles, and any assembled alleles are used to predict the sample's serotype, and can predict potential contamination. If the <code>seqsero2_mode</code> optional variable is changed to <code>\"k\"</code> (for k-mer mode), SeqSero2 will perform serotyping based on unique k-mers of serotype determinants. If the input data is an assembly FASTA, the k-mer mode must be used, and the genome assembly is used to generate the search k-mers instead of the raw reads. </p> <p>SeqSero2 Technical Details</p> Links Task task_seqsero2.wdl Software Source Code SeqSero2 Software Documentation SeqSero2 Original Publication(s) Salmonella serotype determination utilizing high-throughput genome sequencing data.SeqSero2: rapid and improved Salmonella serotype determination using whole genome sequencing data."},{"location":"common_text/seroba_task/","title":"Seroba task","text":"<code>SeroBA</code>: Serotyping for Illumina_PE only <p>SeroBA is a k-mer based method for serotyping using the capsular polysaccharide biosynthesis (cps) locus of Streptococcus pneumoniae from paired-end sequencing data. This locus encodes the serotype and is a major virulence factor for the species. Identifying circulating serotypes is important to determine the epidemiological trends and vaccine impact.</p> <p>By adapting a database from PneumoCaT (Pneumococcal Capsular Typing), SeroBA uses KMC to generate a k-mer database and then uses a capsular type variant database and an ARIBA-compatible database that clusters all serotypes by serogroups. A k-mer analysis is performed and the serotype with the highest normalized sequence converage is selected. ARIBA then is used to build an assembly to confirm the selected serotype from the read data and aligns the cps sequence against a reference to identify variants.</p> <p>SeroBA Technical Details</p> Links Task task_seroba.wdl Software Source Code SeroBA on GitHub Software Documentation SeroBA on GitHub Original Publication(s) SeroBA: rapid high-throughput serotyping of Streptococcus pneumoniae from whole genome sequence data"},{"location":"common_text/serotypefinder_task/","title":"Serotypefinder task","text":"<code>SerotypeFinder</code>: Serotyping <p>SerotypeFinder, from the Centre for Genomic Epidemiology (CGE), identifies the serotype of total or partially-sequenced isolates of E. coli. By using BLAST and KMA, the SerotypeFinder database of specific O-antigen processing system genes (for O typing) and flagellin genes (for H typing) is queried and compared against the target sequence to identify the closest serotype.</p> <p>SerotypeFinder Technical Details</p> Links Task task_serotypefinder.wdl Software Source Code SerotypeFinder on BitBucketSerotypeFinder Database on BitBucket Software Documentation SerotypeFinder on BitBucket Original Publication(s) Rapid and Easy In Silico Serotyping of Escherichia coli Isolates by Use of Whole-Genome Sequencing Data"},{"location":"common_text/shared_variants_task/","title":"Shared variants task","text":"Concatenate Variants (optional) Concatenate Variants <pre><code>The `cat_variants` task concatenates variant data from multiple samples into a single file `concatenated_variants`. It is very similar to the `cat_files` task, but also adds a column to the output file that indicates the sample associated with each row of data.\n\nThe `concatenated_variants` file will be in the following format:\n\n| samplename | CHROM | POS | TYPE | REF | ALT | EVIDENCE | FTYPE | STRAND | NT_POS | AA_POS | EFFECT | LOCUS_TAG | GENE | PRODUCT |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| sample1 | PEKT02000007 | 5224 | snp | C | G | G:21 C:0 |  |  |  |  |  |  |  |  |\n| sample2 | PEKT02000007 | 34112 | snp | C | G | G:32 C:0 | CDS | + | 153/1620 | 51/539 | missense_variant c.153C&gt;G p.His51Gln | B9J08_002604 | hypothetical protein |  |\n| sample3 | PEKT02000007 | 34487 | snp | T | A | A:41 T:0 | CDS | + | 528/1620 | 176/539 | missense_variant c.528T&gt;A p.Asn176Lys | B9J08_002604 | hypothetical protein |  |\n\n!!! techdetails \"Technical Details\"\n\n    |  | Links |\n    | --- | --- |\n    | Task | [task_cat_files.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/utilities/file_handling/task_cat_files.wdl) |\n</code></pre> Shared Variants (optional) Shared Variants <pre><code>The `shared_variants` task takes in the `concatenated_variants` output from the `cat_variants` task and reshapes the data so that variants are rows and samples are columns. For each variant, samples where the variant was detected are populated with a \"1\" and samples were **either the variant was not detected or there was insufficient coverage to call variants** are populated with a \"0\". The resulting table is available as the `shared_variants_table` output.\n\nThe `shared_variants_table` file will be in the following format:\n\n| CHROM | POS | TYPE | REF | ALT | FTYPE | STRAND | NT_POS | AA_POS | EFFECT | LOCUS_TAG | GENE | PRODUCT | sample1 | sample2 | sample3 |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| PEKT02000007 | 2693938 | snp | T | C | CDS | - | 1008/3000 | 336/999 | synonymous_variant c.1008A&gt;G p.Lys336Lys | B9J08_003879 | NA | chitin synthase 1 | 1 | 1 | 0 |\n| PEKT02000007 | 2529234 | snp | G | C | CDS | + | 282/336 | 94/111 | missense_variant c.282G&gt;C p.Lys94Asn | B9J08_003804 | NA | cytochrome c | 1 | 1 | 1 |\n| PEKT02000002 | 1043926 | snp | A | G | CDS | - | 542/1464 | 181/487 | missense_variant c.542T&gt;C p.Ile181Thr | B9J08_000976 | NA | dihydrolipoyl dehydrogenase | 1 | 1 | 0 |\n\n!!! techdetails \"Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_shared_variants.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/phylogenetic_inference/utilities/task_shared_variants.wdl) |\n</code></pre>"},{"location":"common_text/shared_variants_task/#concatenate-variants-optional","title":"Concatenate Variants (optional)","text":"<p>This task activates when <code>call_shared_variants</code> is true.</p>"},{"location":"common_text/shared_variants_task/#concatenate-variants","title":"Concatenate Variants","text":""},{"location":"common_text/shared_variants_task/#shared-variants-optional","title":"Shared Variants (optional)","text":"<p>This task activates when <code>call_shared_variants</code> is true.</p>"},{"location":"common_text/shared_variants_task/#shared-variants","title":"Shared Variants","text":""},{"location":"common_text/shigatyper_task/","title":"Shigatyper task","text":"<code>ShigaTyper</code>: Shigella/EIEC differentiation and serotyping for Illumina and ONT only <p>ShigaTyper predicts Shigella spp. serotypes from Illumina or ONT read data. If the genome is not Shigella or enteroinvasive E. coli (EIEC), the results from this tool will state this. In the notes it provides, it also reports on the presence of ipaB  which is suggestive of the presence of the \"virulent invasion plasmid\".</p> <p>ShigaTyper works by mapping the sample sequence to a Shigella reference sequence database using minimap2. Specifically, serotype prediction is made through the serotype-specific wzx gene as O-antigen expression is dependent on this gene. Additional criteria are applied if the serotype could not be solely predicted by this gene; please see the publication for more details.</p> <p>ShigaTyper Technical Details</p> Links Task task_shigatyper.wdl Software Source Code ShigaTyper on GitHub Software Documentation ShigaTyper on GitHub Original Publication(s) In Silico Serotyping Based on Whole-Genome Sequencing Improves the Accuracy of Shigella Identification"},{"location":"common_text/shigeifinder_task/","title":"Shigeifinder task","text":"<code>ShigEiFinder</code>: Shigella/EIEC Differentiation and Serotyping using the assembly file as input <code>ShigEiFinder_reads</code>: Shigella/EIEC Differentiation and Serotyping using Illumina read files as input (optional) <p>To activate the <code>shigeifinder_reads</code> task, set the <code>call_shigeifinder_reads_input</code> to be <code>true</code>. If set to <code>true</code>, <code>shigeifinder_reads</code> will run in addition to the assembly-based <code>shigeifinder</code> task.</p> <pre><code>ShigEiFinder differentiates\u00a0_Shigella_ and enteroinvasive _E. coli_ (EIEC) using cluster-specific genes, identifies some serotypes based on the presence of O-antigen and H-antigen genes (_wzx_ and _wzy_), and predicts the number of virulence plasmids. It can serotype over 59 _Shigella_ and 22 EIEC serotypes using BLAST and BWA.\n\n!!! techdetails \"ShigEiFinder Technical Details\"\n\n    |  | Links |\n    | --- | --- |\n    | Task | [task_shigeifinder.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/species_typing/escherichia_shigella/task_shigeifinder.wdl) |\n    | Software Source Code | [ShigEiFinder on GitHub](https://github.com/LanLab/ShigEiFinder) |\n    | Software Documentation | [ShigEiFinder on GitHub](https://github.com/LanLab/ShigEiFinder) |\n    | Original Publication(s) | [Cluster-specific gene markers enhance Shigella and enteroinvasive Escherichia coli in silico serotyping](https://pubmed.ncbi.nlm.nih.gov/34889728/) |\n</code></pre>"},{"location":"common_text/sistr_task/","title":"Sistr task","text":"<code>SISTR</code>: Salmonella Serovar Prediction <p>SISTR performs Salmonella spp. serotype prediction using antigen gene and cgMLST gene alleles. In TheiaProk, SISTR is run on genome assemblies and uses the default database setting (which contains smaller \"centroid\" alleles or representative alleles instead of the full set of cgMLST alleles). The full set of cgMLST alleles can be activated by setting the <code>sistr_use_full_cgmlst_db</code> optional input variable to <code>true</code>. It also runs a QC module to determine the level of confidence in the serovar prediction (please see the section on QC in the SISTR documentation here).</p> <p>SISTR uses a database of Salmonella serovar determination antigens, cgMLST profiles, and MASH sketches of appropriate reference genomes. BLAST is used to compare input assemblies to this database for serotyping, and the Mash MinHash algorithm is used for serovar prediction.</p> <p>SISTR Technical Details</p> Links Task task_sistr.wdl Software Source Code SISTR on GitHub Software Documentation SISTR on GitHub Original Publication(s) The Salmonella In Silico Typing Resource (SISTR): an open web-accessible tool for rapidly typing and subtyping draft Salmonella genome assemblies."},{"location":"common_text/skani_task/","title":"Skani task","text":"<code>skani</code> <p>The <code>skani</code> task is used to identify and select the most closely related reference genome to the de novo assembly. Skani uses an approximate mapping method without base-level alignment to calculate average nucleotide identity (ANI). It is magnitudes faster than BLAST-based methods and almost as accurate.</p> <pre><code>By default, the reference genome is selected from a database of approximately 200,000 viral genomes. This database was constructed with the following methodology:\n\n1. Extracting all [complete NCBI viral genomes](https://ftp.ncbi.nlm.nih.gov/genomes/Viruses/AllNuclMetadata/), excluding RefSeq accessions (redundancy), SARS-CoV-2 accessions, and segmented families (Orthomyxoviridae, Hantaviridae, Arenaviridae, and Phenuiviridae). Some complete gene accessions, and not complete genomes, are included because NCBI `datasets` completeness parameters are susceptible to metadata errors.\n\n2. Adding complete RefSeq segmented viral assembly accessions, which represent segments as individual contigs within the FASTA\n\n3. Adding one SARS-CoV-2 genome for each [major pangolin lineage](https://github.com/cov-lineages/lineages-website/raw/refs/heads/master/_data/lineage_data.full.json)\n</code></pre> <pre><code>!!! techdetails \"Skani Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_skani.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/taxon_id/task_skani.wdl) |\n    | Software Source Code | [Skani on GitHub](https://github.com/bluenote-1577/skani) |\n    | Software Documentation | [Skani Documentation](https://github.com/bluenote-1577/skani/blob/main/README.md) |\n    | Original Publication(s) | [Fast and robust metagenomic sequence comparison through sparse chaining with skani](https://doi.org/10.1038/s41592-023-02018-3) |\n</code></pre>"},{"location":"common_text/skesa_task/","title":"Skesa task","text":"<code>SKESA</code>: De novo Assembly (default) <p>This task is activated by default.</p> <p><code>SKESA</code> (Strategic K-mer Extension for Scrupulous Assemblies) is a de novo assembler that is fairly conservative and introduces breaks in the genome at repeat regions. This leads to higher sequence quality but more fragmented assemblies, which, depending on the final analysis goal, can be either highly preferred or detrimental. Designed for Illumina reads and haploid genomes, SKESA is the default assembler in the <code>digger_denovo</code> subworkflow.</p> <p>SKESA Technical Details</p> Links Task task_skesa.wdl Software Source Code SKESA on GitHub Software Documentation SKESA on GitHub Original Publication(s) SKESA: strategic k-mer externsion for scrupulous assemblies"},{"location":"common_text/snippy_core_task/","title":"Snippy core task","text":"Snippy <pre><code>Snippy is a pipeline for calling SNPs and INDELs in haploid genomes. Before running `Snippy_Tree`, you must run `Snippy_Variants`, another workflow that uses the Snippy tool to align reads against a reference genome for individual samples. In `Snippy_Tree`, the snippy tool is used again to generate a whole-genome multiple sequence alignment (fasta file) of reads from all the samples we'd like in our tree.\n</code></pre> <pre><code>Snippy is used to generate a whole-genome multiple sequence alignment (fasta file) of reads from all the samples we'd like in our tree.\n</code></pre> <pre><code>When generating the multiple sequence alignment, a bed file can be provided by users to mask certain areas of the genome in the alignment. This is particularly relevant for masking known repetitive regions in _Mycobacterium tuberculosis_  genomes, or masking known regions containing phage sequences.\n\n!!! info \"Why do I see `snippy_core` in Terra?\"\n    In Terra, this task is named \"snippy_core\" after the name of the command in the original Snippy tool. Despite the name, this command is NOT being used to make a core genome, but instead a multiple sequence alignment of the whole genome (without any sections masked using a bed file).\n\n!!! techdetails \"Snippy Technical Details\"\n\n    |  | Links |\n    | --- | --- |\n    | Task | [task_snippy_core.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/phylogenetic_inference/utilities/task_snippy_core.wdl) |\n    | Software Source Code | [Snippy on GitHub](https://github.com/tseemann/snippy) |\n    | Software Documentation | [Snippy on GitHub](https://github.com/tseemann/snippy) |\n</code></pre>"},{"location":"common_text/snippy_core_task/#snippy","title":"Snippy","text":""},{"location":"common_text/snippy_qc_concatenation_task/","title":"Snippy qc concatenation task","text":"Snippy_Variants QC Metrics Concatenation (optional)"},{"location":"common_text/snippy_qc_concatenation_task/#snippy_variants-qc-metric-concatenation-optional","title":"Snippy_Variants QC Metric Concatenation (optional)","text":"<p>Optionally, the user can provide the <code>snippy_variants_qc_metrics</code> file produced by the Snippy_Variants workflow as input to the workflow to concatenate the reports for each sample in the tree. These per-sample QC metrics include the following columns:</p> <ul> <li>samplename: The name of the sample.</li> <li>reads_aligned_to_reference: The number of reads that aligned to the reference genome.</li> <li>total_reads: The total number of reads in the sample.</li> <li>percent_reads_aligned: The percentage of reads that aligned to the reference genome.</li> <li>variants_total: The total number of variants detected between the sample and the reference genome.</li> <li>percent_ref_coverage: The percentage of the reference genome covered by reads with a depth greater than or equal to the <code>min_coverage</code> threshold (default is 10).</li> <li>#rname: Reference sequence name (e.g., chromosome or contig name).</li> <li>startpos: Starting position of the reference sequence.</li> <li>endpos: Ending position of the reference sequence.</li> <li>numreads: Number of reads covering the reference sequence.</li> <li>covbases: Number of bases with coverage.</li> <li>coverage: Percentage of the reference sequence covered (depth \u2265 1).</li> <li>meandepth: Mean depth of coverage over the reference sequence.</li> <li>meanbaseq: Mean base quality over the reference sequence.</li> <li>meanmapq: Mean mapping quality over the reference sequence.</li> </ul> <p>The combined QC metrics file includes the same columns as above for all samples. Note that the last set of columns (<code>#rname</code> to <code>meanmapq</code>) may repeat for each chromosome or contig in the reference genome.</p> <p>QC Metrics for Phylogenetic Analysis</p> <p>These QC metrics provide valuable insights into the quality and coverage of your sequencing data relative to the reference genome. Monitoring these metrics can help identify samples with low coverage, poor alignment, or potential issues that may affect downstream analyses, and we recommend examining them before proceeding with phylogenetic analysis if performing Snippy_Variants and Snippy_Tree separately.</p> <p>Technical Details</p> Links Task task_cat_files.wdl"},{"location":"common_text/snippy_variants_task/","title":"Snippy variants task","text":"Snippy_Variants <pre><code>`Snippy_Variants` uses Snippy to align the assemblies for each sample against the reference genome to call SNPs, MNPs and INDELs according to optional input parameters.\n</code></pre> <pre><code>`Snippy_Variants` uses Snippy to align reads to the reference and call SNPs, MNPs and INDELs according to optional input parameters.\n</code></pre> <pre><code>Optionally, if the user provides a value for `query_gene`, the variant file will be searched for any mutations in the specified regions or annotations. The query string MUST match the gene name or annotation as specified in the GenBank file and provided in the output variant file in the `snippy_results` column.\n\n??? toggle \"QC Metrics from Snippy_Variants\"\n</code></pre> <pre><code>    !!! warning \n        The following QC metrics may not be applicable to your dataset as they are geared towards read data, not assemblies. Use these metrics with caution.\n</code></pre> <pre><code>    This task also extracts QC metrics from the Snippy output for each sample and saves them in per-sample TSV files (`snippy_variants_qc_metrics`). These per-sample QC metrics include the following columns:\n\n    - **samplename**: The name of the sample.\n    - **reads_aligned_to_reference**: The number of reads that aligned to the reference genome.\n    - **total_reads**: The total number of reads in the sample.\n    - **percent_reads_aligned**: The percentage of reads that aligned to the reference genome.\n    - **variants_total**: The total number of variants detected between the sample and the reference genome.\n    - **percent_ref_coverage**: The percentage of the reference genome covered by reads with a depth greater than or equal to the `min_coverage` threshold (default is 10).\n    - **#rname**: Reference sequence name (e.g., chromosome or contig name).\n    - **startpos**: Starting position of the reference sequence.\n    - **endpos**: Ending position of the reference sequence.\n    - **numreads**: Number of reads covering the reference sequence.\n    - **covbases**: Number of bases with coverage.\n    - **coverage**: Percentage of the reference sequence covered (depth \u2265 1).\n    - **meandepth**: Mean depth of coverage over the reference sequence.\n    - **meanbaseq**: Mean base quality over the reference sequence.\n    - **meanmapq**: Mean mapping quality over the reference sequence.\n\n    Note that the last set of columns (`#rname` to `meanmapq`) may repeat for each chromosome or contig in the reference genome.\n</code></pre> <pre><code>!!! tip \"QC Metrics for Phylogenetic Analysis\"\n    These QC metrics provide valuable insights into the quality and coverage of your sequencing data relative to the reference genome. Monitoring these metrics can help identify samples with low coverage, poor alignment, or potential issues that may affect downstream analyses, and we recommend examining them before proceeding with phylogenetic analysis if performing Snippy_Variants and Snippy_Tree separately.\n\n    These per-sample QC metrics can also be combined into a single file (`snippy_combined_qc_metrics`) in downstream workflows, such as `snippy_tree`, providing an overview of QC metrics across all samples.\n</code></pre> <code>Snippy_Variants</code>: Antifungal Resistance Detection <p>To detect mutations that may confer antifungal resistance, <code>Snippy</code> is used to find all variants relative to the clade-specific reference, then these variants are queried for product names associated with resistance. It's important to note that unlike <code>amr_search</code>, this task reports all variants found in the searched targets.</p> <pre><code>- FKS1\n- ERG11 (lanosterol 14-alpha demethylase)\n- FUR1 (uracil phosphoribosyltransferase)\n</code></pre> <pre><code>- ERG11\n- GCS1 (FKS1)\n- FUR1\n- RTA2\n</code></pre> <pre><code>- Cyp51A\n- HapE\n- COX10 (AFUA_4G08340)\n</code></pre> <pre><code>- ERG11 (CNA00300)\n</code></pre> <pre><code>We query `Snippy` results to see if any mutations were identified in those genes. By default, we automatically check for the following loci (which can be overwritten by the user). You will find the mutations next to the locus tag in the `theiaeuk_snippy_variants_hits` column corresponding gene name (see below):\n</code></pre> <pre><code>| **TheiaEuk Search Term** | **Corresponding Gene Name** |\n|---|---|\n| B9J08_005340 | ERG6 |\n| B9J08_000401 | FLO8 |\n| B9J08_005343 | Hypothetical protein (PSK74852) |\n| B9J08_003102 | MEC3 |\n| B9J08_003737 | ERG3 |\n| lanosterol.14-alpha.demethylase | ERG11 |\n| uracil.phosphoribosyltransferase | FUR1 |\n| FKS1 | FKS1 |\n\n??? toggle \"Known resistance-conferring mutations for _Candidozyma auris_\"\n    Mutations in these genes that are known to confer resistance are shown below\n\n    | **Organism** | **Found in** | **Gene name** | **Gene locus** | **AA mutation** | **Drug** | **Reference** |\n    | --- | --- | --- | --- | --- | --- | --- |\n    | Candidozyma auris | Human | ERG11 |  | Y132F | Fluconazole | [Simultaneous Emergence of Multidrug-Resistant _Candida auris_ on 3 Continents Confirmed by Whole-Genome Sequencing and Epidemiological Analyses](https://academic.oup.com/cid/article/64/2/134/2706620/Simultaneous-Emergence-of-Multidrug-Resistant) |\n    | Candidozyma auris | Human | ERG11 |  | K143R | Fluconazole | [Simultaneous Emergence of Multidrug-Resistant _Candida auris_ on 3 Continents Confirmed by Whole-Genome Sequencing and Epidemiological Analyses](https://academic.oup.com/cid/article/64/2/134/2706620/Simultaneous-Emergence-of-Multidrug-Resistant) |\n    | Candidozyma auris | Human | ERG11 |  | F126T | Fluconazole | [Simultaneous Emergence of Multidrug-Resistant _Candida auris_ on 3 Continents Confirmed by Whole-Genome Sequencing and Epidemiological Analyses](https://academic.oup.com/cid/article/64/2/134/2706620/Simultaneous-Emergence-of-Multidrug-Resistant) |\n    | Candidozyma auris | Human | FKS1 |  | S639P | Micafungin  | [Activity of CD101, a long-acting echinocandin, against clinical isolates of Candida auris](https://www.sciencedirect.com/science/article/pii/S0732889317303498) |\n    | Candidozyma auris | Human | FKS1 |  | S639P | Caspofungin | [Activity of CD101, a long-acting echinocandin, against clinical isolates of Candida auris](https://www.sciencedirect.com/science/article/pii/S0732889317303498) |\n    | Candidozyma auris | Human | FKS1 |  | S639P | Anidulafungin | [Activity of CD101, a long-acting echinocandin, against clinical isolates of Candida auris](https://www.sciencedirect.com/science/article/pii/S0732889317303498) |\n    | Candidozyma auris | Human | FKS1 |  | S639F | Micafungin | [A multicentre study of antifungal susceptibility patterns among 350 _Candida auris_ isolates (2009\u201317) in India: role of the ERG11 and FKS1 genes in azole and echinocandin resistance](https://academic.oup.com/jac/advance-article/doi/10.1093/jac/dkx480/4794718) |\n    | Candidozyma auris | Human | FKS1 |  | S639F | Caspofungin | [A multicentre study of antifungal susceptibility patterns among 350 _Candida auris_ isolates (2009\u201317) in India: role of the ERG11 and FKS1 genes in azole and echinocandin resistance](https://academic.oup.com/jac/advance-article/doi/10.1093/jac/dkx480/4794718) |\n    | Candidozyma auris | Human | FKS1 |  | S639F | Anidulafungin | [A multicentre study of antifungal susceptibility patterns among 350 _Candida auris_ isolates (2009\u201317) in India: role of the ERG11 and FKS1 genes in azole and echinocandin resistance](https://academic.oup.com/jac/advance-article/doi/10.1093/jac/dkx480/4794718) |\n    | Candidozyma auris | Human | FUR1 | CAMJ_004922 | F211I | 5-flucytosine | [Genomic epidemiology of the UK outbreak of the emerging human fungal pathogen Candida auris](https://doi.org/10.1038/s41426-018-0045-x) |\n</code></pre> <pre><code>| **TheiaEuk Search Term** | **Corresponding Gene Name** |\n|---|---|\n| ERG11 | ERG11 |\n| GCS1 | FKS1 |\n| FUR1 | FUR1 |\n| RTA2 | RTA2 |\n</code></pre> <pre><code>| **TheiaEuk Search Term** | **Corresponding Gene Name** |\n|---|---|\n| Cyp51A | Cyp51A |\n| HapE | HapE |\n| AFUA_4G08340 | COX10 |\n</code></pre> <pre><code>| **TheiaEuk Search Term** | **Corresponding Gene Name** |\n|---|---|\n| CNA00300 | ERG11 |\n</code></pre> <pre><code>??? toggle \"Example Output Interpretation\"\n    For example, one sample may have the following output for the `theiaeuk_snippy_variants_hits` column:\n\n    ```plaintext\n    lanosterol.14-alpha.demethylase: lanosterol 14-alpha demethylase (missense_variant c.428A&gt;G p.Lys143Arg; C:266 T:0),B9J08_000401: hypothetical protein (stop_gained c.424C&gt;T p.Gln142*; A:70 G:0)\n    ```\n\n    Based on this, we can tell that ERG11 has a missense variant at position 143 (Lysine to Arginine) and B9J08_000401 (which is FLO8) has a stop-gained variant at position 142 (Glutamine to Stop).\n</code></pre> <pre><code>!!! techdetails \"Snippy Variants Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_snippy_variants.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/gene_typing/variant_detection/task_snippy_variants.wdl)&lt;br&gt;[task_snippy_gene_query.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/gene_typing/variant_detection/task_snippy_gene_query.wdl) |\n    | Software Source Code | [Snippy on GitHub](https://github.com/tseemann/snippy) |\n    | Software Documentation | [Snippy on GitHub](https://github.com/tseemann/snippy) |\n</code></pre>"},{"location":"common_text/snippy_variants_task/#snippy_variants","title":"Snippy_Variants","text":""},{"location":"common_text/snp_dists_task/","title":"Snp dists task","text":"SNP-dists <p>##### SNP-dists</p> <pre><code>`SNP-dists` computes pairwise SNP distances between genomes. It takes the same alignment of genomes used to generate your phylogenetic tree and produces a matrix of pairwise SNP distances between sequences. This means that if you generated pairwise core-genome phylogeny, the output will consist of pairwise core-genome SNP (cgSNP) distances. Otherwise, these will be whole-genome SNP distances. Regardless of whether core-genome or whole-genome SNPs, this SNP distance matrix will exclude all SNPs in masked regions (i.e. masked with a bed file or gubbins).\n\nThe SNP-distance output can be visualized using software such as [Phandango](http://jameshadfield.github.io/phandango/#/main) to explore the relationships between the genomic sequences. The task can optionally add a Phandango coloring tag (:c1) to the column names in the output matrix to ensure that all columns are colored with the same color scheme throughout by setting `phandango_coloring` to `true`.\n\n!!! techdetails \"SNP-dists Technical Details\"\n\n    |  | Links |\n    | --- | --- |\n    | Task | [task_snp_dists.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/phylogenetic_inference/utilities/task_snp_dists.wdl) |\n    | Software Source Code | [SNP-dists on GitHub](https://github.com/tseemann/snp-dists) |\n    | Software Documentation | [SNP-dists on GitHub](https://github.com/tseemann/snp-dists) |\n</code></pre>"},{"location":"common_text/snp_sites_task/","title":"Snp sites task","text":"SNP-sites (optional)"},{"location":"common_text/snp_sites_task/#snp-sites-optional","title":"SNP-sites (optional)","text":"<p>Turn on SNP-Sites with <code>core_genome</code></p> <p>SNP-sites runs when the <code>core_genome</code> option is set to true.</p> <p>SNP-sites is used to filter out invariant sites in the whole-genome alignment, thereby creating a core genome alignment for phylogenetic inference. The output is a fasta file containing the core genome of each sample only. If Gubbins has been used, this output fasta will not contain any sites that are predicted to have arisen via recombination.</p> <p>SNP-sites technical details</p> Links Task task_snp_sites.wdl Software Source Code SNP-sites on GitHub Software Documentation SNP-sites on GitHub Original Publication(s) SNP-sites: rapid efficient extraction of SNPs from multi-FASTA alignments"},{"location":"common_text/sonneityper_task/","title":"Sonneityper task","text":"<code>SonneiTyper</code>: Shigella sonnei identification, genotyping, and resistance mutation identification for Illumina and ONT data only <p>SonneiTyper identifies Shigella sonnei, and uses single-nucleotide variants for genotyping and prediction of quinolone resistance in gyrA (S83L, D87G, D87Y) and parC (S80I). Outputs are provided in a TSV format described here.</p> <p>SonneiTyper is a wrapper script around another tool, Mykrobe, that analyses the S. sonnei genomes using the S. sonnei-specific genotyping scheme. SonneiTyper parses the Mykrobe predict results and tabulates the results.</p> <p>SonneiTyper Technical Details</p> Links Task task_sonneityping.wdl Software Source Code Mykrobe on GitHubsonneityping on GitHub Software Documentation Mykrobe Wikisonneityping on GitHub Original Publication(s) Mykrobe tool: Antibiotic resistance prediction for Mycobacterium tuberculosis from genome sequence data with MykrobeS. sonnei genotyping scheme: Global population structure and genotyping framework for genomic surveillance of the major dysentery pathogen,\u00a0Shigella sonnei"},{"location":"common_text/spades_task/","title":"Spades task","text":"<code>spades</code> <code>SPAdes</code>: De novo Assembly (alternative) <p>To activate this task, set <code>assembler</code> to <code>spades</code>.</p> <pre><code>`SPAdes` (St. Petersburg genome assembler) is a _de novo_ assembly tool that uses de Bruijn graphs to assemble genomes from Illumina short reads.\n</code></pre> <pre><code>In TheiaProk, SPAdes is run in `--isolate` mode, which is the recommended flag for high-coverage isolate and multi-cell Illumina data, which is typical of most bacterial sequencing projects. This method is optimized for improving assembly quality and decreasing runtime.\n</code></pre> <pre><code>It is run with the `--metaviral` option, which is recommended for viral genomes. MetaviralSPAdes pipeline consists of three independent steps, `ViralAssembly` for finding putative viral subgraphs in a metagenomic assembly graph and generating contigs in these graphs, `ViralVerify` for checking whether the resulting contigs have viral origin and `ViralComplete` for checking whether these contigs represent complete viral genomes. For more details, please see the original publication.\n\nMetaviralSPAdes was selected as the default assembler because it produces the most complete viral genomes within TheiaViral, determined by CheckV quality assessment (see task `checkv` for technical details).\n\n??? dna \"`call_metaviralspades` input parameter\"\n    This parameter controls whether or not the `spades` task is called by the workflow. By default, `call_metaviralspades` is set to `true` because MetaviralSPAdes is used as the primary assembler. MetaviralSPAdes is generally recommended for most users, but it might not perform optimally on all datasets. If users encounter issues with MetaviralSPAdes, they can set the `call_metaviralspades` variable to `false` to bypass the `spades` task and instead *de novo* assemble using [MEGAHIT](https://github.com/voutcn/megahit) (see task `megahit` for details). Additionally, if the `spades` task fails during execution, the workflow will automatically fall back to using MEGAHIT for *de novo* assembly.\n</code></pre> <pre><code>???+ warning \"Non-deterministic output(s)\"\n    This task may yield non-deterministic outputs.\n\n!!! techdetails \"MetaviralSPAdes Technical Details\"\n    |  | Links |\n    | --- | --- |\n    | Task | [task_spades.wdl](https://github.com/theiagen/public_health_bioinformatics/blob/main/tasks/assembly/task_spades.wdl) |\n    | Software Source Code | [SPAdes on GitHub](https://github.com/ablab/spades) |\n    | Software Documentation | [SPAdes Manual](https://ablab.github.io/spades/index.html) |\n    | Original Publication(s) | _TheiaProk_: [SPAdes: A New Genome Assembly Algorithm and Its Applications to Single-Cell Sequencing](https://doi.org/10.1089/cmb.2012.0021)&lt;br&gt;_TheiaViral_: [MetaviralSPAdes: assembly of viruses from metagenomic data](https://doi.org/10.1093/bioinformatics/btaa490) |\n</code></pre>"},{"location":"common_text/spatyper_task/","title":"Spatyper task","text":"<code>spaTyper</code>: Sequence Typing <p>spaTyper works by identifying the number and order of repeats in the Staphylococcus protein A gene (also known as spa) of a S. aureus assembly. The repeats are assigned a numerical code that is used to assign a spa-type. The tool uses the Ridom SpaServer Database in order to assign the appropriate spa-type (please note that this link is typically considered unsafe by modern web browsers).</p> <p>Spa-types can be used for accurate and reliable typing of MRSA (methicillin-resistant Staphylococcus aureus) strains, and are often used in hospital infection control and epidemiological studies.</p> <p>spatyper Technical Details</p> Links Task task_spatyper.wdl Software Source Code spaTyper on GitHub Software Documentation spaTyper on GitHub Original Publication(s) Ridom SpaServer database: Typing of methicillin-resistant Staphylococcus aureus in a university hospital setting by using novel software for spa repeat determination and database management"},{"location":"common_text/srst2_task/","title":"Srst2 task","text":"<code>SRST2</code>: Vibrio Characterization for Illumina only <p>SRST2 is used to perform general characterization of Vibrio genomes using a database of target sequences that are traditionally used in PCR methods. The sequences included in the database are as follows:</p> Resistance Gene Database Sequence Name Sequence Role Purpose in Database toxR Transcriptional activator Species marker where presence identifies V. cholerae ompW Outer Membrane Protein Species marker where presence identifies V. cholerae ctxA Cholera toxin Indicates cholera toxin production tcpA_classical Toxin co-pilus A allele, associated with the Classical biotype Used to infer identity as Classical biotype tcpA_ElTor Toxin co-pilus A allele, associated with the El Tor biotype Used to infer identity as El Tor biotype wbeN O antigen encoding region Used to infer identity as O1 serogroup wbfR O antigen encoding region Used to infer identity as O139 serogroup <p>This database was developed via communication with Dr. Christine Lee, of the National Listeria, Yersinia, Vibrio and Enterobacterales Reference Laboratory within the Enteric Diseases Laboratory Branch at CDC. It is identical to the database used in the <code>abricate_vibrio</code> task except it is formatted for SRST2.</p> <p>SRST2 works by mapping reads to the target sequences in the database and then reporting the details of all those genes that pass the quality thresholds. The presence or absence of specific genes are used to verify the species, identify cholera toxin production, and designation both the biotype and serogroup of the sample. See the table above for the genes used for each of these purposes.</p> <p>SRST2 Technical Details</p> Links Task task_srst2_vibrio.wdl Software Source Code srst2 on GitHub Software Documentation srst2 on GitHub Original Publication(s) SRST2: Rapid genomic surveillance for public health and hospital microbiology labs"},{"location":"common_text/staphopia_sccmec_task/","title":"Staphopia sccmec task","text":"<code>staphopia-sccmec</code>: Sequence Typing <p>SCC_mec_ (staphylococcal cassette chromosome mec) is a mobile genetic element of Staphylococcus species. It includes a methicilin-resistant mecA gene that is shared between Staphylococcus strains via horizontal gene transfer, which leads to MRSA strains. SCC_mec_ has also been found to confer resistance to non-beta-lactam drugs as well, making it an important target for identifying antimicrobial resistance in Staphylococcus aureus.</p> <p>This tool assigns a SCC_mec_ type by using BLAST to compare the SCC_mec_ primers against the provided S. aureus assembly. <code>staphopia-sccmec</code> reports\u00a0<code>True</code> for exact primer matches and\u00a0<code>False</code> all others. The Hamming Distance is also used in TheiaProk's implementation of the tool to include the number of mismatches so that the <code>False</code> results can be examined in more detail.</p> <p>staphopia-sccmec Technical Details</p> Links Task task_staphopiasccmec.wdl Software Source Code staphopia-sccmec on GitHub Software Documentation staphopia-sccmec on GitHub Original Publication(s) Staphylococcus aureus viewed from the perspective of 40,000+ genomes"},{"location":"common_text/stxtyper_task/","title":"Stxtyper task","text":"<code>StxTyper</code>: Identification and Typing of Shiga toxin (Stx) Genes using the assembly file as input <p>StxTyper screens bacterial genome assemblies for shiga toxin genes and subtypes them into known subtypes and also looks for novel subtypes in cases where the detected sequences diverge from the reference sequences.</p> <p>Shiga toxin is the main virulence factor of Shiga-toxin-producing E. coli (STEC), though these genes are also found in Shigella species as well as some other genera more rarely, such as Klebsiella. Please see this review paper that describes shiga toxins in great detail.</p> <p>Running StxTyper via the TheiaProk workflows</p> <p>The TheiaProk workflow will automatically run <code>stxtyper</code> on all E. coli and Shigella spp. samples, but the user can opt-in to running the tool on any sample by setting the optional input variable <code>call_stxtyper</code> to <code>true</code> when configuring the workflow.</p> <p>Generally, <code>stxtyper</code> looks for stxA and stxB subunits that compose a complete operon. The A subunit is longer (in amino acid length) than the B subunit. Stxtyper attempts to detect these, compare them to a database of known sequences, and type them based on amino acid composition.  There typing algorithm and rules defining how to type these genes &amp; operons will be described more completely in a publication that will be available in the future.</p> <p>The <code>stxtyper_report</code> output TSV is provided in this output format.</p> <p>This tool has been incorporated into v4.0.3 of AMRFinderPlus and runs behind-the-scenes when the user (or in this case, the TheiaProk workflow) provides the <code>amrfinder --organism Escherichia --plus</code> options.</p> <p>StxTyper Technical Details</p> Links Task task_stxtyper.wdl Software Source Code ncbi/stxtyper GitHub repository Software Documentation ncbi/stxtyper GitHub repository"},{"location":"common_text/taxon_table_task/","title":"Taxon table task","text":"<code>Taxon Tables</code>: Copy outputs to new data tables based on taxonomic assignment (optional) <p>This task is incompatible when running TheiaProk on the command-line as it is geared specifically for Terra. Do not activate this task if you are a command-line user.</p> <p>Activate this task by providing a value for the <code>taxon_tables</code> input variable. If provided, the user must also provide values to the <code>terra_project</code> and <code>terra_workspace</code> optional input variables.</p> <p>The <code>taxon_tables</code> module, if enabled, will copy sample data to a different data table based on the taxonomic assignment. For example, if an E. coli sample is analyzed, the module will copy the sample data to a new table for E. coli samples or add the sample data to an existing table.</p> <p>To activate the <code>taxon_tables</code> module, provide a file indicating data table names to copy samples of each taxa to in the <code>taxon_tables</code> input variable.</p> <p>Formatting the <code>taxon_tables</code> file</p> <p>The <code>taxon_tables</code>  file must be uploaded a Google storage bucket that is accessible by Terra and should be in the format below. Briefly, the bacterial genera or species should be listed in the leftmost column with the name of the data table to copy samples of that taxon to in the rightmost column.</p> taxon taxon_table Listeria_monocytogenes lmonocytogenes_specimen Salmonella salmonella_specimen Escherichia ecoli_specimen Shigella shigella_specimen Streptococcus strep_pneumo_specimen Legionella legionella_specimen Klebsiella klebsiella_specimen Mycobacterium mycobacterium_specimen Acinetobacter acinetobacter_specimen Pseudomonas pseudomonas_specimen Staphylococcus staphyloccus_specimen Neisseria neisseria_specimen <p>There are no output columns for the taxon table task. The only output of the task is that additional data tables will appear for in the Terra workspace for samples matching a taxa in the <code>taxon_tables</code> file.</p> <p><code>export_taxon_table</code> Technical Details</p> Links Task task_export_taxon_table.wdl"},{"location":"common_text/tbp_parser_task/","title":"Tbp parser task","text":"<code>tbp-parser</code>: Interpretation and Parsing of TBProfiler JSON outputs (optional) <p>To activate this task, set <code>call_tbp_parser</code> to <code>true</code></p> <p>tbp-parser was developed by Theiagen in partnership with the California Department of Public Health. This tool adds useful drug resistance interpretation by applying expert rules and organizing the outputs from TBProfiler. To understand this module and its functions, please examine the documentation for this tool. </p> <p>This tool generates reports that can be automatically imported into your local LIMS system and is highly customizable with additional quality control metrics and fine-tuning. It is highly recommended to read the associated documentation to understand the full capabilities and configuration options available.</p> <p>Please note that this tool has not been tested on ONT data and although it is available, result accuracy should be considered carefully.</p> <p>tbp-parser Technical Details</p> Links Task task_tbp_parser.wdl Software Source Code tbp-parser on GitHub Software Documentation tbp-parser Documentation"},{"location":"common_text/tbprofiler_task/","title":"Tbprofiler task","text":"<code>TBProfiler</code>: Lineage and Drug Susceptibility Prediction for Illumina and ONT only <p>TBProfiler identifies Mycobacterium tuberculosis complex species, lineages, sub-lineages and drug resistance-associated mutations.</p> <p>TBProfiler aligns the input reads to the H37Rv (NC_000962.3/AL123456.3) reference genome with <code>bwa mem</code> (or <code>minimap2</code>) and then calls variants using <code>gatk</code> (default), though other options are available (<code>bcftools</code>, <code>freebayes</code>, <code>lofreq</code>, <code>pilon</code>). After mutations are called and filtered, they are compared against TBProfiler's database (TBDB).</p> <p>A number of outputs are made available from TBProfiler, all of which can be found in the summary results JSON file. Although the JSON file contains the most information, it is not very human readable, which is why the results CSV and TXT files have been made available to the user as outputs. TBProfiler is able to detect the identified lineage and any sublineages, determine the predicted type of drug resistance, a lists the genes that are associated with resistance, along with several other useful outputs.     </p> <p>TBProfiler Technical Details</p> Links Task task_tbprofiler.wdl Software Source Code TBProfiler on GitHub Software Documentation TBProfiler Docs on GitHub Original Publication(s) Integrating informatics tools and portable sequencing technology for rapid detection of resistance to anti-tuberculous drugs"},{"location":"common_text/template_task/","title":"Template task","text":"<code>&lt;tool_name&gt;</code>: &lt;brief description&gt; <p>Provide sufficient information about your task here so that users can understand how to use the task, what actions it performs, and any important considerations or requirements. Use admonitions as appropriate to highlight important information, tips, or technical details.</p> <p>Be sure any links within this file are written relative to the destination file. For example, if this file is in <code>docs/common_text/</code> but is being included in <code>docs/workflows/standalone/</code> and you want to link to a file in <code>docs/assets/figures/</code>, the link should be written as <code>[link_name](../../assets/figures/link_destination.md)</code>.</p> <p>If your task is used slighly differently in different contexts, you can provide conditionals inside of comments.</p> <p>To include any conditional information in the destination page, add the <code>condition=\"condition_name\"</code> parameter to the <code>include_md</code> macro call on the destination page. Please note that the <code>if: &lt;condition_name&gt;</code> and <code>endif</code> syntax within the markdown comment (<code>&lt;!-- --&gt;</code>) is required for a conditional statement to work. </p> <p>Here is an example:</p> <p><code>&lt;!-- if: &lt;condition_name&gt; --&gt;</code></p> <p>Conditional Content</p> <p>This is content that is only shown if &lt;condition_name&gt; is provided. See the <code>kraken_task.md</code> common_text file for examples on conditional usage. </p> <p><code>&lt;!-- endif --&gt;</code></p> <p> Technical Details</p> <p>This section is required for all tasks. If the Software Source Code, Software Documentation, and/or Original Publication(s) fields are not applicable, they may be removed.</p> Links Task .wdl Software Source Code Software Documentation Original Publication(s)"},{"location":"common_text/trimmomatic_task/","title":"Trimmomatic task","text":"<code>Trimmomatic</code>: Read Trimming (default) <p>Read proccessing is available via <code>Trimmomatic</code> by default.</p> <p>Trimmomatic trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>Trimmomatic</code> Technical Details</p> Links Task task_trimmomatic.wdl Software Source Code Trimmomatic on GitHub Software Documentation Trimmomatic Website Original Publication(s) Trimmomatic: a flexible trimmer for Illumina sequence data"},{"location":"common_text/ts_mlst_task/","title":"Ts mlst task","text":"<code>TS_MLST</code>: MLST Profiling <p>Multilocus sequence typing (MLST) is a typing method reflecting population structure. It was developed as a portable, unambiguous method for global epidemiology using PCR, but can be applied to whole-genome sequences in silico. MLST is commonly used for pathogen surveillance, ruling out transmission, and grouping related genomes for comparative analysis.</p> <p>TheiaProk uses the MLST tool developed by Torsten Seeman to assess MLST using traditional PubMLST typing schemes. </p> <p>MLST schemes are taxa-specific. Each scheme uses fragments of typically 7 housekeeping genes (\"loci\") and has a database associating an arbitrary number with each distinct allele of each locus. Each unique combination of alleles (\"allelic profile\") is assigned a numbered sequence type (ST). Significant diversification of genomes is captured by changes to the MLST loci via mutational events creating new alleles and STs, or recombinational events replacing the allele and changing the ST. Relationships between STs are based on the number of alleles they share. Clonal complexes share a scheme-specific number of alleles (usually for five of the seven loci).</p> <p>MLST Limitations</p> <p>Some taxa have multiple MLST schemes, and some MLST schemes are insufficiently robust.</p> Interpretation of MLST results <p>Each MLST results file returns the ST and allele results for one sample. If the alleles and ST are correctly assigned, only a single integer value will be present for each. If an ST cannot be assigned, multiple integers or additional characters will be shown, representing the issues with assignment as described here.</p> Identifying novel alleles and STs <p>The MLST schemes used in TheiaProk are curated on the PubMLST website.If you identify novel alleles or allelic profiles in your data using TheiaProk's MLST task, you can get these assigned via PubMLST:</p> <ol> <li>Check that the novel allele or ST has not already been assigned a type on PubMLST. <ol> <li>Download the assembly file from Terra for your sample with the novel allele or ST</li> <li>Go to the PubMLST webpage for the organism of interest </li> <li>Navigate to the organism \"Typing\" page</li> <li>Under \"Query a sequence\" choose \"Single sequence\" (e.g., this is the page for H. influenzae), select the MLST scheme under \"Please select locus/scheme\", upload the assembly fasta file, and click submit</li> <li>Results will be returned lower on the page</li> </ol> </li> <li>If the allele or ST has not been typed previously on the PubMLST website (step 1), new allele or ST numbers can be assigned using the instructions provided by pubMLST.</li> </ol> Taxa with multiple MLST schemes <p>By default, the MLST tool automatically detects the genome's taxa to select the MLST scheme. Users may specify a desired scheme using the <code>scheme</code> variable of the <code>ts_mlst</code> task. Available schemes are listed here and the scheme name should be provided in quotation marks (\"...\").</p> <p>Some taxa have multiple MLST schemes, e.g. the Escherichia and Leptospira genera,  Acinetobacter baumannii, Clostridium difficile, and Streptococcus thermophilus. Only one scheme will be used by default. This can be changed for Escherichia and A. baumannii by setting the <code>ts_mlst run_secondary_scheme</code> variable to <code>true</code>. This will cause MLST to run the other scheme associated with those organisms and output those results in addition to the default scheme.</p> <p>For E. coli, the user may set <code>ts_mlst scheme_override</code> to be <code>true</code> to prevent running E. coli samples through the \"aeromonas\", \"cfreundii\", and \"senterica\" schemes, which can be common mischaracterizations.</p> <p>TS_MLST Technical Details</p> Links Task task_ts_mlst.wdl Software Source Code mlst on GitHub Software Documentation mlst on GitHub Original Publication(s) PubMLST database: Open-access bacterial population genomics: BIGSdb software, the PubMLST.org website and their applications"},{"location":"common_text/vadr_flu_segments_task/","title":"Vadr flu segments task","text":"<code>vadr_flu_segments</code> <p>This task processes a full or partial influenza genome assembly in multifasta format, along with the output <code>.tar.gz</code> file from a VADR run. It extracts each segment into its own fasta file and also generates a concatenated fasta containing all segments combined into a single sequence. Segment names are assigned based on the specified flu type (A or B) and the segment classification found in the VADR .sqc file.</p> <p>Note: Results may be unreliable if segment lengths deviate from those expected for Influenza A or B. For best results, the input assembly should contain all 8 segments as separate contigs. If the assembly is partial, the task will still extract available segments but may not produce a complete concatenated sequence. Empty fasta files will be created for missing segments.</p> <p>VADR Flu Segments Technical Details</p> Links Task task_vadr_flu_segments.wdl"},{"location":"common_text/vadr_task/","title":"Vadr task","text":"<code>vadr</code> <p>VADR (Viral Annotation DefineR) annotates and validates completed assembly files. For details on VADR default models/parameters, see the organism-specific parameters and logic section. It was primarily developed to test viral sequences to confirm they would be accepted to NCBI's GenBank data repository, but has found wide usage in general sequence validation and annotation.</p> <p>As part of the analysis of the assemblies, more than 70 types of unexpected characteristics, also known as alerts, can be reported. Any identified alerts can be found in the <code>vadr_alerts_list</code> output. Fatal alerts indicate that the sample is unlikely to be accepted to GenBank; non-fatal alerts are designated as passing sequences, but may still require further investigation. A full description of the potential alerts can be found on the VADR README here, including details on how to allow sequencecs to pass despite having fatal alerts.</p> <p>VADR Technical Details</p> Links Task task_vadr.wdl Software Source Code https://github.com/ncbi/vadr Software Documentation https://github.com/ncbi/vadr/wiki Original Publication(s) For SARS-CoV-2: Faster SARS-CoV-2 sequence validation and annotation for GenBank using VADR For non-SARS_CoV-2: VADR: validation and annotation of virus sequence submissions to GenBank"},{"location":"common_text/versioning_task/","title":"Versioning task","text":"<code>versioning</code>: Version Capture <p>The <code>versioning</code> task captures the workflow version from the GitHub (code repository) version.</p> <p>Version Capture Technical details</p> Links Task task_versioning.wdl"},{"location":"common_text/vibecheck_task/","title":"Vibecheck task","text":"<code>Vibecheck</code>: O1 Vibrio  cholerae Lineage Classification for Illumina PE only <p>The <code>Vibecheck</code> task classifies O1 V. cholerae sequences into canonical lineages (T1-T17) using variant frequency demixing. The O1 designation is determined through the use of the SRST2 task.</p> <p>Vibecheck works by aligning the reads to an O1 V. cholerae reference genome, calling variants from the alignment, and estimating lineage abundances using Freyja by using a database built from canonical SNPs that define the known lineages.</p> <p>Vibecheck Technical Details</p> Links Task task_vibecheck_vibrio.wdl Software Source Code Vibecheck on GitHub Software Documentation Vibecheck on GitHub"},{"location":"common_text/virulencefinder_task/","title":"Virulencefinder task","text":"<code>VirulenceFinder</code>: Virulence Gene Identification <p>VirulenceFinder, from the Center for Genomic Epidemiology (GCE) in TheiaProk is only run on assembly files due to issues regarding discordant results when using read files on the web application versus the command-line. VirulenceFinder uses BLAST and KMA to query against a database of virulence genes in E. coli to identify any virulence factors in the sample.</p> <p>VirulenceFinder Technical Details</p> Links Task task_virulencefinder.wdl Software Source Code VirulenceFinder on BitBucketVirulenceFinder Database on BitBucket Software Documentation VirulenceFinder on BitBucketVirulenceFinder Database on BitBucket Original Publication(s) Real-time whole-genome sequencing for routine typing, surveillance, and outbreak detection of verotoxigenic Escherichia coli"},{"location":"contributing/code_contribution/","title":"Contributing to the Code","text":""},{"location":"contributing/code_contribution/#phb-code-contributions","title":"PHB Code Contributions","text":"<p>Theiagen Genomics\u2019 Public Health Bioinformatics (PHB) workflows are written in\u00a0WDL, a language for specifying data processing workflows with a human-readable and writable syntax. Contributions to the workflows contained in the repository are warmly welcomed.</p> <p>This document gives coding conventions for the WDL code comprising the workflow and task development for PHB. This style guide evolves over time as additional conventions are identified and past conventions are rendered obsolete by changes in the language itself.</p> <p>Style guide inspired by\u00a0Scott Frazer\u2019s\u00a0WDL Best Practices Style Guide.</p>"},{"location":"contributing/code_contribution/#general-guidelines","title":"General Guidelines","text":"<p>Please ensure your code adheres to our philosophy of failures</p> <p>At Theiagen, we believe our workflows should only fail because of technical issues, not because of poor quality data. Our goal is to create workflows that can handle data in any condition and still provide meaningful results, especially if that data isn\u2019t perfect. For more information, see our Workflow Failure Philosophy.</p> <p>Modularity and Metadata</p> <ul> <li>Best Practice: Place tasks and workflows in separate files to maintain modularity and clarity.</li> <li> <p>Add a <code>meta</code> block to every task and workflow to provide a brief description of its purpose.</p> <pre><code>meta {\n  description: \"This tool does X\"\n}\n</code></pre> </li> </ul> <p>Docker Containers</p> <ul> <li> <p>Use a specific Docker container version instead of 'latest' to ensure reproducibility and prevent unexpected changes in container behavior.</p> <pre><code>String docker = \"us-docker.pkg.dev/docker_image:version\"\n</code></pre> </li> <li> <p>Preferentially use containers <code>Google's Artifact Registry</code> rather than those from <code>quay.io</code> or <code>dockerhub</code></p> </li> </ul> <p>Indentation and Whitespace</p> <ul> <li> <p>Use 2-space indentation for all blocks. Avoid using tabs to ensure uniform formatting across editors:</p> <pre><code># perform action\nif [ condition ]; then\n  perform_action(variable)\nfi\n</code></pre> </li> <li> <p>Use a single space when defining variables (<code>this = that</code> not <code>this= that</code> (unless a bash variable where <code>this=that</code> is required))</p> </li> </ul> <p>Bracket and Spacing Conventions</p> <ul> <li>Avoid line breaks for opening braces. Keep them on the same line as the declaration. i.e <code>input {</code> instead of <code>input\\n{</code></li> </ul> <pre><code>  # Correct\ninput {\n  String input_variable\n}\n\n# Incorrect\ninput\n{\n  String input_variable\n}\n</code></pre> <ul> <li>Use single space when defining input/output variables &amp; runtime attributes  (<code>output {</code> instead of <code>output{</code>)</li> <li>Separate non-indented constructs (like input and output sections) with a single-line break for readability.</li> </ul> <p>Command Block Syntax</p> <ul> <li> <p>Enclose command blocks in triple angle brackets (&lt;&lt;&lt; ... &gt;&gt;&gt;) for consistency and easier handling of multi-line scripts. It also avoids issues with unescaped special characters in the command block:</p> <pre><code>command &lt;&lt;&lt;\n  tool --input ~{input} --output ~{output}\n&gt;&gt;&gt;\n</code></pre> </li> </ul>"},{"location":"contributing/code_contribution/#task-blocks","title":"Task Blocks","text":"<p>A WDL task block defines a discrete, reusable step in a workflow. To ensure readability and consistency, follow these conventions when writing task blocks. Include single spaces between the input, command, output, and runtime sections and their enclosing curly brackets.</p> <pre><code>task example_task {\n  input {\n\n  }\n  command &lt;&lt;&lt;\n\n  &gt;&gt;&gt;\n  output {\n\n  }\n  runtime {\n\n  }\n}\n</code></pre>"},{"location":"contributing/code_contribution/#the-input-block","title":"The <code>input</code> block","text":"<ul> <li>The following conventions are used to expose docker, CPU, memory, and disk size:</li> </ul> <pre><code>input {\n  Int cpu = 4                              # Number of CPUs\n  Int disk_size = 100                      # Disk space in GB\n  String docker = \"us-docker.pkg.dev/example:1.0.0\"  # Docker container for the task\n  Int memory = 16                          # Memory in GB\n}\n</code></pre> <ul> <li> <p>Include optional tool parameters as inputs to the task</p> <pre><code>input {\n  Int? optional_tool_parameter1\n  String optional_tool_parameter2_with_default = \"default_value\"\n}\n</code></pre> </li> <li> <p>Input and output lists should not be formatted to have the equal sign aligned, but instead use a single space before and after the <code>=</code></p> <pre><code>correct_output = \"output_file\"\nlong_variable_name = \"long_file_name\"\n</code></pre> </li> <li> <p>Expose Docker as an input, an output (if versioning information not available), and runtime variable:</p> <pre><code>input {\n  String docker = \"us-docker.pkg.dev/example:1.0.0\"\n}\n...\noutput {\n  String used_docker = docker\n}\nruntime {\n  docker: docker\n}\n</code></pre> </li> </ul>"},{"location":"contributing/code_contribution/#the-command-block","title":"The <code>command</code> block","text":"<ul> <li> <p>Ensure use of line breaks between different sections of code to improve readability</p> <pre><code># Perform task step 1\nif [ condition ]; then\n  action1(variable)\nfi\n\n# Perform task step 2\nif [ another_condition ]; then\n  action2(variable)\nfi\n</code></pre> </li> <li> <p>Split command calls into multiple lines if they have user input variables and/or if the length of the command is very long to avoid text wrapping and/or side-scrolling, e.g.</p> <ul> <li>Use backslashes for continuation and indentation to clarify structure:</li> </ul> <pre><code> tool \\\n  --input ~{input_file} \\\n  --output ~{output_file} \\\n  --option1 ~{option1} \\\n  ...\n  --optionN ~{optionN}\n</code></pre> </li> <li> <p>Add comments that</p> <ul> <li>Explain what the optional parameters are</li> <li>Provide links to the tool documentation so future readers of the code know where to find that information</li> <li> <p>Explain what non-intuitive bash/python text wrangling actions do, e.g.</p> <pre><code>## awk for gene column ($6) to grab subtype ($15)\ncat ~{file} | awk -F '\\t' '{if ($6==\"M1\") print $15}' &gt; FLU_TYPE\n</code></pre> </li> </ul> </li> </ul>"},{"location":"contributing/code_contribution/#the-output-block","title":"The <code>output</code> block","text":"<ul> <li>The output block specifies the files or variables produced by the task. Follow these conventions:</li> </ul> <pre><code>output {\n  File result_csv = \"output.csv\"  # CSV file generated\n  File result_log = \"log.txt\"     # Log file\n}\n</code></pre> <ul> <li> <p>Ensure the docker container is exposed as an output string, e.g.</p> <pre><code>input {\n  String docker = \"us-docker.pkg.dev/general-theiagen/tool:version\"\n}\n...\noutput {\n  String XX_docker = docker\n}\nruntime {\n  docker: docker\n}\n</code></pre> </li> </ul>"},{"location":"contributing/code_contribution/#the-runtime-block","title":"The <code>runtime</code> block","text":"<ul> <li>The runtime block defines the compute resources and environment for the task.</li> <li> <p>Always specify a Docker:</p> <pre><code>runtime {\n  docker: docker\n  cpu: cpu\n  memory: memory\n  disk: disk_size\n}\n</code></pre> </li> </ul>"},{"location":"contributing/code_contribution/#workflow-blocks","title":"Workflow Blocks","text":"<p>A WDL workflow block orchestrates the execution of tasks and subworkflows. It defines the inputs, calls tasks or subworkflows, and specifies the final outputs. To ensure readability and consistency, follow these conventions when writing workflow blocks:</p>"},{"location":"contributing/code_contribution/#the-import-section","title":"The <code>import</code> section","text":"<ul> <li>Include a block of <code>import</code> statements (sorted in alphabetical order).</li> <li> <p>When a workflow imports a task, ensure it is imported under a unique name to avoid conflicts.</p> <pre><code>import \"../tasks/task_task1.wdl\" as task1_task\nimport \"../tasks/task_task2.wdl\" as task2_task\n</code></pre> </li> <li> <p>Order import statements alphabetically by the path of the imported file.</p> </li> </ul>"},{"location":"contributing/code_contribution/#the-input-block_1","title":"The <code>input</code> block","text":"<ul> <li>Optional inputs that should be able to be edited by the user, such as docker containers should be exposed on the workflow level as in the example</li> <li>In the case of subworkflows, all optional inputs should be exposed on the workflow level so that they can be modified by users on Terra</li> </ul> <pre><code>input {\n  String input\n  String task1_docker = \"us-docker.pkg.dev/general-theiagen/tool:version\"\n  String? task1_optional_argument\n}\n</code></pre>"},{"location":"contributing/code_contribution/#the-call-sections","title":"The <code>call</code> sections","text":"<ul> <li>Import task files as something other than the included task nam in order to avoid namespace conflicts</li> </ul> <pre><code>call task1_task.task1 {\n  input:\n    input = input,\n    docker = task1_docker\n}\n</code></pre>"},{"location":"contributing/code_contribution/#the-output-block_1","title":"The <code>output</code> block","text":"<ul> <li>Define all workflow outputs in this section.</li> <li>Use descriptive names for each output variable.</li> <li>Order outputs alphabetically by the name of the output variable</li> </ul> <pre><code>output {\n  # Task 1 outputs\n  File task1_out_csv = task1.output_csv\n  String task1_version = task1.version\n\n  # Subworkflow outputs\n  File subworkflow_out_tsv = subworkflow.task3_out_tsv\n  String subworkflow_version = subworkflow.task3_version\n}\n</code></pre>"},{"location":"contributing/code_contribution/#example-workflow-formats","title":"Example Workflow formats","text":"wf_example_wf.wdl <pre><code>import \"../tasks/task_task1.wdl\" as task1_task\nimport \"../tasks/task_task2.wdl\" as task2_task\n\nimport \"../workflows/wf_subworkflow.wdl\" as subworkflow\n\nworkflow example_wf {\n  input {\n    String input\n    String task1_docker = \"us-docker.pkg.dev/general-theiagen/task_1:version\"\n    String task2_docker = \"us-docker.pkg.dev/general-theiagen//task_2:version\"\n    String? hidden_task3_argument \n    String? hidden_task3_docker\n    String? hidden_task4_docker\n  }\n  call task1_task.task1 {\n    input:\n      input = input,\n      docker = task1_docker\n  }\n  call task2_task.task2 {\n    input: \n      input = input,\n      docker = task2_docker\n  }\n  call subworkflow.subworkflow {\n    input:\n      input = input,\n      task3_argument = hidden_task3_argument,\n      task3_docker = hidden_task3_docker\n      task4_docker = hidden_task4_docker\n  }\n  output {\n    # Task 1 outputs\n    File task1_out_csv = task1.output_csv\n    String task1_version = task1.version\n    String task1_docker = task1.docker\n    # Task 2 outputs\n    File task2_out_tsv = task2.output_tsv\n    String task2_version = task2.version\n    String task2_docker = task2.docker\n    # Subworkflow outputs for task 3\n    File task3_out_tsv = subworkflow.task3_out_tsv\n    String task3_version = subworkflow.task3_version\n    String task3_docker = subworkflow.task3_docker\n    # Subworkflow outputs for task 4\n    String task4_output = subworkflow.task4_output\n    String task4_version = subworkflow.task4_version\n  }      \n}\n</code></pre> wf_subworkflow.wdl <pre><code>import \"../tasks/task_task3.wdl\" as task3_task\nimport \"../tasks/task_task4.wdl\" as task4_task\n\nworkflow subworkflow {\n  input {\n    String input\n\n    # optional inputs for tasks inside subworkflows cannot\n    #  be seen on Terra, so make them available at the subworkflow\n    #  level so they can be modified by a Terra user\n    String? task3_argument \n    String? task3_docker\n    String? task4_docker\n  }\n  call task3_task.task3 {\n    input:\n      input = input,\n      args = task3_argument,\n      docker = task3_docker\n  }\n  call task4_task.task4 {\n    input:\n      input = task3.output_tsv,\n      docker = task4_docker\n  }\n  output {\n    File task3_out_tsv = task3.output_tsv\n    String task3_version = task3.version\n    String task3_docker = task3.docker\n    String task4_output = task4.output\n    String task4_version = task4.version\n  }\n}\n</code></pre>"},{"location":"contributing/doc_contribution/","title":"Contributing to the Documentation","text":""},{"location":"contributing/doc_contribution/#phb-documentation-contribution-guide","title":"PHB Documentation Contribution Guide","text":"<p>The documentation for PHB is hosted in the <code>docs/</code> directory. This documentation is written in Markdown and is built using MkDocs and the Material for MkDocs theme.</p> <p>This guide is intended to provide a brief overview of the documentation structure and how to contribute to the documentation, including standard language and formatting conventions.</p>"},{"location":"contributing/doc_contribution/#local-installation-live-previews","title":"Local Installation &amp; Live Previews","text":"<p>Since the documentation is built off of the <code>main</code> branch, it is highly recommended to preview your changes before making a PR. You can do this by installing the necessary packages and previewing (\"serving\") the documentation locally.</p> <p>To test your documentation changes, you will need to have the following packages installed on your local VM:</p> <pre><code>pip install mkdocs-material mkdocs-material-extensions mkdocs-git-revision-date-localized-plugin mike mkdocs-glightbox mkdocs-macros-plugin pandas\n</code></pre> <p>Once installed, navigate to the top directory in PHB. The live preview server can be activated by running the following command:</p> <pre><code>mkdocs serve\n</code></pre> <p>This will prompt you to open your browser to the appropriate local host address (by default, localhost:8000). Every time you save a change, the documentation will automatically update in the browser.</p>"},{"location":"contributing/doc_contribution/#vscode-extensions","title":"VSCode Extensions","text":"<p>Here are some VSCode Extensions can help you write and edit your markdown files (and allow you preview changes without running the server, though formatting will suffer):</p> <ul> <li>Markdown Preview Enhanced (Yiyi Wang) - This extension is good for previewing markdown files in VSCode, but is not good at rendering any of the more advanced features such as callouts or tables.</li> <li>Markdown All in One (Yu Zhang) - This extension allows you to use regular word-processing short-cuts to format your markdown files, like Ctrl-B to bold text, Ctrl-I for italics without having to manually type the <code>**</code> or <code>_</code> characters.</li> <li>markdownlint (David Anson) - This extension will help you catch any formatting errors in your markdown files.</li> </ul>"},{"location":"contributing/doc_contribution/#helpful-websites","title":"Helpful Websites","text":"<ul> <li>Excel to Markdown Table - This website will convert an Excel table into markdown format, which can be copied and pasted into your markdown file. Currently, we recommend using the <code>render_tsv_table()</code> macro (described below) to import TSV files, but this is a good alternative if you want to create a smaller table from scratch.</li> <li>Material for MkDocs Reference - This is the official reference for the Material for MkDocs theme, which will help you understand how to use the theme's features.</li> <li>Dead Link Check - This website will scan your website to ensure that all links are working correctly. This will only work on the deployed version of the documentation, not the local version.</li> </ul>"},{"location":"contributing/doc_contribution/#standard-language-formatting-conventions","title":"Standard Language &amp; Formatting Conventions","text":"<p>In order to maintain cohesive documentation, the following language and formatting conventions should be followed:</p>"},{"location":"contributing/doc_contribution/#language-conventions","title":"Language Conventions","text":"<p>The following language conventions should be followed when writing documentation:</p> <ul> <li>The documentation should be written in American English (sorry to our friends across the pond!)</li> <li>The following variables should receive the following descriptions:<ul> <li><code>cpu</code> - Number of CPUs to allocate to the task</li> <li><code>disk_size</code> - Amount of storage (in GB) to allocate to the task</li> <li><code>docker</code> or <code>docker_image</code> - The Docker container to use for the task</li> <li><code>memory</code> - Amount of memory/RAM (in GB) to allocate to the task</li> </ul> </li> </ul>"},{"location":"contributing/doc_contribution/#formatting-conventions","title":"Formatting Conventions","text":"<ul> <li>Bold Text - Use <code>**bold text**</code> to indicate text that should be bolded.</li> <li>Italicized Text - Use <code>_italicized text_</code> to indicate text that should be italicized.</li> <li>Highlighted Text - Use <code>==highlighted text==</code> to indicate text that should be highlighted.</li> <li><code>Code</code> - Use <code>`code`</code> (backticks) to indicate text that should be formatted as code.</li> <li>Underlined Text - Use <code>^^underlined text^^</code> to indicate text that should be underlined (works with our theme; not all Markdown renderers support this).</li> <li> <p>Citations</p> <ul> <li>Use a <code>&gt;</code> to activate quote formatting for a citation. Make sure to separate multiple citations with a comment line (<code>&lt;!-- --&gt;</code>) to prevent the citations from running together.</li> <li>Use a reputable citation style (e.g., Vancouver, Nature, etc.) for all citations.</li> </ul> </li> <li> <p>Callouts/Admonitions - These features are called \"call-outs\" in Notion, but are \"Admonitions\" in MkDocs. I highly recommend referring to the Material for MkDocs documentation page on Admonitions to learn how best to use this feature. Use the following syntax to create a callout:</p> <pre><code>!!! note \"Title\"\n    This is a note. Observe I am indented with four spaces.\n</code></pre> <p>Please see the Admonition documentation for more information on how to change the title, enable toggles, and more.</p> <p>The following custom callout types are supported in addition to the standard admonitions supported by our theme more information on the standard admonitions here:</p> <p>Dna</p> <p>This is a DNA admonition. Admire the cute green DNA emoji. You can create this with the <code>!!! dna</code> syntax.</p> <p>Use this admonition when wanting to convey general information or highlight specific facts.</p> Toggle <p>This is a toggle-able section. The emoji is an arrow pointing to the right downward. You can create this with the <code>??? toggle</code> syntax. I have added a <code>+</code> at the end of the question marks to make it open by default.</p> <p>Use this admonition when wanting to provide additional optional information or details that are not strictly necessary, or take up a lot of space.</p> Task <p>This is a toggle-able section for a workflow task. The emoji is a gear. Use the <code>??? task</code> syntax to create this admonition. Use <code>!!! task</code> if you want to have it be permanently expanded. I have add a <code>+</code> at the end of the question marks to make this admonition open by default and still enable its collapse.</p> <p>Use this admonition when providing details on a workflow, task, or tool.</p> <p>Caption</p> <p>This is a caption. The emoji is a painting. You can create this with the <code>!!! caption</code> syntax. A caption can be added beneath the picture and will also look nice.</p> <p>Use this admonition when including images or diagrams in the documentation.</p> <p>Techdetails</p> <p>This is where you will put technical details for a workflow task. You can create this by <code>!!! techdetails</code> syntax.</p> <p>Use this admonition when providing technical details for a workflow task or tool. These admonitions should include the following table:</p> Links Task [link to the task file in the PHB repository on GitHub] Software Source Code [link to tool's source code] Software Documentation [link to tool's documentation] Original Publication(s) [link to tool's publication] <p>If any of these items are unfillable, delete the row.</p> </li> <li> <p>Images - Use the following syntax to insert an image:</p> <pre><code>!!! caption \"Image Title\"\n    ![Alt Text](/path/to/image.png)\n</code></pre> </li> <li> <p>Indentation - FOUR spaces are required instead of the typical two. This is a side effect of using this theme. If you use two spaces, the list and/or indentations will not render correctly. This will make your linter sad :(</p> <pre><code>- first item\n    - second item\n        - third item\n</code></pre> </li> <li> <p>Tables - Use the following syntax to create a table</p> <pre><code>| Header 1 | Header 2 | Header 3 |\n|---|---|---|\n| value 1 | value2 | value3 |\n</code></pre> <p>Note that this is not a \"pretty\" markdown table. This is because the spacing would be crazy in the markdown file, especially for tables with a lot of text and/or columns. The table will render correctly in the documentation.</p> </li> <li> <p>Links - Use the following syntax to create a link. This is works for both files and websites. If linking a file, use the relative path.</p> <pre><code>[Link Text](https://www.example.com)\n</code></pre> </li> <li> <p>End all pages with an empty line</p> </li> </ul>"},{"location":"contributing/doc_contribution/#documentation-structure","title":"Documentation Structure","text":"<p>A brief description of the documentation structure is as follows:</p> <ul> <li><code>docs/</code> - Contains the Markdown files for the documentation.<ul> <li><code>assets/</code> - Contains images and other files used in the documentation.<ul> <li><code>figures/</code> - Contains images, figures, and workflow diagrams used in the documentation. For workflows that contain many images (such as BaseSpace_Fetch), it is recommended to create a subdirectory for the workflow.</li> <li><code>files/</code> - Contains files that are used in the documentation. This may include example outputs or templates. For workflows that contain many files (such as TheiaValidate), it is recommended to create a subdirectory for the workflow.</li> <li><code>logos/</code> - Contains Theiagen logos and symbols used in the documentation.</li> <li><code>metadata_formatters/</code> - Contains the most up-to-date metadata formatters for our submission workflows.</li> <li><code>sops/</code> - Contains any Standard Operating Procedures (SOPs) that correspond to workflows in the documentation.</li> <li><code>tables/</code> - Contains TSV files used to generate tables in the documentation. These are used to generate the overview tables for workflows, as well as the input and output tables for workflows.</li> <li><code>new_workflow_template.md</code> - A template for adding a new workflow page to the documentation. You can see this template here</li> </ul> </li> <li><code>common_text/</code> - Contains the Markdown files for common text used in the documentation. This includes task descriptions, workflow descriptions, and other common text. This is where you will put any new task descriptions or workflow descriptions that are not specific to a single workflow. This enables modular and reusable documentation.</li> <li><code>contributing/</code> - Contains the Markdown files for our contribution guides, such as this file</li> <li><code>javascripts/</code> - Contains JavaScript files used in the documentation.<ul> <li><code>tablesort.js</code> - A JavaScript file used to enable table sorting in the documentation.</li> </ul> </li> <li><code>overrides/</code> - Contains HTMLs used to override theme defaults<ul> <li><code>main.html</code> - Contains the HTML used to display a warning when the latest version is not selected</li> </ul> </li> <li><code>stylesheets/</code> - Contains CSS files used in the documentation.<ul> <li><code>extra.css</code> - A custom CSS file used to style the documentation; contains all custom theme elements (scrollable tables, resizable columns, Theiagen colors), and custom admonitions.</li> </ul> </li> <li><code>workflows/</code> - Contains the Markdown files for each workflow, organized into subdirectories by workflow category</li> <li><code>workflows_overview/</code> - Contains the Markdown files for the overview tables for each display type: alphabetically, by applicable kingdom, and by workflow type.</li> <li><code>index.md</code> - The home/landing page for our documentation.</li> </ul> </li> </ul>"},{"location":"contributing/doc_contribution/#new-page","title":"Adding a Page for a New Workflow","text":"<p>Hey, we've got a template for that!</p> <p>Please see our template here for ease of use. Please remove all italicized text and replace with the appropriate information. If in doubt, please refer to existing documentation.</p> <p>If you are adding a new workflow, there are a number of things to do in order to include the page in the documentation:</p> <ol> <li>Add a page with the title of the workflow to appropriate subdirectory in <code>docs/workflows/</code>. Please use the template found in the <code>assets/</code> folder to ensure all information is added.</li> <li>Collect the following information for your new workflow:<ul> <li>Workflow Name - Link the name with a relative path to the workflow page in appropriate <code>docs/workflows/</code> subdirectory</li> <li>Workflow Description - Brief description of the workflow</li> <li>Applicable Kingdom - Link one of the following options to the corresponding heading in the <code>docs/workflows_overview/workflows_kingdom.md</code> file. Options: \"Any taxa\", \"Bacteria\", \"Mycotics\", \"Viral\"</li> <li>Workflow Level (on Terra) - Options: \"Sample-level\", \"Set-level\", or \"\"</li> <li>Workflow Type - Link one of the following options to the corresponding heading in the <code>docs/workflows_overview/workflows_type.md</code> file. Options: \"Data Import\", \"Genomic Characterization\", \"Phylogenetic Construction\", \"Phylogenetic Placement\", \"Public Data Sharing\", \"Exporting Data from Terra\", or \"Standalone\"; this should match the location/naming of the workflow page in <code>docs/workflows/</code>.</li> <li>Command-line compatibility - Options: \"Yes\", \"No\", and/or \"Some optional features incompatible\"</li> <li>The version where the last known changes occurred (likely the upcoming version if it is a new workflow -- if the upcoming version number is currently unknown, please use vX.X.X)</li> <li>Link to the workflow on Dockstore - Link the workflow name to the information tab on Dockstore.</li> </ul> </li> <li>Format this information in the <code>assets/tables/all_workflows.tsv</code> file.</li> <li>Copy the path to the workflow documentation page to ALL of the appropriate locations in the <code>mkdocs.yml</code> file (under the <code>nav:</code> section) in the main directory of this repository. This ensures the workflow can be accessed from the navigation sidebar.</li> </ol>"},{"location":"contributing/doc_contribution/#macros","title":"Macros","text":"<p>The documentation uses a few macros to help with the formatting of the documentation. These macros are defined in <code>macros/main.py</code> and are used in the documentation files. The following macros are available:</p> <ul> <li><code>render_tsv_table()</code> - This macro is used to create a table from a TSV file. The TSV file should be in the <code>docs/assets/tables</code> directory and should be formatted as a TAB-DELIMITED table. The macro will automatically create a table from the TSV file and insert it into the documentation.</li> <li><code>include_md()</code> - This macro is used to include a Markdown file in the documentation. The macro will automatically adjust the heading levels, resolve relative links, and support conditional and nested includes.</li> </ul> <p>Please see the macros README for more information.</p>"},{"location":"getting_started/commandline/","title":"With the Command-Line","text":""},{"location":"getting_started/commandline/#getting-started-with-the-command-line","title":"Getting Started with the Command-Line","text":"<p>What is WDL?</p> <p>Running workflows on the command-line requires the direct use of the WDL (Workflow Development Language). As the name suggests, this is the workflow management language that is used to write and execute workflows. Frank has put together a great video describing \ud83d\udcfa WDL Task and Workflow Files and you can find full instructions below on running these WDL workflows.</p>"},{"location":"getting_started/commandline/#step-1-obtain-the-workflow-and-data","title":"Step 1: Obtain the Workflow and Data","text":"<p>You will need to have access to the WDL workflow file (.wdl) and any associated input files (such as reference genomes, input data files, etc.). To do this, complete the following steps:</p>"},{"location":"getting_started/commandline/#1-install-git-if-not-already-installed","title":"1. Install Git (if not already installed)","text":"<p>If you don't already have Git installed on your system, you will need to install it. Here's how you can install Git on some common operating systems:</p> Linux (Ubuntu/Debian) <pre><code>sudo apt update\nsudo apt install git\n</code></pre> macOS <p>Git is usually pre-installed on macOS. However, you can install or update it using Homebrew:</p> <pre><code>brew install git\n</code></pre> Windows <p>Download and install Git from the official website: https://git-scm.com/download/win</p>"},{"location":"getting_started/commandline/#2-clone-the-repository","title":"2. Clone the Repository","text":"<ol> <li>Open your terminal.</li> <li> <p>Create a directory where you want to store the cloned repository and navigate to it.</p> <pre><code>mkdir /path/to/your/desired/new/directory\ncd /path/to/your/desired/new/directory\n</code></pre> </li> <li> <p>Clone the https://github.com/theiagen/public_health_bioinformatics repository from GitHub using the following command:</p> <pre><code>git clone https://github.com/theiagen/public_health_bioinformatics.git\n</code></pre> </li> <li> <p>After running the command, Git will download all the repository files and set up a local copy in the directory you specified.</p> </li> </ol>"},{"location":"getting_started/commandline/#3-navigate-to-the-cloned-repository","title":"3. Navigate to the Cloned Repository","text":"<ol> <li> <p>Change your working directory to the newly cloned repository:</p> <pre><code>cd public_health_bioinformatics\n</code></pre> </li> <li> <p>You're now inside the cloned repository's directory. Here, you should find all the files and directories from the GitHub repository.</p> </li> </ol>"},{"location":"getting_started/commandline/#4-verify-the-cloned-repository","title":"4. Verify the Cloned Repository","text":"<p>You can verify that the repository has been cloned successfully by listing the contents of the current directory using the <code>ls</code> (on Linux/macOS) or <code>dir</code> (on Windows) command:</p> <pre><code>ls\n</code></pre> <p>This should display the files and directories within the https://github.com/theiagen/public_health_bioinformatics.git repository.</p> <p>Congratulations! You've successfully cloned the https://github.com/theiagen/public_health_bioinformatics.git repository from GitHub to your local command-line environment. You're now ready to proceed with running the bioinformatics analysis workflows using WDL as described in subsequent steps.</p>"},{"location":"getting_started/commandline/#step-2-install-docker-and-miniwdl","title":"Step 2: Install docker and miniWDL","text":"<p>Docker and miniwdl will be required for command-line execution. We will check if these are installed on your system and if not, install them now.</p> <ol> <li>Open your terminal.</li> <li> <p>Navigate to the directory where your workflow and input files are located using the <code>cd</code> command:</p> <pre><code>cd /path/to/your/workflow/directory\n</code></pre> </li> <li> <p>Check if Docker is installed:</p> <pre><code>docker --version\n</code></pre> <p>If Docker is not installed, follow the official installation guide for your operating system: https://docs.docker.com/get-docker/</p> </li> <li> <p>Check if <code>miniwdl</code> is installed:</p> <pre><code>miniwdl --version\n</code></pre> <p>If <code>miniwdl</code> is not installed, you can install it using pip:</p> <pre><code>pip install miniwdl\n</code></pre> </li> </ol>"},{"location":"getting_started/commandline/#step-3-set-up-the-inputjson-file-for-your-wdl-workflow","title":"Step 3: Set up the input.json file for your WDL workflow","text":"<p>In a WDL (Workflow Description Language) workflow, an input JSON file is used to provide attributes (values/files etc) for input variables into the workflow. The names of the input variables must match the names of inputs specified in the workflow file. The workflow files can be found within the git repository that you cloned. Each input variable can have a specific type of attribute, such as String, File, Int, Boolean, Array, etc. Here's a detailed outline of how to specify different types of input variables in an input JSON file:</p> String Input <p>To specify a string input, use the name of the input variable as the key and provide the corresponding string value. Example:</p> <pre><code>{\n  \"sampleName\": \"VirusSample1\",\n  \"primerSequence\": \"ACGTGTCAG\"\n}\n</code></pre> File Input <p>To specify a file input, provide the path to the input file relative to the directory where you run the <code>miniwdl</code> command. Example:</p> <pre><code>{\n  \"inputFastq\": \"data/sample.fastq\",\n  \"referenceGenome\": \"reference/genome.fasta\"\n}\n</code></pre> Int Input <p>To specify an integer input, provide the integer value. These do not require quotation marks. Example:</p> <pre><code>{\n  \"minReadLength\": 50,\n  \"maxThreads\": 8\n}\n</code></pre> Boolean Input <p>To specify a boolean input, use <code>true</code> or <code>false</code> (lowercase). Example:</p> <pre><code>{\n  \"useQualityFiltering\": true,\n  \"useDuplicateRemoval\": false\n}\n</code></pre> Array Input <p>To specify an array input, provide the values as an array. Example:</p> <pre><code>{\n  \"sampleList\": [\"Sample1\", \"Sample2\", \"Sample3\"],\n  \"thresholds\": [0.1, 0.05, 0.01]\n}\n</code></pre>"},{"location":"getting_started/commandline/#step-4-execute-the-workflow","title":"Step 4: Execute the Workflow","text":"<p>Run the workflow using <code>miniwdl</code> with the following command, replacing <code>your_workflow.wdl</code> with the actual filename of your WDL workflow and <code>input.json</code> with the filename of your input JSON file.</p> <pre><code>miniwdl run your_workflow.wdl --input input.json\n</code></pre>"},{"location":"getting_started/commandline/#step-5-monitor-workflow-progress","title":"Step 5: Monitor Workflow Progress","text":"<p>You can monitor the progress of the workflow by checking the console output for updates and log messages. This can help you identify any potential issues or errors during execution.</p> Tips for monitoring your workflow What to do if you need to cancel a run"},{"location":"getting_started/commandline/#tips-for-monitoring","title":"Tips for monitoring workflow progress","text":"<p>After you've started the workflow using the <code>miniwdl run</code> command, you'll see various messages appearing in the terminal. These messages provide information about the various steps of the workflow as they are executed. Monitoring this output is crucial for ensuring that the workflow is progressing as expected.</p> <p>The console output will typically show:</p> <ol> <li>Task Execution: You will see messages related to the execution of individual tasks defined in your workflow. These messages will include details about the task's name, input values, and progress.</li> <li>Logging Information: Workflow tasks often generate log messages to provide information about what they are doing. These logs might include details about software versions, input data, intermediate results, and more.</li> <li>Execution Progress: The output will indicate which tasks have completed and which ones are currently running. This helps you track the overall progress of the workflow.</li> <li>Error Messages: If there are any errors or issues during task execution, they will be displayed in the console output. These error messages can help you identify problems and troubleshoot them.</li> <li>Timing Information: You might also see timing information for each task, indicating how long they took to execute. This can help you identify tasks that might be taking longer than expected.</li> </ol> <p>Example Console Output:</p> <p>Here's an example of what the console output might look like while the workflow is running:</p> <pre><code>Running: task1\nRunning: task2\nCompleted: task1 (Duration: 5s)\nRunning: task3\nError: task2 (Exit Code: 1)\nRunning: task4\n...\n</code></pre> <p>In this example, you can see that <code>task1</code> completed successfully in 5 seconds, but <code>task2</code> encountered an error and exited with a non-zero exit code. This kind of output provides insight into the progress and status of the workflow.</p> <p>What to Look For:</p> <p>As you monitor the console output, pay attention to:</p> <ul> <li>Successful Task Completion: Look for messages indicating tasks that have completed successfully. This ensures that the workflow is progressing as intended.</li> <li>Error Messages: Keep an eye out for any error messages or tasks that exit with non-zero exit codes. These indicate issues that need attention.</li> <li>Task Order: The order of task messages can provide insights into the workflow's logic and execution flow.</li> <li>Timing: Notice how long each task takes to complete. If a task takes significantly longer than expected, it might indicate a problem.</li> </ul> <p>Early Troubleshooting:</p> <p>If you encounter errors or unexpected behavior, the console output can provide valuable information for troubleshooting. You can search for the specific error messages to understand the problem and take appropriate action, such as correcting input values, adjusting parameters, or addressing software dependencies. </p> <p>Monitoring the workflow progress through the console output is an essential practice for successful execution. It allows you to track the status of individual tasks, identify errors, and ensure that your analysis is proceeding as planned. Regularly reviewing the output will help you address any issues and improve the efficiency of your bioinformatics workflow.</p>"},{"location":"getting_started/commandline/#canceling-a-run","title":"Canceling a Running Workflow","text":"<p>Canceling a running workflow is an important step in case you need to stop the execution due to errors, unexpected behavior, or any other reason. If you're using <code>miniwdl</code> to run your workflow, here's how you can cancel a workflow run while it's in progress:</p> <ol> <li>Ctrl + C: The simplest way to cancel a running command in the terminal is to press <code>Ctrl + C</code>. This sends an interrupt signal to the running process, which should gracefully terminate it. However, keep in mind that this might not work for all scenarios, and some tasks might not be able to cleanly terminate.</li> <li>Terminate Docker Containers: If your workflow involves Docker containers, you might need to ensure that any Docker containers launched by the workflow are also terminated. To do this, you can manually stop the Docker containers associated with the workflow. You can use the <code>docker ps</code> command to list running containers and <code>docker stop &lt;container_id&gt;</code> to stop a specific container.</li> <li> <p>Kill the miniwdl Process: If the <code>Ctrl + C</code> approach doesn't work, you might need to explicitly kill the <code>miniwdl</code> process running in the terminal. To do this, you can use the <code>kill</code> command. First, find the process ID (PID) of the <code>miniwdl</code> process by running:</p> <pre><code>ps aux | grep miniwdl\n</code></pre> <p>Identify the PID in the output and then run:</p> <pre><code>kill -9 &lt;PID&gt;\n</code></pre> <p>This forcefully terminates the process.</p> </li> <li> <p>Clean Up Intermediate Files: Depending on the workflow and how tasks are structured, there might be intermediate files or resources that were generated before the cancellation. You might need to manually clean up these files to free up disk space.</p> </li> <li>Check for Workflow-Specific Cancellation: Some workflows might have specific mechanisms to handle cancellation. Refer to the workflow documentation or user guide to understand if there's a recommended way to cancel the workflow gracefully.</li> <li>Check for Any Remaining Resources: After canceling the workflow, it's a good practice to check for any remaining resources that might need to be cleaned up. This could include temporary files, Docker images, or other resources that were created during the workflow's execution.</li> </ol> <p>Remember that canceling a workflow might leave the system in an inconsistent state, especially if some tasks were partially executed. After canceling, it's a good idea to review the output and logs to identify any cleanup actions you might need to take.</p> <p>It's important to approach workflow cancellation carefully, as abruptly terminating processes can potentially lead to data loss or other unintended consequences. Always make sure you understand the workflow's behavior and any potential side effects of cancellation before proceeding.</p>"},{"location":"getting_started/commandline/#step-6-review-output","title":"Step 6: Review Output","text":"<p>Once the workflow completes successfully, you will find the output files and results in the designated output directory as defined in your WDL workflow.</p> Substep 1: Locate the Output Directory <p>Before you begin reviewing outputs, make sure you know where the output directory of your workflow is located. This is typically specified in the workflow configuration or input JSON file. Navigate to this directory using the <code>cd</code> command in your terminal.</p> <pre><code>cd /path/to/your/output/directory\n</code></pre> Substep 2: Logs <p>Logs are a valuable source of information about what happened during each step of the workflow. Each task in the workflow might generate its own log file. Here's how to review logs:</p> <ol> <li> <p>Use the <code>ls</code> command to list the files in the output directory:</p> <pre><code>ls\n</code></pre> </li> <li> <p>Look for log files with names that correspond to the tasks in your workflow. These files often have a <code>.log</code> extension.</p> </li> <li> <p>Open a log file using a text editor like <code>less</code> or <code>cat</code>:</p> <pre><code>less task_name.log\n</code></pre> <p>Use the arrow keys to navigate through the log, and press <code>q</code> to exit.</p> </li> <li> <p>Inspect the log for messages related to the task's execution, input values, software versions, and any errors or warnings that might have occurred.</p> </li> </ol> Substep 3: stderr (Standard Error) and stdout (Standard Output) <p>stderr and stdout are streams where processes write error messages and standard output, respectively. These are often redirected to files during workflow execution. Here's how to review them:</p> <ol> <li>Use the <code>ls</code> command to list the files in the output directory.</li> <li>Look for files with names like <code>task_name.err</code> (for stderr) and <code>task_name.out</code> (for stdout).</li> <li> <p>Open the files using a text editor:</p> <pre><code>less task_name.err\nless task_name.out\n</code></pre> <p>These files might contain additional information about the task's execution, errors, and output generated during the analysis.</p> </li> </ol> Substep 4: Reviewing Output Files <p>Workflow tasks might generate various types of output files, such as plots, reports, or data files. Here's how to review them:</p> <ol> <li>Use the <code>ls</code> command to list the files in the output directory.</li> <li>Identify the files generated by your workflow tasks.</li> <li>Depending on the file type, you can use different tools to open and view them. For example, you might use <code>less</code> or a text editor for text-based files, or an image viewer for image files.</li> </ol> Substep 5: Interpretation and Troubleshooting <p>As you review the outputs, keep these points in mind:</p> <ul> <li>Successful Execution: Look for indicators of successful task execution, such as expected messages, correct output files, and absence of error messages.</li> <li>Errors and Warnings: Pay close attention to any error or warning messages in logs, stderr, or stdout. These can help you identify issues that need troubleshooting.</li> <li>Input Values and Parameters: Verify that input values and parameters were correctly passed to tasks. Incorrect input can lead to unexpected behavior.</li> <li>Software Versions: Check if the versions of the tools and software used in the workflow match what you expected.</li> <li>Intermediate Outputs: Review intermediate outputs generated by tasks. These might provide insights into the workflow's progress and results.</li> </ul> Substep 6: Make Notes and Take Action <p>As you review the outputs, make notes of any issues, errors, or unexpected behavior you encounter. Depending on the severity of the issues, you might need to:</p> <ul> <li>Adjust input parameters.</li> <li>Re-run specific tasks.</li> <li>Debug and troubleshoot errors.</li> <li>Consult the workflow documentation.</li> <li>Reach out to the Theiagen Genomics bioinformatics experts for assistance. (support@theiagen.com)</li> </ul> <p>Output Review Conclusion</p> <p>Reviewing the outputs of your bioinformatics workflow is a critical step to ensure the quality of your analysis. Logs, stderr, stdout, and generated output files provide valuable insights into the execution process and results. By carefully reviewing these outputs and addressing any issues, you can enhance the reliability and accuracy of your bioinformatics analysis.</p>"},{"location":"getting_started/commandline/#step-7-troubleshooting-and-debugging","title":"Step 7: Troubleshooting and Debugging","text":"<ol> <li>If the workflow encounters errors or fails to execute properly, review the error messages in the terminal.</li> <li>Check for any missing input files, incorrect paths, or issues related to software dependencies.</li> <li>Double-check your input JSON file to ensure that all required inputs are correctly specified.</li> </ol> <p>Congratulations! You have successfully executed a bioinformatics analysis workflow using WDL on the command-line. This tutorial covered the basic steps to run a WDL workflow using the <code>miniwdl</code> command-line tool.</p> <p>Remember that the specific steps and commands might vary depending on the details of your workflow, software versions, and environment. Be sure to consult the documentation for <code>miniwdl</code>, WDL, and any other tools you're using for more advanced usage and troubleshooting.</p> <p>Happy analyzing!</p>"},{"location":"getting_started/philosophy/","title":"Workflow Failure Philosophy","text":""},{"location":"getting_started/philosophy/#workflow-failure-philosophy","title":"Workflow Failure Philosophy","text":""},{"location":"getting_started/philosophy/#our-approach-to-workflow-failures","title":"Our Approach to Workflow Failures","text":"<p>At Theiagen, we believe our workflows should only fail because of technical issues, not because of poor quality data. Our goal is to create workflows that can handle data in any condition and still provide meaningful results, especially if that data isn\u2019t perfect.</p>"},{"location":"getting_started/philosophy/#what-you-can-expect","title":"What You Can Expect","text":"<ul> <li> <p>Your workflow will keep running, even with imperfect data</p> <p>Data quality shouldn't cause failures. Poor or incomplete data should never stop your workflow. Instead, the workflow will process it and (hopefully!) provide meaningful outputs, which can include blank results or messages indicating the value could not be generated.</p> </li> <li> <p>Your workflow will provide useful feedback, not errors</p> <p>If an issue arises in your data, such as missing or invalid data in a template control, you can know that any workflow failures are due to underlying programmatic issues, not your data.</p> </li> <li> <p>You\u2019ll gain a better understanding of your data</p> <p>Since poor-quality data will not cause workflow failures, the relevant QC results will be available as output, so you can understand what's happened and make any needed adjustments moving forward.</p> </li> </ul>"},{"location":"getting_started/philosophy/#ongoing-improvements","title":"Ongoing Improvements","text":"<p>While we\u2019ve made a lot of progress, we\u2019re still working on fully implementing this philosophy across all of our workflows. If you encounter an issue where poor data quality leads to a failure, please let us know. Your feedback helps us make continuous improvements.</p> <p>Thanks for being part of the process! We\u2019re always working to improve and your feedback plays a huge role in making that happen. Together, we\u2019ll keep making things run smoother and easier for everyone.</p> <p>If you experience a workflow failure related to data quality, we want to hear from you! Please reach out to us at support@theiagen.com with the following details:</p> <ul> <li>The type of data involved</li> <li>The error messages or failures encountered</li> <li>The steps that led to the issue<ul> <li>if this error was generated on the command-line, please include the full command used</li> <li>if this error was generated when running the workflow with Terra.bio, please provide a link to the specific workflow's job history page</li> </ul> </li> </ul>"},{"location":"getting_started/terra/","title":"With Terra.bio","text":""},{"location":"getting_started/terra/#getting-started-with-terra","title":"Getting Started with Terra","text":"<p>Our Approach</p> <p>Theiagen\u2019s approach to genomic analysis in public health typically uses the Terra platform to run workflows that undertake bioinformatic analysis, then uses other platforms for visualization of the resulting data. This is described in more depth in our paper Accelerating bioinformatics implementation in public health, and the application of this approach for genomic surveillance of SARS-CoV-2 in California is described in the paper Pathogen genomics in public health laboratories: successes, challenges, and lessons learned from California\u2019s SARS-CoV-2 Whole-Genome Sequencing Initiative, California COVIDNet.</p> <p>When undertaking genomic analysis using Terra and other data visualization platforms, it is essential to consider the necessary and appropriate workflows and resources for your analysis. To help you make these choices, take a look at the relationship between the most commonly used Theiagen workflows, and the descriptions of the major stages in genomic data analysis below.</p> <p>Analysis Approaches for Genomic Data</p> General Workflow RelationshipsAvailable Standalone Workflows <p></p> <p>This diagram shows the available workflows in the PHB repository, represented by circles, that are available for analysis of genomic data. Workflows are grouped into boxes that represent the major types of analysis that they perform. The arrows between the boxes represent the relationships between the workflows, showing which workflows may be used consecutively, while the large arrow underlying everything indicates the general process of analysis.</p> <p></p> <p>This diagram shows the available standalone workflows in the PHB repository, represented by circles, that are available for analysis of genomic data. Workflows are grouped by colors that represent the major types of analysis that they perform. These workflows can be used independently of the major workflow groupings as either supplements or alternatives.</p> <p>Find more SOPs</p> <p>You can see all available SOPs on our Available SOPs page. We have provided links to the relevant and most recent SOPs in the sections below, but please note that this page offers an incomplete listing.</p> <p>Current SOPs for getting started in Terra</p> SOP SOP version PHB version compatibility Pathogen/Category Getting Started In Terra v4 v2, v3 Getting Started"},{"location":"getting_started/terra/#data-import-to-terra","title":"Data Import to Terra","text":"<p>To start using Terra for data analysis, you will first need to import your data into your workspace. There are multiple ways to do this:</p> <ul> <li>Using Terra\u2019s native features to upload data from your local computer or link to data that\u2019s already in a Google bucket</li> <li>Data import workflows<ul> <li>Using the SRA_Fetch workflow to import publicly available data from any repository in the INSDC (including with SRA, ENA and DRA)</li> <li>Using the Assembly_Fetch workflow to import publicly available genome assemblies from NCBI</li> <li>Using the BaseSpace_Fetch workflow to import data from your Illumina BaseSpace account</li> <li>Using the Create_Terra_Table workflow to help create your data table after manual upload to your Terra workspace (or a Google Cloud Storage Bucket)</li> </ul> </li> </ul> <p>Current SOPs for importing data into a Terra workspace</p> SOP Workflow SOP version PHB version compatibility Pathogen/Category Linking BaseSpace and Importing BaseSpace Reads to Terra BaseSpace_Fetch v3 v3 Data Import Uploading Data, Creating Metadata Tables and TSV files, and Importing Workflows None v4 v3 Data Import"},{"location":"getting_started/terra/#genome-assembly-qc-and-characterization","title":"Genome assembly, QC, and characterization","text":""},{"location":"getting_started/terra/#theiax-workflows","title":"TheiaX workflows","text":"<p>The TheiaX workflows are used for genome assembly, quality control, and characterization. The TheiaCoV Workflow Series, TheiaProk Workflow Series, and TheiaEuk Workflow Series workflows are intended for viral, bacterial, and fungal pathogens, respectively. TheiaMeta Workflow Series  is intended for the analysis of a single taxon from metagenomic data.</p> <p>Current SOPs for the TheiaX workflows</p> For analyzing with TheiaCoV SOP Workflow SOP version PHB version compatibility Pathogen/Category Analyze SARS-COV-2 using TheiaCoV_FASTA FASTA, TheiaCoV v2 v1 SC2 Analyze SARS-COV-2 using TheiaCoV_Illumina_PE_PHB PE, TheiaCoV v4 v3 SC2 Analyze SARS-COV-2 using TheiaCoV_Illumina_SE_PHB SE, TheiaCoV v4 v3 SC2 Analyze SARS-COV-2 using TheiaCoV_ONT ONT, TheiaCoV v4 v3 SC2 Analyzing SARS-CoV-2 using TheiaCov_ClearLabs CL, TheiaCoV v4 v3 SC2 For analyzing with TheiaProk SOP Workflow SOP version PHB version compatibility Pathogen/Category Analyzing Bacterial Data in Terra using Theiagen\u2019s TheiaProk Illumina PE Workflow PE, TheiaProk v3 v2, v3 Bacterial TheiaProk_ONT ONT, TheiaProk v3 v2, v3 Bacterial"},{"location":"getting_started/terra/#quality-evaluation","title":"Quality evaluation","text":"<p>The TheiaX workflows will generate various quality metrics. These should be evaluated relative to quality thresholds that have been agreed upon within your laboratory or sequencing program and define the sufficient quality characteristics for a genome and sequence data to be used. For the TheiaCoV Workflow Series, TheiaProk Workflow Series, and TheiaEuk Workflow Series workflows, this quality evaluation may be undertaken using the optional <code>QC_check</code> task. Full instructions for the use of this task may be found on the relevant workflow page. Some quality metrics are not evaluated by the <code>QC_check</code> task and should be evaluated manually.</p> <p>Genomes that fail to meet agreed quality thresholds should not be used. Results for characterization of these genomes may be inaccurate or unreliable. The inclusion of poor-quality genomes in downstream comparative analyses will bias their results. Samples that fail to meet QC thresholds will need to be re-sequenced and sample processing may need to be repeated (e.g. culture-based isolation of clonal bacteria, DNA/RNA extraction, and processing for sequencing).</p>"},{"location":"getting_started/terra/#update-workflows-for-sars-cov-2-genomes","title":"Update workflows for SARS-CoV-2 genomes","text":"<p>Workflows are available for updating the Pangolin and VADR assignments made to SARS-CoV-2 genomes. The Pangolin Update workflow accounts for the delay in assigning names to newly emerging lineages that you may have already sequenced. The VADR_Update workflow similarly accounts for features that have been newly identified in SARS-CoV-2 genomes when assessing genome quality with VADR.</p>"},{"location":"getting_started/terra/#phylogenetics","title":"Phylogenetics","text":""},{"location":"getting_started/terra/#phylogenetic-construction","title":"Phylogenetic construction","text":"<p>Phylogenetic trees are constructed to assess the evolutionary relationships between sequences in the tree. These evolutionary relationships are often used as a proxy for epidemiological relationships, and sometimes for inferring transmission between isolation sources.</p> <p>There are various methods for constructing phylogenetic trees, depending on the sequencing data being used, the organism being analyzed and how it evolved, what you would like to infer from the tree, and the computational resources available for the tree construction. Theiagen has a number of workflows for constructing phylogenetic trees. For full details of these workflows, please see Guide to Phylogenetics, which includes advice on the appropriate tree-building workflows and phylogenetic visualization approaches.</p> <p>Current SOPs for phylogenetic construction</p> SOP Workflow SOP version PHB version compatibility Pathogen/Category Running Theiagen\u2019s Snippy_Variants_PHB Workflow in Terra Snippy_Variants v1 v2 Bacterial, Phylogenetic construction"},{"location":"getting_started/terra/#phylogenetic-placement","title":"Phylogenetic placement","text":"<p>Phylogenetic placement is used to place your own sequences onto an existing phylogenetic tree. This may be used to find the closest relatives to your sequence(s). More details, including phylogenetic visualization approaches, can be found in Guide to Phylogenetics.  </p>"},{"location":"getting_started/terra/#public-data-sharing","title":"Public Data Sharing","text":"<p>Current SOPs for data submissions</p> SOP Workflow SOP version PHB version compatibility Pathogen/Category Submitting SC2 Sequence Data to GISAID using Theiagen\u2019s Terra 2 GISAID Workflow Terra_2_GISAID v2 v2 Public data sharing, SC2"},{"location":"getting_started/terra/#wastewater-metagenomic-analysis","title":"Wastewater Metagenomic Analysis","text":"<p>Current SOPs for wastewater metagenomic data analysis</p> SOP Workflow SOP version PHB version compatibility Pathogen/Category Analyzing SARS-CoV-2 Metagenomic Samples using Freyja FASTQ Freyja v2 v2 SC2 Creating Static Reference Files for Freyja Analysis in Terra using Freyja Update Freyja v2 v2 SC2 Creating a Dashboard Visualization of SARS-CoV-2 Metagenomic Samples using Freyja Dashboard Freyja v2 v2 SC2 Plotting SARS-CoV-2 Metagenomic Sample Data using Freyja Plot Freyja v3 v2 SC2 Running Influenza A, H3N2 Metagenomic Samples in Terra using Theiagen\u2019s Freyja FASTQ Workflow Freyja v1 v3 Flu"},{"location":"guides/custom_organisms/","title":"Guide to Running Custom Organisms on TheiaCoV","text":""},{"location":"guides/custom_organisms/#guide-to-running-custom-organisms-on-theiacov","title":"Guide to Running Custom Organisms on TheiaCoV","text":"<p>We encourage users to refer to the TheiaViral workflow series for assembling viruses that are not accounted for in TheiaCoV. </p>"},{"location":"guides/custom_organisms/#the-theiacov-workflow-series","title":"The TheiaCoV Workflow Series","text":"<p>The TheiaCoV Workflow Series is a suite of bioinformatics workflows designed for the assembly, quality assessment, and characterization of viral genomes. These workflows accommodate various input data types and support multiple viral organisms, facilitating comprehensive genomic analyses for public health applications.</p> <p>TheiaCoV Workflow Diagram</p> <p></p> <p>Figure 1: The TheiaCoV workflow diagram. SARS-CoV-2 is the default organism, but compatibility with several others is directly implemented and custom viruses can be submitted for reference-based genome assembly. Depending on the organism provided, which is controlled by the <code>organism</code> optional input, independent and tailored genomic characterization modules are triggered. All organisms follow a consensus assembly approach computed by iVar, with the exception of flu which is assembled by IRMA.</p>"},{"location":"guides/custom_organisms/#theiacov-default-organisms","title":"TheiaCoV Default Organisms","text":"<p>Supported Organisms</p> <p>These workflows currently support the following organisms:</p> <ul> <li>SARS-CoV-2\u00a0(<code>\"sars-cov-2\"</code>,\u00a0<code>\"SARS-CoV-2\"</code>) - default organism input</li> <li>Mpox virus\u00a0(<code>\"MPXV\"</code>,\u00a0<code>\"mpox\"</code>,\u00a0<code>\"monkeypox\"</code>,\u00a0<code>\"Monkeypox virus\"</code>,\u00a0<code>\"Mpox\"</code>)</li> <li>Human Immunodeficiency Virus\u00a0(<code>\"HIV\"</code>)</li> <li>West Nile Virus\u00a0(<code>\"WNV\"</code>,\u00a0<code>\"wnv\"</code>,\u00a0<code>\"West Nile virus\"</code>)</li> <li>Influenza\u00a0(<code>\"flu\"</code>,\u00a0<code>\"influenza\"</code>,\u00a0<code>\"Flu\"</code>,\u00a0<code>\"Influenza\"</code>)</li> <li>RSV-A\u00a0(<code>\"rsv_a\"</code>,\u00a0<code>\"rsv-a\"</code>,\u00a0<code>\"RSV-A\"</code>,\u00a0<code>\"RSV_A\"</code>)</li> <li>RSV-B\u00a0(<code>\"rsv_b\"</code>,\u00a0<code>\"rsv-b\"</code>,\u00a0<code>\"RSV-B\"</code>,\u00a0<code>\"RSV_B\"</code>)</li> <li>Measles (<code>\"measles\"</code>, <code>\"Measles\"</code>, <code>\"mev\"</code>, <code>\"MeV\"</code>, <code>\"Morbillivirus\"</code>, <code>\"morbillivirus\"</code>)</li> </ul> <p>These workflows currently support seven organisms (see above). The workflows are adaptable, with parameters that can be customized for specific organisms. Input JSON files with preset configurations for each supported virus are provided here, streamlining the setup process.</p> <p>Except for influenza, which follows a different process in TheiaCoV, all organisms are assembled through consensus from a reference genome (see Figure 2 below).</p> <p>Assembly process in TheiaCoV</p> <p></p> <p>Figure 2: TheiaCoV viral genome assembly flowchart. FASTQ-formatted reads are binned into taxonomic groups, trimmed, QC\u2019ed, mapped to the reference genome, and the consensus assembly is created with respect to the reference.</p> <p>All non-influenza default organisms go through read quality control and consensus assembly with iVar. First, the human reads are removed from the sample with NCBI's human read removal tool (HRRT), and the data is taxonomically profiled with Kraken2 (using a database with all viral data in RefSeq and human) before and after human read removal. The reads are then trimmed with trimmomatic (default) or fastp. Sequencing adapters, if they exist, are removed with bbduck, and raw and clean read quality is assessed using fastq_scan (default) or FastQC. The clean reads are then mapped to the reference genome after indexing with bwa. Primers are trimmed from the alignment with iVar, and variants are called with samtools. Finally, samtools and iVar are called to generate the consensus assembly. </p> <p>For default organisms, we provide all the necessary files for all of these processes. To successfully generate a consensus assembly for a non-default organism, depending on the workflow configuration, the intermediary files will need to be provided by the user. We drafted a set of recommendations below to facilitate this process.</p>"},{"location":"guides/custom_organisms/#workflow-recommendations-for-custom-viruses","title":"Workflow Recommendations for \"Custom\" Viruses","text":"<p>We encourage users to refer to the TheiaViral workflow series for assembling viruses that are not accounted for in TheiaCoV. Tiled amplicon viruses may fail TheiaViral's de novo assembly process, though a reference genome can be provided by the user to bypass this step. The following is legacy information on running custom viruses with TheiaCoV.</p> <p>TheiaCoV is not designed for custom viruses, so it is important to assess the validity of resulting assemblies. The custom virus approach requires a closely related reference genome as input, or else the workflow will fail due to an insufficient quantity of reads mapping to the reference. Such errors will occur at the <code>ivar_consensus</code> task during read alignment/extraction or during post-assembly variant calling because a consensus assembly comprising degenerate nucleotides was created. These errors primarily occur due to read mapping difficulty in small (&lt; 20 kb), recombinant, or evolutionarily diverse lineages, such as norovirus or rhinovirus. Contamination can also cause reference mapping errors, so it is important to review the Kraken2 report to ensure the taxonomic composition of the sample sufficiently comprises the expected viral lineage.</p> <p>Table 1: Required and optional inputs for running custom viruses</p> Task Input Description Custom virus requirement theiacov_* genome_length Expected genome length of organism Required theiacov_* organism Name of expected organism Required theiacov_* reference_gff Reference sequence in GFF3 format Required for SE, PE, ONT;Omitted from FASTA theiacov_* primer_bed Bed file with primer locations Required for ONT;Optional for SE and PE only if trim_primers is set to False theiacov_* reference_gene_locations_bed Bed file with gene location Optional to estimate gene coverage theiacov_* reference_genome Reference sequence in FASTA format Required theiacov_* target_organism Name of the expected organism in Kraken2 database Optional to quantify percent of reads matching target organism"},{"location":"guides/custom_organisms/#request-support-for-running-theiacov-with-custom-viruses","title":"Request Support for Running TheiaCoV with \"Custom\" Viruses","text":"<p>Depending on your organism of interest, the guidance above might not be sufficient. For additional support, please reach out to support@theiagen.com! We'll be more than happy to assist you with your analyses.</p>"},{"location":"guides/gambit/","title":"Guide to GAMBIT","text":""},{"location":"guides/gambit/#gambit","title":"GAMBIT","text":"<p>GAMBIT (Genomic Approximation Method for Bacterial Identification and Tracking) determines the taxon of the query genome assembly using a k-mer-based approach to match the assembly sequence to the closest complete genome in a database.</p> <p>GAMBIT genomic distance metric correlates with sequence identity!</p> <p>GAMBIT uses an efficient genomic distance metric along with a curated database to identify genome assemblies in seconds. You can read more about how the distance metric is calculated in the Technical Details section!</p> <p>If the distance between the query genome assembly and the closest genome in the database is within a built-in species threshold, GAMBIT will assign the query genome to that species. Species thresholds are determined through a combination of automated and manual curation processes based on the diversity within the taxon.</p> <p>GAMBIT includes a manually curated, high-quality database!</p> <p>GAMBIT databases consist of two files:</p> <ol> <li>A signatures file containing the GAMBIT signatures (compressed representations) of all genomes represented in the database </li> <li>A metadata file relating the represented genomes to their genome accessions, taxonomic identifications, and species thresholds</li> </ol> <ul> <li> <p> Latest GAMBIT Version</p> <p>GAMBIT v1.0.1 source code</p> </li> <li> <p> Latest Database Version</p> <p>GAMBIT Prokaryotic GTDB Database v2.0.1</p> <p>GAMBIT Fungal Database v1.0.0</p> </li> </ul>"},{"location":"guides/gambit/#gambit-on-terrabio","title":"GAMBIT on Terra.bio","text":"<p>Theiagen\u2019s Public Health Bioinformatics (PHB) is a suite of workflows for characterization, epidemiology and sharing of pathogen genomes. Workflows are available for viruses, bacteria, and fungi.</p>"},{"location":"guides/gambit/#importing-and-using-gambit-via-the-phb-workflows","title":"Importing and using GAMBIT via the PHB workflows","text":"<p>The GAMBIT_Query_PHB workflow performs taxon assignment of a genome assembly using the GAMBIT. It can be imported directly to Terra.bio via Dockstore.</p> <p>Two inputs are required for the GAMBIT_Query_PHB workflow: a genome assembly and a sample name associated with the genome assembly. The default GAMBIT database used for taxonomic identification is the Prokaryotic GAMBIT Database GTDB v2.0.1, but alternate GAMBIT databases can be provided.</p> <p>Gambit_Query_PHB</p> <p>More information on GAMBIT_Query_PHB is available here.</p> <p>Import workflows to Terra.bio:</p> <p>GAMBIT_Query_PHB</p> <ul> <li>Gambit_Query_PHB</li> </ul> <p>TheiaProk Workflow Series</p> <ul> <li>TheiaProk_Illumina_PE_PHB</li> <li>TheiaProk_Illumina_SE_PHB</li> <li>TheiaProk_ONT_PHB</li> <li>TheiaProk_FASTA_PHB</li> </ul> <p>TheiaEuk Workflow Series</p> <ul> <li>TheiaEuk_Illumina_PE_PHB</li> </ul> <p>Additionally, GAMBIT is also part of the TheiaProk and TheiaEuk collection of workflows, the first dedicated to the analysis of prokaryotic data, and the second data to mycotics. The TheiaProk or TheiaEuk most appropriate for your type of input data can be imported from the Dockstore links on the right.</p> <p>In both, GAMBIT is responsible for performing the taxonomic identification of the assembled sequences, which can trigger taxa-specific submodules for further genomic characterization. For TheiaProk, the default database is the Prokaryotic GAMBIT Database GTDB v2.0.1 and for TheiaEuk, the default database is the Fungal GAMBIT Database v1.0.0.</p> <p>TheiaProk and TheiaEuk</p> <p>More information on TheiaProk and TheiaEuk is available on the following pages:</p> <ul> <li>TheiaProk Workflow Series</li> <li>TheiaEuk Workflow Series</li> </ul>"},{"location":"guides/gambit/#using-gambit-on-your-local-machine","title":"Using GAMBIT on your local machine","text":"<p>This guide assumes you have prior knowledge of how to install software locally in a Unix command-line environment. The necessary databases will have to be downloaded independently to be used with GAMBIT. They are available in the GAMBIT Databases section of this document and should be placed in a directory of your choice. The directory should not contain any other files with the same extensions.</p>"},{"location":"guides/gambit/#installation","title":"Installation","text":""},{"location":"guides/gambit/#installation-from-bioconda","title":"Installation from Bioconda","text":"<p>The recommended way to install the tool is through the\u00a0Conda\u00a0package manager from the\u00a0Bioconda\u00a0channel. You can simply run the following command to download GAMBIT\u2019s latest version:</p> <pre><code>conda install -c bioconda gambit\n</code></pre>"},{"location":"guides/gambit/#installation-with-docker","title":"Installation with Docker","text":"<p>The latest version of GAMBIT software is available as a Docker container in Theiagen\u2019s Google Artifact Registry (GAR). If Docker is installed in your system you can simply run the following command to download the container:</p> <pre><code>docker pull us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0\n</code></pre> <p>You can access the container with the following command (note: with the <code>-v $PWD:/data</code>, your current directory is being mounted to the <code>data/</code> folder inside the container):</p> <pre><code>docker run -v $PWD:/data -it us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 bash\n</code></pre>"},{"location":"guides/gambit/#installation-from-source","title":"Installation from source","text":"<p>These instructions assume that you have Git, Python and Pip installed in your system. Navigate to https://github.com/jlumpe/gambit and clone the repository, or use the following command:</p> <pre><code>git clone https://github.com/jlumpe/gambit.git\n</code></pre> <p>Installing from source requires the Cython package as well as a C compiler to be installed on your system.  Navigate to the repository and install the package:</p> <pre><code>pip install .\n</code></pre>"},{"location":"guides/gambit/#usage","title":"Usage","text":"<p>Positional arguments are one or more FASTA files containing query genome assemblies. You must provide the path to the directory containing the database files using either the\u00a0<code>-d</code>\u00a0option (before\u00a0the\u00a0<code>query</code>\u00a0subcommand) or by setting the\u00a0<code>GAMBIT_DB_PATH</code>\u00a0environment variable. The results can be optionally outputted to a file, but by default, they are written to the terminal.</p> <pre><code>gambit [-d &lt;/path/to/database/&gt;] query [-o results.csv] genome1.fasta genome2.fasta ...\n</code></pre>"},{"location":"guides/gambit/#advanced-usage","title":"Advanced Usage","text":"<p>There are many available commands in GAMBIT:</p> <pre><code>Usage: gambit [OPTIONS] COMMAND [ARGS]...\n\n  Tool for rapid taxonomic identification of microbial pathogens from genomic data.\n\nOptions:\n  -d, --db DIRECTORY  Directory containing GAMBIT database files.\n  --version           Show the version and exit.\n  --help              Show this message and exit.\n\nCommands:\n  dist        Calculate the GAMBIT distances between a set of query...\n  query       Predict taxonomy of microbial samples from genome sequences.\n  signatures  Create and inspect GAMBIT signature files.\n  tree        Estimate a relatedness tree for a set of genomes and output...\n</code></pre> <p>GAMBIT\u2019s <code>query</code> is the most used as it computes the distance of a query genome to the genomes provided in the database.</p> <pre><code>Usage: gambit query [OPTIONS] GENOMES...\n\n  Predict taxonomy of microbial samples from genome sequences.\n\nOptions:\n  -l LISTFILE                     File containing paths to query genomes, one\n                                  per line.\n  --ldir DIRECTORY                Parent directory of paths in LISTFILE.\n  -o, --output FILENAME           File path to write to. If omitted will write\n                                  to stdout.\n  -f, --outfmt [csv|json|archive]\n                                  Format to output results in.\n  -s, --sigfile FILE              File containing query signatures, to use in\n                                  place of GENOMES.\n  --progress / --no-progress      Show/don't show progress meter.\n  -c, --cores INTEGER RANGE       Number of CPU cores to use.  [x&gt;=1]\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"guides/gambit/#gambit-databases","title":"GAMBIT Databases","text":""},{"location":"guides/gambit/#gambit-prokaryotic-databases","title":"GAMBIT Prokaryotic Databases","text":""},{"location":"guides/gambit/#gambit-gtdb-database-v201","title":"GAMBIT GTDB Database v2.0.1","text":"Database Details <p>This database is a patch update to the v2.0.0 database. This database is identical to the v2.0.0 database except that the following genomes were removed. </p> <pre><code>GCF_003977345.1\nGCF_003977375.1\nGCF_004025385.1\nGCF_002249045.1\nGCF_004402105.1\nGCF_003977405.1\nGCF_003985005.1\nGCF_002246205.1\nGCF_003977245.1\nGCF_007197595.1\nGCF_003977285.1\nGCF_001063095.1\nGCF_002248705.1\n</code></pre> <p>These genomes currently named as Shigella species in NCBI, but are actually Escherichia coli according to the best match type strain using ANI. Their removal from the database prevents false assignment of Echerichia coli query genomes to Shigella species.</p> <p>Database Files</p> <p>These database files are hosted in a public Google bucket by Theiagen Genomics:</p> <p>GS URI (for Terra.bio usage):</p> <ul> <li><code>gs://gambit-databases-rp/2.0.0/gambit-metadata-2.0.1-20250505.gdb</code></li> <li><code>gs://gambit-databases-rp/2.0.0/gambit-signatures-2.0.1-20250505.gs</code></li> </ul> <p>HTTPS URL (for local download):</p> <ul> <li>https://storage.cloud.google.com/gambit-databases-rp/2.0.0/gambit-metadata-2.0.1-20250505.gdb</li> <li>https://storage.cloud.google.com/gambit-databases-rp/2.0.0/gambit-signatures-2.0.1-20250505.gs</li> </ul>"},{"location":"guides/gambit/#gambit-gtdb-database-v200","title":"GAMBIT GTDB Database v2.0.0","text":"Database Details <p>This database is a major update to the Curated v1.3.0 database. This iteration of the GAMBIT database relies upon the Genome Taxonomy Database (GTDB), an initiative to establish a standardised microbial taxonomy based on genome phylogeny. The genomes used to construct the phylogeny are obtained from RefSeq and GenBank, independently quality-controlled using CheckM before inclusion in GTDB.</p> <p>This database was computed from GTDB Release 214.1 as of April 28th, 2023. </p> <ul> <li> <p>Automated curation efforts</p> <p>The following curation steps were followed for all species:</p> <ul> <li>The candidates for an existing genus were collapsed (e.g genus_A, genus_B becomes genus)</li> </ul> <p>The following species were updated:</p> <ul> <li>Shigella sp.<ul> <li>This genus is not present in GTDB  as it is collapsed under Escherichia coli;</li> <li>All Shigella genomes in RefSeq were added to the database with no clustering using default quality criteria.</li> </ul> </li> <li>Mycolicibacterium/Mycolicibacter/Mycolicibacillus/Mycobacteroides/Mycobacterium sp.<ul> <li>All genomes available were used.</li> </ul> </li> <li>Tropheryma whipplei<ul> <li>This species has a low completeness score of 75%;</li> <li>The CheckM completeness score was lowered to 70% for genomes belonging to this species.</li> </ul> </li> </ul> </li> </ul> <p>Database Files</p> <p>These database files are hosted in a public Google bucket by Theiagen Genomics:</p> <p>GS URI (for Terra.bio usage):</p> <ul> <li><code>gs://gambit-databases-rp/2.0.0/gambit-metadata-2.0.0-20240628.gdb</code></li> <li><code>gs://gambit-databases-rp/2.0.0/gambit-signatures-2.0.0-20240628.gs</code></li> </ul> <p>HTTPS URL (for local download):</p> <ul> <li>https://storage.cloud.google.com/gambit-databases-rp/2.0.0/gambit-metadata-2.0.0-20240628.gdb</li> <li>https://storage.cloud.google.com/gambit-databases-rp/2.0.0/gambit-signatures-2.0.0-20240628.gs</li> </ul> <p>Taxa included in the GAMBIT database</p> <p>Summary of species represented in the database with number of genomes representing each species and the species threshold:</p> <ul> <li> <p>https://storage.cloud.google.com/gambit-databases-rp/2.0.0/gambit-taxa-2.0.0-20240628.tsv</p> <p>Note: Species with a threshold of \"0\" have been sub-speciated. Subspecies are not listed in this table.</p> </li> </ul>"},{"location":"guides/gambit/#gambit-refseq-curated-database-v130","title":"GAMBIT RefSeq Curated Database v1.3.0","text":"Database Details <p>This database is a patch update to the Curated v1.2.0 database. In addition to all of the species included in the v1.2.0 database below, this database replaces all species in the Mycobacterium, Mycolicibacterium, Mycobacteroides, and Mycolicibacter genera with the available genomes in RefSeq as of October 16th, 2023.</p> <ul> <li> <p>Manual curation efforts</p> <p>The following species were updated:</p> <ul> <li>Mycolicibacterium/Mycolicibacter/Mycolicibacillus/Mycobacteroides/Mycobacterium sp.<ul> <li>All genomes available were used</li> </ul> </li> </ul> </li> </ul> <p>Database Files</p> <p>These database files are hosted in a public Google bucket by Theiagen Genomics:</p> <p>GS URI (for Terra.bio usage):</p> <ul> <li><code>gs://gambit-databases-rp/1.3.0/gambit-metadata-1.3-231016.gdb</code></li> <li><code>gs://gambit-databases-rp/1.3.0/gambit-signatures-1.3-231016.gs</code></li> </ul> <p>HTTPS URL (for local download):</p> <ul> <li>https://storage.cloud.google.com/gambit-databases-rp/1.3.0/gambit-metadata-1.3-231016.gdb</li> <li>https://storage.cloud.google.com/gambit-databases-rp/1.3.0/gambit-signatures-1.3-231016.gs</li> </ul> <p>Taxa included in the GAMBIT database</p> <p>Summary of species represented in the database with number of genomes representing each species and the species threshold:</p> <ul> <li> <p>https://storage.cloud.google.com/gambit-databases-rp/1.3.0/gambit-1.3-231016-taxa-list.txt</p> <p>Note: Species with a threshold of \"0\" have been sub-speciated. Subspecies are not listed in this table.</p> </li> </ul>"},{"location":"guides/gambit/#gambit-refseq-curated-database-v120","title":"GAMBIT RefSeq Curated Database v1.2.0","text":"Database Details <p>This database is a patch update to the RefSeq Curated v1.1.0 database. In addition to all of the species included in the v1.1.0 database below, this database includes new species that were under-represented as of August 11th, 2023.</p> <ul> <li> <p>Automated curation efforts</p> <p>Automated addition of new species to the database that are genetically distant from all current species in the v1.1.0 GAMBIT database. </p> <p>Genomes represented in the Genome Taxonomy Database (GTDB) were added. These genomes predominantly originate from the RefSeq and GenBank databases with taxonomic metadata curated by GTDB. Any genomes added to the GAMBIT database from GTDB are added with the metadata from GTDB.</p> <ul> <li> <p>Genomes added from GTDB include the following species:</p> <p>gambit-list-of-new-species-db-v1_2_0.txt</p> </li> </ul> </li> <li> <p>Manual curation efforts</p> <p>Manually curated updates to several taxa relevant to public health. All genomes representing the taxa below were removed and replaced with the RefSeq genomes representing each species as of August 11th, 2023.</p> <ul> <li>Citrobacter, Providencia, Hafnia, Neisseria, Proteus, Achromobacter, Aeromonas, Bacillus, Brucella, Afipia, Burkholderia, Paraburkholderia, Corynebacterium, Morganella</li> </ul> </li> </ul> <p>Database Files</p> <p>These database files are hosted in a public Google bucket by Theiagen Genomics:</p> <p>GS URI (for Terra.bio usage):</p> <ul> <li><code>gs://gambit-databases-rp/1.2.0/gambit-metadata-1.2-231002.gdb</code></li> <li><code>gs://gambit-databases-rp/1.2.0/gambit-signatures-1.2-231002.gs</code></li> </ul> <p>HTTPS URL (for local download):</p> <ul> <li>https://storage.cloud.google.com/gambit-databases-rp/1.2.0/gambit-metadata-1.2-231002.gdb</li> <li>https://storage.cloud.google.com/gambit-databases-rp/1.2.0/gambit-signatures-1.2-231002.gs</li> </ul> <p>Taxa included in the GAMBIT database</p> <p>Summary of species represented in the database with number of genomes representing each species and the species threshold:</p> <ul> <li>https://storage.cloud.google.com/gambit-databases-rp/1.2.0/gambit-1.2-231002-taxa-list.txt     Note: Species with a threshold of \"0\" have been sub-speciated. Subspecies are not listed in this table.</li> </ul>"},{"location":"guides/gambit/#gambit-refseq-curated-database-v110","title":"GAMBIT RefSeq Curated Database v1.1.0","text":"Database Details <p>This database is a patch update to the RefSeq Curated v1.0.0 database. In addition to all of the species included in the v1.0.0 database below, this database replaces all species in the Enterobacter, Legionella, and Vibrio genera with the available genomes in RefSeq as of April 17th, 2023.</p> <p>Database Files</p> <p>These database files are hosted in a public Google bucket by Theiagen:</p> <p>GS URI (for Terra.bio usage):</p> <ul> <li><code>gs://gambit-databases-rp/1.1.0/gambit-metadata-1.1-230417.gdb</code></li> <li><code>gs://gambit-databases-rp/1.1.0/gambit-signatures-1.1-230417.gs</code></li> </ul> <p>HTTPS URL (for local download):</p> <ul> <li>https://storage.cloud.google.com/gambit-databases-rp/1.1.0/gambit-metadata-1.1-230417.gdb</li> <li>https://storage.cloud.google.com/gambit-databases-rp/1.1.0/gambit-signatures-1.1-230417.gs</li> </ul> <p>Taxa included in the GAMBIT database</p> <p>Summary of species represented in the database with number of genomes representing each species and the species threshold:</p> <ul> <li> <p>https://storage.cloud.google.com/gambit-databases-rp/1.1.0/gambit-1.1-230417-taxa-list.txt</p> <p>Note: Species with a threshold of \"0\" have been sub-speciated. Subspecies are not listed in this table.</p> </li> </ul>"},{"location":"guides/gambit/#gambit-refseq-curated-database-v100","title":"GAMBIT RefSeq Curated Database v1.0.0","text":"Database Details <p>The GAMBIT RefSeq Curated v1.0.0 database was used for the analysis described in the GAMBIT publication. This database was constructed based on the available genomes in RefSeq as of July 1st, 2016.  Genomes that did not have associated genus and/or species were removed. Additionally, at least two separate sequenced isolates for a given species were required in order to determine the classification threshold.  </p> <ul> <li> <p>Manual curation efforts</p> <p>Ambiguous genomes were removed if they met any of the following criteria: </p> <ol> <li>A genome that did not cluster well with the majority of the other genomes within their species;</li> <li>A genome that clustered well with some members of their species but also several members of another species in the database&lt;</li> <li>A genome that did not cluster well with any genomes in the database.</li> </ol> </li> </ul> <p>Database Files</p> <p>These database files are hosted in a public Google bucket by Theiagen:</p> <p>GS URI (for Terra.bio usage):</p> <ul> <li><code>gs://gambit-databases-rp/1.0b2/gambit-genomes-1.0b2-rev2-211116.db</code></li> <li><code>gs://gambit-databases-rp/1.0b2/gambit-signatures-1.0b1-210719.h5</code></li> </ul> <p>HTTPS URL (for local download):</p> <ul> <li>https://storage.cloud.google.com/gambit-databases-rp/1.0b2/gambit-genomes-1.0b2-rev2-211116.db</li> <li>https://storage.cloud.google.com/gambit-databases-rp/1.0b2/gambit-signatures-1.0b1-210719.h5</li> </ul> <p>Taxa included in the GAMBIT database</p> <p>Summary of species represented in the database with number of genomes representing each species and the species threshold:</p> <ul> <li> <p>https://storage.cloud.google.com/gambit-databases-rp/1.0b2/gambit-1.0b2-rev2-211116-taxa-list.txt</p> <p>Note: Species with a threshold of \"0\" have been sub-speciated. Subspecies are not listed in this table.</p> </li> </ul>"},{"location":"guides/gambit/#gambit-fungal-databases","title":"GAMBIT Fungal Databases","text":""},{"location":"guides/gambit/#gambit-fungal-database-v100","title":"GAMBIT Fungal Database v1.0.0","text":"Database Details <p>The GAMBIT Fungal Database v1.0.0 database was constructed based on the available genomes in RefSeq/GenBank as of December 13th, 2024. For inclusion in the database, species were required to have at least two genomes in GenBank and at least one genome representing the species in RefSeq.</p> <ol> <li>Species with a diameter of zero were excluded;</li> <li>Species with three or fewer genomes and a diameter greater than 0.75 were excluded.</li> </ol> <p>Manual curation efforts</p> <ul> <li>Species were curated based on GAMBIT diameter:</li> <li>The database was manually curated to remove highly distant genomes which were likely mislabeled.</li> <li>Six species were divided into subspecies to ensure non-overlapping species diameters.</li> <li>Two pairs of species were too closely related to distinguish (Aspergillus flavus/Aspergillus oryzae\u00a0and\u00a0Aspergillus niger/Aspergillus welwitschiae), therefore were combined.</li> </ul> <p>Database Files</p> <p>These database files are hosted in a public Google bucket by Theiagen:</p> <p>GS URI (for Terra.bio usage):</p> <ul> <li><code>gs://gambit-databases-rp/fungal-version/1.0.0/gambit-fungal-metadata-1.0.0-20241213.gdb</code></li> <li><code>gs://gambit-databases-rp/fungal-version/1.0.0/gambit-fungal-signatures-1.0.0-20241213.gs</code></li> </ul> <p>HTTPS URL (for local download):</p> <ul> <li>https://storage.cloud.google.com/gambit-databases-rp/fungal-version/1.0.0/gambit-fungal-metadata-1.0.0-20241213.gdb</li> <li>https://storage.cloud.google.com/gambit-databases-rp/fungal-version/1.0.0/gambit-fungal-signatures-1.0.0-20241213.gs</li> </ul> <p>Taxa included in the GAMBIT database</p> <p>360 fungal species from 176 genera are represented in the fungal database from a total of 8073 fungal genomes. A table indicating the number of genomes and species diameter for each species represented in the database is indicated below.</p> <p>gambit-1.0.0-20241213-taxa-list.txt</p>"},{"location":"guides/gambit/#gambit-fungal-database-v020","title":"GAMBIT Fungal Database v0.2.0","text":"Database Details <p>The GAMBIT Fungal Database v0.2.0 database was used for the analysis described in the TheiaEuk publication. This database was constructed based on the available genomes in GenBank as of November 30th, 2022. For inclusion in the database, species were required to have at least two genomes in GenBank and at least one genome representing the species in RefSeq.</p> <ol> <li>Species with a diameter of zero were excluded;</li> <li>Species with three or fewer genomes and a diameter greater than 0.75 were excluded.</li> </ol> <p>Manual curation efforts</p> <ul> <li>Species were curated based on GAMBIT diameter:</li> <li>The database was manually curated to remove highly distant genomes which were likely mislabeled.</li> <li>Nine species were divided into subspecies to ensure non-overlapping species diameters.</li> <li>Two pairs of species were too closely related to distinguish (Aspergillus flavus/Aspergillus oryzae\u00a0and\u00a0Aspergillus niger/Aspergillus welwitschiae), therefore were combined.</li> </ul> <p>Database Files</p> <p>These database files are hosted in a public Google bucket by Theiagen:</p> <p>GS URI (for Terra.bio usage):</p> <ul> <li><code>gs://gambit-databases-rp/fungal-version/0.2/221130-theiagen-fungal-v0.2.db</code></li> <li><code>gs://gambit-databases-rp/fungal-version/0.2/221130-theiagen-fungal-v0.2.h5</code></li> </ul> <p>HTTPS URL (for local download):</p> <ul> <li>https://storage.cloud.google.com/gambit-databases-rp/fungal-version/0.2/221130-theiagen-fungal-v0.2.db</li> <li>https://storage.cloud.google.com/gambit-databases-rp/fungal-version/0.2/221130-theiagen-fungal-v0.2.h5</li> </ul> <p>Taxa included in the GAMBIT database</p> <p>245 fungal species from 138 genera are represented in the fungal database from a total of 5,667 fungal genomes. A table indicating the number of genomes and species diameter for each species represented in the database is indicated below.</p> <p>gambit-0.2.0-221130-taxa-list.tsv</p>"},{"location":"guides/gambit/#technical-details","title":"Technical Details","text":""},{"location":"guides/gambit/#k-mer-based-representation-of-the-genomes","title":"K-mer-based representation of the genomes","text":"<p>A GAMBIT signature is a compressed representation of a genome sequence that supports the efficient calculation of the GAMBIT genomic distance metric. It is defined as the set of k-mers present in the genome which occur immediately following a fixed prefix sequence. GAMBIT finds all 11-mers in a genome assembly that immediately follows the prefix sequence ATGAC.</p> <p>This allows not only thousands of genomes to be represented in a relatively small (~3GB) database, but the comparison of the query genome to the set of references provided in the used GAMBIT database to be performed very fast.</p> <p>Taxonomy information</p> <p>The GAMBIT database used for classification consists of pre-calculated signatures for the reference genomes along with additional genome metadata and a taxonomy tree. As of GAMBIT Prokaryotic database v2.0.0, taxonomy information is derived from the  Genome Taxonomy Database (GTDB) but restricted to the genus and species ranks and subject to additional curation. The other databases have the taxonomy information derived from the NCBI taxonomy database.</p>"},{"location":"guides/gambit/#distance-metric-calculation","title":"Distance Metric Calculation","text":"<p>The Jaccard Index, also known as the Jaccard Similarity Coefficient, is a statistic used for gauging the similarity and diversity between two sample sets. It ranges from 0 to 1, where if 0 the sets have no elements in common, whereas if 1 the sets are identical. In GAMBIT, the Jaccard Index is used to compare genetic sequences.</p> <p>Jacard Distance vs Index</p> <p>The Jaccard Distance, equal to one minus the Jaccard index, shares the same properties as the Jaccard index albeit inversely. It ranges from 0 to 1, where  0 the sets are identical and if 1, the sets have no elements in common.</p> <p>In GAMBIT, the Jaccard Distance is calculated between two pre-computed k-mer sets in sparse coordinate format, one representing the query genome and another the GAMBIT database.</p> <p>Distribution of GAMBIT distances</p> <p>Relationship between GAMBIT distance and ANI</p>"},{"location":"guides/gambit/#built-in-species-distance-threshold","title":"Built-in Species Distance Threshold","text":"<p>GAMBIT classifies unknown genomes by finding the distance to the closest reference genome and comparing that distance against the thresholds of the reference genome\u2019s species and genus.</p> <p>For GAMBIT Prokaryotic database v2.0.0 and above, the threshold for a given species corresponds to the maximum intra-species distance (\"max intra,\" or diameter) (Figure 1). Some species are not well separated from their closest sister taxon and, in some cases, even overlap. Such as the case of Escherichia coli and Shigella sonnei in GAMBIT\u2019s Prokaryotic Database. In these scenarios, the species were divided into subspecies groups based on clustering of their intra-species distances, and then reporting matches to these subgroups and their parent species.</p> <p>If the query genome distance is greater than the species diameter, GAMBIT attempts to report the genus. Genus diameters are computed and manually curated based on the diversity of the genus.</p>"},{"location":"guides/gambit/#figure1","title":"Figure 1","text":"<p>Figure 1: Distribution of GAMBIT distances within a species and to the nearest sister taxon in the GAMBIT reference database. Three histograms are shown in each panel (each normalized independently). The green histogram represents the distribution of GAMBIT distances from each reference genome in the species to the closest genome also within the same species. The blue histogram represents the distribution of GAMBIT distances for all pairwise comparisons within the species. The red histogram represents the distribution of GAMBIT distances from each genome in the species of interest to the closest genome in the species\u2019 closest sister taxon. The dashed blue line represents the classification threshold for that species in the GAMBIT database, which in both cases was derived from the maximum intra-species distance. Panel A shows Klebsiella pneumoniae and its closest sister taxon Klebsiella variicola, panel B shows Neisseria gonorrhoeae and its closest sister taxon Neisseria meningitidis. </p> <p>Sourced from https://doi.org/10.1371/journal.pone.0277575.g004.</p>"},{"location":"guides/gambit/#gambit-distances-correlate-with-sequence-identity","title":"GAMBIT distances correlate with sequence identity","text":"<p>Average Nucleotide Identity (ANI) has been the benchmark for nucleic acid comparisons and was used as a baseline measure of genomic similarity to validate the GAMBIT distance metric. ANI is generally used to determine similarity at the species or genus level with thresholds above 0.92 being optimal for species-level calls.</p> <p>The ANI values were compared against GAMBIT distances for all pairs of genomes in each of the four data sets:</p> <p>Test sets for GAMBIT distance versus ANI</p> Set Number of Genomes Phylogenetic Diversity Assembly Quality Reference Set 1 492 Low (E. coli only) Medium https://doi.org/10.1186/s13059-016-0997-x Set 2 70 High (muliple phyla) High https://doi.org/10.1073/pnas.0308653100 Set 3 88 High (multiple phyla) Medium https://doi.org/10.1371/journal.pone.0277575 Set 4 604 High (multiple phyla) Medium https://doi.org/10.1371/journal.pone.0277575 <p>Spearman correlation was high in all four data sets (Figure 2) (Set 1 = -0.977; Set 2 = -0.968; Set 3 = -0.969; Set 4 = -0.979) for comparisons in which the ANI was reported by the FastANI tool (100%, 5.59%, 7.42% and 47.4%), revealing a nearly monotonic relationship between GAMBIT distance and ANI.</p>"},{"location":"guides/gambit/#figure2","title":"Figure 2","text":"<p>Figure 2: Relationship between GAMBIT distance and ANI (Average Nucleotide Identity).  The relationship is nonlinear but very close to monotonic as measured by Spearman correlation (shown in the bottom left corner of each subplot). ANI was calculated using the FastANI tool with default parameter values. GAMBIT distances were calculated for all sets using the same parameter (k = 11, prefix = ATGAC). As FastANI only reports ANI values greater than ~80%, the fraction of total pairwise comparisons shown here were 100%, 5.5%, 7.4% and 47.4% for data sets 1\u20134 respectively. </p> <p>Sourced from https://doi.org/10.1371/journal.pone.0277575.g001.</p>"},{"location":"guides/gambit/#gambit-database-creation-and-curation","title":"GAMBIT Database Creation and Curation","text":"<p>As of v2.0.0, the GAMBIT Database is built iteratively over a Genome Taxonomy Database (GTDB) release, starting with the species with the most publicly available genomes.</p> <p>GAMBIT Database Creation can be done by you!</p> <p>GAMBIT Database Creation</p> <p>The creation of a GAMBIT Database usually follows these steps:</p> <ul> <li>From a public repository, the genomes of interest are downloaded. Each taxa should have at least 2 genomes for GAMBIT diameters to be calculated;</li> <li>The downloaded genomes undergo a round of quality-control to minimize the possibility that the genomes are too fragmented, contaminated or too incomplete. Third-party tools, such as QUAST and CheckM/BUSCO are used in this step;</li> <li>GAMBIT distances are calculated for all pairs of genomes, removing overlapping sequences and misclassification to increase the accuracy of GAMBIT;</li> <li>The database undergoes a curation to remove outliers and improve classification in underrepresented taxa and reflect public health usage and biological historical consensus more closely.</li> </ul> <p>Because GAMBIT databases have built-in species thresholds, genomes are included in each database version and the thresholds associated with each species are curated prior to release. Curation approaches may vary by GAMBIT database release but aim to ensure that mislabeled genomes are removed and that species are non-overlapping. Detailed information on the curation steps that each GAMBIT Database was subjected to can be found in the GAMBIT Databases section.</p> <p>Dependent on public data</p> <p>Please note that GAMBIT databases undergo curation and testing prior to release, but are limited by the availability and accuracy of sequencing data in public repositories.</p>"},{"location":"guides/gambit/#gambit-faqs","title":"GAMBIT FAQs","text":"What GAMBIT database should I use? <p>GAMBIT Databases are domain-specific. Currently two domains are available: Bacteria and Fungi. Choosing the appropriate type of database for your data is important as it can lead to erroneous/no classification results.</p> <p>As a rule of thumb, we recommend the latest version of any GAMBIT Database to be used.  Instances where one might prefer to use an older database, versus the most up to date, include:</p> <ol> <li>Maintaining use of a database that has been validated previously by your laboratory, or </li> <li>Utilizing a database that draws the genomes and their annotations from a specific source. For example, bacterial GAMBIT databases v1.0.0 through v1.3.0 draw their genome annotations predominantly from NCBI\u2019s RefSeq database, whereas v2.0.0 draws all genome annotations from GTDB. Database v1.0.0 is also inclusive of all bacterial genomes that were available on RefSeq at the time of creation, whereas v2.0.0 excludes genomes that do not expand the diversity of their species.</li> </ol> How do I list taxa included in a GAMBIT database? <p>There are several ways to retrieve the information regarding which taxa were included in a given GAMBIT database release. The easiest way is to download the taxa list file provided on this documentation page for every GAMBIT database release.</p> <p>Additionally, there are several programmatic ways to retrieve this information directly from the GAMBIT metadata file (which typically ends in \".gdb\"). Here we present a few examples: using SQLite3, DBeaver or the GAMBITtools software.</p> Example 1: SQLite3 <p>To retrieve the list of taxa directly from the database, the following command can be run (after installing SQLite3 through your favourite installer). Substitute <code>&lt;gambit metadata gdb file&gt;</code> with your metadata file location.</p> <pre><code>sqlite3 &lt;gambit metadata gdb file&gt; \"SELECT * FROM taxa;\" &gt; list-of-taxa.tsv\n</code></pre> <p>To retrieve the list of genomes, the following command can be run. Substitute <code>&lt;gambit metadata gdb file&gt;</code> by your metadata file location.</p> <pre><code>sqlite3 &lt;gambit metadata gdb file&gt; \"SELECT * FROM genomes;\" &gt; list-of-genome.tsv\n</code></pre> Example 2: DBeaver <p>After downloading and installing DBeaver, open the GAMBIT metadata file by clicking on <code>New Database Connection</code> (or hitting Ctrl+Shift+N) on the top left corner of the window. Under the SQL section, select the <code>SQLite</code> option and open the path to the metadata file. If prompted, install the required drivers by DBeaver. </p> <p>SQLite</p> <p></p> <p>Select <code>SQL Editor</code> in the toolbar and then click on <code>New SQL Script</code>. </p> <p>New SQL Script</p> <p></p> <p>Type <code>SELECT * FROM taxa;</code> and check that you get the results (press <code>CTRL+Enter</code> or click the orange arrow to execute SQL statements). To save the results click on <code>Export data</code>  on the bottom right corner and select what file format to save the information in (we recommend CSV format that can then be loaded onto Excel). </p> <p>List Taxa</p> <p></p> Example 3: GAMBITtools <p>The GAMBITtools suite of scripts are Python tools written for working with GAMBIT. We recommend using Docker to interact with GAMBITtools. </p> <p>After building the gambittools docker image, use the <code>gambit-list-taxa</code> command as demonstrated below to generate a list of taxa included in a GAMBIT database. Substitute <code>&lt;gambit metadata gdb file&gt;</code> with your metadata file location</p> <pre><code>docker build -t gambittools .\n</code></pre> <pre><code>docker run -v $(pwd):/data gambittools gambit-list-taxa &lt;gambit metadata gdb file&gt;\n</code></pre> How do I get the number of genomes representing a given species? <p>Like retrieving the list of taxa, there are several ways of retrieving the number of species for a given species. </p> Example 1: SQLite3 <p>To retrieve the list of taxa and respective number of genomes directly from the database, the following command can be run (after installing SQLite3 through your favourite installer). Substitute <code>&lt;gambit metadata gdb file&gt;</code> with your metadata file location.</p> <pre><code>sqlite3 &lt;gambit metadata gdb file&gt; \"SELECT taxa.name,COUNT(genome_annotations.taxon_id) FROM taxa LEFT JOIN genome_annotations ON genome_annotations.taxon_id = taxa.id WHERE taxa.rank LIKE 'species' GROUP BY taxa.key ORDER BY taxa.name ASC;\" &gt; list-of-taxa-with-number-of-genomes.tsv\n</code></pre> Example 2: DBeaver <p>After downloading and installing DBeaver, open the GAMBIT metadata file by clicking on <code>New Database Connection</code> (or hitting Ctrl+Shift+N) on the top left corner of the window. Under the SQL section, select the <code>SQLite</code> option and open the path to the metadata file. If prompted, install the required drivers by DBeaver. </p> <p>SQLite</p> <p></p> <p>Select <code>SQL Editor</code> in the toolbar and then click on <code>New SQL Script</code>. </p> <p>New SQL Script</p> <p></p> <p>Type <code>SELECT taxa.name,COUNT(genome_annotations.taxon_id) FROM taxa LEFT JOIN genome_annotations ON genome_annotations.taxon_id = taxa.id WHERE taxa.rank LIKE 'species' GROUP BY taxa.key ORDER BY taxa.name ASC;</code> and check that you get the results (press <code>CTRL+Enter</code> or click the orange arrow to execute SQL statements). To save the results click on <code>Export data</code>  on the bottom right corner and select what file format to save the information in (we recommend CSV format that can then be loaded onto Excel). </p> <p>Number of Genomes</p> <p></p> How do I get the number of genomes and the distance threshold representing a given species? <p>Like retrieving the list of taxa and the number of genomes representing a given species, there are several ways of retrieving the distance threshold for a given species. </p> Example 1: SQLite3 <p>To retrieve the list of taxa and respective number of genomes directly from the database, the following command can be run (after installing SQLite3 through your favourite installer). Substitute <code>&lt;gambit metadata gdb file&gt;</code> with your metadata file location.</p> <pre><code>sqlite3 &lt;gambit metadata gdb file&gt; \"SELECT taxa.name,taxa.distance_threshold,COUNT(genome_annotations.taxon_id) FROM taxa LEFT JOIN genome_annotations ON genome_annotations.taxon_id = taxa.id WHERE taxa.rank LIKE 'species' GROUP BY taxa.key ORDER BY taxa.name ASC;\" &gt; list-of-taxa-with-number-of-genomes.tsv\n</code></pre> Example 2: DBeaver <p>After downloading and installing DBeaver, open the GAMBIT metadata file by clicking on <code>New Database Connection</code> (or hitting Ctrl+Shift+N) on the top left corner of the window. Under the SQL section, select the <code>SQLite</code> option and open the path to the metadata file. If prompted, install the required drivers by DBeaver. </p> <p>SQLite</p> <p></p> <p>Select <code>SQL Editor</code> in the toolbar and then click on <code>New SQL Script</code>. </p> <p>New SQL Script</p> <p></p> <p>Type <code>SELECT taxa.name,taxa.distance_threshold,COUNT(genome_annotations.taxon_id) FROM taxa LEFT JOIN genome_annotations ON genome_annotations.taxon_id = taxa.id WHERE taxa.rank LIKE 'species' GROUP BY taxa.key ORDER BY taxa.name ASC;</code> and check that you get the results (press <code>CTRL+Enter</code> or click the orange arrow to execute SQL statements). To save the results click on <code>Export data</code>  on the bottom right corner and select what file format to save the information in (we recommend CSV format that can then be loaded onto Excel). </p> <p>Number of Genomes and Distance Threshold</p> <p></p> How do I create a custom GAMBIT database? <p>Creating a custom GAMBIT database can be a laborious task.  The easiest way to go about it is to reach out to Theiagen Genomics at support@theiagen.com to request assistance.  A guide can be found on GAMBIT Database Creation </p> How well does GAMBIT perform discerning between Escherichia coli and Shigella sp? <p>Escherichia coli and Shigella are closely genetically related, to the extent that they would be considered the same species if not for their distinguishing phenotypic characteristics. GAMBIT databases are curated to enable differentiation between the two groups, however, it is worth bearing in mind that these genomes are highly genetically similar thus tools that take a more granular approach to genome comparison may be more reliable. </p> What should I do if a GAMBIT taxonomic assignment does not align with the expected results based on another bioinformatics tool or molecular testing? <p>In this instance, please reach out to support@theiagen.com and David Hess at the Nevada State Public Health Laboratory dhess@med.unr.edu. We will be happy to investigate your sample and improve the GAMBIT database in subsequent versions!</p>"},{"location":"guides/gambit/#other-resources","title":"Other Resources","text":"<ul> <li>Original GAMBIT publication</li> <li>GAMBIT Fungal Database publication</li> <li>GAMBIT Software GitHub - repository of GAMBIT software</li> <li>GAMBIT suite GitHub - tools for working with GAMBIT including GAMBITdb for automated GAMBIT database creation</li> </ul>"},{"location":"guides/gambit/#references","title":"References","text":"<p>Please cite the article below when using the GAMBIT software and/or GAMBIT RefSeq Curated Database v1.0.0:</p> <p>Lumpe J, Gumbleton L, Gorzalski A, Libuit K, Varghese V, et al. (2023) GAMBIT (Genomic Approximation Method for Bacterial Identification and Tracking): A methodology to rapidly leverage whole genome sequencing of bacterial isolates for clinical identification. PLOS ONE 18(2): e0277575.\u00a0https://doi.org/10.1371/journal.pone.0277575</p> <p>Please cite the reference below when using the GAMBIT Fungal Database v0.2.0:</p> <p>Ambrosio III, F. J., Scribner, M. R., Wright, S. M., Otieno, J. R., Doughty, E. L., Gorzalski, A., ... &amp; Hess, D. (2023). TheiaEuk: a species-agnostic bioinformatics workflow for fungal genomic characterization.\u00a0Frontiers in Public Health,\u00a011. https://doi.org/10.3389/fpubh.2023.1198213</p>"},{"location":"guides/gambit_database/","title":"Guide to GAMBIT Database Creation","text":""},{"location":"guides/gambit_database/#gambit-database-creation","title":"GAMBIT Database Creation","text":"<p>GAMBIT (Genomic Approximation Method for Bacterial Identification and Tracking) incorporates k-mer based strategy for the identification of taxonomic information with a highly curated searchable database.</p> <p>A GAMBIT databases consist of two files:</p> <ol> <li>A signatures file containing the GAMBIT signatures (compressed representations) of all genomes represented in the database; </li> <li>A metadata file relating the represented genomes to their genome accessions, taxonomic identifications, and species thresholds.</li> </ol> <p>The goal in creating a database for GAMBIT is two-fold:</p> <ul> <li>Genomes representing each species in the database must contain enough distinction from other species so that similarity thresholds can be extracted;</li> <li>The highest level of confidence is obtained that a genome in the database is actually from the species that matched its labelled identification.</li> </ul> <ul> <li> <p> GAMBIT allows for rapid taxonomic identification of microbial pathogens.</p> <p>The GAMBIT database is designed to facilitate the exploration and analysis of genomic data from a wide variety of prokaryotic or fungal isolates. It integrates and annotates genomic information based on information from curated sources. Several sources of complete and draft genomic sequences exist, with the most common being RefSeq, GenBank and GTDB. Alternative sources, such as BakRep, can also be used as long as taxonomic information is available.</p> </li> <li> <p> Several pre-computed GAMBIT databases are available for prokaryotic and fungal genomes.</p> <p>The full list of databases available can be consulted here, with information on what curation steps were followed and what genomes are included.</p> </li> </ul>"},{"location":"guides/gambit_database/#database-creation-process","title":"Database Creation Process","text":""},{"location":"guides/gambit_database/#creating-a-gambit-database-from-a-pre-curated-list-of-genomes-gtdb-and-gambitdb","title":"Creating a GAMBIT database from a pre-curated list of genomes - GTDB and GAMBITdb","text":"<p>The creation and curation of a GAMBIT database is a laborious process which involves sourcing genomic information, setting minimum quality thresholds, and finally building a signature and a database file.</p>"},{"location":"guides/gambit_database/#identifying-data-source","title":"Identifying Data Source","text":"<p>As of v2.0.0 of the GAMBIT Prokaryotic database, GTDB is the selected source of taxonomic information for genomes sourced from RefSeq and GenBank. Automation is available through the GAMBITdb which takes as input a GTDB release metadata spreadsheet including information on taxonomy and assembly quality metrics. GTDB\u2019s release spreadsheets are available at https://data.gtdb.ecogenomic.org/releases.</p>"},{"location":"guides/gambit_database/#curation-of-genomic-data","title":"Curation of Genomic Data","text":"<p>By default, genomes with less than 0.1 diameter between them are not included if compression is enabled, allowing the database to remain at a fairly low size (less than 3GB), instead being represented by a single centroid genome. This is because many genomes are identical or nearly identical to others in the public archives and there is no benefit to having multiple examples, for example, in an outbreak dozens of identical genomes could be sequenced and after the first, there is no new information for classification.</p> <p>The inclusion criteria for genome assemblies for addition to the GAMBIT database are as follows:</p> <ul> <li>Completeness computed by CheckM being equal or over 97%;</li> <li>Contamination  computed by CheckM being less than 3%;</li> <li>Having less than 300 contigs.</li> </ul> <p>Species missing from previous iterations of the database were attempted to be added with looser quality criteria:</p> <ul> <li>Completeness computed by CheckM being equal or over 90%;</li> <li>Contamination  computed by CheckM being less than 5%;</li> <li>Having less than 600 contigs.</li> </ul> <p>Curation is included in the post-processing steps of GAMBITdb. This is primarily because taxonomy has evolved over more than a century in a pre-genomics world and has many edge cases. Examples include:</p> <ul> <li>The GTDB candidates for an existing genus were collapsed (e.g. genus_A, genus_B becomes genus). GTDB proposes new genus/species based on ANI however, these are not currently formally accepted by the community.</li> <li>The following species were updated:<ul> <li>Shigella sp.<ul> <li>This genus is not present in GTDB  as it is collapsed under Escherichia coli; This is a controversial decision within the community, particularly as Shigella has specific clinical presentations.</li> <li>All Shigella genomes in RefSeq were added to the database with no clustering using default quality criteria.</li> </ul> </li> <li>Mycolicibacterium/Mycolicibacter/Mycolicibacillus/Mycobacteroides/Mycobacterium sp.<ul> <li>All genomes available were used.</li> </ul> </li> <li>Tropheryma whipplei<ul> <li>This species has a low completeness score of 75%;</li> <li>The CheckM completeness score was lowered to 70% for genomes belonging to this species.  CheckM was subsequently updated to a new version (not used in this instance) and completeness for this species is rectified, so this fix will be deprecated in the next release.</li> </ul> </li> </ul> </li> </ul>"},{"location":"guides/gambit_database/#using-gambitdb","title":"Using GAMBITdb","text":"<p>The GAMBIT-suite organization provides multiple repositories for tools for\u00a0GAMBIT. It includes the GAMBITdb repository which features several tools to generate a GAMBIT database from a GTDB\u2019s release spreadsheet.</p> <p>To run GAMBITdb, the following dependencies are required:</p> <ul> <li>GAMBIT</li> <li>ncbi-genome-download</li> <li>GAMBITtools</li> </ul> <p>A Bash wrapper is available for creating a database from a GTDB spreadsheet (one for bacteria, one for archaea). This script will download the data, create a GAMBIT database and signatures files, and then check the recall against the downloaded files for QC purposes. It is the easiest way to create a database.</p> <pre><code>run_gambitdb_bacteria.sh &lt;/path/to/working_directory&gt; &lt;/path/to/gtdb_metadata_spreadsheet.tsv&gt; &lt;num_cores&gt;\n</code></pre> <p>A collection of scripts is called by the Bash wrapper to:</p> <ol> <li>Parse a GTDB spreadsheet and output a list of accessions to download, a species taxon file and a genome metadata file;</li> <li>Download the genomes from NCBI (GenBank and RefSeq)</li> <li>Generate a GAMBIT database from a directory containing assemblies in FASTA format and a CSV file containing the assembly file and path, and the species taxon ID;</li> </ol> <p>Automatic Database Curation</p> <p>These steps allow you to obtain a working GAMBIT database without much manual intervention, given that all dependencies are installed correctly in your system. As of v2.0.0, the curation steps have been automated but require functionality deep access within the GAMBITdb software and are mostly for advanced usage. More detailed information is available within the GAMBITdb repository.</p> <p>Sometimes repairs are required as even with curation of the GTDB spreadsheet errors can make their way to the final database. A utility is available to perform maintenance and repair operations on a GAMBIT database:</p> <pre><code>gambitdb-repair-db &lt;/path/to/metadata_file&gt;\n</code></pre> <p>Manual curation efforts have been automated and are also available:</p> <pre><code>gambitdb-manual-curation &lt;/path/to/metadata_file&gt; &lt;/path/to/signatures_file&gt; &lt;/path/to/gtdb_metadata_spreadsheet.tsv&gt;\n</code></pre>"},{"location":"guides/gambit_database/#manually-creating-and-curating-a-gambit-database","title":"Manually creating and curating a GAMBIT database","text":"<p>The manual creation and curation of a GAMBIT database is a complex and sometimes difficult process and is not advised without guidance. Please feel free to reach out to support@theiagen.com with any questions you might have.</p>"},{"location":"guides/gambit_database/#sourcing-genomic-information","title":"Sourcing Genomic Information","text":"<p>A GAMBIT database can be created from genomes retrieved from a wide variety of sources, not just GTDB. To do so, all the automated steps in the GAMBITdb need to be followed individually. Some officially supported databases, such as the GAMBIT Fungal Database v0.2.0, were created following these steps.</p>"},{"location":"guides/gambit_database/#step-1-download-genomes-to-be-included-in-the-database","title":"Step 1: Download genomes to be included in the database","text":"<p>Genomes may be downloaded from public repositories like NCBI and GTDB. Genomes must be in FASTA file format. It is also necessary to create a file listing each genome with its species identity. The RefSeq FTP site is a useful resource for both tasks.</p> <p>Example: https://ftp.ncbi.nlm.nih.gov/genomes/refseq/fungi/assembly_summary.txt</p>"},{"location":"guides/gambit_database/#step-2-perform-quality-control-on-the-sourced-genomes-optional","title":"Step 2: Perform quality control on the sourced genomes (optional)","text":"<p>It is advised to perform some quality assessment and control on the downloaded genomes to reduce the possibility of including low-quality and/or erroneous sequences in the database. QUAST is a popular software for obtaining useful reference-free metrics such as the number of contigs, number of basepairs, length of largest contig and N50. Tools like BUSCO and CheckM provide valuable information regarding the completeness and contamination of a genome</p>"},{"location":"guides/gambit_database/#step-3-compress-genomes-into-the-gambit-signatures-file-and-calculate-pairwise-distances-between-all-genomes","title":"Step 3: Compress genomes into the GAMBIT signatures file and calculate pairwise distances between all genomes","text":"<p>Compressing genomes into a GAMBIT signatures file can be accomplished using GAMBIT\u2019s <code>gambit signatures</code> command:</p> <pre><code>gambit signatures create -k 11 -p ATGAC -o signatures.gs fasta_dir/*.fna.gz\n</code></pre> <p>K-mer Length</p> <p>The length of the k-mer, controlled by the <code>-k</code> parameter, and the k-mer prefix, controlled by the <code>-p</code> parameter, need to match between the GAMBIT database and the way GAMBIT query is run.  We strongly advise that these parameters not to be changed!</p> <p>After the GAMBIT signatures file is created, a pairwise distance matrix for every genome in the signatures file can be created using the <code>gambit dist</code> command:</p> <pre><code>gambit dist --qs signatures.gs --square -o pw_dists.csv\n</code></pre> <p>GAMBIT Metadata Database Scheme</p>"},{"location":"guides/gambit_database/#figure1","title":"Figure 1","text":"<p>Figure 1: Scheme for GAMBIT\u2019s metadata database</p>"},{"location":"guides/gambit_database/#step-4-calculate-diameters-for-taxa-and-resolve-overlaps","title":"Step 4: Calculate diameters for taxa and resolve overlaps","text":"<p>The defining feature of GAMBIT is the ability to determine if a query genome is genetically similar enough to the closest genome in the GAMBIT database to assign it to that species. For GAMBIT to work as intended, the database must be curated to ensure that no genomes are mislabeled and that species classifications are well-defined.</p> <p>Most GAMBIT databases are curated by examining the pairwise GAMBIT distance matrix generated in step 3 and resolving any of the following issues:</p> <ol> <li>Distantly related subspecies<ol> <li>Manifestation: In the pairwise-distance matrix, there are two or more groups of genomes within the species that are closely related, but are highly distant from each other.</li> <li>Solution: Create a subspecies taxon. </li> </ol> </li> <li>Outlier genomes that may be labelled with the incorrect species<ol> <li>Manifestation: The genome will be distant from other genomes within its species, but highly similar to genomes of another species.</li> <li>Solution: Remove this genome. Assigning a new taxa is also possible.</li> </ol> </li> <li>Outlier genomes that are the result of poor assemblies<ol> <li>Manifestation: The genome will be distant from all other genomes in the distance matrix.</li> <li>Solution: Remove this genome.</li> </ol> </li> </ol> <p>Any remaining species overlaps following removal of outlier genomes and separation of subspecies is likely the result of species groupings reflecting historical practices that do not align well with genetic distinctions between species (i.e. E. coli and Shigella).</p>"},{"location":"guides/gambit_database/#step-5-download-taxa","title":"Step 5: Download taxa","text":"<p>Entrez, available through Biopython, is a useful resource for downloading data directly from NCBI including Taxonomy, a database of organism names and classifications.</p> <p>For each entry in the database, the most up-to-date taxonomy needs to be retrieved. In the GAMBIT database, the taxon IDs of the genomes need to be mapped to their species-level ancestors.</p> <p>We provide a Python script to accomplish this. Please add the missing information marked with <code>&lt;&gt;</code> to make the utility function and make sure you have all the required dependencies installed in your system, including Pandas and Biopython.</p> <pre><code>#!/usr/bin/env python\n# coding: utf-8\n\n# Download ESummary data for taxonomy tree.\n\nfrom pathlib import Path\nimport json\nimport pandas as pd\nfrom Bio import Entrez\nfrom tqdm import tqdm\n\n# ## Setup\n\nEntrez.email = '&lt;your_email_here&gt;' #TO BE REPLACED\n\nDATESTR = '&lt;YYMMDD&gt;' #TO BE REPLACED\nNBNAME = f'{DATESTR}-download-taxa'\n\ninfiles = dict(\n    genomes='&lt;genomes_CSV_file&gt;',  #TO BE REPLACED\n)\n\nintermediate_data = Path('data-intermediate') / NBNAME\nintermediate_data.mkdir(exist_ok=True)\n\noutfiles = dict(\n    taxa=intermediate_data / 'taxa',\n)\n\noutfiles['taxa'].mkdir(exist_ok=True)\n\n# ## Load data\n\ngenomes = pd.read_csv(infiles['genomes'])\n\n# ## Download taxonomy data\n\nto_download = set(genomes['ncbi_taxid'])\ntaxa = dict()\n\nwhile to_download:\n    # Next to download\n    taxid = next(iter(to_download))\n    print(taxid)\n    file = outfiles['taxa'] / f'{taxid}.json'\n\n    if not file.exists():\n        # Fetch data from NCBI\n        result = Entrez.read(Entrez.efetch(db='taxonomy', id=taxid))\n        (taxon,) = result\n\n        # Save to local file\n        with open(file, 'w') as f:\n            json.dump(taxon, f)\n\n    else:\n        # Already downloaded, read from the existing file\n        with open(file) as f:\n            taxon = json.load(f)\n\n    taxa[taxid] = taxon\n    to_download.remove(taxid)\n\n    # If not a species, find the species ancestor and add to the download list\n    if taxon['Rank'] != 'species':\n        for ancestor in taxon['LineageEx']:\n            if ancestor['Rank'] == 'species':\n                tid = int(ancestor['TaxId'])\n                if tid not in taxa:\n                    to_download.add(tid)\n                break\n        else:\n            raise RuntimeError('No species ancestor found')\n</code></pre>"},{"location":"guides/gambit_database/#step-6-create-the-database","title":"Step 6: Create the database","text":"<p>The next step is to create the SQLite database file for the GAMBIT database. Figure 1 depicts the database structure expected by GAMBIT. </p> <p>We provide a Python script to accomplish this. Please add the missing information marked with <code>&lt;&gt;</code> to make the utility function and make sure you have all the required dependencies installed in your system, including GAMBIT and SQLalchemy.</p> <pre><code>#!/usr/bin/env python\n# coding: utf-8\n\n# This creates the sqlite database file for the Candida DB.\n\nfrom pathlib import Path\nimport json\nfrom datetime import date\nimport pandas as pd\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\nfrom gambit.db import ReferenceGenomeSet, Genome, AnnotatedGenome, Taxon\nfrom gambit.db.migrate import init_db\nfrom entrez_tools.db.assembly import format_summary_meta\n\n# ## Setup\n\nDATESTR = '&lt;YYMMDD&gt;' #TO BE REPLACED\nNBNAME = f'{DATESTR}-create-db'\n\ninfiles = dict(\n    genomes_table=Path('&lt;genomes_CSV_file&gt;'), #TO BE REPLACED\n    taxa_table=Path(f'data-intermediate/{DATESTR}_3-find-diameters/species-data.csv'),\n    fasta_dir=Path('&lt;path_to_directory_with_fastas&gt;'), #TO BE REPLACED\n    genome_esummary_dir=Path(f'data-intermediate/{DATESTR}_1-download-genomes/esummary'),\n    taxon_esummary_dir=Path(f'data-intermediate/{DATESTR}_4-download-taxa/taxa'),\n)\n\nprocessed_data = Path('data-processed') / NBNAME\nprocessed_data.mkdir(exist_ok=True, parents=True)\n\noutfiles = dict(\n    db=processed_data / f'{DATESTR}-&lt;database_name&gt;.db', #TO BE REPLACED\n)\n\n# ## Load data\n\ngenomes_df = pd.read_csv(infiles['genomes_table'])\ntaxa_df = pd.read_csv(infiles['taxa_table'])\n\ngenome_summaries = dict()\n\nfor uid in genomes_df['uid']:\n    with open(infiles['genome_esummary_dir'] / f'{uid}.json') as f:\n        genome_summaries[uid] = json.load(f)\n\ntaxon_summaries = dict()\n\nfor taxid in set(genomes_df['ncbi_taxid']):\n    with open(infiles['taxon_esummary_dir'] / f'{taxid}.json') as f:\n        taxon_summaries[uid] = json.load(f)\n\n# ## Create database\n\nif outfiles['db'].is_file():\n    outfiles['db'].unlink()\n\nengine = create_engine('sqlite:///' + str(outfiles['db']))\n\ninit_db(engine)\n\nSession = sessionmaker(engine)\nsession = Session()\n\n# ### Genome set\n\ngset = ReferenceGenomeSet(\n    key='&lt;database_name&gt;', # TO BE REPLACED, suggested &lt;organization/name&gt;\n    version='x.y.z', # TO BE REPLACED\n    name='&lt;name&gt;', # TO BE REPLACED\n    description='&lt;description&gt;', # TO BE REPLACED\n    extra=dict(\n        author='&lt;author&gt;', # TO BE REPLACED\n        date=date.today().isoformat(),\n    ),\n)\n\nsession.add(gset)\nsession.commit()\n\n# ### Taxa\n\ntaxa = dict()\n\nfor row in taxa_df.itertuples():\n    taxon = Taxon(\n        genome_set=gset,\n        # Arbitrary unique string ID\n        # These are all regular NCBI taxa\n        key=f'ncbi/{row.ncbi_taxid}',\n        # Using names I got from you here, NCBI reassigned several to other genera\n        name=row.name,\n        rank='species',\n        #description\n        distance_threshold=row.diameter,\n        #report\n        #genome set id\n        #parent_id\n        ncbi_id=row.ncbi_taxid,\n        # Arbitrary JSON-formatted metadata\n        extra=dict(\n            # The actual name used by NCBI\n            ncbi_name=row.ncbi_name,\n        ),\n    )\n\n    taxa[row.ncbi_taxid] = taxon\n    session.add(taxon)\n\nsession.commit()\n\n# ### Genomes\n\nfor row in genomes_df.itertuples():\n    summary = genome_summaries[row.uid]\n    assembly_stats = format_summary_meta(summary['meta'])\n    taxon = taxa[row.ncbi_taxid]\n\n    genome = Genome(\n        #edited next line\n        key='/data/fasta/'f'{row.genbank_acc}''.fna.gz',\n        description=f'[{row.genbank_acc}] {summary[\"organism\"]}',\n        ncbi_db='assembly',\n        ncbi_id=row.uid,\n        genbank_acc=row.genbank_acc,\n        # More JSON metadata\n        extra=dict(\n            length=assembly_stats['total_length'],\n        )\n    )\n    session.add(genome)\n\n    ag = AnnotatedGenome(\n        genome=genome,\n        genome_set=gset,\n        taxon=taxon,\n        organism=taxon.name,\n    )\n    session.add(ag)\n\nsession.commit()\n</code></pre>"},{"location":"guides/gambit_database/#step-7-finalise-the-signatures-file","title":"Step 7: Finalise the signatures file","text":"<p>The Last step is to finalise the signatures file. This last Python utility adds metadata to the database signatures file. Please add the missing information marked with <code>&lt;&gt;</code> to make the utility function and make sure you have all the required dependencies installed in your system, including GAMBIT and SQLalchemy.</p> <pre><code>#!/usr/bin/env python\n# coding: utf-8\n\n# # Finalize signatures\n\nfrom pathlib import Path\nimport json\nfrom datetime import date\nfrom gambit.sigs import SignaturesMeta, load_signatures, dump_signatures, AnnotatedSignatures\n\n# ## Setup\n\nDATESTR = '&lt;YYMMDD&gt;' #TO BE REPLACED\nNBNAME = f'{DATESTR}-finalize-signatures'\n\ninfiles = dict(\n    signatures=Path(f'data-intermediate/{DATESTR}-signatures-and-dists/signatures.h5'),\n)\n\nprocessed_data = Path('data-processed') / NBNAME\nprocessed_data.mkdir(exist_ok=True, parents=True)\n\noutfiles = dict(\n    signatures=processed_data / f'{DATESTR}-&lt;db_name&gt;.h5', #TO BE REPLACED\n)\n\n# ## Assign metadata\n\nmeta = SignaturesMeta(\n    id='&lt;database_name&gt;', # TO BE REPLACED, suggested &lt;organization/name&gt;\n    version='x.y.z', # TO BE REPLACED\n    name='&lt;name&gt;', # TO BE REPLACED\n    description='&lt;description&gt;', # TO BE REPLACED\n    id_attr='key',\n)\n\nwith load_signatures(infiles['signatures']) as src:\n    out_sigs = AnnotatedSignatures(src, src.ids, meta)\n    dump_signatures(outfiles['signatures'], out_sigs)\n</code></pre>"},{"location":"guides/gambit_database/#help-available","title":"Help Available","text":"<p>Please feel free to reach out to support@theiagen.com with any questions you might have.</p>"},{"location":"guides/phylogenetics/","title":"Guide to Phylogenetics","text":""},{"location":"guides/phylogenetics/#introduction-to-phylogenetics","title":"Introduction to Phylogenetics","text":"<p>Phylogenetics is an approach to understanding evolutionary relationships among organisms, primarily through analysis of gene, amino acid, or genome sequences. These evolutionary relationships are graphically represented by phylogenetic trees.</p>"},{"location":"guides/phylogenetics/#broadly-there-are-two-phylogenetic-analysis-methods","title":"Broadly, there are two phylogenetic analysis methods","text":"<ul> <li> <p> Phylogenetic tree construction</p> <p>Creation of a phylogenetic tree from a set of sequences</p> <ul> <li>Goal: Determine the evolutionary relationship between a set of sequences, often to rule out likely transmission</li> <li>Pros:<ul> <li>Can be constructed form any suitable set of samples</li> <li>More accurate than phylogenetic placement when a high-quality dataset and appropriate methods are used</li> </ul> </li> <li>Cons:<ul> <li>Can be comparably slow and computationally expensive, especially for trees with a large number of sequences and large genomes</li> </ul> </li> </ul> </li> <li> <p> Phylogenetic placement</p> <p>Placement of genomes onto an existing phylogenetic tree</p> <ul> <li>Goal: Determine the closest relatives to a new sequence</li> <li>Pros:<ul> <li>It avoids needing to build a whole tree which is comparably slow and computationally expensive, especially for large amounts of data</li> </ul> </li> <li>Cons:<ul> <li>Requires an existing tree to add the new sample to</li> <li>Less accurate than building a new phylogenetic tree</li> </ul> </li> </ul> </li> </ul>"},{"location":"guides/phylogenetics/#phylogenetic-tree-construction-approaches","title":"Phylogenetic tree construction approaches","text":""},{"location":"guides/phylogenetics/#key-considerations-before-generating-a-phylogenetic-tree","title":"Key considerations before generating a phylogenetic tree","text":"<ul> <li>When using Theiagen workflows, sequences should have been previously analyzed with TheiaCoV, TheiaProk, or TheiaEuk to assess sequence quality, generate assemblies or annotation files that may be required for some phylogenetic tree-building workflows, and generate any metadata that you might like to use for visualization against the tree.</li> <li>All samples included in a phylogenetic tree should pass agreed QC thresholds<ul> <li>FASTA input trees are particularly reliant on a high-quality assembly<ul> <li>Repetitive regions may be incorrectly assembled (particularly for de novo assemblies as generated by TheiaProk and TheiaEuk)</li> <li>Low-coverage regions and heterologous sites may be included in the phylogeny</li> </ul> </li> </ul> </li> <li>For transmission analyses, samples in the same tree should be closely related- the same lineage or sequence type</li> </ul>"},{"location":"guides/phylogenetics/#workflow-recommendations-for-phylogenetic-tree-construction","title":"Workflow recommendations for phylogenetic tree construction","text":"<p>Recommendations</p> <ul> <li>Augur_Prep &amp; Augur: For building phylogenetic trees from viral genomes</li> <li>kSNP3: For analysis of clonal sets of genomes (e.g., foodborne outbreak analyses), using a simple method</li> <li>Snippy_Streamline: For analysis of bacterial genomes that may undergo recombination or require masking of the genome</li> <li>Snippy_Variants &amp; Snippy_Tree: Similar to Snippy_Streamline, but for when you want more control over the workflow parameters or if you want to generate the tree multiple times using different combinations of sequences aligned against the same reference</li> <li>Mashtree_FASTA: For very quick trees</li> <li>Core_Gene_SNP: For generation of a pangenome analysis, with an additional core- or pan-gene phylogeny to visualize the pangenome against</li> </ul> Full comparison of Theiagen phylogenetic construction workflows Genome suitability Input files Method Use cases Pros Cons Mashtree Low-divergence bacterial genome sets Assembly FASTA for each genome NJ tree based on mash distances Identification of obvious outliers/contaminated samples in a dataset; analysis of extensive datasets where other methods are not suitable (thousands of samples) Very quick; low computational cost; fairly accurate for large low-diversity trees; does not require input reference genome; very easy to run Does not model evolution; cannot handle complex evolutionary histories (recombination, HGT, etc) or highly divergent genomes; does not compute SNPs to identify SNP distances kSNP3 Clonal bacterial genome sets (e.g. foodborne outbreak genomes) Assembly FASTA for each genome Parsimony (default), NJ or ML tree based on kmer differences Analysis of clonal pathogens Reasonably fast for small datasets; does not require input reference genome; very easy to run Not suitable for highly divergent genomes; does not remove recombination or SNPs within ~9 nucleotides; no control over SNP support; computationally demanding for very large datasets; no control of the evolutionary model, even for ML trees Snippy phylogenetics workflows All bacterial genome sets FASTQ read files for each genome; reference genome or assemblies that can be used to identify a reference Maximum likelihood with a large selection of nucleotide substitution models; can mask recombination or other genomic regions specified with a bed file Analysis of any bacterial genome, without expectations for population partitioning Can generate very high-quality trees; highly modifiable parameters Slower and more computationally expensive than some other methods; requires the user to consider appropriate input parameters, including computational resources for trees with hundreds of samples Core_Gene_SNP Bacterial genome sets GFF3 annotation files for each genome (from Prokka, run during TheiaProk) Gene/CDS alignment and SNP-calling with a maximum likelihood tree; core gene and pan-gene trees available Assessment of accessory CDS that are present or absent amongst all genomes in the dataset, against a phylogenetic tree Does not require a reference genome; core genes are less likely to have been involved in recombination; provides pangenome presence/absence output Augur SARS-CoV-2, mpox virus, influenza genome sets (other viral pathogens require more parameter configuration as defaults are not provided) FASTA assembly Phylogenetic analysis for the specified organisms for visualization on Auspice or any platform that takes Newick files Compatible with Auspice, high-quality trees for the specified pathogens Custom configurations of tree generation and visualizations can require extensive parameter knowledge and manipulation"},{"location":"guides/phylogenetics/#interpreting-phylogenetic-trees-and-snp-distances","title":"Interpreting phylogenetic trees and SNP distances","text":"<p>Resources for phylogenetic tree interpretation</p> <ul> <li>Understanding phylogenetic trees, particularly what they represent</li> <li>How to read a phylogenetic tree</li> <li>How to interpret phylogenetic trees in terms of transmission</li> </ul>"},{"location":"guides/phylogenetics/#snp-distances","title":"SNP distances","text":"<p>During outbreak investigations, SNP distances are sometimes used to help interpret the potential for transmission. SNP distance thresholds have been established for some pathogens, under some circumstances. Typically, SNP distance thresholds can</p> <ul> <li>Identify potential transmission clusters</li> <li>Rule out transmission events (may be directional, between two specified location/people)</li> </ul> <p>It can be difficult to determine SNP thresholds because of:     - within-host diversity     - unknown number of transmissions/other bottlenecks decreasing genetic diversity     - variable mutation rates between strains, in different environments, and/or in different regions of the genome     - imprecise removal of recombination or erroneous SNPs</p> <p>The comparison of SNP distances between potentially related strains and background strains can be helpful for source attribution (e.g. foodborne outbreaks). Combination with epidemiological data can help identify suitable thresholds to rule out transmission. In addition, mutation rates can be calculated based on SNPs at different time points, allowing inference of start of outbreak. Be aware of incomplete sampling as SNP distances don't reveal if there were other infected individuals that weren\u2019t sampled</p>"},{"location":"guides/phylogenetics/#visualizing-phylogenetic-trees","title":"Visualizing phylogenetic trees","text":"<p>Recommendations</p> <ul> <li>Auspice for phylogenetic trees generated using the Augur workflows</li> <li>Phandango for visualizing metadata against the phylogenetic tree (e.g. presence/absence of ARGs or plasmid replicons, SNP-distance matrices, recombination gff files from gubbins, or pangenome visualizations)</li> <li>FigTree for re-rooting phylogenetic trees, visualizing trees with annotated nodes (e.g. time-dated phylogenies) and looking at branch lengths</li> <li>MicrobeTrace for visualizing phylogenetic trees with transmission networks</li> </ul> Full comparison of no-code phylogenetic tree visualization software Consideration Auspice Phandango FigTree iTOL GrapeTree MicrobeTrace Link https://auspice.us/ https://jameshadfield.github.io/phandango/#/ http://tree.bio.ed.ac.uk/software/figtree/ https://itol.embl.de/ https://achtman-lab.github.io/GrapeTree/MSTree_holder.html https://microbetrace.cdc.gov/MicrobeTrace/ Ease of use Easy: drag and drop files to visualize; control the view with the menu Easy: drag and drop files to visualize; control the view with the menu Easy: Click to load, control view with the menu Easy: Click to load, control view with the menu Easy: Click to load, control view with the menu Easy to visualize a tree: drag and drop files, but you have to change the visualization from network  to tree Performance Can handle large and complex trees Difficult to view very large trees (thousands of genomes) Can take large and complex trees May be slow to display large trees Can take large and complex trees Can take large and complex trees Interactivity Zoom, re-color the tree according to the metadata Zoom, dynamic metadata views alongside tree Zoom, tree arrangement Zoom, tree arrangement Zoom, tree arrangement, re-color tree according to metadata No zoom, but you can alter horizontal &amp; vertical stretch Metadata visualization Terminal nodes color-coded to metadata Metadata visualized alongside a phylogeny Branches, internal, and tips color-coded to metadata Difficult to add metadata Terminal nodes color-coded to metadata Terminal nodes color-coded,  shape-coded, or sized according to metadata, can also add labels Input tree type JSON Newick Newick and Nexus Newick Newick Newick Metadata files supported CSV of sample characteristics CSV of sample characteristics, .gff for recombination or pangenome TXT of sample characteristics N/a CSV of sample characteristics CSV of sample characteristics Saving tree views ? Image files only Nexus, image files (PNG, SVG, JPEG), and PDF Export options are limited in the free version JSON, Newick, SVG Save the MicrobeTrace session as a zip file on the computer, then drag &amp; drop to restore Availability Browser-based, but does not share data Browser-based, but does not share data Installed on the local computer, requires Java Browser-based, but does not share data Browser-based, but does not share data, or installed on the local computer Browser-based, but does not share data Other considerations Highly interactive; a great all-rounder Great quickly assessing associations between tree topology and metadata, e.g. cluster association with a given characteristic; can also visualize recombination and pangenome assessments relative to tree No longer under active development, so some bugs may not be fixed, very useful for rearranging tree view and viewing dates of nodes Very useful for rearranging tree view Primarily intended for visualization of transmission networks with steep learning curve; actively maintained by CDC Limitations Difficult to quickly assess which metadata characteristics may be associated with tree topology No scale; no ability to rearrange tree file; limitations to interactive views Difficult to visualize additional metadata Difficult to visualize additional metadata Minimum-spanning trees only No (useful) scale Maintained Yes No No Yes No? Yes <p>To learn more about MicrobeTrace, please see the following video: \ud83d\udcfa Using KSNP3 in Terra and Visualizing Bacterial Genomic Networks in MicrobeTrace</p>"},{"location":"guides/sops/","title":"Available SOPs","text":""},{"location":"guides/sops/#available-standard-operating-procedures","title":"Available Standard Operating Procedures","text":"<p>Theiagen has developed a number of Standard Operating Procedures (SOPs) to help you analyze your data. Please see the available SOPs below.</p>"},{"location":"guides/sops/#all-sops","title":"All SOPs","text":"SOP SOP version Workflow PHB version compatibility Pathogen/Category Current or prior wf version? Analyze SARS-COV-2 using TheiaCoV_FASTA v2 FASTA, TheiaCoV v1 SC2 Current Analyze SARS-COV-2 using TheiaCoV_Illumina_PE_PHB v4 PE, TheiaCoV v3 SC2 Current Analyze SARS-COV-2 using TheiaCoV_Illumina_SE_PHB v4 SE, TheiaCoV v3 SC2 Current Analyze SARS-COV-2 using TheiaCoV_ONT v4 ONT, TheiaCoV v3 SC2 Current Analyzing Bacterial Data in Terra using Theiagen\u2019s TheiaProk Illumina PE Workflow v3 PE, TheiaProk v2, v3 Bacterial Current Analyzing SARS-CoV-2 Metagenomic Samples using Freyja FASTQ v2 Freyja v2 SC2 Current Analyzing SARS-CoV-2 using TheiaCov_ClearLabs v4 CL, TheiaCoV v3 SC2 Current Comparing Terra Data Tables using Theiagen\u2019s TheiaValidate Workflow v1 TheiaValidate v1, v2 Validations Current Comparing Terra Data Tables using Theiagen\u2019s TheiaValidate Workflow v3 TheiaValidate v2, v3 Validations Current Creating Static Reference Files for Freyja Analysis in Terra using Freyja Update v2 Freyja v2 SC2 Current Creating a Dashboard Visualization of SARS-CoV-2 Metagenomic Samples using Freyja Dashboard v2 Freyja v2 SC2 Current Getting Started In Terra v4 None v2, v3 Getting Started Current Linking BaseSpace and Importing BaseSpace Reads to Terra v3 BaseSpace_Fetch v3 Data Import Current Plotting SARS-CoV-2 Metagenomic Sample Data using Freyja Plot v3 Freyja v2 SC2 Current Running Influenza A, H3N2 Metagenomic Samples in Terra using Theiagen\u2019s Freyja FASTQ Workflow v1 Freyja v3 Flu Current Running Theiagen\u2019s Rasusa Workflow in Terra to Randomly Downsample Reads v2 RASUSA v1, v2 Downsampling Current Running Theiagen\u2019s Snippy_Variants_PHB Workflow in Terra v1 Snippy_Variants v2 Bacterial, Phylogenetic construction Current Submitting SC2 Sequence Data to GISAID using Theiagen\u2019s Terra 2 GISAID Workflow v2 Terra_2_GISAID v2 Public data sharing, SC2 Current TheiaProk_ONT v3 ONT, TheiaProk v2, v3 Bacterial Current Uploading Data, Creating Metadata Tables and TSV files, and Importing Workflows v4 None v3 Data Import Current Analyze SARS-COV-2 using TheiaCoV_Illumina_PE_PHB v3 PE, TheiaCoV v2 SC2 Prior Analyze SARS-COV-2 using TheiaCoV_Illumina_SE_PHB v3 SE, TheiaCoV v2 SC2 Prior Analyze SARS-COV-2 using TheiaCoV_ONT v2 ONT, TheiaCoV v1 SC2 Prior Analyze SARS-COV-2 using TheiaCoV_ONT v3 ONT, TheiaCoV v2 SC2 Prior Analyzing Bacterial Data in Terra using Theiagen\u2019s TheiaProk Illumina PE Workflow v2 PE, TheiaProk v1 Bacterial Prior Analyzing Flu Data in Terra using TheiaCov_Illumina_PE and Augur Workflows v1 Augur, PE, TheiaCoV v1 Flu, Phylogenetic construction Prior Analyzing HAI Pathogens using Phoenix Version 1 in Terra v1 Phoenix v1 HAI Prior Analyzing HAI Pathogens using Phoenix Version 2 in Terra v1 Phoenix v1 HAI Prior Analyzing Phylogenetic Relationships in Terra using Theiagen\u2019s Augur Workflows v1 Augur v1 Phylogenetic construction Prior Analyzing SARS-CoV-2 using TheiaCov_ClearLabs v3 CL, TheiaCoV v2 SC2 Prior Comparing Terra Data Tables using Theiagen\u2019s TheiaValidate Workflow v2 TheiaValidate v2 Validations Prior Getting Started In Terra v3 None v2, v3 Getting Started Prior Linking BaseSpace and Importing BaseSpace Reads to Terra v2 BaseSpace_Fetch v2 Data Import Prior TheiaProk_ONT v2 ONT, TheiaProk v1 Bacterial Prior Uploading Data, Creating Metadata Tables and TSV files, and Importing Workflows v3 None v1, v2 Data Import Prior"},{"location":"guides/sops/#most-up-to-date-sops","title":"Most Up-to-Date SOPs","text":"SOP SOP version Workflow PHB version compatibility Pathogen/Category Current or prior wf version? Analyze SARS-COV-2 using TheiaCoV_FASTA v2 FASTA, TheiaCoV v1 SC2 Current Analyze SARS-COV-2 using TheiaCoV_Illumina_PE_PHB v4 PE, TheiaCoV v3 SC2 Current Analyze SARS-COV-2 using TheiaCoV_Illumina_SE_PHB v4 SE, TheiaCoV v3 SC2 Current Analyze SARS-COV-2 using TheiaCoV_ONT v4 ONT, TheiaCoV v3 SC2 Current Analyzing Bacterial Data in Terra using Theiagen\u2019s TheiaProk Illumina PE Workflow v3 PE, TheiaProk v2, v3 Bacterial Current Analyzing SARS-CoV-2 Metagenomic Samples using Freyja FASTQ v2 Freyja v2 SC2 Current Analyzing SARS-CoV-2 using TheiaCov_ClearLabs v4 CL, TheiaCoV v3 SC2 Current Comparing Terra Data Tables using Theiagen\u2019s TheiaValidate Workflow v1 TheiaValidate v1, v2 Validations Current Comparing Terra Data Tables using Theiagen\u2019s TheiaValidate Workflow v3 TheiaValidate v2, v3 Validations Current Creating Static Reference Files for Freyja Analysis in Terra using Freyja Update v2 Freyja v2 SC2 Current Creating a Dashboard Visualization of SARS-CoV-2 Metagenomic Samples using Freyja Dashboard v2 Freyja v2 SC2 Current Getting Started In Terra v4 None v2, v3 Getting Started Current Linking BaseSpace and Importing BaseSpace Reads to Terra v3 BaseSpace_Fetch v3 Data Import Current Plotting SARS-CoV-2 Metagenomic Sample Data using Freyja Plot v3 Freyja v2 SC2 Current Running Influenza A, H3N2 Metagenomic Samples in Terra using Theiagen\u2019s Freyja FASTQ Workflow v1 Freyja v3 Flu Current Running Theiagen\u2019s Rasusa Workflow in Terra to Randomly Downsample Reads v2 RASUSA v1, v2 Downsampling Current Running Theiagen\u2019s Snippy_Variants_PHB Workflow in Terra v1 Snippy_Variants v2 Bacterial, Phylogenetic construction Current Submitting SC2 Sequence Data to GISAID using Theiagen\u2019s Terra 2 GISAID Workflow v2 Terra_2_GISAID v2 Public data sharing, SC2 Current TheiaProk_ONT v3 ONT, TheiaProk v2, v3 Bacterial Current Uploading Data, Creating Metadata Tables and TSV files, and Importing Workflows v4 None v3 Data Import Current"},{"location":"guides/sops/#data-import-sops","title":"Data Import SOPs","text":"SOP SOP version Workflow PHB version compatibility Pathogen/Category Current or prior wf version? Linking BaseSpace and Importing BaseSpace Reads to Terra v3 BaseSpace_Fetch v3 Data Import Current Uploading Data, Creating Metadata Tables and TSV files, and Importing Workflows v4 None v3 Data Import Current Linking BaseSpace and Importing BaseSpace Reads to Terra v2 BaseSpace_Fetch v2 Data Import Prior Uploading Data, Creating Metadata Tables and TSV files, and Importing Workflows v3 None v1, v2 Data Import Prior"},{"location":"guides/sops/#viral-sops","title":"Viral SOPs","text":"SOP SOP version Workflow PHB version compatibility Pathogen/Category Current or prior wf version? Analyze SARS-COV-2 using TheiaCoV_FASTA v2 FASTA, TheiaCoV v1 SC2 Current Analyze SARS-COV-2 using TheiaCoV_Illumina_PE_PHB v4 PE, TheiaCoV v3 SC2 Current Analyze SARS-COV-2 using TheiaCoV_Illumina_SE_PHB v4 SE, TheiaCoV v3 SC2 Current Analyze SARS-COV-2 using TheiaCoV_ONT v4 ONT, TheiaCoV v3 SC2 Current Analyzing SARS-CoV-2 using TheiaCov_ClearLabs v4 CL, TheiaCoV v3 SC2 Current Analyze SARS-COV-2 using TheiaCoV_Illumina_PE_PHB v3 PE, TheiaCoV v2 SC2 Prior Analyze SARS-COV-2 using TheiaCoV_Illumina_SE_PHB v3 SE, TheiaCoV v2 SC2 Prior Analyze SARS-COV-2 using TheiaCoV_ONT v2 ONT, TheiaCoV v1 SC2 Prior Analyze SARS-COV-2 using TheiaCoV_ONT v3 ONT, TheiaCoV v2 SC2 Prior Analyzing Flu Data in Terra using TheiaCov_Illumina_PE and Augur Workflows v1 Augur, PE, TheiaCoV v1 Flu, Phylogenetic construction Prior Analyzing SARS-CoV-2 using TheiaCov_ClearLabs v3 CL, TheiaCoV v2 SC2 Prior"},{"location":"guides/sops/#bacterial-sops","title":"Bacterial SOPs","text":"SOP SOP version Workflow PHB version compatibility Pathogen/Category Current or prior wf version? Analyzing HAI Pathogens using Phoenix Version 1 in Terra v1 Phoenix v1 HAI Prior Analyzing HAI Pathogens using Phoenix Version 2 in Terra v1 Phoenix v1 HAI Prior"},{"location":"guides/sops/#phylogenetic-sops","title":"Phylogenetic SOPs","text":"SOP SOP version Workflow PHB version compatibility Pathogen/Category Current or prior wf version? Running Theiagen\u2019s Snippy_Variants_PHB Workflow in Terra v1 Snippy_Variants v2 Bacterial, Phylogenetic construction Current Analyzing Flu Data in Terra using TheiaCov_Illumina_PE and Augur Workflows v1 Augur, PE, TheiaCoV v1 Flu, Phylogenetic construction Prior Analyzing Phylogenetic Relationships in Terra using Theiagen\u2019s Augur Workflows v1 Augur v1 Phylogenetic construction Prior"},{"location":"guides/sops/#data-sharing-sops","title":"Data Sharing SOPs","text":"SOP SOP version Workflow PHB version compatibility Pathogen/Category Current or prior wf version? Submitting SC2 Sequence Data to GISAID using Theiagen\u2019s Terra 2 GISAID Workflow v2 Terra_2_GISAID v2 Public data sharing, SC2 Current"},{"location":"guides/sops/#miscellaneous-sops","title":"Miscellaneous SOPs","text":"SOP SOP version Workflow PHB version compatibility Pathogen/Category Current or prior wf version? Comparing Terra Data Tables using Theiagen\u2019s TheiaValidate Workflow v1 TheiaValidate v1, v2 Validations Current Comparing Terra Data Tables using Theiagen\u2019s TheiaValidate Workflow v3 TheiaValidate v2, v3 Validations Current Running Theiagen\u2019s Rasusa Workflow in Terra to Randomly Downsample Reads v2 RASUSA v1, v2 Downsampling Current Running Theiagen\u2019s Snippy_Variants_PHB Workflow in Terra v1 Snippy_Variants v2 Bacterial, Phylogenetic construction Current Comparing Terra Data Tables using Theiagen\u2019s TheiaValidate Workflow v2 TheiaValidate v2 Validations Prior"},{"location":"guides/versions/","title":"Database and Docker Versions","text":""},{"location":"guides/versions/#database-and-docker-versions","title":"Database and Docker Versions","text":"<p>Throughout this repository, we have carefully selected a number of default databases and Docker images that are intended to be sufficient starting points for most analyses. The following tables describe the default values for all databases, Docker images, and reference files used throughout the suite of PHB workflows.</p>"},{"location":"guides/versions/#default-databases","title":"Default Databases","text":"Terra Task Name Variable Type Description Default Value Workflow checkv_consensus checkv_db File CheckV database file gs://theiagen-public-resources-rp/reference_data/databases/checkv/checkv-db-v1.5.tar.gz TheiaViral_Illumina_PE, TheiaViral_ONT checkv_denovo checkv_db File CheckV database file gs://theiagen-public-resources-rp/reference_data/databases/checkv/checkv-db-v1.5.tar.gz TheiaViral_Illumina_PE, TheiaViral_ONT gambit gambit_db_genomes File Database of metadata for assembled query genomes; requires complementary signatures file. If not provided, uses default database \"/gambit-db\" gs://gambit-databases-rp/2.0.0/gambit-metadata-2.0.1-20250505.gdb Gambit_Query, TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE gambit gambit_db_signatures File Signatures file; requires complementary genomes file. If not specified, the file from the docker container will be used. gs://gambit-databases-rp/2.0.0/gambit-signatures-2.0.1-20250505.gs Gambit_Query, TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE gamma gamma_db File Multifasta sequence database GAMMA is to use for gene matching gs://theiagen-public-resources-rp/reference_data/databases/gamma/default_ResFinderDB_Combined_05-06-20.fsa TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE kmerfinder kmerfinder_db File Bacterial database for KmerFinder gs://theiagen-public-resources-rp/reference_data/databases/kmerfinder/kmerfinder_bacteria_20230911.tar.gz TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE kraken2 kraken2_db File The database used to run Kraken2 gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz NCBI_Scrub_PE, NCBI_Scrub_SE kraken2_dehosted kraken2_db File The database used to run Kraken2. Must contain viral and human sequences. gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz TheiaCoV_ClearLabs kraken2_raw kraken2_db File The database used to run Kraken2. Must contain viral and human sequences. gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz TheiaCoV_ClearLabs merlin_magic poppunk_gps_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_clusters.csv TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_gps_dists_npy File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.dists.npy TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_gps_dists_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.dists.pkl TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_gps_external_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_external_clusters.csv TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_gps_fit_npz File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_fit.npz TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_gps_fit_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_fit.pkl TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_gps_graph_gt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_graph.gt TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_gps_h5 File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.h5 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_gps_qcreport_txt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_qcreport.txt TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_gps_refs File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_gps_refs_dists_npy File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.dists.npy TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_gps_refs_dists_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.dists.pkl TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_gps_refs_graph_gt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6refs_graph.gt TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_gps_refs_h5 File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.h5 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_gps_unword_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_unword_clusters.csv TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic virulencefinder_database String The specific database to use virulence_ecoli TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE metabuli metabuli_db File Metabuli database file gs://theiagen-public-resources-rp/reference_data/databases/metabuli/refseq_virus-v223.tar.gz TheiaViral_ONT read_QC_trim kraken_db File A kraken2 database to use with the kraken2 optional task. The file must be a .tar.gz kraken2 database. Must contain human and viral sequences gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz TheiaCoV_ONT, TheiaCoV_Illumina_PE, TheiaCoV_Illumina_SE, TheiaCoV_ONT read_QC_trim midas_db File The database used by the MIDAS task in .tar.gz format gs://theiagen-public-files-rp/terra/theiaprok-files/midas/midas_db_v1.2.tar.gz TheiaMeta_Illumina_PE, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE referenceseeker referenceseeker_db File Database used by the referenceseeker tool that contains bacterial genomes from RefSeq release 205. Downloaded from the referenceseeker GitHub repository. gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-bacteria-refseq-205.v20210406.tar.gz Assembly_Fetch, Snippy_Streamline, Snippy_Streamline_FASTA skani skani_db File Skani database file gs://theiagen-public-resources-rp/reference_data/databases/skani/skani_db_20250613.tar TheiaViral_Illumina_PE, TheiaViral_ONT theiaeuk_illumina_pe gambit_db_genomes File User-provided database of assembled query genomes; requires complementary signatures file. If not provided, uses default database, \"/gambit-db\" gs://gambit-databases-rp/fungal-version/1.0.0/gambit-fungal-metadata-1.0.0-20241213.gdb TheiaEuk_Illumina_PE theiaeuk_illumina_pe gambit_db_signatures File User-provided signatures file; requires complementary genomes file. If not specified, the file from the docker container will be used. gs://gambit-databases-rp/fungal-version/1.0.0/gambit-fungal-signatures-1.0.0-20241213.gs TheiaEuk_Illumina_PE theiaeuk_ont gambit_db_genomes File User-provided database of assembled query genomes; requires complementary signatures file. If not provided, uses default database, \"/gambit-db\" gs://gambit-databases-rp/fungal-version/1.0.0/gambit-fungal-metadata-1.0.0-20241213.gdb TheiaEuk_ONT theiaeuk_ont gambit_db_signatures File User-provided signatures file; requires complementary genomes file. If not specified, the file from the docker container will be used. gs://gambit-databases-rp/fungal-version/1.0.0/gambit-fungal-signatures-1.0.0-20241213.gs TheiaEuk_ONT theiameta_illumina_pe kraken2_db File A Kraken2 database in .tar.gz format gs://theiagen-public-resources-rp/reference_data/databases/kraken2/k2_standard_08gb_20230605.tar.gz TheiaMeta_Illumina_PE theiaprok_fasta abricate_db String Database to use with the Abricate tool. Options: NCBI, CARD, ARG-ANNOT, Resfinder, MEGARES, EcOH, PlasmidFinder, Ecoli_VF and VFDB vfdb TheiaProk_FASTA theiaprok_fasta bakta_db String Database selection for Bakta annotation. Options: light (smaller, faster), full (more comprehensive), or a Google Storage URI (gs://...) pointing to a custom Bakta database archive (.tar.gz). The selected database will be extracted before annotation. full TheiaProk_FASTA theiaprok_illumina_pe abricate_db String Database to use with the Abricate tool. Options: NCBI, CARD, ARG-ANNOT, Resfinder, MEGARES, EcOH, PlasmidFinder, Ecoli_VF and VFDB vfdb TheiaProk_Illumina_PE theiaprok_illumina_pe bakta_db String Database selection for Bakta annotation. Options: light (smaller, faster), full (more comprehensive), or a Google Storage URI (gs://...) pointing to a custom Bakta database archive (.tar.gz). The selected database will be extracted before annotation. full TheiaProk_Illumina_PE theiaprok_illumina_se abricate_db String Database to use with the Abricate tool. Options: NCBI, CARD, ARG-ANNOT, Resfinder, MEGARES, EcOH, PlasmidFinder, Ecoli_VF and VFDB vfdb TheiaProk_Illumina_SE theiaprok_illumina_se bakta_db String Database selection for Bakta annotation. Options: light (smaller, faster), full (more comprehensive), or a Google Storage URI (gs://...) pointing to a custom Bakta database archive (.tar.gz). The selected database will be extracted before annotation. full TheiaProk_Illumina_SE theiaprok_ont abricate_db String Database to use with the Abricate tool. Options: NCBI, CARD, ARG-ANNOT, Resfinder, MEGARES, EcOH, PlasmidFinder, Ecoli_VF and VFDB vfdb TheiaProk_ONT theiaprok_ont bakta_db String Database selection for Bakta annotation. Options: light (smaller, faster), full (more comprehensive), or a Google Storage URI (gs://...) pointing to a custom Bakta database archive (.tar.gz). The selected database will be extracted before annotation. full TheiaProk_ONT theiaviral_illumina_pe kraken_db File Kraken2 database file gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz TheiaViral_Illumina_PE vadr_update vadr_model_file File Path to the a tar + gzipped VADR model file gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-sarscov2-1.3-2.tar.gz VADR_Update"},{"location":"guides/versions/#default-docker-images","title":"Default Docker Images","text":"<p>All Docker variables are String types with the description: \"The Docker container to use for the task\".</p> Terra Task Name Variable Default Value Workflow abricate docker us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE add_biosample_accessions docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Terra_2_NCBI amr_search docker us-docker.pkg.dev/general-theiagen/theiagen/amrsearch:0.2.1 AMR_Search amrfinderplus_nuc docker us-docker.pkg.dev/general-theiagen/staphb/ncbi-amrfinderplus:4.0.23-2025-07-16.1 AMRFinderPlus amrfinderplus_task docker us-docker.pkg.dev/general-theiagen/staphb/ncbi-amrfinderplus:4.0.23-2025-07-16.1 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE ani docker us-docker.pkg.dev/general-theiagen/staphb/mummer:4.0.0-rgdv2 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE arln_stats docker us-docker.pkg.dev/general-theiagen/theiagen/arln_stats:1.0.0 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE assembled_reads_percent docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 TheiaMeta_Illumina_PE augur_align docker us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Augur augur_ancestral docker us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Augur augur_clades docker us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Augur augur_export docker us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Augur augur_refine docker us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Augur augur_traits docker us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Augur augur_translate docker us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Augur augur_tree docker us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Augur bakta docker us-docker.pkg.dev/general-theiagen/staphb/bakta:1.10.3 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE bam_to_unaligned_fastq docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Host_Decontaminate bcftools_consensus docker us-docker.pkg.dev/general-theiagen/staphb/bcftools:1.20 TheiaViral_ONT biosample_submit_tsv_ftp_upload docker us-docker.pkg.dev/general-theiagen/broadinstitute/ncbi-tools:2.10.7.10 Terra_2_NCBI busco docker us-docker.pkg.dev/general-theiagen/ezlabgva/busco:v5.7.1_cv1 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE bwa docker us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Freyja_FASTQ, TheiaMeta_Illumina_PE, TheiaViral_Illumina_PE calculate_coverage docker us-docker.pkg.dev/general-theiagen/staphb/bedtools:2.31.0 TheiaMeta_Illumina_PE calculate_coverage_paf docker us-docker.pkg.dev/general-theiagen/quay/ubuntu:latest TheiaMeta_Illumina_PE cat_files docker_image us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Concatenate_Column_Content, Augur cat_files_fasta docker_image us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 TheiaCoV_FASTA_Batch cat_lanes docker us-docker.pkg.dev/general-theiagen/theiagen/utility:1.2 Concatenate_Illumina_Lanes cat_ont_barcodes docker us-docker.pkg.dev/general-theiagen/theiagen/ont-barcodes:0.0.2 ONT_Barcode_Concatenation cat_variants docker_image us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Find_Shared_Variants centroid docker us-docker.pkg.dev/general-theiagen/theiagen/centroid:0.1.0 Snippy_Streamline, Snippy_Streamline_FASTA cg_pipeline_clean docker us-docker.pkg.dev/general-theiagen/staphb/lyveset:1.1.4f TheiaEuk_Illumina_PE, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE cg_pipeline_raw docker us-docker.pkg.dev/general-theiagen/staphb/lyveset:1.1.4f TheiaEuk_Illumina_PE, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE cg_reorder_matrix docker us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Snippy_Tree checkv_consensus docker us-docker.pkg.dev/general-theiagen/staphb/checkv:1.0.3 TheiaViral_Illumina_PE, TheiaViral_ONT checkv_denovo docker us-docker.pkg.dev/general-theiagen/staphb/checkv:1.0.3 TheiaViral_Illumina_PE, TheiaViral_ONT chunk_files docker us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Dorado_Basecalling cladetyper docker us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Cauris_CladeTyper clair3 docker us-docker.pkg.dev/general-theiagen/theiagen/clair3-extra-models:1.0.10 TheiaViral_ONT clair3_variants_ont clair3_docker us-docker.pkg.dev/general-theiagen/staphb/clair3:1.0.10 Clair3_Variants_ONT clean_check_reads docker us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 TheiaCoV_ONT, TheiaCoV_Illumina_PE, TheiaCoV_Illumina_SE, TheiaEuk_Illumina_PE, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE, TheiaViral_Illumina_PE, TheiaViral_ONT, TheiaEuk_ONT compare_two_tsvs docker us-docker.pkg.dev/general-theiagen/theiagen/theiavalidate:1.1.2 TheiaValidate concatenate_qc_metrics docker_image us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Snippy_Tree concatenate_variants docker_image us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Snippy_Tree consensus docker us-docker.pkg.dev/general-theiagen/staphb/artic-ncov2019-epi2me TheiaCoV_ONT consensus docker us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan TheiaViral_Illumina_PE consensus_qc docker us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 TheiaCoV_ClearLabs, TheiaCoV_FASTA, TheiaCoV_ONT, TheiaCoV_Illumina_PE, TheiaCoV_Illumina_SE, TheiaViral_Illumina_PE, TheiaViral_ONT, VADR_Update core_iqtree docker us-docker.pkg.dev/general-theiagen/staphb/iqtree:1.6.7 Core_Gene_SNP core_reorder_matrix docker us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Core_Gene_SNP, kSNP3, kSNP4 core_snp_dists docker us-docker.pkg.dev/general-theiagen/staphb/snp-dists:0.8.2 Core_Gene_SNP, kSNP3, kSNP4 create_table_from_array docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Dorado_Basecalling create_terra_table docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 ONT_Barcode_Concatenation czgenepi_wrangling docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-08-08-2 CZGenEpi_Prep digger_denovo bwa_docker us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan TheiaEuk_Illumina_PE, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE digger_denovo filter_contigs_docker us-docker.pkg.dev/general-theiagen/theiagen/shovilter:0.2 TheiaEuk_Illumina_PE, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE digger_denovo megahit_docker us-docker.pkg.dev/general-theiagen/theiagen/megahit:1.2.9 TheiaEuk_Illumina_PE, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE digger_denovo pilon_docker us-docker.pkg.dev/general-theiagen/biocontainers/pilon:1.24--hdfd78af_0 TheiaEuk_Illumina_PE, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE digger_denovo skesa_docker us-docker.pkg.dev/general-theiagen/staphb/skesa:2.4.0 TheiaEuk_Illumina_PE, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE digger_denovo spades_docker us-docker.pkg.dev/general-theiagen/staphb/spades:4.1.0 TheiaEuk_Illumina_PE, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE dorado_basecall docker us-docker.pkg.dev/general-theiagen/staphb/dorado:0.9.0-cuda12.2.0 Dorado_Basecalling dorado_demux docker us-docker.pkg.dev/general-theiagen/staphb/dorado:0.9.0-cuda12.2.0 Dorado_Basecalling dorado_trim docker us-docker.pkg.dev/general-theiagen/staphb/dorado:0.8.3 Dorado_Basecalling download_accession docker us-docker.pkg.dev/general-theiagen/staphb/ncbi-datasets:16.38.1 Host_Decontaminate download_terra_table docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 CZGenEpi_Prep, Mercury_Prep_N_Batch, Terra_2_ENA export_taxon_table docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE export_two_tsvs docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 TheiaValidate fasta_to_ids docker ubuntu Augur fasta_utilities docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 TheiaViral_ONT fastq_scan_clean_reads docker us-docker.pkg.dev/general-theiagen/biocontainers/fastq-scan:1.0.1--h4ac6f70_3 TheiaCoV_ClearLabs fastq_scan_raw_reads docker us-docker.pkg.dev/general-theiagen/biocontainers/fastq-scan:1.0.1--h4ac6f70_3 TheiaCoV_ClearLabs fetch_bs docker us-docker.pkg.dev/general-theiagen/theiagen/basespace_cli:1.2.1 BaseSpace_Fetch fetch_sra_to_fastq docker us-docker.pkg.dev/general-theiagen/biocontainers/fastq-dl:2.0.4--pyhdfd78af_0 SRA_Fetch fetch_srr docker us-docker.pkg.dev/general-theiagen/biocontainers/fastq-dl:2.0.4--pyhdfd78af_0 Fetch_SRR_Accession filter_sequences_by_length docker us-docker.pkg.dev/general-theiagen/broadinstitute/viral-core:2.1.33 Augur find_files docker us-docker.pkg.dev/general-theiagen/cloudsdktool/google-cloud-cli:427.0.0-alpine Dorado_Basecalling flu_track abricate_flu_docker us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-insaflu-220727 TheiaCoV_FASTA, TheiaCoV_ONT, TheiaCoV_Illumina_PE flu_track assembly_metrics_docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 TheiaCoV_Illumina_PE, TheiaCoV_ONT flu_track genoflu_docker us-docker.pkg.dev/general-theiagen/staphb/genoflu:1.06 TheiaCoV_FASTA, TheiaCoV_ONT, TheiaCoV_Illumina_PE flu_track irma_docker_image us-docker.pkg.dev/general-theiagen/staphb/irma:1.2.0 TheiaCoV_ONT, TheiaCoV_Illumina_PE flu_track nextclade_docker_image us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.14.5 TheiaCoV_ONT, TheiaCoV_Illumina_PE, TheiaCoV_FASTA flu_track nextclade_output_parser_docker us-docker.pkg.dev/general-theiagen/python/python:3.8.18-slim TheiaCoV_FASTA, TheiaCoV_ONT, TheiaCoV_Illumina_PE flye docker us-docker.pkg.dev/general-theiagen/staphb/flye:2.9.4 TheiaViral_ONT freyja docker us-docker.pkg.dev/general-theiagen/staphb/freyja:1.5.3 Freyja_FASTQ freyja_dashboard_task docker us-docker.pkg.dev/general-theiagen/staphb/freyja:1.5.3 Freyja_Dashboard freyja_plot_task docker us-docker.pkg.dev/general-theiagen/staphb/freyja:1.5.3 Freyja_Plot freyja_update_refs docker us-docker.pkg.dev/general-theiagen/staphb/freyja:1.5.3 Freyja_Update gambit docker us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Gambit_Query, TheiaEuk_Illumina_PE, TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE, TheiaEuk_ONT gamma docker us-docker.pkg.dev/general-theiagen/staphb/gamma:2.2 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE gene_coverage docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 TheiaCoV_ClearLabs, TheiaCoV_ONT, TheiaCoV_Illumina_PE, TheiaCoV_Illumina_SE get_fasta_genome_size docker us-docker.pkg.dev/general-theiagen/biocontainers/seqkit:2.4.0--h9ee0642_0 Freyja_FASTQ gisaid_upload docker us-docker.pkg.dev/general-theiagen/broadinstitute/gisaid-cli:3.0 Terra_2_GISAID ivar_consensus ivar_bwa_docker us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan TheiaCoV_Illumina_SE,TheiaCoV_Illumina_PE ivar_consensus ivar_consensus_docker us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan TheiaCoV_Illumina_SE,TheiaCoV_Illumina_PE ivar_consensus ivar_trim_primers_docker us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan TheiaCoV_Illumina_SE,TheiaCoV_Illumina_PE ivar_consensus ivar_variant_docker us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan TheiaCoV_Illumina_SE,TheiaCoV_Illumina_PE ivar_consensus stats_n_coverage_docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 TheiaCoV_Illumina_SE,TheiaCoV_Illumina_PE ivar_consensus stats_n_coverage_primtrim_docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 TheiaCoV_Illumina_SE,TheiaCoV_Illumina_PE ivar_variants docker us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan TheiaViral_Illumina_PE kmerfinder docker us-docker.pkg.dev/general-theiagen/biocontainers/kmerfinder:3.0.2--hdfd78af_0 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE kraken2 docker_image us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db NCBI_Scrub_PE, NCBI_Scrub_SE kraken2_clean docker us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db TheiaMeta_Illumina_PE kraken2_dehosted docker_image us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db TheiaCoV_ClearLabs kraken2_pe docker us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Kraken_PE kraken2_raw docker us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db TheiaMeta_Illumina_PE kraken2_raw docker_image us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db TheiaCoV_ClearLabs kraken2_recalculate_abundances docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-08-28-v4 Kraken_ONT kraken2_se docker us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Kraken_ONT, Kraken_SE krona docker us-docker.pkg.dev/general-theiagen/staphb/krona:2.8.1 Kraken_PE, Kraken_SE krona_clean docker us-docker.pkg.dev/general-theiagen/staphb/krona:2.8.1 TheiaMeta_Illumina_PE krona_raw docker us-docker.pkg.dev/general-theiagen/staphb/krona:2.8.1 TheiaMeta_Illumina_PE ksnp3_task docker_image us-docker.pkg.dev/general-theiagen/staphb/ksnp3:3.1 kSNP3 ksnp4_task docker_image us-docker.pkg.dev/general-theiagen/staphb/ksnp4:4.1 kSNP4 lyveset docker_image us-docker.pkg.dev/general-theiagen/staphb/lyveset:1.1.4f Lyve_SET make_table docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Create_Terra_Table mashtree_task docker us-docker.pkg.dev/general-theiagen/staphb/mashtree:1.2.0 MashTree_FASTA mask_low_coverage docker us-docker.pkg.dev/general-theiagen/staphb/bedtools:2.31.0 TheiaViral_ONT megahit docker us-docker.pkg.dev/general-theiagen/theiagen/megahit:1.2.9 TheiaViral_Illumina_PE mercury docker us-docker.pkg.dev/general-theiagen/theiagen/mercury:1.1.3 Mercury_Prep_N_Batch merlin_magic abricate_abaum_docker_image us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic abricate_vibrio_docker_image us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic agrvate_docker_image us-docker.pkg.dev/general-theiagen/biocontainers/agrvate:1.0.2--hdfd78af_0 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE, TheiaEuk_ONT merlin_magic amr_search_docker_image us-docker.pkg.dev/general-theiagen/theiagen/amrsearch:0.2.1 TheiaEuk_Illumina_PE, TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE, TheiaEuk_ONT merlin_magic clockwork_docker_image us-docker.pkg.dev/general-theiagen/cdcgov/varpipe_wgs_with_refs:2bc7234074bd53d9e92a1048b0485763cd9bbf6f4d12d5a1cc82bfec8ca7d75e TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic ectyper_docker_image us-docker.pkg.dev/general-theiagen/biocontainers/ectyper:1.0.0--pyhdfd78af_1 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic emmtyper_docker_image us-docker.pkg.dev/general-theiagen/biocontainers/emmtyper:0.2.0--py_0 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic emmtypingtool_docker_image us-docker.pkg.dev/general-theiagen/staphb/emmtypingtool:0.0.1 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic genotyphi_docker_image us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.11.0 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic hicap_docker_image us-docker.pkg.dev/general-theiagen/biocontainers/hicap:1.0.3--py_0 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic kaptive_docker_image us-docker.pkg.dev/general-theiagen/staphb/kaptive:2.0.3 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic kleborate_docker_image us-docker.pkg.dev/general-theiagen/staphb/kleborate:2.2.0 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic legsta_docker_image us-docker.pkg.dev/general-theiagen/biocontainers/legsta:0.5.1--hdfd78af_2 TheiaEuk_Illumina_PE, TheiaEuk_ONT merlin_magic lissero_docker_image us-docker.pkg.dev/general-theiagen/biocontainers/lissero:0.4.9--py_0 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic meningotype_docker_image us-docker.pkg.dev/general-theiagen/biocontainers/meningotype:0.8.5--pyhdfd78af_0 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic ngmaster_docker_image us-docker.pkg.dev/general-theiagen/staphb/ngmaster:1.0.0 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic pasty_docker_image us-docker.pkg.dev/general-theiagen/staphb/pasty:1.0.3 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic pbptyper_docker_image us-docker.pkg.dev/general-theiagen/staphb/pbptyper:1.0.4 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic poppunk_docker_image us-docker.pkg.dev/general-theiagen/staphb/poppunk:2.4.0 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic seqsero2_docker_image us-docker.pkg.dev/general-theiagen/staphb/seqsero2:1.2.1 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic seroba_docker_image us-docker.pkg.dev/general-theiagen/staphb/seroba:1.0.2 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic serotypefinder_docker_image us-docker.pkg.dev/general-theiagen/staphb/serotypefinder:2.0.1 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic shigatyper_docker_image us-docker.pkg.dev/general-theiagen/staphb/shigatyper:2.0.5 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic shigeifinder_docker_image us-docker.pkg.dev/general-theiagen/staphb/shigeifinder:1.3.5 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic sistr_docker_image us-docker.pkg.dev/general-theiagen/biocontainers/sistr_cmd:1.1.1--pyh864c0ab_2 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic snippy_gene_query_docker_image us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 TheiaEuk_Illumina_PE, TheiaEuk_ONT merlin_magic snippy_variants_docker_image us-docker.pkg.dev/general-theiagen/staphb/snippy:4.6.0 TheiaEuk_Illumina_PE, TheiaEuk_ONT merlin_magic sonneityping_docker_image us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic spatyper_docker_image us-docker.pkg.dev/general-theiagen/biocontainers/spatyper:0.3.3--pyhdfd78af_3 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic srst2_docker_image us-docker.pkg.dev/general-theiagen/staphb/srst2:0.2.0-vcholerae TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic staphopia_sccmec_docker_image us-docker.pkg.dev/general-theiagen/biocontainers/staphopia-sccmec:1.0.0--hdfd78af_0 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic stxtyper_docker_image us-docker.pkg.dev/general-theiagen/staphb/stxtyper:1.0.42 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic tbp_parser_docker_image us-docker.pkg.dev/general-theiagen/theiagen/tbp-parser:2.6.0 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic tbprofiler_docker_image us-docker.pkg.dev/general-theiagen/staphb/tbprofiler:6.6.3 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE merlin_magic vibecheck_docker_image watronfire/vibecheck:2025.02.24 TheiaProk_Illumina_PE merlin_magic virulencefinder_docker_image us-docker.pkg.dev/general-theiagen/staphb/virulencefinder:2.0.4 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE metabuli docker us-docker.pkg.dev/general-theiagen/theiagen/metabuli:1.1.0 TheiaViral_ONT metaspades_pe docker us-docker.pkg.dev/general-theiagen/biocontainers/spades:3.12.0--h9ee0642_3 TheiaMeta_Illumina_PE minimap2 docker us-docker.pkg.dev/general-theiagen/staphb/minimap2:2.22 Freyja_FASTQ, Clair3_Variants_ONT, TheiaViral_ONT minimap2_assembly docker us-docker.pkg.dev/general-theiagen/staphb/minimap2:2.22 TheiaMeta_Illumina_PE minimap2_assembly_correction docker us-docker.pkg.dev/general-theiagen/staphb/minimap2:2.22 TheiaMeta_Illumina_PE minimap2_ont docker us-docker.pkg.dev/general-theiagen/staphb/minimap2:2.22 Host_Decontaminate minimap2_pe docker us-docker.pkg.dev/general-theiagen/staphb/minimap2:2.22 Host_Decontaminate minimap2_reads docker us-docker.pkg.dev/general-theiagen/staphb/minimap2:2.22 TheiaMeta_Illumina_PE morgana_magic abricate_flu_docker us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-insaflu-220727 TheiaViral_Illumina_PE, TheiaViral_ONT morgana_magic assembly_metrics_docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 TheiaViral_Illumina_PE, TheiaViral_ONT morgana_magic genoflu_docker us-docker.pkg.dev/general-theiagen/staphb/genoflu:1.06 TheiaViral_Illumina_PE, TheiaViral_ONT morgana_magic irma_docker_image us-docker.pkg.dev/general-theiagen/staphb/irma:1.2.0 TheiaViral_Illumina_PE, TheiaViral_ONT morgana_magic nextclade_docker_image us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.10.2 TheiaViral_Illumina_PE, TheiaViral_ONT morgana_magic nextclade_output_parser_docker us-docker.pkg.dev/general-theiagen/python/python:3.8.18-slim TheiaViral_Illumina_PE, TheiaViral_ONT morgana_magic pangolin_docker_image us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.10.2 TheiaViral_Illumina_PE, TheiaViral_ONT mutation_context docker us-docker.pkg.dev/general-theiagen/theiagen/nextstrain-mpox-mutation-context:2024-06-27 Augur nanoplot_clean docker us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Freyja_FASTQ, TheiaCoV_ONT, TheiaProk_ONT, TheiaViral_ONT, TheiaEuk_ONT nanoplot_raw docker us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Freyja_FASTQ, TheiaCoV_ONT, TheiaProk_ONT, TheiaViral_ONT, TheiaEuk_ONT nanoq docker us-docker.pkg.dev/general-theiagen/biocontainers/nanoq:0.9.0--hec16e2b_1 TheiaViral_ONT ncbi_datasets docker us-docker.pkg.dev/general-theiagen/staphb/ncbi-datasets:16.38.1 TheiaViral_Illumina_PE, TheiaViral_ONT ncbi_datasets_download_genome_accession docker us-docker.pkg.dev/general-theiagen/staphb/ncbi-datasets:16.38.1 Assembly_Fetch, Snippy_Streamline, Snippy_Streamline_FASTA ncbi_identify docker us-docker.pkg.dev/general-theiagen/staphb/ncbi-datasets:16.38.1 TheiaViral_Illumina_PE, TheiaViral_ONT ncbi_scrub_pe docker us-docker.pkg.dev/general-theiagen/ncbi/sra-human-scrubber:2.2.1 NCBI_Scrub_PE ncbi_scrub_se docker us-docker.pkg.dev/general-theiagen/ncbi/sra-human-scrubber:2.2.1 TheiaCoV_ClearLabs, NCBI_Scrub_SE, TheiaViral_ONT ncbi_sftp_upload docker us-docker.pkg.dev/general-theiagen/broadinstitute/ncbi-tools:2.10.7.10 Terra_2_NCBI nextclade_output_parser docker us-docker.pkg.dev/general-theiagen/python/python:3.8.18-slim TheiaCoV_ONT, TheiaCoV_Illumina_PE, TheiaCoV_Illumina_SE, TheiaCoV_FASTA, TheiaCoV_ClearLabs nextclade_v3 docker us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.16.0 TheiaCoV_ClearLabs, TheiaCoV_FASTA, TheiaCoV_ONT, TheiaCoV_Illumina_PE, TheiaCoV_Illumina_SE, TheiaCoV_FASTA_Batch nextclade_v3_set docker us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.14.5 Nextclade_Batch organism_parameters pangolin_docker_image us-docker.pkg.dev/general-theiagen/staphb/pangolin:4.3.1-pdata-1.34 Augur, TheiaCoV_ClearLabs, TheiaCoV_FASTA pan_iqtree docker us-docker.pkg.dev/general-theiagen/staphb/iqtree:1.6.7 Core_Gene_SNP pan_reorder_matrix docker us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Core_Gene_SNP, kSNP3, kSNP4 pan_snp_dists docker us-docker.pkg.dev/general-theiagen/staphb/snp-dists:0.8.2 Core_Gene_SNP, kSNP3, kSNP4 pangolin_update_log docker us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Pangolin_Update parse_mapping docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 TheiaViral_ONT, Host_Decontaminate phylovalidate_task docker us-docker.pkg.dev/general-theiagen/theiagen/theiaphylo:0.1.8 PhyloCompare pilon docker us-docker.pkg.dev/general-theiagen/biocontainers/pilon:1.24--hdfd78af_0 TheiaMeta_Illumina_PE pirate docker_image us-docker.pkg.dev/general-theiagen/biocontainers/pirate:1.0.5--hdfd78af_0 Core_Gene_SNP plasmidfinder docker us-docker.pkg.dev/general-theiagen/staphb/plasmidfinder:2.1.6 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE porechop docker us-docker.pkg.dev/general-theiagen/staphb/porechop:0.2.4 TheiaViral_ONT prep_augur_metadata docker us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Augur_Prep primer_trim docker us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Freyja_FASTQ (PE), Freyja_FASTQ (SE) prokka docker us-docker.pkg.dev/general-theiagen/staphb/prokka:1.14.5 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE prune_table docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Terra_2_NCBI qc_check_task docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 TheiaCoV_ClearLabs, TheiaCoV_FASTA, TheiaCoV_ONT, TheiaCoV_Illumina_PE, TheiaCoV_Illumina_SE, TheiaEuk_Illumina_PE, TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE quasitools_illumina_pe docker us-docker.pkg.dev/general-theiagen/biocontainers/quasitools:0.7.0--pyh864c0ab_1 TheiaCoV_Illumina_PE quasitools_ont docker us-docker.pkg.dev/general-theiagen/biocontainers/quasitools:0.7.0--pyh864c0ab_1 TheiaCoV_ONT quast docker us-docker.pkg.dev/general-theiagen/staphb/quast:5.0.2 TheiaEuk_Illumina_PE, TheiaEuk_ONT, TheiaMeta_Illumina_PE, TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE quast_denovo docker us-docker.pkg.dev/general-theiagen/staphb/quast:5.0.2 TheiaViral_Illumina_PE, TheiaViral_ONT rasusa docker us-docker.pkg.dev/general-theiagen/staphb/rasusa:2.1.0 TheiaViral_Illumina_PE, TheiaViral_ONT rasusa_task docker us-docker.pkg.dev/general-theiagen/staphb/rasusa:2.1.0 RASUSA, TheiaEuk_Illumina_PE raven docker us-docker.pkg.dev/general-theiagen/theiagen/raven:1.8.3 TheiaViral_ONT raw_check_reads docker us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 TheiaCoV_ONT, TheiaCoV_Illumina_PE, TheiaCoV_Illumina_SE, TheiaEuk_Illumina_PE, TheiaEuk_ONT, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE read_QC_trim artic_guppyplex_docker us-docker.pkg.dev/general-theiagen/staphb/artic-ncov2019:1.3.0-medaka-1.4.3 TheiaCoV_ONT read_QC_trim kraken2_recalculate_abundances_docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-08-28-v4 TheiaCoV_ONT, TheiaProk_ONT read_QC_trim kraken_docker_image us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db TheiaCoV_ONT, TheiaProk_ONT read_QC_trim nanoq_docker us-docker.pkg.dev/general-theiagen/biocontainers/nanoq:0.9.0--hec16e2b_1 TheiaCoV_ONT, TheiaProk_ONT,TheiaEuk_ONT read_QC_trim ncbi_scrub_docker us-docker.pkg.dev/general-theiagen/ncbi/sra-human-scrubber:2.2.1 TheiaCoV_ONT read_QC_trim rasusa_docker us-docker.pkg.dev/general-theiagen/staphb/rasusa:2.1.0 TheiaProk_ONT read_QC_trim_ont kraken2_recalculate_abundances_docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-08-28-v4 Freyja_FASTQ (ONT) read_mapping_stats docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 TheiaViral_Illumina_PE, TheiaViral_ONT, Host_Decontaminate referenceseeker docker us-docker.pkg.dev/general-theiagen/biocontainers/referenceseeker:1.8.0--pyhdfd78af_0 Assembly_Fetch, Snippy_Streamline, Snippy_Streamline_FASTA register_ena_samples docker us-docker.pkg.dev/general-theiagen/theiagen/terra_to_ena:0.6 Terra_2_ENA rename_PE_files docker us-docker.pkg.dev/general-theiagen/ubuntu/ubuntu:jammy-20230816 Rename_FASTQ rename_SE_files docker us-docker.pkg.dev/general-theiagen/ubuntu/ubuntu:jammy-20230816 Rename_FASTQ reorder_matrix docker us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 MashTree_FASTA, Augur resfinder_task docker us-docker.pkg.dev/general-theiagen/staphb/resfinder:4.1.11 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE retrieve_aligned_contig_paf docker us-docker.pkg.dev/general-theiagen/biocontainers/seqkit:2.4.0--h9ee0642_0 TheiaMeta_Illumina_PE retrieve_aligned_pe_reads_sam docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 TheiaMeta_Illumina_PE retrieve_unaligned_pe_reads_sam docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 TheiaMeta_Illumina_PE root_tree1_task docker us-docker.pkg.dev/general-theiagen/theiagen/theiaphylo:0.1.8 PhyloCompare root_tree2_task docker us-docker.pkg.dev/general-theiagen/theiagen/theiaphylo:0.1.8 PhyloCompare sam_to_sorted_bam docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Freyja_FASTQ, TheiaMeta_Illumina_PE, Clair3_Variants_ONT samtools_faidx docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Clair3_Variants_ONT sc2_defaults docker us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Augur semibin docker us-docker.pkg.dev/general-theiagen/biocontainers/semibin:2.0.2--pyhdfd78af_0 TheiaMeta_Illumina_PE shared_variants docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Find_Shared_Variants, Snippy_Tree skani docker us-docker.pkg.dev/general-theiagen/staphb/skani:0.2.2 TheiaViral_Illumina_PE, TheiaViral_ONT sm_theiacov_fasta_wrangling docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-08-28-v4 TheiaCoV_FASTA_Batch snippy_gene_query docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Snippy_Variants snippy_tree_wf gubbins_docker us-docker.pkg.dev/general-theiagen/biocontainers/gubbins:3.3--py310pl5321h8472f5a_0 Snippy_Streamline, Snippy_Streamline_FASTA, Snippy_Tree snippy_tree_wf iqtree2_docker us-docker.pkg.dev/general-theiagen/staphb/iqtree2:2.1.2 Snippy_Streamline, Snippy_Streamline_FASTA, Snippy_Tree snippy_tree_wf snippy_core_docker us-docker.pkg.dev/general-theiagen/staphb/snippy:4.6.0 Snippy_Streamline, Snippy_Streamline_FASTA, Snippy_Tree snippy_tree_wf snp_dists_docker us-docker.pkg.dev/general-theiagen/staphb/snp-dists:0.8.2 Snippy_Streamline, Snippy_Streamline_FASTA, Snippy_Tree snippy_tree_wf snp_sites_docker us-docker.pkg.dev/general-theiagen/staphb/snp-sites:2.5.1 Snippy_Streamline, Snippy_Streamline_FASTA, Snippy_Tree snippy_variants_wf docker us-docker.pkg.dev/general-theiagen/staphb/snippy:4.6.0 Snippy_Streamline, Snippy_Streamline_FASTA, Snippy_Variants snp_dists docker us-docker.pkg.dev/general-theiagen/staphb/snp-dists:0.8.2 Augur sort_bam_assembly_correction docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 TheiaMeta_Illumina_PE spades docker us-docker.pkg.dev/general-theiagen/staphb/spades:4.1.0 TheiaViral_Illumina_PE sra_tsv_to_xml docker us-docker.pkg.dev/general-theiagen/broadinstitute/ncbi-tools:2.10.7.10 Terra_2_NCBI stats_n_coverage docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 TheiaCoV_ClearLabs, TheiaCoV_ONT stats_n_coverage_primtrim docker us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 TheiaCoV_ClearLabs, TheiaCoV_ONT submit_ena_data docker us-docker.pkg.dev/general-theiagen/theiagen/terra_to_ena:0.6 Terra_2_ENA summarize_data docker us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Core_Gene_SNP, kSNP3, kSNP4, MashTree_FASTA, Snippy_Tree table2asn docker us-docker.pkg.dev/general-theiagen/staphb/ncbi-table2asn:1.26.678 Mercury_Prep_N_Batch tbp_parser docker us-docker.pkg.dev/general-theiagen/theiagen/tbp-parser:2.6.0 TBProfiler_tNGS tbprofiler docker us-docker.pkg.dev/general-theiagen/staphb/tbprofiler:6.6.3 TBProfiler_tNGS theiacov_clearlabs medaka_docker us-docker.pkg.dev/general-theiagen/staphb/artic-ncov2019:1.3.0-medaka-1.4.3 TheiaCoV_ClearLabs theiacov_fasta_batch pangolin_docker us-docker.pkg.dev/general-theiagen/staphb/pangolin:4.3.1-pdata-1.34 TheiaCoV_FASTA_Batch theiacov_illumina_pe pangolin_docker_image us-docker.pkg.dev/general-theiagen/staphb/pangolin:4.3.1-pdata-1.34 TheiaCoV_Illumina_PE theiacov_illumina_se pangolin_docker_image us-docker.pkg.dev/general-theiagen/staphb/pangolin:4.3.1-pdata-1.34 TheiaCoV_Illumina_SE theiacov_ont pangolin_docker_image us-docker.pkg.dev/general-theiagen/staphb/pangolin:4.3.1-pdata-1.34 TheiaCoV_ONT theiaeuk_illumina_pe busco_docker_image us-docker.pkg.dev/general-theiagen/ezlabgva/busco:v5.3.2_cv1 TheiaEuk_Illumina_PE theiaeuk_ont busco_docker_image us-docker.pkg.dev/general-theiagen/ezlabgva/busco:v5.3.2_cv1 TheiaEuk_ONT transfer_files docker us-docker.pkg.dev/general-theiagen/cloudsdktool/google-cloud-cli:427.0.0-alpine Freyja_Update transfer_files docker_image us-docker.pkg.dev/general-theiagen/cloudsdktool/google-cloud-cli:427.0.0-alpine Transfer_Column_Content trim_genbank_fastas docker us-docker.pkg.dev/general-theiagen/staphb/vadr:1.3 Mercury_Prep_N_Batch trimmomatic_pe docker us-docker.pkg.dev/general-theiagen/staphb/trimmomatic:0.39 TBProfiler_tNGS ts_mlst docker us-docker.pkg.dev/general-theiagen/staphb/mlst:2.23.0-2024-12-31 TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE tsv_join docker us-docker.pkg.dev/general-theiagen/broadinstitute/viral-core:2.1.33 Augur usher docker us-docker.pkg.dev/general-theiagen/pathogengenomics/usher:0.6.2 Usher vadr docker us-docker.pkg.dev/general-theiagen/staphb/vadr:1.6.4 TheiaCoV_ClearLabs, TheiaCoV_FASTA, TheiaCoV_ONT, TheiaCoV_Illumina_PE, TheiaCoV_Illumina_SE, VADR_Update version_capture docker us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Concatenate_Column_Content, Transfer_Column_Content, Zip_Column_Content, Assembly_Fetch, BaseSpace_Fetch, SRA_Fetch, Freyja_FASTQ, Freyja_Plot, Freyja_Dashboard, Pangolin_Update, TheiaCoV_ONT, TheiaCoV_Illumina_PE, TheiaCoV_Illumina_SE, TheiaCoV_FASTA, TheiaCoV_ClearLabs, TheiaCoV_FASTA_Batch, TheiaEuk_Illumina_PE, TheiaEuk_ONT, TheiaMeta_Illumina_PE, TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE, VADR_Update, Augur_Prep, Clair3_Variants_ONT, Core_Gene_SNP, CZGenEpi_Prep, Find_Shared_Variants, kSNP3, kSNP4, Lyve_SET, MashTree_FASTA, Snippy_Streamline, Snippy_Streamline_FASTA, Snippy_Tree, Snippy_Variants, Nextclade_Batch, Usher, Fetch_SRR_Accession, Mercury_Prep_N_Batch, Terra_2_GISAID, Terra_2_NCBI, Cauris_CladeTyper, Concatenate_Illumina_Lanes, Dorado_Basecalling, Kraken_ONT, Kraken_PE, Kraken_SE, AMRFinderPlus, NCBI_Scrub_PE, NCBI_Scrub_SE, RASUSA, Rename_FASTQ, TBProfiler_tNGS, TheiaViral_Illumina_PE, TheiaViral_ONT, Host_Decontaminate, PhyloCompare, AMR_Search, Augur, Gambit_Query, Terra_2_ENA, TheiaValidate wg_reorder_matrix docker us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Snippy_Tree zip_files docker_image us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Zip_Column_Content"},{"location":"guides/versions/#default-references","title":"Default References","text":"Terra Task Name Variable Type Description Default Value Workflow augur reference_fasta File The reference FASTA file used to align the genomes and build the trees Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, a reference fasta file must be provided otherwise the workflow fails. Augur augur reference_genbank File The GenBank .gb file for the same reference genome used for the reference_fasta Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, a reference genbank file must be provided otherwise the workflow fails. Augur cladetyper ref_clade1 File The reference assembly for clade 1 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade1_GCA_002759435.3_Cand_auris_B8441_V3_genomic.fasta Cauris_CladeTyper cladetyper ref_clade1_annotated String The path to the annotated reference for clade 1 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade1_GCA_002759435.3_Cand_auris_B8441_V3_genomic.gbff Cauris_CladeTyper cladetyper ref_clade2 File The reference assembly for clade 2 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade2_GCA_003013715.2_ASM301371v2_genomic.fasta Cauris_CladeTyper cladetyper ref_clade2_annotated String The path to the annotated reference for clade 2 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade2_GCA_003013715.2_ASM301371v2_genomic.gbff Cauris_CladeTyper cladetyper ref_clade3 File The reference assembly for clade 3 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade3_GCF_002775015.1_Cand_auris_B11221_V1_genomic.fasta Cauris_CladeTyper cladetyper ref_clade3_annotated String The path to the annotated reference for clade 3 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade3_GCF_002775015.1_Cand_auris_B11221_V1_genomic.gbff Cauris_CladeTyper cladetyper ref_clade4 File The reference assembly for clade 4 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade4_GCA_003014415.1_Cand_auris_B11243_genomic.fasta Cauris_CladeTyper cladetyper ref_clade4_annotated String The path to the annotated reference for clade 4 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade4_GCA_003014415.1_Cand_auris_B11243_genomic.gbff Cauris_CladeTyper cladetyper ref_clade5 File The reference assembly for clade 5 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade5_GCA_016809505.1_ASM1680950v1_genomic.fasta Cauris_CladeTyper cladetyper ref_clade5_annotated String The path to the annotated reference for clade 5 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade5_GCA_016809505.1_ASM1680950v1_genomic.gbff Cauris_CladeTyper cladetyper ref_clade6 File The reference assembly for clade 6 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade6_GCA_032714025.1_ASM3271402v1_genomic.fasta Cauris_CladeTyper merlin_magic cladetyper_ref_clade1 File Reference genome FASTA for Candidozyma auris clade1 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade1_GCA_002759435.2_Cand_auris_B8441_V2_genomic.fasta TheiaEuk_ONT, TheiaEuk_Illumina_PE merlin_magic cladetyper_ref_clade1_annotated File Reference GBFF annotation for C. auris clade1 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade1_GCA_002759435_Cauris_B8441_V2_genomic.gbff TheiaEuk_ONT, TheiaEuk_Illumina_PE merlin_magic cladetyper_ref_clade2 File Reference genome FASTA for C. auris clade2 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade2_GCA_003013715.2_ASM301371v2_genomic.fasta TheiaEuk_ONT, TheiaEuk_Illumina_PE merlin_magic cladetyper_ref_clade2_annotated File Reference GBFF annotation for C. auris clade2 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade2_GCA_003013715.2_ASM301371v2_genomic.gbff TheiaEuk_ONT, TheiaEuk_Illumina_PE merlin_magic cladetyper_ref_clade3 File Reference genome FASTA for C. auris clade3 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade3_GCF_002775015.1_Cand_auris_B11221_V1_genomic.fasta TheiaEuk_ONT, TheiaEuk_Illumina_PE merlin_magic cladetyper_ref_clade3_annotated File Reference GBFF annotation for C. auris clade3 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade3_GCF_002775015.1_Cand_auris_B11221_V1_genomic.gbff TheiaEuk_ONT, TheiaEuk_Illumina_PE merlin_magic cladetyper_ref_clade4 File Reference genome FASTA for C. auris clade4 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade4_GCA_003014415.1_Cand_auris_B11243_genomic.fasta TheiaEuk_ONT, TheiaEuk_Illumina_PE merlin_magic cladetyper_ref_clade4_annotated File Reference GBFF annotation for C. auris clade4 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade4_GCA_003014415.1_Cand_auris_B11243_genomic.gbff TheiaEuk_ONT, TheiaEuk_Illumina_PE merlin_magic cladetyper_ref_clade5 File Reference genome FASTA for C. auris clade5 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade5_GCA_016809505.1_ASM1680950v1_genomic.fasta TheiaEuk_ONT, TheiaEuk_Illumina_PE merlin_magic cladetyper_ref_clade5_annotated File Reference GBFF annotation for C. auris clade5 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade5_GCA_016809505.1_ASM1680950v1_genomic.gbff TheiaEuk_ONT, TheiaEuk_Illumina_PE merlin_magic cladetyper_ref_clade6 File Reference genome FASTA for C. auris clade6 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade6_GCA_032714025.1_ASM3271402v1_genomic.fasta TheiaEuk_ONT, TheiaEuk_Illumina_PE merlin_magic cladetyper_ref_clade6 File The reference assembly for clade 6 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade6_GCA_032714025.1_ASM3271402v1_genomic.fasta TheiaProk_FASTA, TheiaProk_ONT, TheiaProk_Illumina_PE, TheiaProk_Illumina_SE nextclade_batch input_ref File An optional FASTA file containing reference sequence. This file should contain exactly 1 sequence Uses the reference fasta associated with the specified nextclade dataset name Nextclade_Batch nextclade_batch reference_tree_json File An optional phylogenetic reference tree file which serves as a target for phylogenetic placement Uses the reference tree associated with the specified nextclade dataset name Nextclade_Batch nextclade_v3 auspice_reference_tree_json File An Auspice JSON phylogenetic reference tree which serves as a target for phylogenetic placement. Inherited from nextclade dataset TheiaCoV_ClearLabs, TheiaCoV_FASTA, TheiaCoV_ONT, TheiaCoV_Illumina_PE, TheiaCoV_Illumina_SE, TheiaCoV_FASTA_Batch nextclade_v3 input_ref File A nucleotide sequence which serves as a reference for the pairwise alignment of all input sequences. This is also the sequence which defines the coordinate system of the genome annotation. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/02-reference-sequence.html Inherited from nextclade dataset TheiaCoV_ClearLabs, TheiaCoV_FASTA, TheiaCoV_ONT, TheiaCoV_Illumina_PE, TheiaCoV_Illumina_SE, TheiaCoV_FASTA_Batch organism_parameters reference_gff_file File Reference GFF file for the organism being analyzed Default provided for mpox (\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/Mpox-MT903345.1.reference.gff3\") and HIV (primer versions 1 [\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/NC_001802.1.gff3\"] and 2 [\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/AY228557.1.gff3\"]) Augur, TheiaCoV_ClearLabs, TheiaCoV_FASTA, TheiaCoV_ONT, TheiaCoV_FASTA_Batch"},{"location":"workflows/data_export/concatenate_column_content/","title":"Concatenate_Column_Content","text":""},{"location":"workflows/data_export/concatenate_column_content/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Exporting Data from Terra Any taxa v2.1.0 Yes Set-level Concatenate_Column_Content_PHB"},{"location":"workflows/data_export/concatenate_column_content/#concatenate_column_content_phb","title":"Concatenate_Column_Content_PHB","text":"<p>This set-level workflow will create a file containing all of the items from a given column in a Terra Data Table. This is useful when you want to investigate a collection of result files. There is a video available with more information about the Concatenate_Column_Content workflow: \ud83d\udcfa Workflow Focus: Concatenate_Column_Content. Although this video refers to an older version of this workflow and various names may be changed, the concepts presented are still applicable.</p>"},{"location":"workflows/data_export/concatenate_column_content/#inputs","title":"Inputs","text":"<p>This workflow runs on the set level.</p> <p>Include the extension</p> <p>When you provide the name of the output file, be sure to include the extension. For example, if you want the output file to be a FASTA file, you should include the <code>.fasta</code> extension in the <code>concatenated_file_name</code> input variable. Otherwise, the workflow will create a file without any extension, which can cause problems when you try to open it with certain programs and operating systems.</p> <p>Please note that this workflow cannot produce Excel files. If you need an Excel file, you can convert the output file to Excel using a program like Microsoft Excel or Google Sheets.</p> Terra Task Name Variable Type Description Default Value Terra Status concatenate_column_content concatenated_file_name String The name of the output file. Include the extension, such as \".fasta\" or \".txt\". Required concatenate_column_content files_to_cat Array[File] The column that has the files you want to concatenate. Required cat_files cpu Int Number of CPUs to allocate to the task 2 Optional cat_files disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional cat_files docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional cat_files memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional cat_files skip_extra_headers Boolean If the files you are concatenating have identical headers, you can include only the first instance of the header and skip all of the others so they do not appear duplicated in the concatenated file. To activate this, set to true. FALSE Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/data_export/concatenate_column_content/#outputs","title":"Outputs","text":"<p>Prevent Output Overwriting</p> <p>Please note that if you run this workflow on the same Terra set, the results will overwrite each other. We recommend either (1) renaming the output variable, or (2) creating a new set every time you run the workflow. Multiple sets containing the same samples can be created as long as the set names are unique.</p> Variable Type Description concatenate_column_content_analysis_date String The date the workflow was run concatenate_column_content_version String The version of the repository the workflow is hosted in concatenated_files File The file containing all of the items from the column you selected."},{"location":"workflows/data_export/transfer_column_content/","title":"Transfer_Column_Content","text":""},{"location":"workflows/data_export/transfer_column_content/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Exporting Data from Terra Any taxa v1.3.0 Yes Set-level Transfer_Column_Content_PHB"},{"location":"workflows/data_export/transfer_column_content/#transfer_column_content_phb","title":"Transfer_Column_Content_PHB","text":"<p>This set-level workflow will transfer all of the files from a given column in a Terra Data Table to a single Google Cloud Platform (GCP) storage bucket location. This is useful when you want to transfer many files to another GCP storage bucket (this can be a Terra workspace storage bucket or a non-Terra storage bucket).</p> <p>Ensure Proper Permissions</p> <p>This workflow requires that the user's Terra pet-service account has sufficient privileges to read and write to the target storage bucket.</p> <ul> <li>If the target bucket is associated with a Terra workspace, the workspace OWNER/administrator must grant you WRITER privileges to the Terra workspace.</li> <li>If the target bucket is not associated with a Terra workspace (i.e. GCP storage bucket), the user's Terra pet-service account (or their Terra PROXY account) must be granted the ability to read and write to the bucket (Storage Object Admin Google privileges)</li> </ul> <p>Call-Caching Disabled</p> <p>If using Transfer_Column_Content workflow version 1.3.0 or higher, the call-caching feature of Terra has been DISABLED to ensure that the workflow is run from the beginning and data is transferred fresh. Call-caching will not be enabled, even if the user checks the box \u2705 in the Terra workflow interface.</p>"},{"location":"workflows/data_export/transfer_column_content/#inputs","title":"Inputs","text":"<p>This workflow runs on the set level.</p> Terra Task Name Variable Type Description Default Value Terra Status transfer_column_content files_to_transfer Array[String] The column that has the files you want to transfer. Required transfer_column_content target_bucket String The GS URI<sup>1</sup> of the target storage bucket. Note: Do not include spaces, but do include the gs:// at the beginning of the bucket URI Required transfer_files cpu Int Number of CPUs to allocate to the task 4 Optional transfer_files disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional transfer_files docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/cloudsdktool/google-cloud-cli:427.0.0-alpine Optional transfer_files memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/data_export/transfer_column_content/#outputs","title":"Outputs","text":"Variable Type Description transfer_column_content_analysis_date String The date the workflow was run transfer_column_content_version String The version of the repository the workflow is hosted in transferred_files File A list of all of the files now located at the target bucket location (GSURI) <ol> <li> <p>GS URI: Google Storage Uniform Resource Identifier. This is not the same as a URL, which typically begins with http:// or https://. A GS URI begins with <code>gs://</code> and is used to reference a location in a Google Cloud Storage Bucket. For example, <code>gs://bucket-name/folder-name/file-name</code>. Other cloud storage providers have their own URIs, such as <code>s3://</code> for Amazon S3, although this workflow only supports Google Cloud Storage URIs.\u00a0\u21a9</p> </li> </ol>"},{"location":"workflows/data_export/zip_column_content/","title":"Zip_Column_Content","text":""},{"location":"workflows/data_export/zip_column_content/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Exporting Data from Terra Any taxa v2.1.0 Yes Set-level Zip_Column_Content_PHB"},{"location":"workflows/data_export/zip_column_content/#zip_column_content_phb","title":"Zip_Column_Content_PHB","text":"<p>This workflow will create a zip file containing all of the items from a given column in a Terra Data Table. This is useful when you want to share a collection of result files.</p>"},{"location":"workflows/data_export/zip_column_content/#inputs","title":"Inputs","text":"<p>This workflow runs on the set level.</p> <p>Do not include an extension</p> <p>When you provide the name of the otutput file, do not include the extension. The <code>.zip</code> extension will be added to any name you provide.</p> <p>While you can add an extension to the <code>zipped_file_name</code> input variable, it will not affect the output file format. The output file will always be a <code>.zip</code> file.</p> Terra Task Name Variable Type Description Default Value Terra Status zip_column_content files_to_zip Array[File] The column that has the files you want to zip. Required zip_column_content zipped_file_name String The name you want your zipped file to have. The .zip file extension will be added to this name. Required version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional zip_files cpu Int Number of CPUs to allocate to the task 2 Optional zip_files disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional zip_files docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional zip_files memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional"},{"location":"workflows/data_export/zip_column_content/#outputs","title":"Outputs","text":"<p>Prevent Output Overwriting</p> <p>Please note that if you run this workflow on the same Terra set, the results will overwrite each other. We recommend either (1) renaming the output variable, or (2) creating a new set every time you run the workflow. Multiple sets containing the same samples can be created as long as the set names are unique.</p> Variable Type Description zip_column_content_analysis_date String The date the workflow was run zip_column_content_version String The version of the repository the workflow is hosted in zipped_files File The zipped file containing all of the items from the column you selected."},{"location":"workflows/data_import/assembly_fetch/","title":"Assembly_Fetch","text":""},{"location":"workflows/data_import/assembly_fetch/#assembly-fetch","title":"Assembly Fetch","text":""},{"location":"workflows/data_import/assembly_fetch/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Data Import Any taxa v3.1.0 Yes Sample-level Assembly_Fetch_PHB"},{"location":"workflows/data_import/assembly_fetch/#assembly_fetch_phb","title":"Assembly_Fetch_PHB","text":"<p>The <code>Assembly_Fetch</code> workflow downloads assemblies from NCBI. This is particularly useful when you need to align reads against a reference genome, for example during a reference-based phylogenetics workflow. This workflow can be run in two ways:</p> <ol> <li>You can provide an accession for the specific assembly that you want to download, and <code>Assembly_Fetch</code> will run only the NCBI genome download task to download this assembly,</li> <li>You can provide an assembly, and <code>Assembly_Fetch</code> will first use the <code>ReferenceSeeker</code> task to first find the closest reference genome in RefSeq to your query assembly and then will run the NCBI genome download task to download that reference assembly.</li> </ol> <p>Call-Caching Disabled</p> <p>If using Assembly_Fetch workflow version 1.3.0 or higher, the call-caching feature of Terra has been DISABLED to ensure that the workflow is run from the beginning and data is downloaded fresh. Call-caching will not be enabled, even if the user checks the box \u2705 in the Terra workflow interface.</p>"},{"location":"workflows/data_import/assembly_fetch/#inputs","title":"Inputs","text":"<p>Assembly_Fetch requires the input samplename, and either the accession for a reference genome to download (ncbi_accession) or an assembly that can be used to query RefSeq for the closest reference genome to download (assembly_fasta).</p> <p>This workflow runs on the sample level.</p> <p>Note on Downloading Viral Assemblies</p> <p>If downloading viral assemblies, set <code>use_ncbi_virus</code> to true.</p> Terra Task Name Variable Type Description Default Value Terra Status assembly_fetch samplename String The name of the sample being analyzed Required assembly_fetch assembly_fasta File The assembly file for your sample in FASTA format Optional assembly_fetch ncbi_accession String NCBI accession passed to the NCBI datasets task to be downloaded. Example: GCF_000006945.2 (Salmonella enterica subsp. enterica, serovar Typhimurium str. LT2 reference genome) Optional ncbi_datasets_download_genome_accession cpu Int Number of CPUs to allocate to the task 1 Optional ncbi_datasets_download_genome_accession disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional ncbi_datasets_download_genome_accession docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ncbi-datasets:16.38.1 Optional ncbi_datasets_download_genome_accession include_gbff Boolean Set to true if you would like the GenBank Flat File (GBFF) file included in the output. It contains nucleotide sequence, metadata, and annotations. FALSE Optional ncbi_datasets_download_genome_accession include_gff3 Boolean Set to true if you would like the Genomic Feature File v3 (GFF3) file included in the output. It contains nucleotide sequence, metadata, and annotations FALSE Optional ncbi_datasets_download_genome_accession memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional ncbi_datasets_download_genome_accession use_ncbi_virus Boolean Set to true to download from NCBI Virus Datasets FALSE Optional referenceseeker cpu Int Number of CPUs to allocate to the task 4 Optional referenceseeker disk_size Int Amount of storage (in GB) to allocate to the task 200 Optional referenceseeker docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/referenceseeker:1.8.0--pyhdfd78af_0 Optional referenceseeker memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional referenceseeker referenceseeker_ani_threshold Float Bidirectional average nucleotide identity to use as a cut off for identifying reference assemblies with ReferenceSeeker; default value set according to https://github.com/oschwengers/referenceseeker#description 0.95 Optional referenceseeker referenceseeker_conserved_dna_threshold Float Conserved DNA % to use as a cut off for identifying reference assemblies with ReferenceSeeker; default value set according to https://github.com/oschwengers/referenceseeker#description 0.69 Optional referenceseeker referenceseeker_db File Database used by the referenceseeker tool that contains bacterial genomes from RefSeq release 205. Downloaded from the referenceseeker GitHub repository. gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-bacteria-refseq-205.v20210406.tar.gz Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/data_import/assembly_fetch/#workflow-tasks","title":"Workflow Tasks","text":"ReferenceSeeker Details (Optional) NCBI Datasets"},{"location":"workflows/data_import/assembly_fetch/#referenceseeker","title":"ReferenceSeeker","text":"<p><code>ReferenceSeeker</code> uses your draft assembly to identify closely related bacterial, viral, fungal, or plasmid genome assemblies in RefSeq.</p> <p>Databases that can be used with ReferenceSeeker are as follows, and can be used by pasting the GSURI in double quotation marks <code>\" \"</code> into the <code>referenceseeker_db</code> optional input:</p> <ul> <li>archea:  <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-archaea-refseq-205.v20210406.tar.gz</code></li> <li>bacterial (default): <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-bacteria-refseq-205.v20210406.tar.gz</code></li> <li>fungi: <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-fungi-refseq-205.v20210406.tar.gz</code></li> <li>plasmids: <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-plasmids-refseq-205.v20210406.tar.gz</code></li> <li>viral: <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-viral-refseq-205.v20210406.tar.gz</code></li> </ul> <p>For ReferenceSeeker to identify a genome, it must meet user-specified thresholds for sequence coverage (<code>referenceseeker_conserved_dna_threshold</code>; default &gt;= 0.69) and identity (<code>referenceseeker_ani_threshold</code>; default &gt;= 0.95 ). </p> <p>A list of closely related genomes is provided in <code>referenceseeker_tsv</code>. The reference genome that ranks highest according to ANI and conserved DNA values is considered the closest match and will be downloaded, with information about this provided in the <code>assembly_fetch_referenceseeker_top_hit_ncbi_accession</code> output.</p> <p>ReferenceSeeker Technical Details</p> Links Task task_referenceseeker.wdl Software Source Code ReferenceSeeker on GitHub Software Documentation ReferenceSeeker on GitHub Original Publication(s) ReferenceSeeker: rapid determination of appropriate reference genomes"},{"location":"workflows/data_import/assembly_fetch/#ncbi-datasets","title":"NCBI Datasets","text":"<p>The <code>NCBI Datasets</code> task downloads specified assemblies from NCBI using either the virus or genome (for all other genome types) package as appropriate.</p> <p>NCBI Datasets Technical Details</p> Links Task task_ncbi_datasets.wdl Software Source Code NCBI Datasets on GitHub Software Documentation NCBI Datasets Documentation on NCBI Original Publication(s) Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets"},{"location":"workflows/data_import/assembly_fetch/#outputs","title":"Outputs","text":"Variable Type Description assembly_fetch_analysis_date String The date the workflow was run assembly_fetch_ncbi_datasets_assembly_data_report_json File JSON file containing report about assembly downloaded by Asembly_Fetch assembly_fetch_ncbi_datasets_assembly_fasta File FASTA file downloaded by Assembly_Fetch assembly_fetch_ncbi_datasets_docker String Docker file used for NCBI datasets assembly_fetch_ncbi_datasets_gff File Assembly downloaded by Assembly_Fetch in GFF3 format assembly_fetch_ncbi_datasets_gff3 File Assembly downloaded by Assembly_Fetch in GFF format assembly_fetch_ncbi_datasets_version String NCBI datasets version used assembly_fetch_referenceseeker_database String ReferenceSeeker database used assembly_fetch_referenceseeker_docker String Docker file used for ReferenceSeeker assembly_fetch_referenceseeker_top_hit_ncbi_accession String NCBI Accession for the top hit identified by Assembly_Fetch assembly_fetch_referenceseeker_tsv File TSV file of the top hits between the query genome and the Reference Seeker database assembly_fetch_referenceseeker_version String ReferenceSeeker version used assembly_fetch_version String The version of the repository the Assembly Fetch workflow is in"},{"location":"workflows/data_import/assembly_fetch/#references","title":"References","text":"<p>ReferenceSeeker: Schwengers O, Hain T, Chakraborty T, Goesmann A. ReferenceSeeker: rapid determination of appropriate reference genomes. J Open Source Softw. 2020 Feb 4;5(46):1994.</p> <p>NCBI Datasets: O\u2019Leary NA, Cox E, Holmes JB, et al. Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets. Sci Data 11, 732 (2024).</p>"},{"location":"workflows/data_import/basespace_fetch/","title":"BaseSpace_Fetch","text":""},{"location":"workflows/data_import/basespace_fetch/#basespace_fetch","title":"BaseSpace_Fetch","text":""},{"location":"workflows/data_import/basespace_fetch/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Data Import Any taxa v3.1.0 Yes Sample-level BaseSpace_Fetch_PHB"},{"location":"workflows/data_import/basespace_fetch/#basespace_fetch_phb","title":"BaseSpace_Fetch_PHB","text":"<p>The <code>BaseSpace_Fetch</code> workflow facilitates the transfer of Illumina sequencing data from BaseSpace (a cloud location) to a workspace on the Terra.bio platform. Rather than downloading the files to a local drive and then re-uploading them to another location, we can perform a cloud-to-cloud transfer with the <code>BaseSpace_Fetch</code> workflow.</p>"},{"location":"workflows/data_import/basespace_fetch/#setting-up-basespace_fetch","title":"Setting up BaseSpace_Fetch","text":"<p>Some initial set-up is required to use the workflow. To access one's BaseSpace account from within a workflow on Terra.bio, it is necessary to retrieve an access token and the API server address using the BaseSpace command-line tool. The access token is unique to a BaseSpace account. If it is necessary to transfer data from multiple BaseSpace accounts, multiple access tokens will need to be retrieved. Please see the \"Retrieving BaseSpace Access Credentials\" section below.</p>"},{"location":"workflows/data_import/basespace_fetch/#retrieving-basespace-access-credentials","title":"Retrieving BaseSpace Access Credentials","text":"<p>This process must be performed on a command-line before using the <code>BaseSpace_Fetch</code> workflow for the first time. This can be set up in Terra, however it will work in any command-line environment that has access to the internet to install &amp; run the BaseSpace command-line tool: <code>bs</code>.</p> <p>If you already have a command-line environment available, you can skip ahead to Step 2.</p>"},{"location":"workflows/data_import/basespace_fetch/#create-environment","title":"Step 1: Create a command-line environment","text":"Click for more information <ol> <li> <p>Select the \"Environment Configuration\" cloud icon on the right side of the workspace dashboard tab</p> <p>Click on the cloud icon to access the environment configuration</p> <p></p> </li> <li> <p>Select the \"Settings\" button under Jupyter</p> <p>Click on Settings underneath the Jupyter icon</p> <p></p> </li> <li> <p>Click \"CREATE\" at the bottom of the \"Jupyter Cloud Environment\" page. There is no need to alter the default environment configuration.</p> <p>Click on Create at the bottom of the page</p> <p></p> <p>Environment customization</p> <p>The default environment should be sufficient for retrieval of BaseSpace credentials, but if performing other tasks in the environment please modify the resource allocations appropriately. </p> <p>You will be returned to the main page after clicking \"Create\". You will notice two new icons in your right-hand side bar as the environment is being created.</p> <p>Environment creation in progress</p> <p></p> </li> </ol>"},{"location":"workflows/data_import/basespace_fetch/#install-bs-cli","title":"Step 2: Install the BaseSpace Command-Line Tool to Retrieve the Access Token and API Server Address","text":"Click for more information <ol> <li> <p>When the environment is created and active, you should see a green dot in the bottom right corner of the Jupyter icon. Click on the \"Terminal\" icon in the right side-bar of the Terra dashboard to open the terminal.</p> <p>Open the terminal</p> <p></p> <p>The open terminal will appear in a new tab in your browser and will look similar to this:</p> <p>The terminal window</p> <p></p> </li> <li> <p>Download and setup the BaseSpace (BS) command line interface (CLI) tool (as per the Illumina documentation) by following the commands below. The lines beginning with <code>#</code> are comments, the following lines are the commands to be copy/pasted into the terminal</p> BaseSpace Fetch Authentication Instructions<pre><code># create bin directory\nmkdir ~/bin\n\n# download the basespace cli\nwget \"https://launch.basespace.illumina.com/CLI/latest/amd64-linux/bs\" -O $HOME/bin/bs\n\n# provide proper permissions to make the bs cli executable \nchmod u+x $HOME/bin/bs\n\n# add the 'bs' command-line tool to the $PATH variable so that you can call the command-line tool from any directory\nexport PATH=\"$PATH:$HOME/bin/\"\n\n# authenticate with BaseSpace credentials\nbs auth\n\n# navigate to the link provided in stdout and accept the authentication request through BaseSpace\n\n# Print the api server and access token to stdout (replace the path below with the appropriate path returned by the find command above)\ncat ~/.basespace/default.cfg\n</code></pre> </li> <li> <p>Copy and paste the contents of the <code>~/.basespace/default.cfg</code> (specifically, the access_token &amp; API server details) of the <code>default.cfg</code> file into Terra as workspace data elements.</p> <ol> <li>Navigate to the Terra \"DATA\" tab, and select \"Workspace Data\" at the bottom of the left sidebar.</li> <li>Click on \"Edit\" and then \"Add variable\" to add the new workspace data elements as in the examples below.</li> </ol> <p>Create workspace data elements</p> <p></p> </li> </ol>"},{"location":"workflows/data_import/basespace_fetch/#preparing-to-retrieve-a-run-with-basespace_fetch","title":"Preparing to retrieve a run with BaseSpace_Fetch","text":""},{"location":"workflows/data_import/basespace_fetch/#prep-metadata","title":"Step 1: Create a Metadata Sheet from the BaseSpace SampleSheet","text":"Click for more information <p>Best Practices for Sample Identifiers</p> <ul> <li>Avoid the use of underscores and whitespaces in the BaseSpace Project/Run name and/or the sample identifiers</li> <li>Underscores in a sample name may lead to BaseSpace_Fetch failure</li> <li>Avoid re-using Sample IDs. Make all sample IDs unique!</li> </ul> <ol> <li> <p>Download the sample sheet from BaseSpace.</p> <p>On the BaseSpace portal, you can navigate to this via: Runs \u2192 {run} \u2192 Files \u2192 SampleSheet.csv</p> <p>Example SampleSheet.csv</p> <p></p> </li> <li> <p>In Excel or an alternative spreadsheet software, set up a metadata sheet for Terra, with a row for each sample. Please feel free to use our BaseSpace_Fetch Template to help ensure the file is formatted correctly.  </p> <ol> <li>In cell A1, enter the data table name with the \"entity:TABLENAME_id\" format</li> <li> <p>Create a column called <code>basespace_sample_name</code> and populate this with the data found under the <code>Sample_Name</code> column in the BaseSpace sample sheet.</p> <p>Watch out</p> <p>If the contents of the <code>Sample_Name</code> and <code>Sample_ID</code> columns in the BaseSpace sample sheet are different, make a <code>basespace_sample_id</code> column in your spreadsheet and populate this with the data found under the <code>Sample_ID</code> column in the BaseSpace sample sheet.</p> </li> <li> <p>Create a <code>basespace_collection_id</code> column, and populate it with the BaseSpace Project or Run identifier</p> </li> <li> <p>Populate column A of the spreadsheet with the sample names as seen in the sample sheet</p> <p>Example Metadata Sheet</p> <p></p> </li> </ol> </li> </ol>"},{"location":"workflows/data_import/basespace_fetch/#upload-metadata","title":"Step 2: Upload the metadata spreadsheet to the destination workspace in Terra.bio","text":"Click for more information <ol> <li> <p>In Terra, navigate to the \"DATA\" tab, click \"IMPORT DATA\" then \"Upload TSV\"</p> <p>Upload TSV</p> <p></p> </li> <li> <p>Copy and paste the contents of the whole spreadsheet into the \"TEXT IMPORT\" tab and click \"START IMPORT JOB\"</p> <p>Import Metadata</p> <p></p> </li> </ol> <p>You can now use the created table to run the BaseSpace_Fetch workflow.</p>"},{"location":"workflows/data_import/basespace_fetch/#inputs","title":"Inputs","text":"<p>Call-Caching Disabled</p> <p>If using BaseSpace_Fetch workflow version 1.3.0 or higher, the call-caching feature of Terra has been DISABLED to ensure that the workflow is run from the beginning and data is downloaded fresh. Call-caching will not be enabled, even if the user checks the box \u2705 in the Terra workflow interface.</p> <p>Sample_Name and Sample_ID</p> <p>If the Sample_Name and Sample_ID in the BaseSpace sample sheet are different, set the <code>basespace_sample_id</code> input attribute to \"<code>this.basespace_sample_id\"</code>.</p> Terra Task Name Variable Type Description Default Value Terra Status basespace_fetch access_token String The access token is used in place of a username and password to allow the workflow to access the user account in BaseSpace from which the data is to be transferred. It is an alphanumeric string that is 32 characters in length. Example: 9e08a96471df44579b72abf277e113b7 Required basespace_fetch basespace_collection_id String The collection ID is the BaseSpace Run or Project where the data to be transferred is stored. Required basespace_fetch basespace_sample_name String The BaseSpace sample name is the sample identifier used in BaseSpace. This identifier is set on the sample sheet at the onset of an Illumina sequencing run. Required basespace_fetch sample_name String The sample name is the sample identifier used in the Terra.bio data table corresponding to the metadata associated with the sample to be transferred from BaseSpace Required basespace_fetch api_server String The API server is the web address to which data transfer requests can be sent by the workflow. https://api.basespace.illumina.com Optional basespace_fetch basespace_sample_id String The BaseSpace sample ID is an optional additional identifier used in BaseSpace. If a sample has a BaseSpace sample ID it should be available on the sample sheet and must be included in the metadata sheet upload prior to running BaseSpace_Fetch. Optional fetch_bs cpu Int Number of CPUs to allocate to the task 2 Optional fetch_bs disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional fetch_bs docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/basespace_cli:1.2.1 Optional fetch_bs memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/data_import/basespace_fetch/#outputs","title":"Outputs","text":"<p>The outputs of this workflow will be the fastq files imported from BaseSpace into the data table where the sample ID information had originally been uploaded.</p> Variable Type Description basespace_fetch_analysis_date String The date the workflow was run basespace_fetch_version String The version of the repository the Basespace_Fetch workflow is in read1 File File containing the forward reads read2 File File containing the reverse reads (not available for single-end or ONT data)"},{"location":"workflows/data_import/create_terra_table/","title":"Create_Terra_Table","text":""},{"location":"workflows/data_import/create_terra_table/#create_terra_table","title":"Create_Terra_Table","text":""},{"location":"workflows/data_import/create_terra_table/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Data Import Any taxa v2.2.0 No Create_Terra_Table_PHB"},{"location":"workflows/data_import/create_terra_table/#create_terra_table_phb","title":"Create_Terra_Table_PHB","text":"<p>The manual creation of Terra tables can be tedious and error-prone. This workflow will automatically create a Terra data table when provided with the location of the files.</p> <p>We recommend running this workflow with \"Run workflow with inputs defined by file paths\" selected in Terra. This will allow you to upload your data files and provide the necessary information for the workflow to run without having to specify a data table. There are no outputs for this workflow, as the table is created in your workspace.</p>"},{"location":"workflows/data_import/create_terra_table/#inputs","title":"Inputs","text":"<p>Default Behavior</p> <p>Files with underscores and/or decimals in the sample name are not recognized; please use dashes instead.</p> <p>For example, <code>name.banana.hello_yes_please.fastq.gz</code> will become \"name\". This means that <code>se-test_21.fastq.gz</code> and <code>se-test_22.fastq.gz</code> will not be recognized as separate samples.</p> <p>This can be changed by providing information in the <code>file_ending</code> optional input parameter. See below for more information.</p>"},{"location":"workflows/data_import/create_terra_table/#data-location","title":"Finding the <code>data_location_path</code>","text":"Using the Terra data uploader <p>Once you have named your new collection, you will see the collection name directly above where you can drag-and-drop your data files, or on the same line as the Upload button. Right-click the collection name and select \"Copy link address.\" Paste the copied link into the data_location_path variable, remembering to enclose it in quotes.</p> <p>Note</p> <p>If you click \"Next\" after uploading your files, it will ask for a metadata TSV. You do not have to provide this, and can instead exit the window. Your data will still be uploaded.</p> <p>Using the Terra data uiploader</p> <p></p> Using the Files section in Terra <p>You can browse workspace files by clicking on the folder icon in the right-hand sidebar of the Data tab in Terra.</p> <p>Navigate to the folder where your data is (\"example-create-terra-table\" in this example) and click on the clipboard next to the folder name to \"Copy folder URL to clipboard.\"</p> <p>If you uploaded data with the Terra data uploader, your collection will be nested in the \"uploads\" folder.</p> <p>Using the Files section</p> <p></p>"},{"location":"workflows/data_import/create_terra_table/#file-ending","title":"How to determine the appropriate <code>file_ending</code> for your data","text":"<p>The <code>file_ending</code> should be a substring of your file names that is held in common. To include multiple file endings, please separate them with commas, as shown in the \"No elements in common\" section. Click on the toggles below for examples:</p> One or more elements in common <p>If you have the following files:</p> <ul> <li>sample_01_R1.fastq.gz</li> <li>sample_01_R2.fastq.gz</li> <li>sample_02_R1.fastq.gz</li> <li>sample_02_R2.fastq.gz</li> </ul> <p>The default behavior would result in a single entry in the table called \"sample\" which is incorrect. You can rectify this by providing an appropriate <code>file_ending</code> for your samples.</p> <p>In this group, the desired sample names are \"sample_01\" and \"sample_02\". For all the files following the desired names, the text contains <code>_R</code>. If we provide \"_R\" as our <code>file_ending</code>, then \"sample_01\" and \"sample_02\" will appear in our table with the appropriate read files.</p> No elements in common <p>If you have the following files:</p> <ul> <li>sample_01_1.fastq.gz</li> <li>sample_01_2.fastq.gz</li> <li>sample_02_1.fastq.gz</li> <li>sample_02_2.fastq.gz</li> </ul> <p>The default behavior would result in a single entry in the table called \"sample\" which is incorrect. You can rectify this by providing an appropriate <code>file_ending</code> for your samples.</p> <p>In this group, the desired sample names are \"sample_01\" and \"sample_02\". However, in this example, there is no common text following the sample name. Providing <code>\"_\"</code> would result in the same behavior as default. We can provide two different patterns in the <code>file_ending</code> variable: <code>\"_1,_2\"</code> to capture all possible options. By doing this, \"sample_01\" and \"sample_02\" will appear in our table with the appropriate read files.</p> Terra Task Name Variable Type Description Default Value Terra Status create_terra_table assembly_data Boolean Set to true if your data is in FASTA format; set to false if your data is FASTQ format Required create_terra_table data_location_path String The full path to your data's Google bucket folder location, including the gs://; can be easily copied by right-clicking and copying the link address in the header after navigating to the folder in the \"Files\" section of the \"Data\" tab on Terra (see above for examples) Required create_terra_table new_table_name String The name of the new Terra table you want to create Required create_terra_table paired_end Boolean Set to true if your data is paired-end FASTQ files; set to false if not Required create_terra_table terra_project String The name of the Terra project where your data table will be created Required create_terra_table terra_workspace String The name of the Terra workspace where your data table will be created Required create_terra_table file_ending String Use to provide file ending(s) to determine what should be dropped from the filename to determine the name of the sample (see above for more information) Optional make_table cpu Int Number of CPUs to allocate to the task 1 Optional make_table disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional make_table docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Optional make_table memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional"},{"location":"workflows/data_import/create_terra_table/#outputs","title":"Outputs","text":"<p>Your table will automatically appear in your workspace with the following fields:</p> <ul> <li>Sample name (under the <code>new_table_name</code>_id column), which will be the section of the file's name before any decimals or underscores (unless <code>file_ending</code> is provided)<ul> <li>By default:<ul> <li><code>sample01.lane2_flowcell3.fastq.gz</code> will be represented by <code>sample01</code> in the table</li> <li><code>sample02_negativecontrol.fastq.gz</code> will be represented by <code>sample02</code> in the table</li> </ul> </li> <li>See How to determine the appropriate <code>file_ending</code> for your data above to learn how to change this default behavior</li> </ul> </li> <li> <p>Your data in the appropriate columns, dependent on the values of <code>assembly_data</code> and <code>paired_end</code></p> table columns <code>assembly_data</code> is true <code>paired_end</code> is true <code>assembly_data</code> AND <code>paired_end</code> are false read1 \u274c \u2705 \u2705 read2 \u274c \u2705 \u274c assembly_fasta \u2705 \u274c \u274c </li> <li> <p>The date of upload under the <code>upload_date</code> column</p> </li> <li>The name of the workflow under <code>table_created_by</code>, to indicate the table was made by the Create_Terra_Table_PHB workflow.</li> </ul>"},{"location":"workflows/data_import/fetch_srr_accession/","title":"Fetch_SRR_Accession","text":""},{"location":"workflows/data_import/fetch_srr_accession/#fetch-srr-accession-workflow","title":"Fetch SRR Accession Workflow","text":""},{"location":"workflows/data_import/fetch_srr_accession/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Data Import Any taxa v2.3.0 Yes Sample-level Fetch_SRR_Accession_PHB"},{"location":"workflows/data_import/fetch_srr_accession/#fetch-srr-accession","title":"Fetch SRR Accession","text":"<p>This workflow retrieves the Sequence Read Archive (SRA) accession (SRR) associated with a given sample accession. The primary inputs are BioSample IDs (e.g., SAMN00000000) or SRA Experiment IDs (e.g., SRX000000), which link to sequencing data in the SRA repository.</p> <p>The workflow uses the fastq-dl tool to fetch metadata from SRA and specifically parses this metadata to extract the associated SRR accession and outputs the SRR accession.</p>"},{"location":"workflows/data_import/fetch_srr_accession/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status fetch_srr_accession sample_accession String SRA-compatible accession, such as a BioSample ID (e.g., \"SAMN00000000\") or SRA Experiment ID (e.g., \"SRX000000\"), used to retrieve SRR metadata. Required fetch_srr cpu Int Number of CPUs to allocate to the task 2 Optional fetch_srr disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional fetch_srr docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/fastq-dl:2.0.4--pyhdfd78af_0 Optional fetch_srr memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/data_import/fetch_srr_accession/#workflow-tasks","title":"Workflow Tasks","text":"<p>This workflow has a single task that performs metadata retrieval for the specified sample accession.</p> <code>fastq-dl</code>: Fetches SRR metadata for sample accession <p>When provided a BioSample accession or SRA experiment ID, 'fastq-dl' collects metadata and returns the appropriate SRR accession.</p> <p>fastq-dl Technical Details</p> Links Task task_fetch_srr_accession.wdl Software Source Code https://github.com/rpetit3/fastq-dl Software Documentation https://github.com/rpetit3/fastq-dl#usage"},{"location":"workflows/data_import/fetch_srr_accession/#outputs","title":"Outputs","text":"Variable Type Description fetch_srr_accession_analysis_date String The date the fetch_srr_accession analysis was run. fetch_srr_accession_version String The version of the fetch_srr_accession workflow. srr_accession String The SRR accession's associated with the input sample accession."},{"location":"workflows/data_import/ont_barcode_concatenation/","title":"ONT_Barcode_Concatenation","text":""},{"location":"workflows/data_import/ont_barcode_concatenation/#ont_barcode_concatenation","title":"ONT_Barcode_Concatenation","text":""},{"location":"workflows/data_import/ont_barcode_concatenation/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Data Import Any taxa vX.X.X No ONT_Barcode_Concatenation_PHB"},{"location":"workflows/data_import/ont_barcode_concatenation/#ont_barcode_concatenation_phb","title":"ONT_Barcode_Concatenation_PHB","text":"<p>This workflow will automatically concatenate all reads in a given folder and upload those reads to a Terra data table.</p> <p>We recommend running this workflow with \"Run workflow with inputs defined by file paths\" selected in Terra. This will allow you to upload your data files and provide the necessary information for the workflow without having to specify a data table. There are no outputs for this workflow, as the data is added to either a new or existing table in your workspace.</p> <p>Barcodes Must Be In Nested Directories</p> <p>This workflow anticipates that all reads associated with a barcode are located in their own subdirectories while the <code>input_bucket_path</code> points to the parent folder containing all the barcodes that are to be processed.</p> <p>How does directory structure impact my output?</p> <p>If you have the following directory structure:</p> <pre><code>output_bucket_path/\ninput_bucket_path/\n\u251c\u2500\u2500 barcode01/\n\u2502   \u251c\u2500\u2500 ABC123_pass_barcode01_123abc_789xyz_0.fastq.gz\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 ABC123_pass_barcode01_123abc_789xyz_XXX.fastq.gz\n\u251c\u2500\u2500 barcode02/\n\u2502   \u251c\u2500\u2500 ABC123_pass_barcode02_123abc_789xyz_0.fastq.gz\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 ABC123_pass_barcode02_123abc_789xyz_XXX.fastq.gz\n\u251c\u2500\u2500 barcodeXXX/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 random_name/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 ABC123_these_files_will_be_ignored_0.fastq.gz\n\u2514\u2500\u2500 ABC123_these_files_will_be_ignored_1.fastq.gz\n</code></pre> <p>The <code>input_bucket_path</code> in would point to <code>gs://input_bucket_path/</code>, and the workflow would automatically find and concatenate all reads within each subdirectory (both <code>barcode*/</code> and <code>random_name/</code>). Learn how to upload your files in this structure below. Please note: If there are reads located in the parent directory (e.g., <code>ABC123_these_files_will_be_ignored_0.fastq.gz</code> and <code>ABC123_these_files_will_be_ignored_1.fastq.gz</code>), they will be ignored.</p> <p>After concatenation, the resulting reads will appear in the <code>gs://output_bucket_path</code> under the following names:</p> <pre><code>output_bucket_path/\n\u251c\u2500\u2500 previously_concatenated_sample.all.fastq.gz\n\u251c\u2500\u2500 barcode01.all.fastq.gz\n\u251c\u2500\u2500 barcode02.all.fastq.gz\n\u251c\u2500\u2500 ...\n\u251c\u2500\u2500 barcodeXXX.all.fastq.gz\n\u2514\u2500\u2500 random_name.all.fastq.gz\n</code></pre> <p>All data in the <code>output_bucket_path</code> will appear in the specified Terra table under the <code>read1</code> column. The sample name is taken from the text before the <code>.all.fastq.gz</code> suffix, which is the folder name the data was found in. If a file has already been uploaded but is in the <code>output_bucket_path</code>, it will be reuploaded.</p> &lt;terra_table_name&gt;_id read1 previously_concatenated_sample previously_concatenated_sample.all.fastq.gz barcode01 barcode01.all.fastq.gz barcode02 barcode02.all.fastq.gz ... ... barcodeXXX barcodeXXX.all.fastq.gz random_name random_name.all.fastq.gz <p>If a <code>barcode_renaming_file</code> is used (see relevant section below) that maps <code>random_name</code> to <code>my_special_sample</code>, the <code>random_name</code> sample will not appear in the table or in the <code>output_bucket_path</code>, and <code>my_special_sample</code> will appear instead.</p> &lt;terra_table_name&gt;_id read1 my_special_sample my_special_sample.all.fastq.gz"},{"location":"workflows/data_import/ont_barcode_concatenation/#inputs","title":"Inputs","text":""},{"location":"workflows/data_import/ont_barcode_concatenation/#data-upload","title":"Uploading unconcatenated ONT reads to Terra and finding the <code>input_bucket_path</code>","text":"<p>Using the Terra data uploader is not recommended.</p> The following method is recommended for data upload: <ol> <li> <p>Navigate to your Terra workspace's Dashboard page and click on \"Open bucket in browser\" under the \"Cloud Information\" toggle on the right hand side.</p> <p>Open bucket in browser</p> <p></p> </li> <li> <p>Click on the <code>uploads</code> folder.</p> <p>Open the <code>uploads</code> folder</p> <p></p> </li> <li> <p>Click on \"Create folder\". Name the folder a unique name that can be used to identify your run or group of data. Click on \"Create\" once you have entered the new folder name.</p> <p>Create a new folder</p> <p></p> </li> <li> <p>Navigate into the newly created folder by clicking on it. You can now drag and drop entire barcode directories into the browser with your new Google bucket. This process uploads the data directly into your Terra workspace.</p> <p>Drag your barcode folders onto the browser</p> <p></p> <p>When your files are uploaded, you should see them appear.</p> <p>Uploaded folders should look like this</p> <p></p> </li> <li> <p>Once your files are uploaded, you can identify the <code>input_bucket_path</code> by clicking on the two squares next to the file path at the top of the screen, shown below. When pasting this into the workflow inputs, you will need to add the <code>gs://</code> prefix.</p> <p>Copy the file path</p> <p></p> </li> </ol>"},{"location":"workflows/data_import/ont_barcode_concatenation/#file-paths","title":"Finding the <code>output_bucket_path</code>","text":"<p>It is recommended to also create a new folder using the method described above for your <code>output_bucket_path</code>. No files should be uploaded to it.</p> <p>CAUTION! Be careful when reusing <code>output_bucket_path</code></p> <p>The way this workflow currently works is that all files in the <code>output_bucket_path</code> are added to the specified Terra table. If the <code>output_bucket_path</code> is reused, all files will be re-added to Terra and the <code>upload_date</code> column will be overwritten.</p>"},{"location":"workflows/data_import/ont_barcode_concatenation/#barcode-renaming","title":"Creating a <code>barcode_renaming_file</code>","text":"<p>By default, each concatenated file will take the name of the folder that contained the unconcatenated files. If you have specific sample names that correspond to each folder name, you can specify what you would like the concatenated files to be named as using a <code>barcode_renaming_file</code>.</p> <p>This file takes the following tab-delimited format. Do not include a header.</p> <pre><code>barcode01   sample01\nbarcode02   sample02\n</code></pre> <p>The first column is the name of the folder and the second column is the desired sample name.</p> <p>Upload this file to your Terra bucket using either the Data Uploader or by clicking on the file icon on the right sidebar. Copy the file path into the <code>barcode_renaming_file</code> variable, and your files will be appropriate renamed.</p> Terra Task Name Variable Type Description Default Value Terra Status ont_barcode_concatenation input_bucket_path String The full path to your unconcatenated data's Google bucket folder location, including the gs://; can be easily copied by right-clicking and copying the link address in the header after navigating to the folder in the \"Files\" section of the \"Data\" tab on Terra (see above for examples) Required ont_barcode_concatenation output_bucket_path String The full path to where you want the concatenated data to be stored as a Google bucket folder location, including the gs://; can be easily copied by right-clicking and copying the link address in the header after navigating to the desired folder in the \"Files\" section of the \"Data\" tab on Terra (see above for examples) Required ont_barcode_concatenation terra_project String The name of the Terra project where your data table will be located Required ont_barcode_concatenation terra_table_name String The name of the Terra table you want to add your newly concatenated samples to Required ont_barcode_concatenation terra_workspace String The name of the Terra workspace where your data table will be located Required cat_ont_barcodes cpu Int Number of CPUs to allocate to the task 2 Optional cat_ont_barcodes disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional cat_ont_barcodes docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/ont-barcodes:0.0.2 Optional cat_ont_barcodes memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional create_terra_table cpu Int Number of CPUs to allocate to the task 1 Optional create_terra_table disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional create_terra_table docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Optional create_terra_table memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional ont_barcode_concatenation barcode_renaming_file File A tab-delimited file where the name of the barcode folders are mapped to the desired sample name in the Terra table (see above for examples) Optional ont_barcode_concatenation file_extension String If your ONT data ends in a different extension, like \".fq.gz\" or \".fastq\", you can indicate that here. .fastq.gz Optional"},{"location":"workflows/data_import/ont_barcode_concatenation/#outputs","title":"Outputs","text":"<p>Your concatenated ONT data will automatically appear in your workspace in the table of choice with information in the following four fields:</p> <ul> <li>Sample name (under the <code>terra_table_name</code>_id column), which will be either the name of the parent folder or the remapped name indicated by the <code>barcode_renaming_file</code> input.</li> <li>The concatenated ONT data in the <code>read1</code> column</li> <li>The name of the workflow (<code>ONT_Barcode_Concatenation_PHB</code>) under the <code>table_created_by</code> column, to indicate the samples were added by this workflow.</li> <li>The date of upload/when the workflow was run under the <code>upload_date</code> column</li> </ul>"},{"location":"workflows/data_import/sra_fetch/","title":"SRA_Fetch","text":""},{"location":"workflows/data_import/sra_fetch/#sra_fetch","title":"SRA_Fetch","text":""},{"location":"workflows/data_import/sra_fetch/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Data Import Any taxa v2.2.0 Yes Sample-level SRA_Fetch_PHB"},{"location":"workflows/data_import/sra_fetch/#sra_fetch_phb","title":"SRA_Fetch_PHB","text":"<p>The <code>SRA_Fetch</code> workflow downloads sequence data from NCBI's Sequence Read Archive (SRA). It requires an SRA run accession then populates the associated read files to a Terra data table.</p> <p>Read files associated with the SRA run accession provided as input are copied to a Terra-accessible Google bucket. Hyperlinks to those files are shown in the \"read1\" and \"read2\" columns of the Terra data table.</p>"},{"location":"workflows/data_import/sra_fetch/#inputs","title":"Inputs","text":"<p>The only required input for the SRA_Fetch workflow is an SRA run accession beginning \"SRR\", an ENA run accession beginning \"ERR\", or a DRA run accession which beginning \"DRR\".</p> <p>Please see the NCBI Metadata and Submission Overview for assistance with identifying accessions. Briefly, NCBI-accessioned objects have the following naming scheme:</p> STUDY SRP# SAMPLE SRS# EXPERIMENT SRX# RUN SRR# Terra Task Name Variable Type Description Default Value Terra Status fetch_sra_to_fastq accession String SRA, ENA, or DRA accession number Required fetch_sra_to_fastq cpu Int Number of CPUs to allocate to the task 2 Optional fetch_sra_to_fastq disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional fetch_sra_to_fastq docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/fastq-dl:2.0.4--pyhdfd78af_0 Optional fetch_sra_to_fastq fastq_dl_opts String Additional parameters to pass to fastq_dl from here --provider sra Optional fetch_sra_to_fastq memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/data_import/sra_fetch/#outputs","title":"Outputs","text":"<p>Read data are available either with full base quality scores (SRA Normalized Format) or with simplified quality scores (SRA Lite). The\u00a0SRA Normalized Format\u00a0includes full, per-base quality scores, whereas base quality scores have been simplified in SRA Lite files. This means that all quality scores have been artificially set to Q-30 or Q3. More information about these files can be found here.</p> <p>Given the lack of usefulness of SRA Lite formatted FASTQ files, we try to avoid these by preferentially searching SRA directly (SRA-Lite is more probably to be the file synced to other repositories), but sometimes downloading these files is unavoidable. To make the user aware of this, a warning column is present that is populated when an SRA-Lite file is detected.</p> Variable Type Description fastq_dl_date String The date of the read data download fastq_dl_docker String The docker used fastq_dl_fastq_metadata File File containing metadata of the provided accession such as submission_accession, library_selection, instrument_platform, among others fastq_dl_version String The version of fastq-dl used fastq_dl_warning String This warning field is populated if SRA-Lite files are detected. These files contain all quality encoding as Phred-30 or Phred-3. read1 File File containing the forward reads read2 File File containing the reverse reads (not available for single-end or ONT data) sra_fetch_analysis_date String The date the workflow was run sra_fetch_version String The version of the repository the SRA_Fetch workflow is in"},{"location":"workflows/data_import/sra_fetch/#references","title":"References","text":"<p>fastq-dl: Petit III, R. A., Hall, M. B., Tonkin-Hill, G., Zhu, J., &amp; Read, T. D. fastq-dl: efficiently download FASTQ files from SRA or ENA repositories (Version 2.0.2) [Computer software]. https://github.com/rpetit3/fastq-dl</p>"},{"location":"workflows/genomic_characterization/freyja/","title":"Freyja Workflow Series","text":""},{"location":"workflows/genomic_characterization/freyja/#freyja-workflow-series","title":"Freyja Workflow Series","text":""},{"location":"workflows/genomic_characterization/freyja/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Genomic Characterization SARS-CoV-2, Viral v3.1.0 Yes Sample-level, Set-level Freyja_FASTQ_PHB, Freyja_Plot_PHB, Freyja_Dashboard_PHB, Freyja_Update_PHB"},{"location":"workflows/genomic_characterization/freyja/#freyja-overview","title":"Freyja Overview","text":"<p>Freyja is a tool for analysing viral mixed sample genomic sequencing data. Developed by Joshua Levy from the Andersen Lab, it performs two main steps:</p> <ol> <li>Variant Frequency Estimation: Freyja calculates the frequencies of single nucleotide variants (SNVs) in the genomic sequencing data.</li> <li>Depth-Weighted Demixing: It separates mixed populations of viral subtypes using a depth-weighted statistical approach, estimating the proportional abundance of each subtype in the sample based on the frequencies of subtype-defining variants.</li> </ol> <p>Additional post-processing steps can produce visualizations of aggregated samples.</p> <p>Wastewater and more</p> <p>The typical use case of Freyja is to analyze mixed SARS-CoV-2 samples from a sequencing dataset, most often wastewater, but the tool is not limited to this context. With the appropriate reference genomes and barcode files, Freyja can be adapted for other pathogens, including MPXV, Influenza, RSV, and Measles.</p> <p>Default Values</p> <p>The defaults included in the Freyja workflows reflect this use case but can be adjusted for other pathogens. See the Running Freyja on other pathogens section for more information. Please be aware this is an experimental feature and we cannot guarantee complete functionality at this time.</p> <p>Figure 1: Workflow diagram for Freyja Suite of workflows</p> <p>Four workflows have been created that perform different parts of Freyja:</p> <ul> <li>Freyja_Update_PHB</li> <li>Freyja_FASTQ_PHB</li> <li>Freyja_Plot_PHB</li> <li>Freyja_Dashboard_PHB</li> </ul> <p>The main workflow is Freyja_FASTQ_PHB (Figure 1). Depending on the type of input data (Illumina paired-end, Illumina single-end or ONT), it runs various QC modules before aligning the sample with either BWA (Illumina) or minimap2 (ONT) to the provided reference file, followed by iVar for primer trimming. After the preprocessing is completed, Freyja is run to generate relative lineage abundances (demix) from the sample. Optional bootstrapping may be performed.</p> <p>Data Compatability</p> <p>The Freyja_FASTQ_PHB workflow is compatible with the following input data types:</p> <pre><code>- Ilumina Single-End\n- Illumina Paired-End\n- Oxford Nanopore\n</code></pre> <p>Freyja_Update_PHB will copy the SARS-CoV-2 reference files that can then be used as input for the Freyja_FASTQ_PHB workflow.</p> <p>Two options are available to visualize the Freyja results: Freyja_Plot_PHB and Freyja_Dashboard_PHB. Freyja_Plot_PHB aggregates multiple samples using output from Freyja_FASTQ_PHB to generate a plot that shows fractional abundance estimates for all samples. including the option to plot sample collection date information. Alternatively, Freyja_Dashboard_PHB aggregates multiple samples using output from Freyja_FASTQ_PHB to generate an interactive visualization. This workflow requires an additional input field called viral load, which is the number of viral copies per liter.</p>"},{"location":"workflows/genomic_characterization/freyja/#figure1","title":"Figure 1","text":"<p>Depending on the type of data (Illumina or Oxford Nanopore), the Read QC and Filtering steps, as well as the Read Alignment steps use different software. The user can specify if the barcodes and lineages file should be updated with <code>freyja update</code> before running Freyja or if bootstrapping is to be performed with <code>freyja boot</code>.</p>"},{"location":"workflows/genomic_characterization/freyja/#freyja-sequencing-platforms-and-data-quality","title":"Freyja, Sequencing Platforms and Data Quality","text":"<p>The choice of sequencing platform and the quality of the data directly influence Freyja's performance. High-accuracy platforms like Illumina provide reliable SNV detection, enhancing the precision of lineage abundance estimates. In contrast, platforms with higher error rates, such as Nanopore, whilst it has improved greatly in the recent years, may introduce uncertainties in variant calling, affecting the deconvolution process. Sequencing depth requirements will increase as the quality of the sequencing data decreases. A rational target depth is 100X coverage for sequencing data with Q-scores in the range of 25-30.</p> <p>Additionally, inadequate sequencing depth can hinder Freyja's ability to differentiate between lineages, leading to potential misestimations. Sequencing depth requirements will increase with the complexity of the sample composition and the diversity of lineages present. For samples containing multiple closely related lineages, higher sequencing depth is necessary to resolve subtle differences in genetic variation and accurately estimate lineage abundances. This is particularly important for pathogens with high mutation rates or a large number of cocirculating lineages, such as influenza, where distinguishing between lineages relies on detecting specific single nucleotide variants (SNVs) with high confidence.</p>"},{"location":"workflows/genomic_characterization/freyja/#freyja-workflows","title":"Freyja Workflows","text":""},{"location":"workflows/genomic_characterization/freyja/#freyja_update","title":"Freyja_Update_PHB","text":"<p>This workflow will copy the SARS-CoV-2 reference files (<code>curated_lineages.json</code> and <code>usher_barcodes.feather</code>) from the source repository to a user-specific Google Cloud Storage (GCP) location (often a Terra.bio workspace-associated bucket). These files can then be used as input for the Freyja_FASTQ_PHB workflow.</p> <p>Warning</p> <p>This workflow is compatible only with SARS-CoV-2 reference files! To download reference files for other organisms please see the following repository:\u00a0Freyja Barcodes.</p> <p>More information is available in the Running Freyja on other pathogens section.</p>"},{"location":"workflows/genomic_characterization/freyja/#inputs","title":"Inputs","text":"<p>We recommend running this workflow with \"Run inputs defined by file paths\" selected since no information from a Terra data table is actually being used. We also recommend turning off call caching so new information is retrieved every time.</p> Terra Task Name Variable Type Description Default Value Terra Status freyja_update gcp_uri String The path where you want the Freyja reference files to be stored. Include gs:// at the beginning of the string. Full example with a Terra workspace bucket: \"gs://fc-87ddd67a-c674-45a8-9651-f91e3d2f6bb7\" Required freyja_update_refs cpu Int Number of CPUs to allocate to the task 1 Optional freyja_update_refs disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional freyja_update_refs docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/freyja:1.5.3 Optional freyja_update_refs memory Int Amount of memory/RAM (in GB) to allocate to the task 10 Optional transfer_files cpu Int Number of CPUs to allocate to the task 1 Optional transfer_files disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional transfer_files docker String Docker image to use for the task us-docker.pkg.dev/general-theiagen/cloudsdktool/google-cloud-cli:427.0.0-alpine Optional transfer_files memory Int Amount of memory (in GB) to allocate to the task 2 Optional"},{"location":"workflows/genomic_characterization/freyja/#outputs","title":"Outputs","text":"<p>This workflow does not produce any outputs that appear in a Terra data table. The reference files will appear at the location specified with the <code>gcp_uri</code> input variable.</p>"},{"location":"workflows/genomic_characterization/freyja/#freyja_fastq","title":"Freyja_FASTQ_PHB","text":"<p>Freyja measures SNV frequency and sequencing depth at each position in the genome to return an estimate of the true lineage abundances in the sample. The method uses lineage-defining \"barcodes\" that, for SARS-CoV-2, are derived from the UShER global phylogenetic tree as a base set for demixing. Freyja_FASTQ_PHB returns as output a TSV file that includes the lineages present and their corresponding abundances, along with other values.</p> <p>The Freyja_FASTQ_PHB workflow is compatible with the multiple input data types: Ilumina Single-End, Illumina Paired-End and Oxford Nanopore. Depending on the type of input data, different input values are used.</p> <p>Table 1: Freyja_FASTQ_PHB input configuration for different types of input data.</p> Table Columns Illumina Paired-End Illumina Single-End Oxford Nanopore read1 \u2705 \u2705 \u2705 read2 \u2705 \u274c \u274c ont <code>false</code> <code>false</code> <code>true</code>"},{"location":"workflows/genomic_characterization/freyja/#inputs_1","title":"Inputs","text":"<p>This workflow runs on the sample level.</p> Illumina paired-end input dataIllumina single-end input dataONT input data Terra Task Name Variable Type Description Default Value Terra Status freyja_fastq read1 File FASTQ file containing read1 sequences (Illumina or (ONT) Required freyja_fastq reference_genome File The reference genome to use; should match the reference used for alignment (Wuhan-Hu-1) Required freyja_fastq samplename String The name of the sample being analyzed Required freyja_fastq freyja_lineage_metadata File File containing the lineage metadata; the \"curated_lineages.json\" file found https://github.com/andersen-lab/Freyja/tree/main/freyja/data can be used for this variable. Does not need to be provided if update_db is true or if the freyja_pathogen is provided. Optional, Required bwa cpu Int Number of CPUs to allocate to the task 6 Optional bwa disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional bwa docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional bwa memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional freyja adapt Float adaptive lasso penalty parameter 0 Optional freyja bootstrap Boolean Perform bootstrapping FALSE Optional freyja confirmed_only Boolean Include only confirmed SARS-CoV-2 lineages FALSE Optional freyja cpu Int Number of CPUs to allocate to the task 2 Optional freyja disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional freyja docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/freyja:1.5.3 Optional freyja eps Float The minimum lineage abundance cut-off value 0.001 Optional freyja memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional freyja number_bootstraps Int The number of bootstraps to perform (only used if bootstrap = true) 100 Optional freyja update_db Boolean Updates the Freyja reference files (the usher barcodes and lineage metadata files) but will not save them as output (use Freyja_Update for that purpose). If set to true, the freyja_lineage_metadata and freyja_barcodes files are not required. FALSE Optional freyja_fastq depth_cutoff Int The minimum coverage depth with which to exclude sites below this value and group identical barcodes -- THIS MAY NOT WORK FOR NON-SARS-COV-2 ORGANISMS! 10 Optional freyja_fastq freyja_barcodes File Custom barcode file. Does not need to be provided if update_db is true if the freyja_pathogen is provided. Optional freyja_fastq freyja_pathogen String Pathogen of interest, used if not providing the barcodes and lineage metadata files. Options: SARS-CoV-2, MPXV, H5NX, H1N1pdm, FLU-B-VIC, MEASLESN450, MEASLES, RSVa, RSVb Optional freyja_fastq freyja_pathogen String Pathogen to be used by Freyja SARS-CoV-2 Optional freyja_fastq kraken2_target_organism String The organism whose abundance the user wants to check in their reads. This should be a proper taxonomic name recognized by the Kraken database. Severe acute respiratory syndrome coronavirus 2 Optional freyja_fastq ont Boolean Indicates if the input data is derived from an ONT instrument. FALSE Optional freyja_fastq primer_bed File The bed file containing the primers used when sequencing was performed Optional freyja_fastq read2 File Illumina reverse read file in FASTQ file format (compression optional) Optional freyja_fastq reference_gff File The GFF file for reference; should match the reference used for alignment (Wuhan-Hu-1) Optional freyja_fastq trimmomatic_min_length Int The minimum length cut-off when performing read cleaning 25 Optional get_fasta_genome_size cpu Int Number of CPUs to allocate to the task 1 Optional get_fasta_genome_size disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional get_fasta_genome_size docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/seqkit:2.4.0--h9ee0642_0 Optional get_fasta_genome_size memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional minimap2 cpu Int Number of CPUs to allocate to the task 2 Optional minimap2 disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional minimap2 docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/minimap2:2.22 Optional minimap2 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional minimap2 query2 File Internal component, do not modify Optional nanoplot_clean cpu Int Number of CPUs to allocate to the task 4 Optional nanoplot_clean disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoplot_clean docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Optional nanoplot_clean max_length Int The maximum length of clean reads, for which reads longer than the length specified will be hidden. 100000 Optional nanoplot_clean memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional nanoplot_raw cpu Int Number of CPUs to allocate to the task 4 Optional nanoplot_raw disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoplot_raw docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Optional nanoplot_raw max_length Int The maximum length of clean reads, for which reads longer than the length specified will be hidden. 100000 Optional nanoplot_raw memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional primer_trim cpu Int Number of CPUs to allocate to the task 2 Optional primer_trim disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional primer_trim docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional primer_trim keep_noprimer_reads Boolean Include reads with no primers TRUE Optional primer_trim memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim_ont artic_guppyplex_cpu Int Number of CPUs to allocate to the task 8 Optional read_QC_trim_ont artic_guppyplex_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_ont artic_guppyplex_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/artic-ncov2019:1.3.0-medaka-1.4.3 Optional read_QC_trim_ont artic_guppyplex_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional read_QC_trim_ont call_kraken Boolean Internal component, do not modify FALSE Optional read_QC_trim_ont downsampling_coverage Float Internal component, do not modify 150 Optional read_QC_trim_ont genome_length Int Internal component, do not modify Optional read_QC_trim_ont genome_length Int Length of the genome 5000000 Optional read_QC_trim_ont kraken2_recalculate_abundances_cpu Int Internal component, do not modify 4 Optional read_QC_trim_ont kraken2_recalculate_abundances_disk_size Int Internal component, do not modify 100 Optional read_QC_trim_ont kraken2_recalculate_abundances_docker Int Internal component, do not modify us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-08-28-v4 Optional read_QC_trim_ont kraken2_recalculate_abundances_memory Int Internal component, do not modify 8 Optional read_QC_trim_ont kraken_cpu Int Internal component, do not modify 4 Optional read_QC_trim_ont kraken_db File Internal component, do not modify Optional read_QC_trim_ont kraken_disk_size Int Internal component, do not modify 100 Optional read_QC_trim_ont kraken_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Optional read_QC_trim_ont kraken_memory Int Internal component, do not modify 8 Optional read_QC_trim_ont max_length Int Internal component, do not modify Optional read_QC_trim_ont min_length Int Internal component, do not modify Optional read_QC_trim_ont nanoq_cpu Int Number of CPUs to allocate to the task 2 Optional read_QC_trim_ont nanoq_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_ont nanoq_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/nanoq:0.9.0--hec16e2b_1 Optional read_QC_trim_ont nanoq_max_read_length Int Maximum read length to use for filtering Optional read_QC_trim_ont nanoq_max_read_qual Int Maximum read quality to use for filtering Optional read_QC_trim_ont nanoq_memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional read_QC_trim_ont nanoq_min_read_length Int Minimum read length to use for filtering Optional read_QC_trim_ont nanoq_min_read_qual Int Minimum read quality to use for filtering Optional read_QC_trim_ont ncbi_scrub_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim_ont ncbi_scrub_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_ont ncbi_scrub_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ncbi/sra-human-scrubber:2.2.1 Optional read_QC_trim_ont ncbi_scrub_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional read_QC_trim_ont rasusa_bases String Explicitly set the number of bases required e.g., 4.3kb, 7Tb, 9000, 4.1MB. If this option is given, --coverage and --genome-size are ignored Optional read_QC_trim_ont rasusa_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim_ont rasusa_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_ont rasusa_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/rasusa:2.1.0 Optional read_QC_trim_ont rasusa_fraction_of_reads Float Subsample to a fraction of the reads - e.g., 0.5 samples half the reads Optional read_QC_trim_ont rasusa_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim_ont rasusa_number_of_reads Int Subsample to a specific number of reads Optional read_QC_trim_ont rasusa_seed Int Random seed to use Optional read_QC_trim_ont run_prefix String Internal component, do not modify Optional read_QC_trim_ont target_organism String Internal component, do not modify Optional read_QC_trim_pe adapters File A FASTA file containing adapter sequences Optional read_QC_trim_pe bbduk_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim_pe call_kraken Boolean True/False variable that determines if the Kraken2 task should be called; for non-TheiaCoV workflows, the <code>kraken_db</code> variable must be provided. FALSE Optional read_QC_trim_pe call_midas Boolean True/False variable that determines if the MIDAS task should be called. FALSE Optional read_QC_trim_pe extract_unclassified Boolean Internal component, do not modify FALSE Optional read_QC_trim_pe fastp_args String Additional arguments to use with fastp --detect_adapter_for_pe -g -5 20 -3 20 Optional read_QC_trim_pe host String Internal component, do not modify Optional read_QC_trim_pe host_complete_only Boolean Internal component, do not modify FALSE Optional read_QC_trim_pe host_decontaminate_mem Int Internal component, do not modify 32 Optional read_QC_trim_pe host_is_accession Boolean Internal component, do not modify FALSE Optional read_QC_trim_pe host_refseq Boolean Internal component, do not modify TRUE Optional read_QC_trim_pe kraken_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim_pe kraken_db File A kraken2 database to use with the kraken2 optional task. The file must be a .tar.gz kraken2 database. Optional read_QC_trim_pe kraken_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_pe kraken_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim_pe midas_db File Database to use with MIDAS. Not required as one will be auto-selected when running the MIDAS task. Optional read_QC_trim_pe phix File The file containing the phix sequence to be used during bbduk task Optional read_QC_trim_pe read_processing String Options: \"trimmomatic\" or \"fastp\" to indicate which read trimming module to use trimmomatic Optional read_QC_trim_pe read_qc String Allows the user to decide between fastq_scan (default) and fastqc for the evaluation of read quality. fastq_scan Optional read_QC_trim_pe target_organism String The organism whose abundance the user wants to check in their reads. This should be a proper taxonomic name recognized by the Kraken database. Optional read_QC_trim_pe taxon_id Int Internal component, do not modify 0 Optional read_QC_trim_pe trim_quality_min_score Int The minimum quality score to keep during trimming 30 Optional read_QC_trim_pe trim_quality_trim_score Int The minimum quality score to keep during trimming 30 Optional read_QC_trim_pe trim_window_size Int The window size to use during trimming 4 Optional read_QC_trim_pe trimmomatic_args String Additional command-line arguments to use with trimmomatic Optional read_QC_trim_se adapters File Internal component, do not modify Optional read_QC_trim_se bbduk_memory Int Internal component, do not modify 8 Optional read_QC_trim_se call_kraken Boolean Internal component, do not modify FALSE Optional read_QC_trim_se call_midas Boolean Internal component, do not modify FALSE Optional read_QC_trim_se fastp_args String Internal component, do not modify --detect_adapter_for_pe -g -5 20 -3 20 Optional read_QC_trim_se kraken_cpu Int Internal component, do not modify 4 Optional read_QC_trim_se kraken_db File Internal component, do not modify Optional read_QC_trim_se kraken_disk_size Int Internal component, do not modify 100 Optional read_QC_trim_se kraken_memory Int Internal component, do not modify 8 Optional read_QC_trim_se midas_db File Internal component, do not modify Optional read_QC_trim_se phix File Internal component, do not modify Optional read_QC_trim_se read_processing String Internal component, do not modify trimmomatic Optional read_QC_trim_se read_qc String Internal component, do not modify fastq_scan Optional read_QC_trim_se target_organism String Internal component, do not modify Optional read_QC_trim_se trim_quality_min_score Int Internal component, do not modify 30 Optional read_QC_trim_se trim_window_size Int Internal component, do not modify 4 Optional read_QC_trim_se trimmomatic_args String Internal component, do not modify Optional sam_to_sorted_bam cpu Int Number of CPUs to allocate to the task 2 Optional sam_to_sorted_bam disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional sam_to_sorted_bam docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Optional sam_to_sorted_bam memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional sam_to_sorted_bam min_qual Int Minimum quality score for reads to be included in the analysis Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status freyja_fastq read1 File FASTQ file containing read1 sequences (Illumina or (ONT) Required freyja_fastq reference_genome File The reference genome to use; should match the reference used for alignment (Wuhan-Hu-1) Required freyja_fastq samplename String The name of the sample being analyzed Required freyja_fastq freyja_lineage_metadata File File containing the lineage metadata; the \"curated_lineages.json\" file found https://github.com/andersen-lab/Freyja/tree/main/freyja/data can be used for this variable. Does not need to be provided if update_db is true or if the freyja_pathogen is provided. Optional, Required bwa cpu Int Number of CPUs to allocate to the task 6 Optional bwa disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional bwa docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional bwa memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional freyja adapt Float adaptive lasso penalty parameter 0 Optional freyja bootstrap Boolean Perform bootstrapping FALSE Optional freyja confirmed_only Boolean Include only confirmed SARS-CoV-2 lineages FALSE Optional freyja cpu Int Number of CPUs to allocate to the task 2 Optional freyja disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional freyja docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/freyja:1.5.3 Optional freyja eps Float The minimum lineage abundance cut-off value 0.001 Optional freyja memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional freyja number_bootstraps Int The number of bootstraps to perform (only used if bootstrap = true) 100 Optional freyja update_db Boolean Updates the Freyja reference files (the usher barcodes and lineage metadata files) but will not save them as output (use Freyja_Update for that purpose). If set to true, the freyja_lineage_metadata and freyja_barcodes files are not required. FALSE Optional freyja_fastq depth_cutoff Int The minimum coverage depth with which to exclude sites below this value and group identical barcodes -- THIS MAY NOT WORK FOR NON-SARS-COV-2 ORGANISMS! 10 Optional freyja_fastq freyja_barcodes File Custom barcode file. Does not need to be provided if update_db is true if the freyja_pathogen is provided. Optional freyja_fastq freyja_pathogen String Pathogen of interest, used if not providing the barcodes and lineage metadata files. Options: SARS-CoV-2, MPXV, H5NX, H1N1pdm, FLU-B-VIC, MEASLESN450, MEASLES, RSVa, RSVb Optional freyja_fastq freyja_pathogen String Pathogen to be used by Freyja SARS-CoV-2 Optional freyja_fastq kraken2_target_organism String The organism whose abundance the user wants to check in their reads. This should be a proper taxonomic name recognized by the Kraken database. Severe acute respiratory syndrome coronavirus 2 Optional freyja_fastq ont Boolean Indicates if the input data is derived from an ONT instrument. FALSE Optional freyja_fastq primer_bed File The bed file containing the primers used when sequencing was performed Optional freyja_fastq read2 File Illumina reverse read file in FASTQ file format (compression optional) Optional freyja_fastq reference_gff File The GFF file for reference; should match the reference used for alignment (Wuhan-Hu-1) Optional freyja_fastq trimmomatic_min_length Int The minimum length cut-off when performing read cleaning 25 Optional get_fasta_genome_size cpu Int Number of CPUs to allocate to the task 1 Optional get_fasta_genome_size disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional get_fasta_genome_size docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/seqkit:2.4.0--h9ee0642_0 Optional get_fasta_genome_size memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional minimap2 cpu Int Number of CPUs to allocate to the task 2 Optional minimap2 disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional minimap2 docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/minimap2:2.22 Optional minimap2 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional minimap2 query2 File Internal component, do not modify Optional nanoplot_clean cpu Int Number of CPUs to allocate to the task 4 Optional nanoplot_clean disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoplot_clean docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Optional nanoplot_clean max_length Int The maximum length of clean reads, for which reads longer than the length specified will be hidden. 100000 Optional nanoplot_clean memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional nanoplot_raw cpu Int Number of CPUs to allocate to the task 4 Optional nanoplot_raw disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoplot_raw docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Optional nanoplot_raw max_length Int The maximum length of clean reads, for which reads longer than the length specified will be hidden. 100000 Optional nanoplot_raw memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional primer_trim cpu Int Number of CPUs to allocate to the task 2 Optional primer_trim disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional primer_trim docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional primer_trim keep_noprimer_reads Boolean Include reads with no primers TRUE Optional primer_trim memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim_ont artic_guppyplex_cpu Int Number of CPUs to allocate to the task 8 Optional read_QC_trim_ont artic_guppyplex_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_ont artic_guppyplex_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/artic-ncov2019:1.3.0-medaka-1.4.3 Optional read_QC_trim_ont artic_guppyplex_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional read_QC_trim_ont call_kraken Boolean Internal component, do not modify FALSE Optional read_QC_trim_ont downsampling_coverage Float Internal component, do not modify 150 Optional read_QC_trim_ont genome_length Int Internal component, do not modify Optional read_QC_trim_ont genome_length Int Length of the genome 5000000 Optional read_QC_trim_ont kraken2_recalculate_abundances_cpu Int Internal component, do not modify 4 Optional read_QC_trim_ont kraken2_recalculate_abundances_disk_size Int Internal component, do not modify 100 Optional read_QC_trim_ont kraken2_recalculate_abundances_docker Int Internal component, do not modify us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-08-28-v4 Optional read_QC_trim_ont kraken2_recalculate_abundances_memory Int Internal component, do not modify 8 Optional read_QC_trim_ont kraken_cpu Int Internal component, do not modify 4 Optional read_QC_trim_ont kraken_db File Internal component, do not modify Optional read_QC_trim_ont kraken_disk_size Int Internal component, do not modify 100 Optional read_QC_trim_ont kraken_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Optional read_QC_trim_ont kraken_memory Int Internal component, do not modify 8 Optional read_QC_trim_ont max_length Int Internal component, do not modify Optional read_QC_trim_ont min_length Int Internal component, do not modify Optional read_QC_trim_ont nanoq_cpu Int Number of CPUs to allocate to the task 2 Optional read_QC_trim_ont nanoq_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_ont nanoq_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/nanoq:0.9.0--hec16e2b_1 Optional read_QC_trim_ont nanoq_max_read_length Int Maximum read length to use for filtering Optional read_QC_trim_ont nanoq_max_read_qual Int Maximum read quality to use for filtering Optional read_QC_trim_ont nanoq_memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional read_QC_trim_ont nanoq_min_read_length Int Minimum read length to use for filtering Optional read_QC_trim_ont nanoq_min_read_qual Int Minimum read quality to use for filtering Optional read_QC_trim_ont ncbi_scrub_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim_ont ncbi_scrub_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_ont ncbi_scrub_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ncbi/sra-human-scrubber:2.2.1 Optional read_QC_trim_ont ncbi_scrub_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional read_QC_trim_ont rasusa_bases String Explicitly set the number of bases required e.g., 4.3kb, 7Tb, 9000, 4.1MB. If this option is given, --coverage and --genome-size are ignored Optional read_QC_trim_ont rasusa_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim_ont rasusa_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_ont rasusa_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/rasusa:2.1.0 Optional read_QC_trim_ont rasusa_fraction_of_reads Float Subsample to a fraction of the reads - e.g., 0.5 samples half the reads Optional read_QC_trim_ont rasusa_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim_ont rasusa_number_of_reads Int Subsample to a specific number of reads Optional read_QC_trim_ont rasusa_seed Int Random seed to use Optional read_QC_trim_ont run_prefix String Internal component, do not modify Optional read_QC_trim_ont target_organism String Internal component, do not modify Optional read_QC_trim_pe adapters File Internal component, do not modify Optional read_QC_trim_pe bbduk_memory Int Internal component, do not modify 8 Optional read_QC_trim_pe call_kraken Boolean Internal component, do not modify FALSE Optional read_QC_trim_pe call_midas Boolean Internal component, do not modify FALSE Optional read_QC_trim_pe extract_unclassified Boolean Internal component, do not modify FALSE Optional read_QC_trim_pe fastp_args String Internal component, do not modify --detect_adapter_for_pe -g -5 20 -3 20 Optional read_QC_trim_pe host String Internal component, do not modify Optional read_QC_trim_pe host_complete_only Boolean Internal component, do not modify FALSE Optional read_QC_trim_pe host_decontaminate_mem Int Internal component, do not modify 32 Optional read_QC_trim_pe host_is_accession Boolean Internal component, do not modify FALSE Optional read_QC_trim_pe host_refseq Boolean Internal component, do not modify TRUE Optional read_QC_trim_pe kraken_cpu Int Internal component, do not modify 4 Optional read_QC_trim_pe kraken_db File Internal component, do not modify Optional read_QC_trim_pe kraken_disk_size Int Internal component, do not modify 100 Optional read_QC_trim_pe kraken_memory Int Internal component, do not modify 8 Optional read_QC_trim_pe midas_db File Internal component, do not modify Optional read_QC_trim_pe phix File Internal component, do not modify Optional read_QC_trim_pe read_processing String Internal component, do not modify trimmomatic Optional read_QC_trim_pe read_qc String Internal component, do not modify fastq_scan Optional read_QC_trim_pe target_organism String Internal component, do not modify Optional read_QC_trim_pe taxon_id Int Internal component, do not modify 0 Optional read_QC_trim_pe trim_quality_min_score Int The minimum quality score to keep during trimming 30 Optional read_QC_trim_pe trim_quality_trim_score Int Internal component, do not modify 30 Optional read_QC_trim_pe trim_window_size Int Internal component, do not modify 4 Optional read_QC_trim_pe trimmomatic_args String Internal component, do not modify Optional read_QC_trim_se adapters File A FASTA file containing adapter sequences Optional read_QC_trim_se bbduk_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim_se call_kraken Boolean True/False variable that determines if the Kraken2 task should be called; for non-TheiaCoV workflows, the <code>kraken_db</code> variable must be provided. FALSE Optional read_QC_trim_se call_midas Boolean True/False variable that determines if the MIDAS task should be called. FALSE Optional read_QC_trim_se fastp_args String Additional arguments to use with fastp --detect_adapter_for_pe -g -5 20 -3 20 Optional read_QC_trim_se kraken_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim_se kraken_db File A kraken2 database to use with the kraken2 optional task. The file must be a .tar.gz kraken2 database. Optional read_QC_trim_se kraken_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_se kraken_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim_se midas_db File Database to use with MIDAS. Not required as one will be auto-selected when running the MIDAS task. Optional read_QC_trim_se phix File The file containing the phix sequence to be used during bbduk task Optional read_QC_trim_se read_processing String Options: \"trimmomatic\" or \"fastp\" to indicate which read trimming module to use trimmomatic Optional read_QC_trim_se read_qc String Allows the user to decide between fastq_scan (default) and fastqc for the evaluation of read quality. fastq_scan Optional read_QC_trim_se target_organism String The organism whose abundance the user wants to check in their reads. This should be a proper taxonomic name recognized by the Kraken database. Optional read_QC_trim_se trim_quality_min_score Int The minimum quality score to keep during trimming 30 Optional read_QC_trim_se trim_window_size Int The window size to use during trimming 4 Optional read_QC_trim_se trimmomatic_args String Additional command-line arguments to use with trimmomatic Optional sam_to_sorted_bam cpu Int Number of CPUs to allocate to the task 2 Optional sam_to_sorted_bam disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional sam_to_sorted_bam docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Optional sam_to_sorted_bam memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional sam_to_sorted_bam min_qual Int Minimum quality score for reads to be included in the analysis Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status freyja_fastq read1 File FASTQ file containing read1 sequences (Illumina or (ONT) Required freyja_fastq reference_genome File The reference genome to use; should match the reference used for alignment (Wuhan-Hu-1) Required freyja_fastq samplename String The name of the sample being analyzed Required freyja_fastq freyja_lineage_metadata File File containing the lineage metadata; the \"curated_lineages.json\" file found https://github.com/andersen-lab/Freyja/tree/main/freyja/data can be used for this variable. Does not need to be provided if update_db is true or if the freyja_pathogen is provided. Optional, Required bwa cpu Int Number of CPUs to allocate to the task 6 Optional bwa disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional bwa docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional bwa memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional freyja adapt Float adaptive lasso penalty parameter 0 Optional freyja bootstrap Boolean Perform bootstrapping FALSE Optional freyja confirmed_only Boolean Include only confirmed SARS-CoV-2 lineages FALSE Optional freyja cpu Int Number of CPUs to allocate to the task 2 Optional freyja disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional freyja docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/freyja:1.5.3 Optional freyja eps Float The minimum lineage abundance cut-off value 0.001 Optional freyja memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional freyja number_bootstraps Int The number of bootstraps to perform (only used if bootstrap = true) 100 Optional freyja update_db Boolean Updates the Freyja reference files (the usher barcodes and lineage metadata files) but will not save them as output (use Freyja_Update for that purpose). If set to true, the freyja_lineage_metadata and freyja_barcodes files are not required. FALSE Optional freyja_fastq depth_cutoff Int The minimum coverage depth with which to exclude sites below this value and group identical barcodes -- THIS MAY NOT WORK FOR NON-SARS-COV-2 ORGANISMS! 10 Optional freyja_fastq freyja_barcodes File Custom barcode file. Does not need to be provided if update_db is true if the freyja_pathogen is provided. Optional freyja_fastq freyja_pathogen String Pathogen of interest, used if not providing the barcodes and lineage metadata files. Options: SARS-CoV-2, MPXV, H5NX, H1N1pdm, FLU-B-VIC, MEASLESN450, MEASLES, RSVa, RSVb Optional freyja_fastq freyja_pathogen String Pathogen to be used by Freyja SARS-CoV-2 Optional freyja_fastq kraken2_target_organism String The organism whose abundance the user wants to check in their reads. This should be a proper taxonomic name recognized by the Kraken database. Severe acute respiratory syndrome coronavirus 2 Optional freyja_fastq ont Boolean Indicates if the input data is derived from an ONT instrument. FALSE Optional freyja_fastq primer_bed File The bed file containing the primers used when sequencing was performed Optional freyja_fastq read2 File Illumina reverse read file in FASTQ file format (compression optional) Optional freyja_fastq reference_gff File The GFF file for reference; should match the reference used for alignment (Wuhan-Hu-1) Optional freyja_fastq trimmomatic_min_length Int The minimum length cut-off when performing read cleaning 25 Optional get_fasta_genome_size cpu Int Number of CPUs to allocate to the task 1 Optional get_fasta_genome_size disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional get_fasta_genome_size docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/seqkit:2.4.0--h9ee0642_0 Optional get_fasta_genome_size memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional minimap2 cpu Int Number of CPUs to allocate to the task 2 Optional minimap2 disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional minimap2 docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/minimap2:2.22 Optional minimap2 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional minimap2 query2 File Internal component, do not modify Optional nanoplot_clean cpu Int Number of CPUs to allocate to the task 4 Optional nanoplot_clean disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoplot_clean docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Optional nanoplot_clean max_length Int The maximum length of clean reads, for which reads longer than the length specified will be hidden. 100000 Optional nanoplot_clean memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional nanoplot_raw cpu Int Number of CPUs to allocate to the task 4 Optional nanoplot_raw disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoplot_raw docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Optional nanoplot_raw max_length Int The maximum length of clean reads, for which reads longer than the length specified will be hidden. 100000 Optional nanoplot_raw memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional primer_trim cpu Int Internal component, do not modify Optional primer_trim disk_size Int Internal component, do not modify Optional primer_trim docker String Internal component, do not modify Optional primer_trim keep_noprimer_reads Boolean Internal component, do not modify Optional primer_trim memory Int Internal component, do not modify Optional read_QC_trim_ont artic_guppyplex_cpu Int Number of CPUs to allocate to the task 8 Optional read_QC_trim_ont artic_guppyplex_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_ont artic_guppyplex_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/artic-ncov2019:1.3.0-medaka-1.4.3 Optional read_QC_trim_ont artic_guppyplex_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional read_QC_trim_ont call_kraken Boolean True/False variable that determines if the Kraken2 task should be called; for non-TheiaCoV workflows, the <code>kraken_db</code> variable must be provided. FALSE Optional read_QC_trim_ont downsampling_coverage Float Internal component, do not modify 150 Optional read_QC_trim_ont genome_length Int Internal component, do not modify Optional read_QC_trim_ont genome_length Int Length of the genome 5000000 Optional read_QC_trim_ont kraken2_recalculate_abundances_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim_ont kraken2_recalculate_abundances_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_ont kraken2_recalculate_abundances_docker Int The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-08-28-v4 Optional read_QC_trim_ont kraken2_recalculate_abundances_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim_ont kraken_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim_ont kraken_db File A kraken2 database to use with the kraken2 optional task. The file must be a .tar.gz kraken2 database. Optional read_QC_trim_ont kraken_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_ont kraken_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Optional read_QC_trim_ont kraken_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim_ont max_length Int Internal component, do not modify Optional read_QC_trim_ont min_length Int Internal component, do not modify Optional read_QC_trim_ont nanoq_cpu Int Number of CPUs to allocate to the task 2 Optional read_QC_trim_ont nanoq_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_ont nanoq_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/nanoq:0.9.0--hec16e2b_1 Optional read_QC_trim_ont nanoq_max_read_length Int Maximum read length to use for filtering Optional read_QC_trim_ont nanoq_max_read_qual Int Maximum read quality to use for filtering Optional read_QC_trim_ont nanoq_memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional read_QC_trim_ont nanoq_min_read_length Int Minimum read length to use for filtering Optional read_QC_trim_ont nanoq_min_read_qual Int Minimum read quality to use for filtering Optional read_QC_trim_ont ncbi_scrub_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim_ont ncbi_scrub_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_ont ncbi_scrub_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ncbi/sra-human-scrubber:2.2.1 Optional read_QC_trim_ont ncbi_scrub_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional read_QC_trim_ont rasusa_bases String Explicitly set the number of bases required e.g., 4.3kb, 7Tb, 9000, 4.1MB. If this option is given, --coverage and --genome-size are ignored Optional read_QC_trim_ont rasusa_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim_ont rasusa_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim_ont rasusa_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/rasusa:2.1.0 Optional read_QC_trim_ont rasusa_fraction_of_reads Float Subsample to a fraction of the reads - e.g., 0.5 samples half the reads Optional read_QC_trim_ont rasusa_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim_ont rasusa_number_of_reads Int Subsample to a specific number of reads Optional read_QC_trim_ont rasusa_seed Int Random seed to use Optional read_QC_trim_ont run_prefix String Internal component, do not modify Optional read_QC_trim_ont target_organism String This string is searched for in the kraken2 outputs to extract the read percentage Optional read_QC_trim_pe adapters File Internal component, do not modify Optional read_QC_trim_pe bbduk_memory Int Internal component, do not modify 8 Optional read_QC_trim_pe call_kraken Boolean Internal component, do not modify FALSE Optional read_QC_trim_pe call_midas Boolean Internal component, do not modify FALSE Optional read_QC_trim_pe extract_unclassified Boolean Internal component, do not modify FALSE Optional read_QC_trim_pe fastp_args String Internal component, do not modify --detect_adapter_for_pe -g -5 20 -3 20 Optional read_QC_trim_pe host String Internal component, do not modify Optional read_QC_trim_pe host_complete_only Boolean Internal component, do not modify FALSE Optional read_QC_trim_pe host_decontaminate_mem Int Internal component, do not modify 32 Optional read_QC_trim_pe host_is_accession Boolean Internal component, do not modify FALSE Optional read_QC_trim_pe host_refseq Boolean Internal component, do not modify TRUE Optional read_QC_trim_pe kraken_cpu Int Internal component, do not modify 4 Optional read_QC_trim_pe kraken_db File Internal component, do not modify Optional read_QC_trim_pe kraken_disk_size Int Internal component, do not modify 100 Optional read_QC_trim_pe kraken_memory Int Internal component, do not modify 8 Optional read_QC_trim_pe midas_db File Internal component, do not modify Optional read_QC_trim_pe phix File Internal component, do not modify Optional read_QC_trim_pe read_processing String Internal component, do not modify trimmomatic Optional read_QC_trim_pe read_qc String Internal component, do not modify fastq_scan Optional read_QC_trim_pe target_organism String Internal component, do not modify Optional read_QC_trim_pe taxon_id Int Internal component, do not modify 0 Optional read_QC_trim_pe trim_quality_min_score Int The minimum quality score to keep during trimming 30 Optional read_QC_trim_pe trim_quality_trim_score Int Internal component, do not modify 30 Optional read_QC_trim_pe trim_window_size Int Internal component, do not modify 4 Optional read_QC_trim_pe trimmomatic_args String Internal component, do not modify Optional read_QC_trim_se adapters File Internal component, do not modify Optional read_QC_trim_se bbduk_memory Int Internal component, do not modify 8 Optional read_QC_trim_se call_kraken Boolean Internal component, do not modify FALSE Optional read_QC_trim_se call_midas Boolean Internal component, do not modify FALSE Optional read_QC_trim_se fastp_args String Internal component, do not modify --detect_adapter_for_pe -g -5 20 -3 20 Optional read_QC_trim_se kraken_cpu Int Internal component, do not modify 4 Optional read_QC_trim_se kraken_db File Internal component, do not modify Optional read_QC_trim_se kraken_disk_size Int Internal component, do not modify 100 Optional read_QC_trim_se kraken_memory Int Internal component, do not modify 8 Optional read_QC_trim_se midas_db File Internal component, do not modify Optional read_QC_trim_se phix File Internal component, do not modify Optional read_QC_trim_se read_processing String Internal component, do not modify trimmomatic Optional read_QC_trim_se read_qc String Internal component, do not modify fastq_scan Optional read_QC_trim_se target_organism String Internal component, do not modify Optional read_QC_trim_se trim_quality_min_score Int Internal component, do not modify 30 Optional read_QC_trim_se trim_window_size Int Internal component, do not modify 4 Optional read_QC_trim_se trimmomatic_args String Internal component, do not modify Optional sam_to_sorted_bam cpu Int Number of CPUs to allocate to the task 2 Optional sam_to_sorted_bam disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional sam_to_sorted_bam docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Optional sam_to_sorted_bam memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional sam_to_sorted_bam min_qual Int Minimum quality score for reads to be included in the analysis Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/genomic_characterization/freyja/#analysis-tasks","title":"Analysis Tasks","text":"Illumina paired-end input dataIllumina single-end input dataONT input data <code>read_QC_trim</code>: Read Quality Trimming, Adapter Removal, Quantification, and Identification <p><code>read_QC_trim</code> is a sub-workflow that removes low-quality reads, low-quality regions of reads, and sequencing adapters to improve data quality. It uses a number of tasks, described below. The differences between the PE and SE versions of the <code>read_QC_trim</code> sub-workflow lie in the default parameters, the use of two or one input read file(s), and the different output files.</p> <code>HRRT</code>: Human Host Sequence Removal <p>All reads of human origin are removed, including their mates, by using NCBI's human read removal tool (HRRT). </p> <p>HRRT is based on the SRA Taxonomy Analysis Tool and employs a k-mer database constructed of k-mers from Eukaryota derived from all human RefSeq records with any k-mers found in non-Eukaryota RefSeq records subtracted from the database.</p> <p>NCBI-Scrub Technical Details</p> Links Task task_ncbi_scrub.wdl Software Source Code HRRT on GitHub Software Documentation HRRT on NCBI <p>By default, <code>read_processing</code> is set to <code>\"trimmomatic\"</code>. To use <code>fastp</code> instead, set <code>read_processing</code> to <code>\"fastp\"</code>. These tasks are mutually exclusive.</p> <code>Trimmomatic</code>: Read Trimming (default) <p>Read proccessing is available via <code>Trimmomatic</code> by default.</p> <p>Trimmomatic trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>Trimmomatic</code> Technical Details</p> Links Task task_trimmomatic.wdl Software Source Code Trimmomatic on GitHub Software Documentation Trimmomatic Website Original Publication(s) Trimmomatic: a flexible trimmer for Illumina sequence data <code>fastp</code>: Read Trimming (alternative) <p>To activate this task, set <code>read_processing</code> to <code>\"fastp\"</code>.</p> <p><code>fastp</code> trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>fastp</code> also has additional default parameters and features that are not a part of <code>trimmomatic</code>'s default configuration.</p> <code>fastp</code> default read-trimming parameters Parameter Explanation -g enables polyG tail trimming -5 20 enables read end-trimming -3 20 enables read end-trimming --detect_adapter_for_pe enables adapter-trimming only for paired-end reads <p>Additional arguments can be passed using the <code>fastp_args</code> optional parameter.</p> <p>Trimmomatic and fastp Technical Details</p> Links Task task_fastp.wdl Software Source Code fastp on GitHub Software Documentation fastp on GitHub Original Publication(s) fastp: an ultra-fast all-in-one FASTQ preprocessor <code>BBDuk</code>: Adapter Trimming and PhiX Removal <p>Adapters are manufactured oligonucleotide sequences attached to DNA fragments during the library preparation process. In Illumina sequencing, these adapter sequences are required for attaching reads to flow cells. You can read more about Illumina adapters here. For genome analysis, it's important to remove these sequences since they're not actually from your sample. If you don't remove them, the downstream analysis may be affected.</p> <p>The <code>bbduk</code> task removes adapters from sequence reads. To do this:</p> <ul> <li>Repair from the BBTools package reorders reads in paired fastq files to ensure the forward and reverse reads of a pair are in the same position in the two fastq files (it re-pairs).</li> <li>BBDuk  (\"Bestus Bioinformaticus\" Decontamination Using Kmers) is then used to trim the adapters and filter out all reads that have a 31-mer match to PhiX, which is commonly added to Illumina sequencing runs to monitor and/or improve overall run quality.</li> </ul> <p>BBDuk Technical Details</p> Links Task task_bbduk.wdl Software Source Code BBMap on SourceForge Software Documentation BBDuk Guide (archived) <p>By default, <code>read_qc</code> is set to <code>\"fastq_scan\"</code>. To use <code>fastqc</code> instead, set <code>read_qc</code> to <code>\"fastqc\"</code>. These tasks are mutually exclusive.</p> <code>fastq-scan</code>: Read Quantification (default) <p>Read quantification is available via <code>fastq-scan</code> by default.</p> <p><code>fastq-scan</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p><code>fastq-scan</code> Technical Details</p> Links Task task_fastq_scan.wdl Software Source Code fastq-scan on GitHub Software Documentation fastq-scan on GitHub <code>FastQC</code>: Read Quantification (alternative) <p>To activate this task, set <code>read_qc</code> to <code>\"fastqc\"</code>.</p> <p><code>FastQC</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>This tool also provides a graphical visualization of the read quality.</p> <p><code>FastQC</code> Technical Details</p> Links Task task_fastqc.wdl Software Source Code FastQC on Github Software Documentation FastQC Website <p>read_QC_trim Technical Details</p> Links Subworkflow wf_read_QC_trim_pe.wdlwf_read_QC_trim_se.wdl <code>bwa</code> Details <p>This task aligns the cleaned short reads (Illumina) to the reference genome provided by the user.</p> <p>BWA Technical Details</p> Links Task task_bwa.wdl Software Source Code BWA on GitHub Software Documentation BWA Documentation Original Publication(s) Fast and accurate short read alignment with Burrows-Wheeler transform <code>primer_trim</code> Details <p>This task trims the primer sequences from the aligned bam file with iVar. The optional input, <code>keep_noprimer_reads</code>, does not have to be modified.</p> <p>Primer Trim Technical Details</p> Links Task task_ivar_primer_trim.wdl Software Source Code https://github.com/andersen-lab/ivar Software Documentation https://andersen-lab.github.io/ivar/html/manualpage.html Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar <code>read_QC_trim</code>: Read Quality Trimming, Adapter Removal, Quantification, and Identification <p><code>read_QC_trim</code> is a sub-workflow that removes low-quality reads, low-quality regions of reads, and sequencing adapters to improve data quality. It uses a number of tasks, described below. The differences between the PE and SE versions of the <code>read_QC_trim</code> sub-workflow lie in the default parameters, the use of two or one input read file(s), and the different output files.</p> <code>HRRT</code>: Human Host Sequence Removal <p>All reads of human origin are removed, including their mates, by using NCBI's human read removal tool (HRRT). </p> <p>HRRT is based on the SRA Taxonomy Analysis Tool and employs a k-mer database constructed of k-mers from Eukaryota derived from all human RefSeq records with any k-mers found in non-Eukaryota RefSeq records subtracted from the database.</p> <p>NCBI-Scrub Technical Details</p> Links Task task_ncbi_scrub.wdl Software Source Code HRRT on GitHub Software Documentation HRRT on NCBI <p>By default, <code>read_processing</code> is set to <code>\"trimmomatic\"</code>. To use <code>fastp</code> instead, set <code>read_processing</code> to <code>\"fastp\"</code>. These tasks are mutually exclusive.</p> <code>Trimmomatic</code>: Read Trimming (default) <p>Read proccessing is available via <code>Trimmomatic</code> by default.</p> <p>Trimmomatic trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>Trimmomatic</code> Technical Details</p> Links Task task_trimmomatic.wdl Software Source Code Trimmomatic on GitHub Software Documentation Trimmomatic Website Original Publication(s) Trimmomatic: a flexible trimmer for Illumina sequence data <code>fastp</code>: Read Trimming (alternative) <p>To activate this task, set <code>read_processing</code> to <code>\"fastp\"</code>.</p> <p><code>fastp</code> trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>fastp</code> also has additional default parameters and features that are not a part of <code>trimmomatic</code>'s default configuration.</p> <code>fastp</code> default read-trimming parameters Parameter Explanation -g enables polyG tail trimming -5 20 enables read end-trimming -3 20 enables read end-trimming --detect_adapter_for_pe enables adapter-trimming only for paired-end reads <p>Additional arguments can be passed using the <code>fastp_args</code> optional parameter.</p> <p>Trimmomatic and fastp Technical Details</p> Links Task task_fastp.wdl Software Source Code fastp on GitHub Software Documentation fastp on GitHub Original Publication(s) fastp: an ultra-fast all-in-one FASTQ preprocessor <code>BBDuk</code>: Adapter Trimming and PhiX Removal <p>Adapters are manufactured oligonucleotide sequences attached to DNA fragments during the library preparation process. In Illumina sequencing, these adapter sequences are required for attaching reads to flow cells. You can read more about Illumina adapters here. For genome analysis, it's important to remove these sequences since they're not actually from your sample. If you don't remove them, the downstream analysis may be affected.</p> <p>The <code>bbduk</code> task removes adapters from sequence reads. To do this:</p> <ul> <li>Repair from the BBTools package reorders reads in paired fastq files to ensure the forward and reverse reads of a pair are in the same position in the two fastq files (it re-pairs).</li> <li>BBDuk  (\"Bestus Bioinformaticus\" Decontamination Using Kmers) is then used to trim the adapters and filter out all reads that have a 31-mer match to PhiX, which is commonly added to Illumina sequencing runs to monitor and/or improve overall run quality.</li> </ul> <p>BBDuk Technical Details</p> Links Task task_bbduk.wdl Software Source Code BBMap on SourceForge Software Documentation BBDuk Guide (archived) <p>By default, <code>read_qc</code> is set to <code>\"fastq_scan\"</code>. To use <code>fastqc</code> instead, set <code>read_qc</code> to <code>\"fastqc\"</code>. These tasks are mutually exclusive.</p> <code>fastq-scan</code>: Read Quantification (default) <p>Read quantification is available via <code>fastq-scan</code> by default.</p> <p><code>fastq-scan</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p><code>fastq-scan</code> Technical Details</p> Links Task task_fastq_scan.wdl Software Source Code fastq-scan on GitHub Software Documentation fastq-scan on GitHub <code>FastQC</code>: Read Quantification (alternative) <p>To activate this task, set <code>read_qc</code> to <code>\"fastqc\"</code>.</p> <p><code>FastQC</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>This tool also provides a graphical visualization of the read quality.</p> <p><code>FastQC</code> Technical Details</p> Links Task task_fastqc.wdl Software Source Code FastQC on Github Software Documentation FastQC Website <p>read_QC_trim Technical Details</p> Links Subworkflow wf_read_QC_trim_pe.wdlwf_read_QC_trim_se.wdl <code>bwa</code> Details <p>This task aligns the cleaned short reads (Illumina) to the reference genome provided by the user.</p> <p>BWA Technical Details</p> Links Task task_bwa.wdl Software Source Code BWA on GitHub Software Documentation BWA Documentation Original Publication(s) Fast and accurate short read alignment with Burrows-Wheeler transform <code>primer_trim</code> Details <p>This task trims the primer sequences from the aligned bam file with iVar. The optional input, <code>keep_noprimer_reads</code>, does not have to be modified.</p> <p>Primer Trim Technical Details</p> Links Task task_ivar_primer_trim.wdl Software Source Code https://github.com/andersen-lab/ivar Software Documentation https://andersen-lab.github.io/ivar/html/manualpage.html Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar <code>read_QC_trim_ont</code>: Read Quality Trimming, Quantification, and Identification <p><code>read_QC_trim_ont</code> is a sub-workflow that filters low-quality reads and trims low-quality regions of reads. It uses several tasks, described below.</p> <code>HRRT</code>: Human Host Sequence Removal <p>All reads of human origin are removed, including their mates, by using NCBI's human read removal tool (HRRT). </p> <p>HRRT is based on the SRA Taxonomy Analysis Tool and employs a k-mer database constructed of k-mers from Eukaryota derived from all human RefSeq records with any k-mers found in non-Eukaryota RefSeq records subtracted from the database.</p> <p>NCBI-Scrub Technical Details</p> Links Task task_ncbi_scrub.wdl Software Source Code HRRT on GitHub Software Documentation HRRT on NCBI <code>artic_guppyplex</code>: Read Filtering <p>Reads are filtered by length with <code>artic_guppyplex</code>, which is a part of the <code>ARTIC</code> protocol. Since TheiaCoV was developed primarily for amplicon-based viral sequencing, this task is included to remove chimeric reads that are either too short or too long.</p> <p>artic_guppyplex Technical Details</p> Links Task task_artic_guppyplex.wdl Software Source Code ARTIC on GitHub Software Documentation ARTIC Documentation <code>Kraken2</code>: Read Identification <p><code>Kraken2</code> is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>Kraken2 is run on both the raw and clean reads.</p> <p>Database-dependent</p> <p>This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz</code>.</p> <p>Kraken2 Technical Details</p> Links Task task_kraken2.wdl Software Source Code Kraken2 on GitHub Software Documentation Kraken2 Documentation Original Publication(s) Improved metagenomic analysis with Kraken 2 <code>NanoPlot</code>: Read Quantification <p>NanoPlot is used for the determination of mean quality scores, read lengths, and number of reads. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>While this task currently is run outside of the <code>read_QC_trim_ont</code> workflow, it is being included here as it calculates statistics on the read data. This is done so that the actual assembly genome lengths can be used (if an estimated genome length is not provided by the user) to ensure the estimated coverage statistics are accurate.</p> <p>NanoPlot Technical Details</p> Links Task task_nanoplot.wdl Software Source Code NanoPlot on GitHub Software Documentation NanoPlot Documentation Original Publication(s) NanoPack2: population-scale evaluation of long-read sequencing data <p>read_QC_trim_ont Technical Details</p> Links Subworkflow wf_read_QC_trim_ont.wdl <code>minimap2</code>: Read Alignment Details <p><code>minimap2</code> is a popular aligner that is used to align reads (or assemblies) to an assembly file. In minimap2, \"modes\" are a group of preset options.</p> <p>The mode used in this task is <code>map-ont</code> which is the default mode for long reads and indicates that long reads of ~10% error rates should be aligned to the reference genome. The output file is in SAM format.</p> <p>For more information regarding modes and the available options for <code>minimap2</code>, please see the minimap2 manpage</p> <p>minimap2 Technical Details</p> Links Task task_minimap2.wdl Software Source Code minimap2 on GitHub Software Documentation minimap2 Original Publication(s) Minimap2: pairwise alignment for nucleotide sequences <code>freyja</code> Details <p>The Freyja task will call variants and capture sequencing depth information to identify the relative abundance of lineages present. Optionally, if <code>bootstrap</code> is set to true, bootstrapping will be performed. After the optional bootstrapping step, the variants are demixed.</p> <p>Freyja Technical Details</p> Links Task task_freyja_one_sample.wdl Software Source Code https://github.com/andersen-lab/Freyja Software Documentation https://andersen-lab.github.io/Freyja/index.html#"},{"location":"workflows/genomic_characterization/freyja/#outputs_1","title":"Outputs","text":"<p>The main output file used in subsequent Freyja workflows is found under the <code>freyja_demixed</code> column. This TSV file takes on the following format:</p> sample name summarized [('Delta', 0.65), ('Other', 0.25), ('Alpha', 0.1')] lineages ['B.1.617.2' 'B.1.2' 'AY.6' 'Q.3'] abundances \"[0.5 0.25 0.15 0.1]\" resid 3.14159 coverage 95.8 <ul> <li>The <code>summarized</code>\u00a0array denotes a sum of all lineage abundances in a particular WHO designation (i.e. B.1.617.2 and AY.6 abundances are summed in the above example), otherwise they are grouped into \"Other\".</li> <li>The <code>lineage</code>\u00a0array lists the identified lineages in descending order</li> <li>The <code>abundances</code>\u00a0array contains the corresponding abundances estimates.</li> <li>The value of\u00a0<code>resid</code>\u00a0corresponds to the residual of the weighted least absolute deviation problem used to estimate lineage abundances.</li> <li>The\u00a0<code>coverage</code>\u00a0value provides the 10x coverage estimate (percent of sites with 10 or greater reads)</li> </ul> <p>Click \"Ignore empty outputs\"</p> <p>When running the Freyja_FASTQ_PHB workflow, it is recommended to select the \"Ignore empty outputs\" option in the Terra UI. This will hide the output columns that will not be generated for your input data type.</p> Illumina paired-end output dataIllumina single-end output dataONT output data Variable Type Description aligned_bai String Index companion file to the bam file generated during the consensus assembly process aligned_bam String Sorted BAM file containing the alignments of reads to the reference genome alignment_method String The method used to generate the alignment bbduk_docker String The Docker image for bbduk, which was used to remove the adapters from the sequences bwa_version String Version of BWA software used fastp_html_report String The HTML report made with fastp fastp_version String The version of fastp used fastq_scan_clean1_json String The JSON file output from <code>fastq-scan</code> containing summary stats about clean forward read quality and length fastq_scan_clean2_json File The JSON file output from <code>fastq-scan</code> containing summary stats about clean reverse read quality and length fastq_scan_num_reads_clean1 String The number of forward reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_clean2 Int The number of reverse reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_clean_pairs String The number of read pairs after cleaning as calculated by fastq_scan fastq_scan_num_reads_raw1 String The number of input forward reads as calculated by fastq_scan fastq_scan_num_reads_raw2 Int The number of input reserve reads as calculated by fastq_scan fastq_scan_num_reads_raw_pairs String The number of input read pairs as calculated by fastq_scan fastq_scan_raw1_json String The JSON file output from <code>fastq-scan</code> containing summary stats about raw forward read quality and length fastq_scan_raw2_json File The JSON file output from <code>fastq-scan</code> containing summary stats about raw reverse read quality and length fastq_scan_version String The version of fastq_scan fastqc_clean1_html String An HTML file that provides a graphical visualization of clean forward read quality from fastqc to open in an internet browser fastqc_clean2_html File An HTML file that provides a graphical visualization of clean reverse read quality from fastqc to open in an internet browser fastqc_docker String The Docker container used for fastqc fastqc_num_reads_clean1 String The number of forward reads after cleaning by fastqc fastqc_num_reads_clean2 Int The number of reverse reads after cleaning by fastqc fastqc_num_reads_clean_pairs String The number of read pairs after cleaning by fastqc fastqc_num_reads_raw1 String The number of input forward reads by fastqc before cleaning fastqc_num_reads_raw2 Int The number of input reverse reads by fastqc before cleaning fastqc_num_reads_raw_pairs String The number of input read pairs by fastqc before cleaning fastqc_raw1_html String An HTML file that provides a graphical visualization of raw forward read quality from fastqc to open in an internet browser fastqc_raw2_html File An HTML file that provides a graphical visualization of raw reverse read quality from fastqc to open in an internet browser fastqc_version String Version of fastqc software used freyja_abundances String Abundances estimates identified by Freyja and parsed from freyja_demixed file freyja_barcode_file String Barcode file used with Freyja freyja_barcode_version String Name of barcode file used, or the date if update_db is true freyja_bootstrap_lineages String A CSV that contains the 0.025, 0.05, 0.25, 0.5 (median), 0.75, 0.95, and 0.975 percentiles for each lineage freyja_bootstrap_lineages_pdf String A boxplot of the bootstrap lineages CSV file freyja_bootstrap_summary String A CSV that contains the 0.025, 0.05, 0.25, 0.5 (median), 0.75, 0.95, and 0.975 percentiles for each WHO designated VOI/VOC freyja_bootstrap_summary_pdf String A boxplot of the bootstrap summary CSV file freyja_coverage Float Coverage identified by Freyja and parsed from freyja_demixed file freyja_demixed File The main output TSV; see the section directly above this table for an explanation freyja_demixed_parsed File Parsed freyja_demixed file, containing the same information, for easy result concatenation freyja_depths File A TSV listing the depth of every position freyja_fastq_wf_analysis_date String Date of analysis freyja_fastq_wf_version String The version of the Public Health Bioinformatics (PHB) repository used freyja_lineage_metadata_file String Metadata file for lineages identified by Freyja freyja_lineages String Lineages in descending order identified by Freyja and parsed from freyja_demixed file freyja_metadata_version String Name of lineage metadata file used, or the date if update_db is true freyja_resid String Residual of the weighted least absolute deviation problem used to estimate lineage abundances identified by Freyja and parsed from freyja_demixed file freyja_summarized String Sum of all lineage abundances in a particular WHO designation identified by Freyja and parsed from freyja_demixed file freyja_variants File The TSV file containing the variants identified by Freyja freyja_version String version of Freyja used ivar_version_primtrim String Version of iVar for running the iVar trim command kraken_human Float Percent of human read data detected using the Kraken2 software kraken_human_dehosted Float Percent of human read data detected using the Kraken2 software after host removal kraken_report String Full Kraken report kraken_report_dehosted File Full Kraken report after host removal kraken_sc2 String Percent of SARS-CoV-2 read data detected using the Kraken2 software kraken_sc2_dehosted String Percent of SARS-CoV-2 read data detected using the Kraken2 software after host removal kraken_version String Version of Kraken software used primer_bed_name String Name of the primer bed files used for primer trimming primer_trimmed_read_percent Float Percentage of read data with primers trimmed as determined by iVar trim read1_clean File Forward read file after quality trimming and adapter removal read1_dehosted File The dehosted forward reads file; suggested read file for SRA submission read2_clean File Reverse read file after quality trimming and adapter removal read2_dehosted File The dehosted reverse reads file; suggested read file for SRA submission samtools_version String The version of SAMtools used to sort and index the alignment file samtools_version_primtrim String The version of SAMtools used to create the pileup before running iVar trim trimmomatic_docker String The docker image used for the trimmomatic module in this workflow trimmomatic_version String The version of Trimmomatic used Variable Type Description aligned_bai String Index companion file to the bam file generated during the consensus assembly process aligned_bam String Sorted BAM file containing the alignments of reads to the reference genome alignment_method String The method used to generate the alignment bbduk_docker String The Docker image for bbduk, which was used to remove the adapters from the sequences bwa_version String Version of BWA software used fastp_html_report String The HTML report made with fastp fastp_version String The version of fastp used fastq_scan_clean1_json String The JSON file output from <code>fastq-scan</code> containing summary stats about clean forward read quality and length fastq_scan_num_reads_clean1 String The number of forward reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_raw1 String The number of input forward reads as calculated by fastq_scan fastq_scan_raw1_json String The JSON file output from <code>fastq-scan</code> containing summary stats about raw forward read quality and length fastq_scan_version String The version of fastq_scan fastqc_clean1_html String An HTML file that provides a graphical visualization of clean forward read quality from fastqc to open in an internet browser fastqc_docker String The Docker container used for fastqc fastqc_num_reads_clean1 String The number of forward reads after cleaning by fastqc fastqc_num_reads_raw1 String The number of input forward reads by fastqc before cleaning fastqc_raw1_html String An HTML file that provides a graphical visualization of raw forward read quality from fastqc to open in an internet browser fastqc_version String Version of fastqc software used freyja_abundances String Abundances estimates identified by Freyja and parsed from freyja_demixed file freyja_barcode_file String Barcode file used with Freyja freyja_barcode_version String Name of barcode file used, or the date if update_db is true freyja_bootstrap_lineages String A CSV that contains the 0.025, 0.05, 0.25, 0.5 (median), 0.75, 0.95, and 0.975 percentiles for each lineage freyja_bootstrap_lineages_pdf String A boxplot of the bootstrap lineages CSV file freyja_bootstrap_summary String A CSV that contains the 0.025, 0.05, 0.25, 0.5 (median), 0.75, 0.95, and 0.975 percentiles for each WHO designated VOI/VOC freyja_bootstrap_summary_pdf String A boxplot of the bootstrap summary CSV file freyja_coverage Float Coverage identified by Freyja and parsed from freyja_demixed file freyja_demixed File The main output TSV; see the section directly above this table for an explanation freyja_demixed_parsed File Parsed freyja_demixed file, containing the same information, for easy result concatenation freyja_depths File A TSV listing the depth of every position freyja_fastq_wf_analysis_date String Date of analysis freyja_fastq_wf_version String The version of the Public Health Bioinformatics (PHB) repository used freyja_lineage_metadata_file String Metadata file for lineages identified by Freyja freyja_lineages String Lineages in descending order identified by Freyja and parsed from freyja_demixed file freyja_metadata_version String Name of lineage metadata file used, or the date if update_db is true freyja_resid String Residual of the weighted least absolute deviation problem used to estimate lineage abundances identified by Freyja and parsed from freyja_demixed file freyja_summarized String Sum of all lineage abundances in a particular WHO designation identified by Freyja and parsed from freyja_demixed file freyja_variants File The TSV file containing the variants identified by Freyja freyja_version String version of Freyja used ivar_version_primtrim String Version of iVar for running the iVar trim command kraken_human Float Percent of human read data detected using the Kraken2 software kraken_human_dehosted Float Percent of human read data detected using the Kraken2 software after host removal kraken_report String Full Kraken report kraken_report_dehosted File Full Kraken report after host removal kraken_sc2 String Percent of SARS-CoV-2 read data detected using the Kraken2 software kraken_sc2_dehosted String Percent of SARS-CoV-2 read data detected using the Kraken2 software after host removal kraken_version String Version of Kraken software used primer_bed_name String Name of the primer bed files used for primer trimming primer_trimmed_read_percent Float Percentage of read data with primers trimmed as determined by iVar trim samtools_version String The version of SAMtools used to sort and index the alignment file samtools_version_primtrim String The version of SAMtools used to create the pileup before running iVar trim trimmomatic_docker String The docker image used for the trimmomatic module in this workflow trimmomatic_version String The version of Trimmomatic used Variable Type Description aligned_bai String Index companion file to the bam file generated during the consensus assembly process aligned_bam String Sorted BAM file containing the alignments of reads to the reference genome alignment_method String The method used to generate the alignment freyja_abundances String Abundances estimates identified by Freyja and parsed from freyja_demixed file freyja_barcode_file String Barcode file used with Freyja freyja_barcode_version String Name of barcode file used, or the date if update_db is true freyja_bootstrap_lineages String A CSV that contains the 0.025, 0.05, 0.25, 0.5 (median), 0.75, 0.95, and 0.975 percentiles for each lineage freyja_bootstrap_lineages_pdf String A boxplot of the bootstrap lineages CSV file freyja_bootstrap_summary String A CSV that contains the 0.025, 0.05, 0.25, 0.5 (median), 0.75, 0.95, and 0.975 percentiles for each WHO designated VOI/VOC freyja_bootstrap_summary_pdf String A boxplot of the bootstrap summary CSV file freyja_coverage Float Coverage identified by Freyja and parsed from freyja_demixed file freyja_demixed File The main output TSV; see the section directly above this table for an explanation freyja_demixed_parsed File Parsed freyja_demixed file, containing the same information, for easy result concatenation freyja_depths File A TSV listing the depth of every position freyja_fastq_wf_analysis_date String Date of analysis freyja_fastq_wf_version String The version of the Public Health Bioinformatics (PHB) repository used freyja_lineage_metadata_file String Metadata file for lineages identified by Freyja freyja_lineages String Lineages in descending order identified by Freyja and parsed from freyja_demixed file freyja_metadata_version String Name of lineage metadata file used, or the date if update_db is true freyja_resid String Residual of the weighted least absolute deviation problem used to estimate lineage abundances identified by Freyja and parsed from freyja_demixed file freyja_summarized String Sum of all lineage abundances in a particular WHO designation identified by Freyja and parsed from freyja_demixed file freyja_variants File The TSV file containing the variants identified by Freyja freyja_version String version of Freyja used ivar_version_primtrim String Version of iVar for running the iVar trim command kraken_human Float Percent of human read data detected using the Kraken2 software kraken_human_dehosted Float Percent of human read data detected using the Kraken2 software after host removal kraken_report String Full Kraken report kraken_report_dehosted File Full Kraken report after host removal kraken_sc2 String Percent of SARS-CoV-2 read data detected using the Kraken2 software kraken_sc2_dehosted String Percent of SARS-CoV-2 read data detected using the Kraken2 software after host removal kraken_version String Version of Kraken software used minimap2_docker String The Docker image of minimap2 minimap2_version String The version of minimap2 nanoplot_html_clean File An HTML report describing the clean reads nanoplot_html_raw File An HTML report describing the raw reads nanoplot_num_reads_clean1 Int Number of clean reads nanoplot_num_reads_raw1 Int Number of raw reads nanoplot_r1_est_coverage_clean Float Estimated coverage on the clean reads by nanoplot nanoplot_r1_est_coverage_raw Float Estimated coverage on the raw reads by nanoplot nanoplot_r1_mean_q_clean Float Mean quality score of clean forward reads nanoplot_r1_mean_q_raw Float Mean quality score of raw forward reads nanoplot_r1_mean_readlength_clean Float Mean read length of clean forward reads nanoplot_r1_mean_readlength_raw Float Mean read length of raw forward reads nanoplot_r1_median_q_clean Float Median quality score of clean forward reads nanoplot_r1_median_q_raw Float Median quality score of raw forward reads nanoplot_r1_median_readlength_clean Float Median read length of clean forward reads nanoplot_r1_median_readlength_raw Float Median read length of raw forward reads nanoplot_r1_n50_clean Float N50 of clean forward reads nanoplot_r1_n50_raw Float N50 of raw forward reads nanoplot_r1_stdev_readlength_clean Float Standard deviation read length of clean forward reads nanoplot_r1_stdev_readlength_raw Float Standard deviation read length of raw forward reads nanoplot_tsv_clean File A TSV report describing the clean reads nanoplot_tsv_raw File A TSV report describing the raw reads nanoq_version String Version of nanoq used in analysis primer_bed_name String Name of the primer bed files used for primer trimming primer_trimmed_read_percent Float Percentage of read data with primers trimmed as determined by iVar trim samtools_version String The version of SAMtools used to sort and index the alignment file samtools_version_primtrim String The version of SAMtools used to create the pileup before running iVar trim"},{"location":"workflows/genomic_characterization/freyja/#freyja_plot","title":"Freyja_Plot_PHB","text":"<p>This workflow visualizes aggregated freyja_demixed output files produced by Freyja_FASTQ_PHB in a single plot (pdf format) which provides fractional abundance estimates for all aggregated samples.</p> <p>Options exist to provide lineage-specific breakdowns and/or sample collection time information.</p>"},{"location":"workflows/genomic_characterization/freyja/#inputs_2","title":"Inputs","text":"<p>This workflow runs on the set level.</p> Terra Task Name Variable Type Description Default Value Terra Status freyja_plot freyja_demixed Array[File] An array containing the output files (freyja_demixed) made by Freyja_FASTQ Required freyja_plot freyja_plot_name String The name of the plot to be produced. Example: \"my-freyja-plot\" Required freyja_plot samplename Array[String] The names of the samples being analyzed Required freyja_plot collection_date Array[String] An array containing the collection dates for the sample (YYYY-MM-DD format) Optional freyja_plot_task cpu Int Number of CPUs to allocate to the task 1 Optional freyja_plot_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional freyja_plot_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/freyja:1.5.3 Optional freyja_plot_task memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional freyja_plot_task mincov Int The minimum genome coverage used as a cut-off of data to include in the plot 60 Optional freyja_plot_task plot_day_window Int The width of the rolling average window; only used if plot_time_interval is \"D\" 14 Optional freyja_plot_task plot_lineages Boolean If true, will plot a lineage-specific breakdown FALSE Optional freyja_plot_task plot_time Boolean If true, will plot sample collection time information (requires the collection_date input variable) FALSE Optional freyja_plot_task plot_time_interval String Options: \"MS\" for month, \"D\" for day MS Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/genomic_characterization/freyja/#analysis-tasks_1","title":"Analysis Tasks","text":"<code>freyja_plot_task</code> Details <p>This task will aggregate multiple samples together, and then creates a plot. Several optional inputs dictate the plot appearance (see each variable's description for more information).</p> <p>Freyja Plot Technical Details</p> Links Task wf_freyja_plot.wdl Software Source Code https://github.com/andersen-lab/Freyja Software Documentation https://github.com/andersen-lab/Freyja"},{"location":"workflows/genomic_characterization/freyja/#outputs_2","title":"Outputs","text":"Variable Type Description freyja_demixed_aggregate File A TSV file that summarizes the <code>freyja_demixed</code> outputs for all samples freyja_plot File A PDF of the plot produced by the workflow freyja_plot_metadata File The metadata used to create the plot freyja_plot_version String The version of Freyja used freyja_plot_wf_analysis_date String The date of analysis freyja_plot_wf_version String The version of the Public Health Bioinformatics (PHB) repository used"},{"location":"workflows/genomic_characterization/freyja/#freyja_dashboard","title":"Freyja_Dashboard_PHB","text":"<p>This workflow creates a group of interactive visualizations based off of the aggregated freyja_demixed output files produced by Freyja_FASTQ_PHB called a \"dashboard\". Creating this dashboard requires knowing the viral load of your samples (viral copies/litre).</p> <p>Warning</p> <p>This dashboard is not \"live\" \u2014 that is, you must rerun the workflow every time you want new data to be included in the visualizations.</p>"},{"location":"workflows/genomic_characterization/freyja/#inputs_3","title":"Inputs","text":"<p>This workflow runs on the set level.</p> Terra Task Name Variable Type Description Default Value Terra Status freyja_dashboard collection_date Array[String] An array containing the collection dates for the sample (YYYY-MM-DD format) Required freyja_dashboard freyja_dashboard_title String The name of the dashboard to be produced. Example: \"my-freyja-dashboard\" Required freyja_dashboard freyja_demixed Array[File] An array containing the output files (freyja_demixed) made by Freyja_FASTQ workflow Required freyja_dashboard samplename Array[String] The names of the samples being analyzed Required freyja_dashboard viral_load Array[String] An array containing the number of viral copies per liter Required freyja_dashboard_task config File (found in the optional section, but is required) A yaml file that applies various configurations to the dashboard, such as grouping lineages together, applying colorings, etc. See also https://github.com/andersen-lab/Freyja/blob/main/freyja/data/plot_config.yml. Optional, Required freyja_dashboard dashboard_intro_text File A file containing the text to be contained at the top of the dashboard. SARS-CoV-2 lineage de-convolution performed by the Freyja workflow (https://github.com/andersen-lab/Freyja). Optional freyja_dashboard_task cpu Int Number of CPUs to allocate to the task 1 Optional freyja_dashboard_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional freyja_dashboard_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/freyja:1.5.3 Optional freyja_dashboard_task headerColor String A hex color code to change the color of the header Optional freyja_dashboard_task memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional freyja_dashboard_task mincov Float The minimum genome coverage used as a cut-off of data to include in the dashboard. Default is set to 60 by the freyja command-line tool (not a WDL task default, per se) Optional freyja_dashboard_task scale_by_viral_load Boolean If set to true, averages samples taken the same day while taking viral load into account FALSE Optional freyja_dashboard_task thresh Float The minimum lineage abundance cut-off value Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/genomic_characterization/freyja/#analysis-tasks_2","title":"Analysis Tasks","text":"<code>freyja_dashboard_task</code> Details <p>This task will aggregate multiple samples together, and then create an interactive HTML visualization. Several optional inputs dictate the dashboard appearance (see each variable's description for more information).</p> <p>Freyja Dashboard Technical Details</p> Links Task wf_freyja_dashboard.wdl Software Source Code https://github.com/andersen-lab/Freyja Software Documentation https://github.com/andersen-lab/Freyja"},{"location":"workflows/genomic_characterization/freyja/#outputs_3","title":"Outputs","text":"Variable Type Description freyja_dashboard File The HTML file of the dashboard created freyja_dashboard_metadata File The metadata used to create the dashboard freyja_dashboard_version String The version of Freyja used freyja_dashboard_wf_analysis_date String The date of analysis freyja_dashboard_wf_version String The version of the Public Health Bioinformatics (PHB) repository used freyja_demixed_aggregate File A TSV file that summarizes the <code>freyja_demixed</code> outputs for all samples"},{"location":"workflows/genomic_characterization/freyja/#running-freyja-on-other-pathogens","title":"Running Freyja on other pathogens","text":"<p>Experimental Feature</p> <p>Please be aware this is an experimental feature and we cannot guarantee complete functionality at this time.</p> <p>The main requirement to run Freyja on other pathogens is the existence of a barcode file for your pathogen of interest. Currently, barcodes exist for the following organisms:</p> <ul> <li>SARS-CoV-2 (default)</li> <li>FLU-B-VIC</li> <li>H1N1</li> <li>H3N2</li> <li>H5Nx-cattle</li> <li>H5NX</li> <li>MEASLESN450</li> <li>MEASLESgenome</li> <li>MPX</li> <li>RSVa</li> <li>RSVb</li> </ul> <p>Freyja barcodes for other pathogens</p> <p>Data for various pathogens can be found in the following repository:\u00a0Freyja Barcodes</p> <p>Folders are organized by pathogen, with each subfolder named after the date the barcode was generated, using the format YYYY-MM-DD, as well as a \"latest\" folder. Barcode files are named <code>barcode.csv</code>, and reference genome files are named <code>reference.fasta</code>.</p> <p>There are two ways to run Freyja_FASTQ_PHB for non-SARS-CoV-2 organisms:</p> <ul> <li>Using the <code>freyja_pathogen</code> optional input (limited set of allowable organisms)</li> <li>Providing the appropriate barcode file through the <code>freyja_barcodes</code> optional input (any organism for which barcodes are supplied)</li> </ul>"},{"location":"workflows/genomic_characterization/freyja/#using-the-freyja_pathogen-flag","title":"Using the <code>freyja_pathogen</code> flag","text":"<p>When using the <code>freyja_pathogen</code> flag, the user must set the optional <code>update_db</code> flag to true, so that the latest version of the barcode file is automatically downloaded by Freyja. </p> <p>Figure 2:  Optional input for Freyja_FASTQ_PHB to provide the pathogen to be used by Freyja</p> <p>Allowed options:</p> <ul> <li>SARS-CoV-2 (default)</li> <li>MPXV</li> <li>H1N1pdm</li> <li>H5NX</li> <li>FLU-B-VIC</li> <li>MEASLESN450</li> <li>MEASLES</li> <li>RSVa</li> <li>RSVb</li> </ul> <p>Warning</p> <p>The <code>freyja_pathogen</code> flag is not used if a barcodes file is provided. This means that this option is ignored if a barcode file is provided through <code>freyja_barcodes</code>.</p>"},{"location":"workflows/genomic_characterization/freyja/#figure2","title":"Figure 2","text":""},{"location":"workflows/genomic_characterization/freyja/#providing-the-appropriate-barcode-file","title":"Providing the appropriate barcode file","text":"<p>The appropriate barcode file for your organism of interest and reference sequence need to be downloaded and uploaded to your Terra.bio workspace. When running Freyja_FASTQ_PHB, the appropriate reference and barcodes file need to be passed as inputs. The first is a required input and will show up at the top of the workflows inputs page on Terra.bio (Figure 3).</p> <p>Figure 3:  Required input for Freyja_FASTQ_PHB to provide the reference genome to be used by Freyja</p> <p>The barcodes file can be passed directly to Freyja by the <code>freyja_barcodes</code> optional input (Figure 4).</p> <p>Figure 4: Optional input for Freyja_FASTQ_PHB to provide the barcodes file to be used by Freyja</p>"},{"location":"workflows/genomic_characterization/freyja/#figure3","title":"Figure 3","text":""},{"location":"workflows/genomic_characterization/freyja/#figure4","title":"Figure 4","text":""},{"location":"workflows/genomic_characterization/freyja/#references","title":"References","text":"<p>If you use any of the Freyja workflows, please cite:</p> <p>Karthikeyan, S., Levy, J.I., De Hoff, P.\u00a0et al.\u00a0Wastewater sequencing reveals early cryptic SARS-CoV-2 variant transmission.\u00a0Nature 609, 101\u2013108 (2022). https://doi.org/10.1038/s41586-022-05049-6</p> <p>Freyja source code can be found at https://github.com/andersen-lab/Freyja</p> <p>Freyja barcodes (non-SARS-CoV-2): https://github.com/gp201/Freyja-barcodes</p>"},{"location":"workflows/genomic_characterization/pangolin_update/","title":"Pangolin_Update","text":""},{"location":"workflows/genomic_characterization/pangolin_update/#pangolin_update","title":"Pangolin_Update","text":""},{"location":"workflows/genomic_characterization/pangolin_update/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Genomic Characterization SARS-CoV-2, Viral v3.0.1 Yes Sample-level Pangolin_Update_PHB"},{"location":"workflows/genomic_characterization/pangolin_update/#pangolin_update_phb","title":"Pangolin_Update_PHB","text":"<p>The Pangolin_Update workflow re-runs Pangolin updating prior lineage calls from one docker image to meet the lineage calls specified in an alternative docker image. The most common use case for this is updating lineage calls to be up-to-date with the latest Pangolin nomenclature by using the latest available Pangolin docker image (found\u00a0here).</p>"},{"location":"workflows/genomic_characterization/pangolin_update/#inputs","title":"Inputs","text":"<p>This workflow runs on the sample level.</p> Terra Task Name Variable Type Description Default Value Terra Status pangolin_update assembly_fasta File The assembly file for your sample in FASTA format Required pangolin_update old_lineage String The Pangolin lineage previously assigned to the sample Required pangolin_update old_pangolin_assignment_version String Version of the Pangolin software previously used for lineage assignment. Required pangolin_update old_pangolin_docker String The Pangolin docker image previously used for lineage assignment. Required pangolin_update old_pangolin_versions String All pangolin software and database versions previously used for lineage assignment. Required pangolin_update samplename String The name of the sample being analyzed Required organism_parameters auspice_config File Auspice config file for customizing visualizations in the Augur_PHB workflow; takes priority over the other customization values available for augur_export. Defaults are set for various organisms &amp; flu segments. A minimal auspice config file is set in cases where organism is not specified and user does not provide an optional input config file. Optional organism_parameters clades_tsv File Internal component, do not modify Optional organism_parameters flu_genoflu_genotype String Internal component, do not modify N/A Optional organism_parameters lat_longs_tsv File Internal component, do not modify Optional organism_parameters min_date Float Internal component, do not modify Optional organism_parameters min_num_unambig Int Minimum number of called bases in genome to pass prefilter Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, the default value is 0 Optional organism_parameters narrow_bandwidth Float Internal component, do not modify Optional organism_parameters pivot_interval Int Internal component, do not modify Optional organism_parameters proportion_wide Float Internal component, do not modify Optional organism_parameters reference_genbank File Internal component, do not modify Optional organism_parameters vadr_model File Path to the a tar + gzipped VADR model file gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-sarscov2-1.3-2.tar.gz Optional pangolin4 analysis_mode String Used to switch between usher and pangolearn analysis modes. Only use usher because pangolearn is no longer supported as of Pangolin v4.3 and higher versions. Optional pangolin4 cpu Int Number of CPUs to allocate to the task 4 Optional pangolin4 disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional pangolin4 expanded_lineage Boolean True/False that determines if a lineage should be expanded without aliases (e.g., BA.1 \u2192 B.1.1.529.1) TRUE Optional pangolin4 max_ambig Float The maximum proportion of Ns allowed for pangolin to attempt an assignment 0.5 Optional pangolin4 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional pangolin4 min_length Int Minimum query length allowed for pangolin to attempt an assignment 10000 Optional pangolin4 pangolin_arguments String Optional arguments for pangolin e.g. ''--skip-scorpio'' Optional pangolin4 skip_designation_cache Boolean A True/False option that determines if the designation cache should be used FALSE Optional pangolin4 skip_scorpio Boolean A True/False option that determines if scorpio should be skipped. FALSE Optional pangolin_update lineage_log File TSV file detailing previous lineage assignments and software versions for this sample. Optional pangolin_update new_pangolin_docker String The Pangolin docker image used to update the Pangolin lineage assignments. Optional pangolin_update organism String The organism to be analyzed sars-cov-2 Optional pangolin_update_log cpu Int Number of CPUs to allocate to the task 4 Optional pangolin_update_log disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional pangolin_update_log docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional pangolin_update_log memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional pangolin_update_log timezone String Set the time zone to get an accurate date of update (uses UTC by default) Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/genomic_characterization/pangolin_update/#outputs","title":"Outputs","text":"Variable Type Description pango_lineage String Pango lineage as determined by Pangolin pango_lineage_expanded String Pango lineage without use of aliases; e.g., \"BA.1\" \u2192 \"B.1.1.529.1\" pango_lineage_log File TSV file listing Pangolin lineage assignments and software versions for this sample pango_lineage_report File Full Pango lineage report generated by Pangolin pangolin_assignment_version String The version of the pangolin software (e.g. PANGO or PUSHER) used for lineage assignment pangolin_conflicts String Number of lineage conflicts as determined by Pangolin pangolin_docker String Docker image used to run Pangolin pangolin_notes String Lineage notes as determined by Pangolin pangolin_update_analysis_date String Date of analysis pangolin_update_version String Version of the Public Health Bioinformatics (PHB) repository used pangolin_updates String Result of Pangolin Update (lineage changed versus unchanged) with lineage assignment and date of analysis pangolin_versions String All Pangolin software and database versions"},{"location":"workflows/genomic_characterization/pangolin_update/#references","title":"References","text":"<p>Pangolin: RRambaut A, Holmes EC, O'Toole \u00c1, Hill V, McCrone JT, Ruis C, du Plessis L, Pybus OG. A dynamic nomenclature proposal for SARS-CoV-2 lineages to assist genomic epidemiology. Nat Microbiol. 2020 Nov;5(11):1403-1407. doi: 10.1038/s41564-020-0770-5. Epub 2020 Jul 15. PMID: 32669681; PMCID: PMC7610519.</p>"},{"location":"workflows/genomic_characterization/theiacov/","title":"TheiaCoV Workflow Series","text":""},{"location":"workflows/genomic_characterization/theiacov/#theiacov-workflow-series","title":"TheiaCoV Workflow Series","text":""},{"location":"workflows/genomic_characterization/theiacov/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Genomic Characterization HIV, Influenza, Monkeypox virus, RSV-A, RSV-B, SARS-CoV-2, Viral, WNV vX.X.X Some optional features incompatible, Yes Sample-level, Set-level TheiaCoV_Illumina_PE_PHB, TheiaCoV_Illumina_SE_PHB, TheiaCoV_ONT_PHB, TheiaCoV_ClearLabs_PHB, TheiaCoV_FASTA_PHB, TheiaCoV_FASTA_Batch_PHB"},{"location":"workflows/genomic_characterization/theiacov/#theiacov-workflows","title":"TheiaCoV Workflows","text":"<p>The TheiaCoV workflows are for the assembly, quality assessment, and characterization of viral genomes. There are currently five TheiaCoV workflows designed to accommodate different kinds of input data:</p> <ol> <li>Illumina paired-end sequencing (TheiaCoV_Illumina_PE)</li> <li>Illumina single-end sequencing (TheiaCoV_Illumina_SE)</li> <li>ONT sequencing (TheiaCoV_ONT)</li> <li>Genome assemblies (TheiaCoV_FASTA)</li> <li>ClearLabs sequencing (TheiaCoV_ClearLabs)</li> </ol> <p>Additionally, the TheiaCoV_FASTA_Batch workflow is available to process several hundred SARS-CoV-2 assemblies at the same time.</p> <p>Key Resources</p> <p>Reference Materials for SARS-CoV-2</p> <p>Reference Materials for Mpox</p> <p>Reference Materials for non-default viruses (TheiaViral)</p> HIV Input JSONs <ul> <li>TheiaCoV_Illumina_PE_HIV_v1_2024-04-19.json</li> <li>TheiaCoV_Illumina_PE_HIV_v2_2024-04-19.json</li> <li>TheiaCoV_ONT_HIV_v1_2024-04-19.json</li> <li>TheiaCoV_ONT_HIV_v2_2024-04-19.json</li> </ul> WNV Input JSONs <ul> <li>TheiaCoV_Illumina_PE_WNV_2024-04-19.json</li> <li>TheiaCoV_Illumina_SE_WNV_2024-04-19.json</li> <li>TheiaCoV_FASTA_WNV_2024-04-19.json</li> </ul> Flu Input JSONs <ul> <li>TheiaCoV_Illumina_PE_flu_2024-04-19.json</li> <li>TheiaCoV_ONT_flu_2024-04-19.json</li> <li>TheiaCoV_FASTA_flu_2024-04-19.json</li> </ul> RSV-A Input JSONs <ul> <li>TheiaCoV_Illumina_PE_RSV-A_2024-04-19.json</li> <li>TheiaCoV_FASTA_RSV-A_2024-04-19.json</li> </ul> RSV-B Input JSONs <ul> <li>TheiaCoV_Illumina_PE_RSV-B_2024-04-19.json</li> <li>TheiaCoV_FASTA_RSV-B_2024-04-19.json</li> </ul> <p>TheiaCoV Workflow Diagram</p> <p></p>"},{"location":"workflows/genomic_characterization/theiacov/#supported-organisms","title":"Supported Organisms","text":"<p>These workflows currently support the following organisms. The first option in the list (bolded) is what our workflows use as the standardized organism name:</p> <ul> <li>SARS-CoV-2 (<code>\"sars-cov-2\"</code>, <code>\"SARS-CoV-2\"</code>) - default organism input</li> <li>Monkeypox virus (<code>\"MPXV\"</code>, <code>\"mpox\"</code>, <code>\"monkeypox\"</code>, <code>\"Monkeypox virus\"</code>, <code>\"Mpox\"</code>)</li> <li>Human Immunodeficiency Virus (<code>\"HIV\"</code>)</li> <li>West Nile Virus (<code>\"WNV\"</code>, <code>\"wnv\"</code>, <code>\"West Nile virus\"</code>)</li> <li>Influenza (<code>\"flu\"</code>, <code>\"influenza\"</code>, <code>\"Flu\"</code>, <code>\"Influenza\"</code>)</li> <li>RSV-A (<code>\"rsv_a\"</code>, <code>\"rsv-a\"</code>, <code>\"RSV-A\"</code>, <code>\"RSV_A\"</code>)</li> <li>RSV-B (<code>\"rsv_b\"</code>, <code>\"rsv-b\"</code>, <code>\"RSV-B\"</code>, <code>\"RSV_B\"</code>)</li> <li>Measles (<code>\"measles\"</code>, <code>\"Measles\"</code>, <code>\"mev\"</code>, <code>\"MeV\"</code>, <code>\"Morbillivirus\"</code>, <code>\"morbillivirus\"</code>)</li> <li>Mumps (<code>\"mumps\"</code>, <code>\"Mumps\"</code>, <code>\"MuV\"</code>, <code>\"muv\"</code>, <code>\"Mumps virus\"</code>, <code>\"mumps virus\"</code>)</li> <li>Rubella (<code>\"rubella\"</code>, <code>\"Rubella\"</code>, <code>\"RuV\"</code>, <code>\"ruv\"</code>, <code>\"Rubella virus\"</code>, <code>\"rubella virus\"</code>)</li> </ul> <p>The compatibility of each workflow with each pathogen is shown below:</p> SARS-CoV-2 Mpox HIV WNV Influenza RSV-A RSV-B Measles Mumps Rubella Illumina_PE \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 Illumina_SE \u2705 \u2705 \u274c \u2705 \u274c \u2705 \u2705 \u2705 \u2705 \u2705 ONT \u2705 \u2705 \u2705 \u274c \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 FASTA \u2705 \u2705 \u274c \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 ClearLabs \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c <p>We've provided the following information to help you set up the workflow for each organism in the form of input JSONs.</p>"},{"location":"workflows/genomic_characterization/theiacov/#inputs","title":"Inputs","text":"<p>Input Data</p> TheiaCoV_Illumina_PETheiaCoV_Illumina_SETheiaCoV_ONTTheiaCoV_FASTATheiaCoV_ClearLabsTheiaCoV_FASTA_Batch <p>The TheiaCoV_Illumina_PE workflow takes in Illumina paired-end read data. Read file names should end with <code>.fastq</code> or <code>.fq</code>, with the optional addition of <code>.gz</code>. When possible, Theiagen recommends zipping files with gzip before Terra uploads to minimize data upload time.</p> <p>By default, the workflow anticipates\u00a02 x 150bp\u00a0reads (i.e. the input reads were generated using a 300-cycle sequencing kit). Modifications to the optional parameter for <code>trim_minlen</code> may be required to accommodate shorter read data, such as the 2 x 75bp reads generated using a 150-cycle sequencing kit.</p> <p>TheiaCoV_Illumina_SE takes in Illumina single-end reads. Read file names should end with <code>.fastq</code> or <code>.fq</code>, with the optional addition of <code>.gz</code>. Theiagen highly recommends zipping files with gzip before uploading to Terra to minimize data upload time &amp; save on storage costs.</p> <p>By default, the workflow anticipates 1 x 35 bp reads  (i.e. the input reads were generated using a 70-cycle sequencing kit). Modifications to the optional parameter for <code>trim_minlen</code> may be required to accommodate longer read data.</p> <p>The TheiaCoV_ONT workflow takes in base-called ONT read data. Read file names should end with <code>.fastq</code> or <code>.fq</code>, with the optional addition of <code>.gz</code>. When possible, Theiagen recommends zipping files with gzip before uploading to Terra to minimize data upload time.</p> <p>The ONT sequencing kit and base-calling approach can produce substantial variability in the amount and quality of read data. Genome assemblies produced by the TheiaCoV_ONT workflow must be quality assessed before reporting results.</p> <p>The TheiaCoV_FASTA workflow takes in assembly files in FASTA format.</p> <p>Note for TheiaCoV_FASTA users analyzing Influenza:</p> <p>TheiaCoV_FASTA will use the output of VADR to classify and partition Influenza segments from the input assembly. See <code>vadr_flu_segments</code> task for more details.</p> <p>The TheiaCoV_ClearLabs workflow takes in read data produced by the Clear Dx platform from ClearLabs. However, many users use the TheiaCoV_FASTA workflow instead of this one due to a few known issues when generating assemblies with this pipeline that are not present when using ClearLabs-generated FASTA files.</p> <p>The TheiaCoV_FASTA_Batch workflow takes in a set of assembly files in FASTA format.</p> TheiaCoV_Illumina_PETheiaCoV_Illumina_SETheiaCoV_ONTTheiaCoV_FASTATheiaCoV_ClearLabsTheiaCoV_FASTA_Batch Terra Task Name Variable Type Description Default Value Terra Status theiacov_illumina_pe read1 File Illumina forward read file in FASTQ file format (compression optional) Required theiacov_illumina_pe read2 File Illumina reverse read file in FASTQ file format (compression optional) Required theiacov_illumina_pe samplename String The name of the sample being analyzed Required clean_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional clean_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional clean_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional clean_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional consensus_qc cpu Int Number of CPUs to allocate to the task 1 Optional consensus_qc disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional consensus_qc docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional consensus_qc memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional flu_track abricate_flu_cpu Int Number of CPUs to allocate to the task 2 Optional flu_track abricate_flu_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flu_track abricate_flu_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-insaflu-220727 Optional flu_track abricate_flu_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional flu_track abricate_flu_min_percent_coverage Int Minimum DNA percent coverage 60 Optional flu_track abricate_flu_min_percent_identity Int Minimum DNA percent identity 70 Optional flu_track antiviral_aa_subs String Additional list of antiviral resistance associated amino acid substitutions of interest to be searched against those called on the sample segments. They take the format of :, e.g. NA:A26V Optional flu_track assembly_fasta File Internal component, do not modify Optional flu_track assembly_metrics_cpu Int Number of CPUs to allocate to the task 2 Optional flu_track assembly_metrics_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flu_track assembly_metrics_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional flu_track assembly_metrics_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional flu_track flu_h1_ha_ref File Internal component, do not modify Optional flu_track flu_h1n1_m2_ref File Internal component, do not modify Optional flu_track flu_h3_ha_ref File Internal component, do not modify Optional flu_track flu_h3n2_m2_ref File Internal component, do not modify Optional flu_track flu_n1_na_ref File Internal component, do not modify Optional flu_track flu_n2_na_ref File Internal component, do not modify Optional flu_track flu_pa_ref File Internal component, do not modify Optional flu_track flu_pb1_ref File Internal component, do not modify Optional flu_track flu_pb2_ref File Internal component, do not modify Optional flu_track flu_subtype String The influenza subtype being analyzed. Used for picking nextclade datasets. Options: \"Yamagata\", \"Victoria\", \"H1N1\", \"H3N2\", \"H5N1\". Only use to override the subtype call from IRMA and ABRicate. Optional flu_track genoflu_cpu Int Number of CPUs to allocate to the task 1 Optional flu_track genoflu_cross_reference File An Excel file to cross-reference BLAST findings; probably useful if novel genotypes are not in the default file used by genoflu.py Optional flu_track genoflu_disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional flu_track genoflu_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/genoflu:1.06 Optional flu_track genoflu_memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional flu_track genoflu_min_percent_identity Float Percent identity threshold used for calling matches for each genome segment that make up the final GenoFlu genotype 98 Optional flu_track irma_cpu Int Number of CPUs to allocate to the task 4 Optional flu_track irma_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flu_track irma_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/irma:1.2.0 Optional flu_track irma_keep_ref_deletions Boolean True/False variable that determines if sites missed (i.e. 0 reads for a site in the reference genome) during read gathering should be deleted by ambiguation by inserting N's or deleting the sequence entirely. False sets this IRMA paramater to \"DEL\" and true sets it to \"NNN\" TRUE Optional flu_track irma_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional flu_track irma_min_ambiguous_threshold Float Minimum called Single Nucleotide Variant (SNV) frequency for mixed based calls in the output consensus assembly (AKA amended consensus). 0.2 Optional flu_track irma_min_avg_consensus_allele_quality Int Minimum allele coverage depth to call plurality consensus, otherwise calls \"N\". Setting this value too high can negatively impact final amended consensus. 10 Optional flu_track irma_min_read_length Int Minimum read length to include reads in read gathering step in IRMA. This value should not be greater than the typical read length. 75 Optional flu_track nextclade_cpu Int Number of CPUs to allocate to the task 2 Optional flu_track nextclade_custom_input_dataset File For H5N1 flu samples only. A custom Nextclade dataset in JSON format. If provided, this dataset will be used to process any H5N1 flu samples. If not provided, a custom dataset will be selected depending on the GenoFLU Genotype. Defaults are GenoFLU Genotype specific. Please find these default values here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional flu_track nextclade_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional flu_track nextclade_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.14.5 Optional flu_track nextclade_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional flu_track nextclade_output_parser_cpu Int Number of CPUs to allocate to the task 2 Optional flu_track nextclade_output_parser_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional flu_track nextclade_output_parser_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/python/python:3.8.18-slim Optional flu_track nextclade_output_parser_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional flu_track vadr_outputs_tgz File Internal component, do not modify Optional gene_coverage cpu Int Number of CPUs to allocate to the task 2 Optional gene_coverage disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional gene_coverage docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional gene_coverage memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional gene_coverage min_depth Int The minimum depth to determine if a position was covered. 10 Optional gene_coverage sc2_s_gene_start Int start nucleotide position of the SARS-CoV-2 Spike gene 21563 Optional gene_coverage sc2_s_gene_stop Int End/Last nucleotide position of the SARS-CoV-2 Spike gene 25384 Optional ivar_consensus ivar_bwa_cpu Int Number of CPUs to allocate to the task 6 Optional ivar_consensus ivar_bwa_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ivar_consensus ivar_bwa_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional ivar_consensus ivar_bwa_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional ivar_consensus ivar_consensus_cpu Int Number of CPUs to allocate to the task 2 Optional ivar_consensus ivar_consensus_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ivar_consensus ivar_consensus_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional ivar_consensus ivar_consensus_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional ivar_consensus ivar_trim_primers_cpu Int Number of CPUs to allocate to the task 2 Optional ivar_consensus ivar_trim_primers_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ivar_consensus ivar_trim_primers_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional ivar_consensus ivar_trim_primers_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional ivar_consensus ivar_variant_cpu Int Number of CPUs to allocate to the task 2 Optional ivar_consensus ivar_variant_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ivar_consensus ivar_variant_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional ivar_consensus ivar_variant_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional ivar_consensus skip_N Boolean True/False variable that determines if regions with depth less than minimum depth should not be added to the consensus sequence FALSE Optional ivar_consensus stats_n_coverage_cpu Int Number of CPUs to allocate to the task 2 Optional ivar_consensus stats_n_coverage_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ivar_consensus stats_n_coverage_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional ivar_consensus stats_n_coverage_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional ivar_consensus stats_n_coverage_primtrim_cpu Int Number of CPUs to allocate to the task 2 Optional ivar_consensus stats_n_coverage_primtrim_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ivar_consensus stats_n_coverage_primtrim_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional ivar_consensus stats_n_coverage_primtrim_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional nextclade_output_parser cpu Int Number of CPUs to allocate to the task 2 Optional nextclade_output_parser disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional nextclade_output_parser docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/python/python:3.8.18-slim Optional nextclade_output_parser memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional nextclade_v3 auspice_reference_tree_json File An Auspice JSON phylogenetic reference tree which serves as a target for phylogenetic placement. Inherited from nextclade dataset Optional nextclade_v3 cpu Int Number of CPUs to allocate to the task 2 Optional nextclade_v3 custom_input_dataset File For H5N1 flu samples only. A custom Nextclade dataset in JSON format. If provided, this dataset will be used to process any H5N1 flu samples. If not provided, a custom dataset will be selected depending on the GenoFLU Genotype. Defaults are GenoFLU Genotype specific. Please find these default values here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional nextclade_v3 disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional nextclade_v3 docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.16.0 Optional nextclade_v3 gene_annotations_gff File A genome annotation to specify how to translate the nucleotide sequence to proteins (genome_annotation.gff3). specifying this enables codon-informed alignment and protein alignments. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/03-genome-annotation.html Inherited from nextclade dataset Optional nextclade_v3 input_ref File A nucleotide sequence which serves as a reference for the pairwise alignment of all input sequences. This is also the sequence which defines the coordinate system of the genome annotation. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/02-reference-sequence.html Inherited from nextclade dataset Optional nextclade_v3 memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional nextclade_v3 nextclade_pathogen_json File General dataset configuration file. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/05-pathogen-config.html Inherited from nextclade dataset Optional nextclade_v3 verbosity String other options are: \"off\" , \"error\" , \"info\" , \"debug\" , and \"trace\" (highest level of verbosity) warn Optional organism_parameters auspice_config File Auspice config file for customizing visualizations in the Augur_PHB workflow; takes priority over the other customization values available for augur_export. Defaults are set for various organisms &amp; flu segments. A minimal auspice config file is set in cases where organism is not specified and user does not provide an optional input config file. Optional organism_parameters clades_tsv File Internal component, do not modify Optional organism_parameters flu_genoflu_genotype String Internal component, do not modify N/A Optional organism_parameters flu_segment String Influenza genome segment being analyzed. Options: \"HA\" or \"NA\". Automatically determined. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs N/A Optional organism_parameters flu_subtype String The influenza subtype being analyzed. Options: \"Yamagata\", \"Victoria\", \"H1N1\", \"H3N2\", \"H5N1\". Automatically determined. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs N/A Optional organism_parameters hiv_primer_version String The version of HIV primers used. Options are https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl#L156 and https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl#L164. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs v1 Optional organism_parameters lat_longs_tsv File Internal component, do not modify Optional organism_parameters min_date Float Internal component, do not modify Optional organism_parameters min_num_unambig Int Minimum number of called bases in genome to pass prefilter Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, the default value is 0 Optional organism_parameters narrow_bandwidth Float Internal component, do not modify Optional organism_parameters pivot_interval Int Internal component, do not modify Optional organism_parameters proportion_wide Float Internal component, do not modify Optional organism_parameters reference_genbank File Internal component, do not modify Optional pangolin4 analysis_mode String Used to switch between usher and pangolearn analysis modes. Only use usher because pangolearn is no longer supported as of Pangolin v4.3 and higher versions. Optional pangolin4 cpu Int Number of CPUs to allocate to the task 4 Optional pangolin4 disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional pangolin4 expanded_lineage Boolean True/False that determines if a lineage should be expanded without aliases (e.g., BA.1 \u2192 B.1.1.529.1) TRUE Optional pangolin4 max_ambig Float The maximum proportion of Ns allowed for pangolin to attempt an assignment 0.5 Optional pangolin4 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional pangolin4 min_length Int Minimum query length allowed for pangolin to attempt an assignment 10000 Optional pangolin4 pangolin_arguments String Optional arguments for pangolin e.g. ''--skip-scorpio'' Optional pangolin4 skip_designation_cache Boolean A True/False option that determines if the designation cache should be used FALSE Optional pangolin4 skip_scorpio Boolean A True/False option that determines if scorpio should be skipped. FALSE Optional qc_check_task ani_highest_percent Float Internal component, do not modify Optional qc_check_task ani_highest_percent_bases_aligned Float Internal component, do not modify Optional qc_check_task assembly_length Int Internal component, do not modify Optional qc_check_task busco_results String Internal component, do not modify Optional qc_check_task combined_mean_q_clean Float Internal component, do not modify Optional qc_check_task combined_mean_q_raw Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task cpu Int Number of CPUs to allocate to the task 4 Optional qc_check_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional qc_check_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional qc_check_task est_coverage_clean Float Internal component, do not modify Optional qc_check_task est_coverage_raw Float Internal component, do not modify Optional qc_check_task gambit_predicted_taxon String Internal component, do not modify Optional qc_check_task kraken_sc2 Float Internal component, do not modify Optional qc_check_task kraken_sc2_dehosted Float Internal component, do not modify Optional qc_check_task kraken_target_organism Float Internal component, do not modify Optional qc_check_task kraken_target_organism_dehosted Float Internal component, do not modify Optional qc_check_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional qc_check_task midas_secondary_genus_abundance Float Internal component, do not modify Optional qc_check_task midas_secondary_genus_coverage Float Internal component, do not modify Optional qc_check_task n50_value Int Internal component, do not modify Optional qc_check_task number_contigs Int Internal component, do not modify Optional qc_check_task quast_gc_percent Float Internal component, do not modify Optional qc_check_task r1_mean_q_clean Float Internal component, do not modify Optional qc_check_task r1_mean_q_raw Float Internal component, do not modify Optional qc_check_task r1_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task r1_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task r2_mean_q_clean Float Internal component, do not modify Optional qc_check_task r2_mean_q_raw Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task sc2_s_gene_mean_coverage Float Internal component, do not modify Optional qc_check_task sc2_s_gene_percent_coverage Float Internal component, do not modify Optional quasitools_illumina_pe cpu Int Number of CPUs to allocate to the task 2 Optional quasitools_illumina_pe disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional quasitools_illumina_pe docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/quasitools:0.7.0--pyh864c0ab_1 Optional quasitools_illumina_pe memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional raw_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional raw_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional raw_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional raw_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional read_QC_trim bbduk_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim call_kraken Boolean True/False variable that determines if the Kraken2 task should be called; for non-TheiaCoV workflows, the <code>kraken_db</code> variable must be provided. FALSE Optional read_QC_trim call_midas Boolean True/False variable that determines if the MIDAS task should be called. FALSE Optional read_QC_trim extract_unclassified Boolean Internal component, do not modify FALSE Optional read_QC_trim fastp_args String Additional arguments to use with fastp --detect_adapter_for_pe -g -5 20 -3 20 Optional read_QC_trim host String Internal component, do not modify Optional read_QC_trim host_complete_only Boolean Internal component, do not modify FALSE Optional read_QC_trim host_decontaminate_mem Int Internal component, do not modify 32 Optional read_QC_trim host_is_accession Boolean Internal component, do not modify FALSE Optional read_QC_trim host_refseq Boolean Internal component, do not modify TRUE Optional read_QC_trim kraken_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim kraken_db File A kraken2 database to use with the kraken2 optional task. The file must be a .tar.gz kraken2 database. Must contain human and viral sequences gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz Optional read_QC_trim kraken_disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional read_QC_trim kraken_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional read_QC_trim midas_db File Internal component, do not modify gs://theiagen-public-files-rp/terra/theiaprok-files/midas/midas_db_v1.2.tar.gz Optional read_QC_trim read_processing String The name of the tool to perform basic read processing; options: \"trimmomatic\" or \"fastp\" trimmomatic Optional read_QC_trim read_qc String The tool used for quality control (QC) of reads. Options are \"fastq_scan\" (default) and \"fastqc\" fastq_scan Optional read_QC_trim taxon_id Int Internal component, do not modify 0 Optional read_QC_trim trimmomatic_args String Additional arguments to pass to trimmomatic. \"-phred33\" specifies the Phred Q score encoding which is almost always phred33 with modern sequence data. -phred33 Optional theiacov_illumina_pe adapters File A FASTA file containing adapter sequences /bbmap/resources/adapters.fa Optional theiacov_illumina_pe consensus_min_freq Float The minimum frequency for a variant to be called a SNP in consensus genome 0.6 Optional theiacov_illumina_pe genome_length Int User-specified expected genome length to be used in genome statistics calculations Optional theiacov_illumina_pe max_genome_length Int Maximum genome length able to pass read screening 2673870 Optional theiacov_illumina_pe min_basepairs Int Minimum number of base pairs able to pass read screening 17000 Optional theiacov_illumina_pe min_coverage Int Minimum genome coverage able to pass read screening 10 Optional theiacov_illumina_pe min_depth Int Minimum depth of reads required to call variants and generate a consensus genome. This value is passed to the iVar software. 100 Optional theiacov_illumina_pe min_genome_length Int Minimum genome length to pass read screening 1700 Optional theiacov_illumina_pe min_proportion Int Minimum proportion of total reads in each read file to pass read screening 40 Optional theiacov_illumina_pe min_reads Int Minimum number of reads to pass read screening 57 Optional theiacov_illumina_pe nextclade_dataset_name String Nextclade organism dataset names. However, if organism input is set correctly, this input will be automatically assigned the corresponding dataset name. See organism defaults for more information Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional theiacov_illumina_pe nextclade_dataset_tag String Nextclade dataset tag. Used for pulling up-to-date reference genomes and associated information specific to nextclade datasets (QC thresholds, organism-specific information like SARS-CoV-2 clade &amp; lineage information, etc.) that is required for running the Nextclade tool. Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional theiacov_illumina_pe organism String The organism that is being analyzed. Options: \"sars-cov-2\", \"MPXV\", \"WNV\", \"HIV\", \"flu\", \"rsv_a\", \"rsv_b\". However, \"flu\" is not available for TheiaCoV_Illumina_SE sars-cov-2 Optional theiacov_illumina_pe pangolin_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pangolin:4.3.1-pdata-1.34 Optional theiacov_illumina_pe phix File File that contains the phix used /bbmap/resources/phix174_ill.ref.fa.gz Optional theiacov_illumina_pe primer_bed File The bed file containing the primers used when sequencing was performed Optional theiacov_illumina_pe qc_check_table File TSV value with taxons for rows and QC values for columns; internal cells represent user-determined QC thresholds; if provided, turns on the QC Check task. See below for an example QC Check table. Optional theiacov_illumina_pe reference_gene_locations_bed File Use to provide locations of interest where average coverage will be calculated Optional theiacov_illumina_pe reference_genome File An optional reference genome used for consensus assembly and QC Optional theiacov_illumina_pe reference_gff File The general feature format (gff) of the reference genome. Optional theiacov_illumina_pe seq_method String The sequencing methodology used to generate the input read data; for TheiaProk workflows, this input will be used in the \"seq_id\" column in any taxon-specific tables created in the Export Taxon Tables task ILLUMINA Optional theiacov_illumina_pe skip_screen Boolean Set to True to skip the read screening prior to analysis FALSE Optional theiacov_illumina_pe target_organism String The organism whose abundance the user wants to check in their reads. This should be a proper taxonomic name recognized by the Kraken database. Optional theiacov_illumina_pe trim_min_length Int Specifies minimum length of each read after trimming to be kept 75 Optional theiacov_illumina_pe trim_primers Boolean A True/False option that determines if primers should be trimmed. TRUE Optional theiacov_illumina_pe trim_quality_min_score Int Specifies the minimum average quality of bases in a sliding window to be kept 30 Optional theiacov_illumina_pe trim_window_size Int Specifies window size for trimming (the number of bases to average the quality across) 4 Optional theiacov_illumina_pe vadr_max_length Int Maximum length of contig allowed to run VADR Optional theiacov_illumina_pe vadr_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 (RSV-A and RSV-B) and 8 (all other TheiaCoV organisms) Optional theiacov_illumina_pe vadr_model_file File Path to the a tar + gzipped VADR model file Defaults are organism-specific. Please find default values for all organisms here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. Optional theiacov_illumina_pe vadr_options String Additional options to provide to VADR Optional theiacov_illumina_pe vadr_skip_length Int Minimum assembly length (unambiguous) to run VADR 10000 Optional theiacov_illumina_pe variant_min_freq Float Minimum frequency for a variant to be reported in ivar outputs 0.6 Optional vadr cpu Int Number of CPUs to allocate to the task 4 Optional vadr disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional vadr docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/vadr:1.6.4 Optional vadr min_length Int Minimum length subsequence to possibly replace Ns for the fasta-trim-terminal-ambigs.pl VADR script 50 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status theiacov_illumina_se read1 File Illumina forward read file in FASTQ file format (compression optional) Required theiacov_illumina_se samplename String The name of the sample being analyzed Required clean_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional clean_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional clean_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional clean_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional consensus_qc cpu Int Number of CPUs to allocate to the task 1 Optional consensus_qc disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional consensus_qc docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional consensus_qc genome_length Int Internal component, do not modify Optional consensus_qc memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional gene_coverage cpu Int Number of CPUs to allocate to the task 2 Optional gene_coverage disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional gene_coverage docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional gene_coverage memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional gene_coverage min_depth Int The minimum depth to determine if a position was covered. 10 Optional gene_coverage sc2_s_gene_start Int start nucleotide position of the SARS-CoV-2 Spike gene 21563 Optional gene_coverage sc2_s_gene_stop Int End/Last nucleotide position of the SARS-CoV-2 Spike gene 25384 Optional ivar_consensus ivar_bwa_cpu Int Number of CPUs to allocate to the task 6 Optional ivar_consensus ivar_bwa_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ivar_consensus ivar_bwa_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional ivar_consensus ivar_bwa_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional ivar_consensus ivar_consensus_cpu Int Number of CPUs to allocate to the task 2 Optional ivar_consensus ivar_consensus_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ivar_consensus ivar_consensus_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional ivar_consensus ivar_consensus_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional ivar_consensus ivar_trim_primers_cpu Int Number of CPUs to allocate to the task 2 Optional ivar_consensus ivar_trim_primers_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ivar_consensus ivar_trim_primers_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional ivar_consensus ivar_trim_primers_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional ivar_consensus ivar_variant_cpu Int Number of CPUs to allocate to the task 2 Optional ivar_consensus ivar_variant_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ivar_consensus ivar_variant_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional ivar_consensus ivar_variant_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional ivar_consensus read2 File Internal component, do not modify Optional ivar_consensus skip_N Boolean True/False variable that determines if regions with depth less than minimum depth should not be added to the consensus sequence FALSE Optional ivar_consensus stats_n_coverage_cpu Int Number of CPUs to allocate to the task 2 Optional ivar_consensus stats_n_coverage_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ivar_consensus stats_n_coverage_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional ivar_consensus stats_n_coverage_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional ivar_consensus stats_n_coverage_primtrim_cpu Int Number of CPUs to allocate to the task 2 Optional ivar_consensus stats_n_coverage_primtrim_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ivar_consensus stats_n_coverage_primtrim_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional ivar_consensus stats_n_coverage_primtrim_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional nextclade_output_parser cpu Int Number of CPUs to allocate to the task 2 Optional nextclade_output_parser disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional nextclade_output_parser docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/python/python:3.8.18-slim Optional nextclade_output_parser memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional nextclade_v3 auspice_reference_tree_json File An Auspice JSON phylogenetic reference tree which serves as a target for phylogenetic placement. Inherited from nextclade dataset Optional nextclade_v3 cpu Int Number of CPUs to allocate to the task 2 Optional nextclade_v3 custom_input_dataset File For H5N1 flu samples only. A custom Nextclade dataset in JSON format. If provided, this dataset will be used to process any H5N1 flu samples. If not provided, a custom dataset will be selected depending on the GenoFLU Genotype. Defaults are GenoFLU Genotype specific. Please find these default values here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional nextclade_v3 disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional nextclade_v3 docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.16.0 Optional nextclade_v3 gene_annotations_gff File A genome annotation to specify how to translate the nucleotide sequence to proteins (genome_annotation.gff3). specifying this enables codon-informed alignment and protein alignments. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/03-genome-annotation.html Inherited from nextclade dataset Optional nextclade_v3 input_ref File A nucleotide sequence which serves as a reference for the pairwise alignment of all input sequences. This is also the sequence which defines the coordinate system of the genome annotation. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/02-reference-sequence.html Inherited from nextclade dataset Optional nextclade_v3 memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional nextclade_v3 nextclade_pathogen_json File General dataset configuration file. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/05-pathogen-config.html Inherited from nextclade dataset Optional nextclade_v3 verbosity String other options are: \"off\" , \"error\" , \"info\" , \"debug\" , and \"trace\" (highest level of verbosity) warn Optional organism_parameters auspice_config File Auspice config file for customizing visualizations in the Augur_PHB workflow; takes priority over the other customization values available for augur_export. Defaults are set for various organisms &amp; flu segments. A minimal auspice config file is set in cases where organism is not specified and user does not provide an optional input config file. Optional organism_parameters clades_tsv File Internal component, do not modify Optional organism_parameters flu_genoflu_genotype String Internal component, do not modify N/A Optional organism_parameters flu_segment String Influenza genome segment being analyzed. Options: \"HA\" or \"NA\". Automatically determined. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs N/A Optional organism_parameters flu_subtype String The influenza subtype being analyzed. Options: \"Yamagata\", \"Victoria\", \"H1N1\", \"H3N2\", \"H5N1\". Automatically determined. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs N/A Optional organism_parameters hiv_primer_version String The version of HIV primers used. Options are https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl#L156 and https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl#L164. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs v1 Optional organism_parameters kraken_target_organism_input String The organism whose abundance the user wants to check in their reads. This should be a proper taxonomic name recognized by the Kraken database. Default provided for mpox (Monkeypox virus), WNV (West Nile virus), and HIV (Human immunodeficiency virus 1) Optional organism_parameters lat_longs_tsv File Internal component, do not modify Optional organism_parameters min_date Float Internal component, do not modify Optional organism_parameters min_num_unambig Int Minimum number of called bases in genome to pass prefilter Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, the default value is 0 Optional organism_parameters narrow_bandwidth Float Internal component, do not modify Optional organism_parameters pivot_interval Int Internal component, do not modify Optional organism_parameters proportion_wide Float Internal component, do not modify Optional organism_parameters reference_genbank File Internal component, do not modify Optional pangolin4 analysis_mode String Used to switch between usher and pangolearn analysis modes. Only use usher because pangolearn is no longer supported as of Pangolin v4.3 and higher versions. Optional pangolin4 cpu Int Number of CPUs to allocate to the task 4 Optional pangolin4 disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional pangolin4 expanded_lineage Boolean True/False that determines if a lineage should be expanded without aliases (e.g., BA.1 \u2192 B.1.1.529.1) TRUE Optional pangolin4 max_ambig Float The maximum proportion of Ns allowed for pangolin to attempt an assignment 0.5 Optional pangolin4 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional pangolin4 min_length Int Minimum query length allowed for pangolin to attempt an assignment 10000 Optional pangolin4 pangolin_arguments String Optional arguments for pangolin e.g. ''--skip-scorpio'' Optional pangolin4 skip_designation_cache Boolean A True/False option that determines if the designation cache should be used FALSE Optional pangolin4 skip_scorpio Boolean A True/False option that determines if scorpio should be skipped. FALSE Optional qc_check_task ani_highest_percent Float Internal component, do not modify Optional qc_check_task ani_highest_percent_bases_aligned Float Internal component, do not modify Optional qc_check_task assembly_length Int Internal component, do not modify Optional qc_check_task busco_results String Internal component, do not modify Optional qc_check_task combined_mean_q_clean Float Internal component, do not modify Optional qc_check_task combined_mean_q_raw Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task cpu Int Number of CPUs to allocate to the task 4 Optional qc_check_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional qc_check_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional qc_check_task est_coverage_clean Float Internal component, do not modify Optional qc_check_task est_coverage_raw Float Internal component, do not modify Optional qc_check_task gambit_predicted_taxon String Internal component, do not modify Optional qc_check_task kraken_human_dehosted Float Internal component, do not modify Optional qc_check_task kraken_sc2 Float Internal component, do not modify Optional qc_check_task kraken_sc2_dehosted Float Internal component, do not modify Optional qc_check_task kraken_target_organism Float Internal component, do not modify Optional qc_check_task kraken_target_organism_dehosted Float Internal component, do not modify Optional qc_check_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional qc_check_task midas_secondary_genus_abundance Float Internal component, do not modify Optional qc_check_task midas_secondary_genus_coverage Float Internal component, do not modify Optional qc_check_task n50_value Int Internal component, do not modify Optional qc_check_task num_reads_clean2 Int Internal component, do not modify Optional qc_check_task num_reads_raw2 Int Internal component, do not modify Optional qc_check_task number_contigs Int Internal component, do not modify Optional qc_check_task quast_gc_percent Float Internal component, do not modify Optional qc_check_task r1_mean_q_clean Float Internal component, do not modify Optional qc_check_task r1_mean_q_raw Float Internal component, do not modify Optional qc_check_task r1_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task r1_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task r2_mean_q_clean Float Internal component, do not modify Optional qc_check_task r2_mean_q_raw Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task sc2_s_gene_mean_coverage Float Internal component, do not modify Optional qc_check_task sc2_s_gene_percent_coverage Float Internal component, do not modify Optional raw_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional raw_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional raw_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional raw_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional read_QC_trim bbduk_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim call_kraken Boolean True/False variable that determines if the Kraken2 task should be called; for non-TheiaCoV workflows, the <code>kraken_db</code> variable must be provided. FALSE Optional read_QC_trim call_midas Boolean True/False variable that determines if the MIDAS task should be called. FALSE Optional read_QC_trim fastp_args String Additional arguments to use with fastp -g -5 20 -3 20 Optional read_QC_trim kraken_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim kraken_db File A kraken2 database to use with the kraken2 optional task. The file must be a .tar.gz kraken2 database. Must contain human and viral sequences gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz Optional read_QC_trim kraken_disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional read_QC_trim kraken_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional read_QC_trim midas_db File Internal component, do not modify gs://theiagen-public-files-rp/terra/theiaprok-files/midas/midas_db_v1.2.tar.gz Optional read_QC_trim read_processing String The name of the tool to perform basic read processing; options: \"trimmomatic\" or \"fastp\" trimmomatic Optional read_QC_trim read_qc String The tool used for quality control (QC) of reads. Options are \"fastq_scan\" (default) and \"fastqc\" fastq_scan Optional read_QC_trim trimmomatic_args String Additional arguments to pass to trimmomatic. \"-phred33\" specifies the Phred Q score encoding which is almost always phred33 with modern sequence data. -phred33 Optional theiacov_illumina_se adapters File A FASTA file containing adapter sequences /bbmap/resources/adapters.fa Optional theiacov_illumina_se consensus_min_freq Float The minimum frequency for a variant to be called a SNP in consensus genome 0.6 Optional theiacov_illumina_se genome_length Int User-specified expected genome length to be used in genome statistics calculations Optional theiacov_illumina_se max_genome_length Int Maximum genome length able to pass read screening 2673870 Optional theiacov_illumina_se min_basepairs Int Minimum number of base pairs able to pass read screening 17000 Optional theiacov_illumina_se min_coverage Int Minimum genome coverage able to pass read screening 10 Optional theiacov_illumina_se min_depth Int Minimum depth of reads required to call variants and generate a consensus genome. This value is passed to the iVar software. 100 Optional theiacov_illumina_se min_genome_length Int Minimum genome length to pass read screening 1700 Optional theiacov_illumina_se min_reads Int Minimum number of reads to pass read screening 57 Optional theiacov_illumina_se nextclade_dataset_name String Nextclade organism dataset names. However, if organism input is set correctly, this input will be automatically assigned the corresponding dataset name. See organism defaults for more information Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional theiacov_illumina_se nextclade_dataset_tag String Nextclade dataset tag. Used for pulling up-to-date reference genomes and associated information specific to nextclade datasets (QC thresholds, organism-specific information like SARS-CoV-2 clade &amp; lineage information, etc.) that is required for running the Nextclade tool. Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional theiacov_illumina_se organism String The organism that is being analyzed. Options: \"sars-cov-2\", \"MPXV\", \"WNV\", \"HIV\", \"flu\", \"rsv_a\", \"rsv_b\". However, \"flu\" is not available for TheiaCoV_Illumina_SE sars-cov-2 Optional theiacov_illumina_se pangolin_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pangolin:4.3.1-pdata-1.34 Optional theiacov_illumina_se phix File File that contains the phix used /bbmap/resources/phix174_ill.ref.fa.gz Optional theiacov_illumina_se primer_bed File The bed file containing the primers used when sequencing was performed Optional theiacov_illumina_se qc_check_table File TSV value with taxons for rows and QC values for columns; internal cells represent user-determined QC thresholds; if provided, turns on the QC Check task. See below for an example QC Check table. Optional theiacov_illumina_se reference_gene_locations_bed File Use to provide locations of interest where average coverage will be calculated Optional theiacov_illumina_se reference_genome File An optional reference genome used for consensus assembly and QC Optional theiacov_illumina_se reference_gff File The general feature format (gff) of the reference genome. Optional theiacov_illumina_se seq_method String The sequencing methodology used to generate the input read data; for TheiaProk workflows, this input will be used in the \"seq_id\" column in any taxon-specific tables created in the Export Taxon Tables task ILLUMINA Optional theiacov_illumina_se skip_mash Boolean If true, skips estimation of genome size and coverage using mash in read screening steps. As a result, providing true also prevents screening using these parameters. FALSE Optional theiacov_illumina_se skip_screen Boolean Set to True to skip the read screening prior to analysis FALSE Optional theiacov_illumina_se trim_min_length Int Specifies minimum length of each read after trimming to be kept 25 Optional theiacov_illumina_se trim_primers Boolean A True/False option that determines if primers should be trimmed. TRUE Optional theiacov_illumina_se trim_quality_min_score Int Specifies the minimum average quality of bases in a sliding window to be kept 30 Optional theiacov_illumina_se trim_window_size Int Specifies window size for trimming (the number of bases to average the quality across) 4 Optional theiacov_illumina_se vadr_max_length Int Maximum length of contig allowed to run VADR Optional theiacov_illumina_se vadr_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 (RSV-A and RSV-B) and 8 (all other TheiaCoV organisms) Optional theiacov_illumina_se vadr_model_file File Path to the a tar + gzipped VADR model file Defaults are organism-specific. Please find default values for all organisms here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. Optional theiacov_illumina_se vadr_options String Additional options to provide to VADR Optional theiacov_illumina_se vadr_skip_length Int Minimum assembly length (unambiguous) to run VADR 10000 Optional theiacov_illumina_se variant_min_freq Float Minimum frequency for a variant to be reported in ivar outputs 0.6 Optional vadr cpu Int Number of CPUs to allocate to the task 4 Optional vadr disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional vadr docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/vadr:1.6.4 Optional vadr min_length Int Minimum length subsequence to possibly replace Ns for the fasta-trim-terminal-ambigs.pl VADR script 50 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status theiacov_ont read1 File ONT read file in FASTQ file format (compression optional) Required theiacov_ont samplename String The name of the sample being analyzed Required clean_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional clean_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional clean_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional clean_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional consensus cpu Int Number of CPUs to allocate to the task 8 Optional consensus disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional consensus docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/artic-ncov2019-epi2me Optional consensus medaka_model String In order to obtain the best results, the appropriate model must be set to match the sequencer's basecaller model; this string takes the format of {pore}{device}{caller variant}_{caller_version}. See also https://github.com/nanoporetech/medaka?tab=readme-ov-file#models. r941_min_high_g360 Optional consensus memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional consensus_qc cpu Int Number of CPUs to allocate to the task 1 Optional consensus_qc disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional consensus_qc docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional consensus_qc memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional flu_track abricate_flu_cpu Int Number of CPUs to allocate to the task 2 Optional flu_track abricate_flu_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flu_track abricate_flu_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-insaflu-220727 Optional flu_track abricate_flu_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional flu_track abricate_flu_min_percent_coverage Int Minimum DNA percent coverage 60 Optional flu_track abricate_flu_min_percent_identity Int Minimum DNA percent identity 70 Optional flu_track antiviral_aa_subs String Additional list of antiviral resistance associated amino acid substitutions of interest to be searched against those called on the sample segments. They take the format of :, e.g. NA:A26V Optional flu_track assembly_fasta File Internal component, do not modify Optional flu_track assembly_metrics_cpu Int Number of CPUs to allocate to the task 2 Optional flu_track assembly_metrics_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flu_track assembly_metrics_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional flu_track assembly_metrics_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional flu_track flu_h1_ha_ref File Internal component, do not modify Optional flu_track flu_h1n1_m2_ref File Internal component, do not modify Optional flu_track flu_h3_ha_ref File Internal component, do not modify Optional flu_track flu_h3n2_m2_ref File Internal component, do not modify Optional flu_track flu_n1_na_ref File Internal component, do not modify Optional flu_track flu_n2_na_ref File Internal component, do not modify Optional flu_track flu_pa_ref File Internal component, do not modify Optional flu_track flu_pb1_ref File Internal component, do not modify Optional flu_track flu_pb2_ref File Internal component, do not modify Optional flu_track flu_subtype String The influenza subtype being analyzed. Used for picking nextclade datasets. Options: \"Yamagata\", \"Victoria\", \"H1N1\", \"H3N2\", \"H5N1\". Only use to override the subtype call from IRMA and ABRicate. Optional flu_track genoflu_cpu Int Number of CPUs to allocate to the task 1 Optional flu_track genoflu_cross_reference File An Excel file to cross-reference BLAST findings; probably useful if novel genotypes are not in the default file used by genoflu.py Optional flu_track genoflu_disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional flu_track genoflu_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/genoflu:1.06 Optional flu_track genoflu_memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional flu_track genoflu_min_percent_identity Float Percent identity threshold used for calling matches for each genome segment that make up the final GenoFlu genotype 98 Optional flu_track irma_cpu Int Number of CPUs to allocate to the task 4 Optional flu_track irma_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flu_track irma_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/irma:1.2.0 Optional flu_track irma_keep_ref_deletions Boolean True/False variable that determines if sites missed (i.e. 0 reads for a site in the reference genome) during read gathering should be deleted by ambiguation by inserting N's or deleting the sequence entirely. False sets this IRMA paramater to \"DEL\" and true sets it to \"NNN\" TRUE Optional flu_track irma_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional flu_track irma_min_ambiguous_threshold Float Minimum called Single Nucleotide Variant (SNV) frequency for mixed based calls in the output consensus assembly (AKA amended consensus). 0.2 Optional flu_track irma_min_avg_consensus_allele_quality Int Minimum allele coverage depth to call plurality consensus, otherwise calls \"N\". Setting this value too high can negatively impact final amended consensus. 10 Optional flu_track irma_min_read_length Int Minimum read length to include reads in read gathering step in IRMA. This value should not be greater than the typical read length. 75 Optional flu_track nextclade_cpu Int Number of CPUs to allocate to the task 2 Optional flu_track nextclade_custom_input_dataset File For H5N1 flu samples only. A custom Nextclade dataset in JSON format. If provided, this dataset will be used to process any H5N1 flu samples. If not provided, a custom dataset will be selected depending on the GenoFLU Genotype. Defaults are GenoFLU Genotype specific. Please find these default values here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional flu_track nextclade_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional flu_track nextclade_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.14.5 Optional flu_track nextclade_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional flu_track nextclade_output_parser_cpu Int Number of CPUs to allocate to the task 2 Optional flu_track nextclade_output_parser_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional flu_track nextclade_output_parser_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/python/python:3.8.18-slim Optional flu_track nextclade_output_parser_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional flu_track read2 File Internal component, do not modify Optional flu_track vadr_outputs_tgz File Internal component, do not modify Optional gene_coverage cpu Int Number of CPUs to allocate to the task 2 Optional gene_coverage disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional gene_coverage docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional gene_coverage memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional gene_coverage min_depth Int The minimum depth to determine if a position was covered. 10 Optional gene_coverage sc2_s_gene_start Int start nucleotide position of the SARS-CoV-2 Spike gene 21563 Optional gene_coverage sc2_s_gene_stop Int End/Last nucleotide position of the SARS-CoV-2 Spike gene 25384 Optional nanoplot_clean cpu Int Number of CPUs to allocate to the task 4 Optional nanoplot_clean disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoplot_clean docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Optional nanoplot_clean max_length Int The maximum length of clean reads, for which reads longer than the length specified will be hidden. 100000 Optional nanoplot_clean memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional nanoplot_raw cpu Int Number of CPUs to allocate to the task 4 Optional nanoplot_raw disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoplot_raw docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Optional nanoplot_raw max_length Int The maximum length of clean reads, for which reads longer than the length specified will be hidden. 100000 Optional nanoplot_raw memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional nextclade_output_parser cpu Int Number of CPUs to allocate to the task 2 Optional nextclade_output_parser disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional nextclade_output_parser docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/python/python:3.8.18-slim Optional nextclade_output_parser memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional nextclade_v3 auspice_reference_tree_json File An Auspice JSON phylogenetic reference tree which serves as a target for phylogenetic placement. Inherited from nextclade dataset Optional nextclade_v3 cpu Int Number of CPUs to allocate to the task 2 Optional nextclade_v3 custom_input_dataset File For H5N1 flu samples only. A custom Nextclade dataset in JSON format. If provided, this dataset will be used to process any H5N1 flu samples. If not provided, a custom dataset will be selected depending on the GenoFLU Genotype. Defaults are GenoFLU Genotype specific. Please find these default values here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional nextclade_v3 disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional nextclade_v3 docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.16.0 Optional nextclade_v3 gene_annotations_gff File A genome annotation to specify how to translate the nucleotide sequence to proteins (genome_annotation.gff3). specifying this enables codon-informed alignment and protein alignments. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/03-genome-annotation.html Inherited from nextclade dataset Optional nextclade_v3 input_ref File A nucleotide sequence which serves as a reference for the pairwise alignment of all input sequences. This is also the sequence which defines the coordinate system of the genome annotation. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/02-reference-sequence.html Inherited from nextclade dataset Optional nextclade_v3 memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional nextclade_v3 nextclade_pathogen_json File General dataset configuration file. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/05-pathogen-config.html Inherited from nextclade dataset Optional nextclade_v3 verbosity String other options are: \"off\" , \"error\" , \"info\" , \"debug\" , and \"trace\" (highest level of verbosity) warn Optional organism_parameters auspice_config File Auspice config file for customizing visualizations in the Augur_PHB workflow; takes priority over the other customization values available for augur_export. Defaults are set for various organisms &amp; flu segments. A minimal auspice config file is set in cases where organism is not specified and user does not provide an optional input config file. Optional organism_parameters clades_tsv File Internal component, do not modify Optional organism_parameters flu_genoflu_genotype String Internal component, do not modify N/A Optional organism_parameters flu_segment String Influenza genome segment being analyzed. Options: \"HA\" or \"NA\". Automatically determined. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs N/A Optional organism_parameters flu_subtype String The influenza subtype being analyzed. Options: \"Yamagata\", \"Victoria\", \"H1N1\", \"H3N2\", \"H5N1\". Automatically determined. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs N/A Optional organism_parameters hiv_primer_version String The version of HIV primers used. Options are https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl#L156 and https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl#L164. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs v1 Optional organism_parameters lat_longs_tsv File Internal component, do not modify Optional organism_parameters min_date Float Internal component, do not modify Optional organism_parameters min_num_unambig Int Minimum number of called bases in genome to pass prefilter Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, the default value is 0 Optional organism_parameters narrow_bandwidth Float Internal component, do not modify Optional organism_parameters pivot_interval Int Internal component, do not modify Optional organism_parameters proportion_wide Float Internal component, do not modify Optional organism_parameters reference_genbank File Internal component, do not modify Optional organism_parameters reference_gff_file File Reference GFF file for the organism being analyzed Default provided for mpox (\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/Mpox-MT903345.1.reference.gff3\") and HIV (primer versions 1 [\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/NC_001802.1.gff3\"] and 2 [\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/AY228557.1.gff3\"]) Optional pangolin4 analysis_mode String Used to switch between usher and pangolearn analysis modes. Only use usher because pangolearn is no longer supported as of Pangolin v4.3 and higher versions. Optional pangolin4 cpu Int Number of CPUs to allocate to the task 4 Optional pangolin4 disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional pangolin4 expanded_lineage Boolean True/False that determines if a lineage should be expanded without aliases (e.g., BA.1 \u2192 B.1.1.529.1) TRUE Optional pangolin4 max_ambig Float The maximum proportion of Ns allowed for pangolin to attempt an assignment 0.5 Optional pangolin4 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional pangolin4 min_length Int Minimum query length allowed for pangolin to attempt an assignment 10000 Optional pangolin4 pangolin_arguments String Optional arguments for pangolin e.g. ''--skip-scorpio'' Optional pangolin4 skip_designation_cache Boolean A True/False option that determines if the designation cache should be used FALSE Optional pangolin4 skip_scorpio Boolean A True/False option that determines if scorpio should be skipped. FALSE Optional qc_check_task ani_highest_percent Float Internal component, do not modify Optional qc_check_task ani_highest_percent_bases_aligned Float Internal component, do not modify Optional qc_check_task assembly_length Int Internal component, do not modify Optional qc_check_task busco_results String Internal component, do not modify Optional qc_check_task combined_mean_q_clean Float Internal component, do not modify Optional qc_check_task combined_mean_q_raw Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task cpu Int Number of CPUs to allocate to the task 4 Optional qc_check_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional qc_check_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional qc_check_task est_coverage_clean Float Internal component, do not modify Optional qc_check_task est_coverage_raw Float Internal component, do not modify Optional qc_check_task gambit_predicted_taxon String Internal component, do not modify Optional qc_check_task kraken_human_dehosted Float Internal component, do not modify Optional qc_check_task kraken_sc2 Float Internal component, do not modify Optional qc_check_task kraken_sc2_dehosted Float Internal component, do not modify Optional qc_check_task kraken_target_organism Float Internal component, do not modify Optional qc_check_task kraken_target_organism_dehosted Float Internal component, do not modify Optional qc_check_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional qc_check_task midas_secondary_genus_abundance Float Internal component, do not modify Optional qc_check_task midas_secondary_genus_coverage Float Internal component, do not modify Optional qc_check_task n50_value Int Internal component, do not modify Optional qc_check_task num_reads_clean2 Int Internal component, do not modify Optional qc_check_task num_reads_raw2 Int Internal component, do not modify Optional qc_check_task number_contigs Int Internal component, do not modify Optional qc_check_task quast_gc_percent Float Internal component, do not modify Optional qc_check_task r1_mean_q_clean Float Internal component, do not modify Optional qc_check_task r1_mean_q_raw Float Internal component, do not modify Optional qc_check_task r1_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task r1_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task r2_mean_q_clean Float Internal component, do not modify Optional qc_check_task r2_mean_q_raw Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task sc2_s_gene_mean_coverage Float Internal component, do not modify Optional qc_check_task sc2_s_gene_percent_coverage Float Internal component, do not modify Optional quasitools_ont cpu Int Number of CPUs to allocate to the task 2 Optional quasitools_ont disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional quasitools_ont docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/quasitools:0.7.0--pyh864c0ab_1 Optional quasitools_ont memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional quasitools_ont read2 File Internal component, do not modify Optional raw_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional raw_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional raw_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional raw_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional read_QC_trim artic_guppyplex_cpu Int Number of CPUs to allocate to the task 8 Optional read_QC_trim artic_guppyplex_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim artic_guppyplex_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/artic-ncov2019:1.3.0-medaka-1.4.3 Optional read_QC_trim artic_guppyplex_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional read_QC_trim call_kraken Boolean True/False variable that determines if the Kraken2 task should be called; for non-TheiaCoV workflows, the <code>kraken_db</code> variable must be provided. FALSE Optional read_QC_trim downsampling_coverage Float The desired coverage to sub-sample the reads to with RASUSA 150 Optional read_QC_trim kraken2_recalculate_abundances_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim kraken2_recalculate_abundances_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim kraken2_recalculate_abundances_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-08-28-v4 Optional read_QC_trim kraken2_recalculate_abundances_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim kraken_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim kraken_db File A kraken2 database to use with the kraken2 optional task. The file must be a .tar.gz kraken2 database. Must contain human and viral sequences gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz Optional read_QC_trim kraken_disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional read_QC_trim kraken_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Optional read_QC_trim kraken_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional read_QC_trim nanoq_cpu Int Number of CPUs to allocate to the task 2 Optional read_QC_trim nanoq_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim nanoq_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/nanoq:0.9.0--hec16e2b_1 Optional read_QC_trim nanoq_max_read_length Int The maximum read length to keep after trimming 100000 Optional read_QC_trim nanoq_max_read_qual Int The maximum read quality to keep after trimming 40 Optional read_QC_trim nanoq_memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional read_QC_trim nanoq_min_read_length Int The minimum read length to keep after trimming 500 Optional read_QC_trim nanoq_min_read_qual Int The minimum read quality to keep after trimming 10 Optional read_QC_trim ncbi_scrub_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim ncbi_scrub_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim ncbi_scrub_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ncbi/sra-human-scrubber:2.2.1 Optional read_QC_trim ncbi_scrub_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim rasusa_bases String Internal component, do not modify Optional read_QC_trim rasusa_cpu Int Internal component, do not modify Optional read_QC_trim rasusa_disk_size Int Internal component, do not modify Optional read_QC_trim rasusa_docker String Internal component, do not modify Optional read_QC_trim rasusa_fraction_of_reads Float Internal component, do not modify Optional read_QC_trim rasusa_memory Int Internal component, do not modify Optional read_QC_trim rasusa_number_of_reads Int Internal component, do not modify Optional read_QC_trim rasusa_seed Int Internal component, do not modify Optional stats_n_coverage cpu Int Number of CPUs to allocate to the task 2 Optional stats_n_coverage disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional stats_n_coverage docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional stats_n_coverage memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional stats_n_coverage_primtrim cpu Int Number of CPUs to allocate to the task 2 Optional stats_n_coverage_primtrim disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional stats_n_coverage_primtrim docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional stats_n_coverage_primtrim memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional theiacov_ont genome_length Int User-specified expected genome length to be used in genome statistics calculations Optional theiacov_ont irma_min_consensus_support Int Minimum consensus support threshold used by IRMA with ONT data. 50 Optional theiacov_ont max_genome_length Int Maximum genome length able to pass read screening 2673870 Optional theiacov_ont max_length Int Maximum length for a read based on the SARS-CoV-2 primer scheme 700 Optional theiacov_ont min_basepairs Int Minimum number of base pairs able to pass read screening 17000 Optional theiacov_ont min_coverage Int Minimum genome coverage able to pass read screening 10 Optional theiacov_ont min_genome_length Int Minimum genome length to pass read screening 1700 Optional theiacov_ont min_length Int Minimum length of a read based on the SARS-CoV-2 primer scheme 400 Optional theiacov_ont min_reads Int Minimum number of reads to pass read screening 57 Optional theiacov_ont nextclade_dataset_name String Nextclade organism dataset names. However, if organism input is set correctly, this input will be automatically assigned the corresponding dataset name. See organism defaults for more information Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional theiacov_ont nextclade_dataset_tag String Nextclade dataset tag. Used for pulling up-to-date reference genomes and associated information specific to nextclade datasets (QC thresholds, organism-specific information like SARS-CoV-2 clade &amp; lineage information, etc.) that is required for running the Nextclade tool. Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional theiacov_ont normalise Int Used to normalize the amount of reads to the indicated level before variant calling 200 Optional theiacov_ont organism String The organism that is being analyzed. Options: \"sars-cov-2\", \"MPXV\", \"WNV\", \"HIV\", \"flu\", \"rsv_a\", \"rsv_b\". However, \"flu\" is not available for TheiaCoV_Illumina_SE sars-cov-2 Optional theiacov_ont pangolin_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pangolin:4.3.1-pdata-1.34 Optional theiacov_ont primer_bed File The bed file containing the primers used when sequencing was performed Optional theiacov_ont qc_check_table File TSV value with taxons for rows and QC values for columns; internal cells represent user-determined QC thresholds; if provided, turns on the QC Check task. See below for an example QC Check table. Optional theiacov_ont reference_gene_locations_bed File Use to provide locations of interest where average coverage will be calculated Optional theiacov_ont reference_genome File An optional reference genome used for consensus assembly and QC Optional theiacov_ont seq_method String The sequencing methodology used to generate the input read data; for TheiaProk workflows, this input will be used in the \"seq_id\" column in any taxon-specific tables created in the Export Taxon Tables task OXFORD_NANOPORE Optional theiacov_ont skip_mash Boolean If true, skips estimation of genome size and coverage using mash in read screening steps. As a result, providing true also prevents screening using these parameters. FALSE Optional theiacov_ont skip_screen Boolean Set to True to skip the read screening prior to analysis FALSE Optional theiacov_ont target_organism String The organism whose abundance the user wants to check in their reads. This should be a proper taxonomic name recognized by the Kraken database. Optional theiacov_ont vadr_max_length Int Maximum length of contig allowed to run VADR Optional theiacov_ont vadr_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 (RSV-A and RSV-B) and 8 (all other TheiaCoV organisms) Optional theiacov_ont vadr_model_file File Path to the a tar + gzipped VADR model file Defaults are organism-specific. Please find default values for all organisms here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. Optional theiacov_ont vadr_options String Additional options to provide to VADR Optional theiacov_ont vadr_skip_length Int Minimum assembly length (unambiguous) to run VADR 10000 Optional vadr cpu Int Number of CPUs to allocate to the task 4 Optional vadr disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional vadr docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/vadr:1.6.4 Optional vadr min_length Int Minimum length subsequence to possibly replace Ns for the fasta-trim-terminal-ambigs.pl VADR script 50 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status theiacov_fasta assembly_fasta File Input assembly FASTA file. Must contain either all 8 influenza genome segments or a single segment provided in multi-FASTA format. Required theiacov_fasta input_assembly_method String Method used to generate the assembly file Required theiacov_fasta samplename String The name of the sample being analyzed Required theiacov_fasta seq_method String The sequencing methodology used to generate the input read data Required theiacov_fasta flu_segment String Influenza genome segment being analyzed. Options: \"HA\" or \"NA\". Only required if input assembly is a singular flu segment. Optional, Required consensus_qc cpu Int Number of CPUs to allocate to the task 1 Optional consensus_qc disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional consensus_qc docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional consensus_qc memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional flu_track abricate_flu_cpu Int Number of CPUs to allocate to the task 2 Optional flu_track abricate_flu_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flu_track abricate_flu_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-insaflu-220727 Optional flu_track abricate_flu_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional flu_track abricate_flu_min_percent_coverage Int Minimum DNA percent coverage 60 Optional flu_track abricate_flu_min_percent_identity Int Minimum DNA percent identity 70 Optional flu_track antiviral_aa_subs String Additional list of antiviral resistance associated amino acid substitutions of interest to be searched against those called on the sample segments. They take the format of :, e.g. NA:A26V Optional flu_track assembly_metrics_cpu Int Internal component, do not modify Optional flu_track assembly_metrics_disk_size Int Internal component, do not modify Optional flu_track assembly_metrics_docker String Internal component, do not modify Optional flu_track assembly_metrics_memory Int Internal component, do not modify Optional flu_track flu_h1_ha_ref File Internal component, do not modify Optional flu_track flu_h1n1_m2_ref File Internal component, do not modify Optional flu_track flu_h3_ha_ref File Internal component, do not modify Optional flu_track flu_h3n2_m2_ref File Internal component, do not modify Optional flu_track flu_n1_na_ref File Internal component, do not modify Optional flu_track flu_n2_na_ref File Internal component, do not modify Optional flu_track flu_pa_ref File Internal component, do not modify Optional flu_track flu_pb1_ref File Internal component, do not modify Optional flu_track flu_pb2_ref File Internal component, do not modify Optional flu_track genoflu_cpu Int Number of CPUs to allocate to the task 1 Optional flu_track genoflu_cross_reference File An Excel file to cross-reference BLAST findings; probably useful if novel genotypes are not in the default file used by genoflu.py Optional flu_track genoflu_disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional flu_track genoflu_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/genoflu:1.06 Optional flu_track genoflu_memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional flu_track genoflu_min_percent_identity Float Percent identity threshold used for calling matches for each genome segment that make up the final GenoFlu genotype 98 Optional flu_track irma_cpu Int Internal component, do not modify Optional flu_track irma_disk_size Int Internal component, do not modify Optional flu_track irma_docker_image String Internal component, do not modify Optional flu_track irma_keep_ref_deletions Boolean Internal component, do not modify Optional flu_track irma_memory Int Internal component, do not modify Optional flu_track irma_min_ambiguous_threshold Float Internal component, do not modify Optional flu_track irma_min_avg_consensus_allele_quality Int Internal component, do not modify Optional flu_track irma_min_consensus_support Int Internal component, do not modify Optional flu_track irma_min_read_length Int Internal component, do not modify Optional flu_track nextclade_cpu Int Number of CPUs to allocate to the task 2 Optional flu_track nextclade_custom_input_dataset File For H5N1 flu samples only. A custom Nextclade dataset in JSON format. If provided, this dataset will be used to process any H5N1 flu samples. If not provided, a custom dataset will be selected depending on the GenoFLU Genotype. Defaults are GenoFLU Genotype specific. Please find these default values here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional flu_track nextclade_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional flu_track nextclade_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.14.5 Optional flu_track nextclade_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional flu_track nextclade_output_parser_cpu Int Number of CPUs to allocate to the task 2 Optional flu_track nextclade_output_parser_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional flu_track nextclade_output_parser_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/python/python:3.8.18-slim Optional flu_track nextclade_output_parser_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional flu_track read1 File Internal component, do not modify Optional flu_track read2 File Internal component, do not modify Optional nextclade_output_parser cpu Int Number of CPUs to allocate to the task 2 Optional nextclade_output_parser disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional nextclade_output_parser docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/python/python:3.8.18-slim Optional nextclade_output_parser memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional nextclade_v3 auspice_reference_tree_json File An Auspice JSON phylogenetic reference tree which serves as a target for phylogenetic placement. Inherited from nextclade dataset Optional nextclade_v3 cpu Int Number of CPUs to allocate to the task 2 Optional nextclade_v3 custom_input_dataset File For H5N1 flu samples only. A custom Nextclade dataset in JSON format. If provided, this dataset will be used to process any H5N1 flu samples. If not provided, a custom dataset will be selected depending on the GenoFLU Genotype. Defaults are GenoFLU Genotype specific. Please find these default values here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional nextclade_v3 disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional nextclade_v3 docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.16.0 Optional nextclade_v3 gene_annotations_gff File A genome annotation to specify how to translate the nucleotide sequence to proteins (genome_annotation.gff3). specifying this enables codon-informed alignment and protein alignments. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/03-genome-annotation.html Inherited from nextclade dataset Optional nextclade_v3 input_ref File A nucleotide sequence which serves as a reference for the pairwise alignment of all input sequences. This is also the sequence which defines the coordinate system of the genome annotation. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/02-reference-sequence.html Inherited from nextclade dataset Optional nextclade_v3 memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional nextclade_v3 nextclade_pathogen_json File General dataset configuration file. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/05-pathogen-config.html Inherited from nextclade dataset Optional nextclade_v3 verbosity String other options are: \"off\" , \"error\" , \"info\" , \"debug\" , and \"trace\" (highest level of verbosity) warn Optional organism_parameters auspice_config File Auspice config file for customizing visualizations in the Augur_PHB workflow; takes priority over the other customization values available for augur_export. Defaults are set for various organisms &amp; flu segments. A minimal auspice config file is set in cases where organism is not specified and user does not provide an optional input config file. Optional organism_parameters clades_tsv File Internal component, do not modify Optional organism_parameters flu_genoflu_genotype String Internal component, do not modify N/A Optional organism_parameters gene_locations_bed_file File Use to provide locations of interest where average coverage will be calculated Default provided for SARS-CoV-2 (\"gs://theiagen-public-resources-rp/reference_data/viral/sars-cov-2/sc2_gene_locations.bed\") and mpox (\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/mpox_gene_locations.bed\") Optional organism_parameters hiv_primer_version String The version of HIV primers used. Options are https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl#L156 and https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl#L164. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs v1 Optional organism_parameters kraken_target_organism_input String The organism whose abundance the user wants to check in their reads. This should be a proper taxonomic name recognized by the Kraken database. Default provided for mpox (Monkeypox virus), WNV (West Nile virus), and HIV (Human immunodeficiency virus 1) Optional organism_parameters lat_longs_tsv File Internal component, do not modify Optional organism_parameters min_date Float Internal component, do not modify Optional organism_parameters min_num_unambig Int Minimum number of called bases in genome to pass prefilter Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, the default value is 0 Optional organism_parameters narrow_bandwidth Float Internal component, do not modify Optional organism_parameters pangolin_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pangolin:4.3.1-pdata-1.34 Optional organism_parameters pivot_interval Int Internal component, do not modify Optional organism_parameters primer_bed_file File The bed file containing the primers used when sequencing was performed REQUIRED FOR SARS-CoV-2, MPOX, WNV, RSV-A &amp; RSV-B. Provided by default only for HIV primer versions 1 (\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/HIV-1_v1.0.primer.hyphen.bed\" and 2 (\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/HIV-1_v2.0.primer.hyphen400.1.bed\") Optional organism_parameters proportion_wide Float Internal component, do not modify Optional organism_parameters reference_genbank File Internal component, do not modify Optional organism_parameters reference_gff_file File Reference GFF file for the organism being analyzed Default provided for mpox (\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/Mpox-MT903345.1.reference.gff3\") and HIV (primer versions 1 [\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/NC_001802.1.gff3\"] and 2 [\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/AY228557.1.gff3\"]) Optional pangolin4 analysis_mode String Used to switch between usher and pangolearn analysis modes. Only use usher because pangolearn is no longer supported as of Pangolin v4.3 and higher versions. Optional pangolin4 cpu Int Number of CPUs to allocate to the task 4 Optional pangolin4 disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional pangolin4 expanded_lineage Boolean True/False that determines if a lineage should be expanded without aliases (e.g., BA.1 \u2192 B.1.1.529.1) TRUE Optional pangolin4 max_ambig Float The maximum proportion of Ns allowed for pangolin to attempt an assignment 0.5 Optional pangolin4 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional pangolin4 min_length Int Minimum query length allowed for pangolin to attempt an assignment 10000 Optional pangolin4 pangolin_arguments String Optional arguments for pangolin e.g. ''--skip-scorpio'' Optional pangolin4 skip_designation_cache Boolean A True/False option that determines if the designation cache should be used FALSE Optional pangolin4 skip_scorpio Boolean A True/False option that determines if scorpio should be skipped. FALSE Optional qc_check_task ani_highest_percent Float Internal component, do not modify Optional qc_check_task ani_highest_percent_bases_aligned Float Internal component, do not modify Optional qc_check_task assembly_length Int Internal component, do not modify Optional qc_check_task assembly_mean_coverage Float Internal component, do not modify Optional qc_check_task busco_results String Internal component, do not modify Optional qc_check_task combined_mean_q_clean Float Internal component, do not modify Optional qc_check_task combined_mean_q_raw Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task cpu Int Number of CPUs to allocate to the task 4 Optional qc_check_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional qc_check_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional qc_check_task est_coverage_clean Float Internal component, do not modify Optional qc_check_task est_coverage_raw Float Internal component, do not modify Optional qc_check_task gambit_predicted_taxon String Internal component, do not modify Optional qc_check_task kraken_human Float Internal component, do not modify Optional qc_check_task kraken_human_dehosted Float Internal component, do not modify Optional qc_check_task kraken_sc2 Float Internal component, do not modify Optional qc_check_task kraken_sc2_dehosted Float Internal component, do not modify Optional qc_check_task kraken_target_organism Float Internal component, do not modify Optional qc_check_task kraken_target_organism_dehosted Float Internal component, do not modify Optional qc_check_task meanbaseq_trim String Internal component, do not modify Optional qc_check_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional qc_check_task midas_secondary_genus_abundance Float Internal component, do not modify Optional qc_check_task midas_secondary_genus_coverage Float Internal component, do not modify Optional qc_check_task n50_value Int Internal component, do not modify Optional qc_check_task num_reads_clean1 Int Internal component, do not modify Optional qc_check_task num_reads_clean2 Int Internal component, do not modify Optional qc_check_task num_reads_raw1 Int Internal component, do not modify Optional qc_check_task num_reads_raw2 Int Internal component, do not modify Optional qc_check_task number_contigs Int Internal component, do not modify Optional qc_check_task quast_gc_percent Float Internal component, do not modify Optional qc_check_task r1_mean_q_clean Float Internal component, do not modify Optional qc_check_task r1_mean_q_raw Float Internal component, do not modify Optional qc_check_task r1_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task r1_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task r2_mean_q_clean Float Internal component, do not modify Optional qc_check_task r2_mean_q_raw Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task sc2_s_gene_mean_coverage Float Internal component, do not modify Optional qc_check_task sc2_s_gene_percent_coverage Float Internal component, do not modify Optional theiacov_fasta flu_subtype String The influenza subtype being analyzed. Options: \"Yamagata\", \"Victoria\", \"H1N1\", \"H3N2\", \"H5N1\". Automatically determined. Optional theiacov_fasta genome_length Int User-specified expected genome length to be used in genome statistics calculations Optional theiacov_fasta nextclade_dataset_name String Nextclade organism dataset names. However, if organism input is set correctly, this input will be automatically assigned the corresponding dataset name. See organism defaults for more information Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional theiacov_fasta nextclade_dataset_tag String Nextclade dataset tag. Used for pulling up-to-date reference genomes and associated information specific to nextclade datasets (QC thresholds, organism-specific information like SARS-CoV-2 clade &amp; lineage information, etc.) that is required for running the Nextclade tool. Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional theiacov_fasta organism String The organism that is being analyzed. Options: \"sars-cov-2\", \"MPXV\", \"WNV\", \"HIV\", \"flu\", \"rsv_a\", \"rsv_b\". However, \"flu\" is not available for TheiaCoV_Illumina_SE sars-cov-2 Optional theiacov_fasta qc_check_table File TSV value with taxons for rows and QC values for columns; internal cells represent user-determined QC thresholds; if provided, turns on the QC Check task. See below for an example QC Check table. Optional theiacov_fasta reference_genome File An optional reference genome used for consensus assembly and QC Optional theiacov_fasta vadr_max_length Int Maximum length of contig allowed to run VADR Optional theiacov_fasta vadr_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 (RSV-A and RSV-B) and 8 (all other TheiaCoV organisms) Optional theiacov_fasta vadr_model_file File Path to the a tar + gzipped VADR model file Defaults are organism-specific. Please find default values for all organisms here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. Optional theiacov_fasta vadr_opts String Additional options to provide to VADR Optional theiacov_fasta vadr_skip_length Int Minimum assembly length (unambiguous) to run VADR 10000 Optional vadr cpu Int Number of CPUs to allocate to the task 4 Optional vadr disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional vadr docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/vadr:1.6.4 Optional vadr min_length Int Minimum length subsequence to possibly replace Ns for the fasta-trim-terminal-ambigs.pl VADR script 50 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status theiacov_clearlabs primer_bed File The bed file containing the primers used when sequencing was performed Required theiacov_clearlabs read1 File Clear Dx-produced read file in FASTQ file format (compression optional) Required theiacov_clearlabs samplename String The name of the sample being analyzed Required consensus cpu Int Number of CPUs to allocate to the task 8 Optional consensus disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional consensus medaka_model String In order to obtain the best results, the appropriate model must be set to match the sequencer's basecaller model; this string takes the format of {pore}{device}{caller variant}_{caller_version}. See also https://github.com/nanoporetech/medaka?tab=readme-ov-file#models. r941_min_high_g360 Optional consensus memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional consensus_qc cpu Int Number of CPUs to allocate to the task 1 Optional consensus_qc disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional consensus_qc docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional consensus_qc genome_length Int Internal component, do not modify Optional consensus_qc memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional fastq_scan_clean_reads cpu Int Number of CPUs to allocate to the task 1 Optional fastq_scan_clean_reads disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional fastq_scan_clean_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/fastq-scan:1.0.1--h4ac6f70_3 Optional fastq_scan_clean_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional fastq_scan_clean_reads read1_name String Internal component, do not modify Optional fastq_scan_raw_reads cpu Int Number of CPUs to allocate to the task 1 Optional fastq_scan_raw_reads disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional fastq_scan_raw_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/fastq-scan:1.0.1--h4ac6f70_3 Optional fastq_scan_raw_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional fastq_scan_raw_reads read1_name String Internal component, do not modify Optional gene_coverage cpu Int Number of CPUs to allocate to the task 2 Optional gene_coverage disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional gene_coverage docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional gene_coverage memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional gene_coverage sc2_s_gene_start Int start nucleotide position of the SARS-CoV-2 Spike gene 21563 Optional gene_coverage sc2_s_gene_stop Int End/Last nucleotide position of the SARS-CoV-2 Spike gene 25384 Optional kraken2_dehosted cpu Int Number of CPUs to allocate to the task 4 Optional kraken2_dehosted disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional kraken2_dehosted docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Optional kraken2_dehosted kraken2_db File The database used to run Kraken2. Must contain viral and human sequences. gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz Optional kraken2_dehosted memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional kraken2_dehosted read2 File Internal component, do not modify Optional kraken2_raw cpu Int Number of CPUs to allocate to the task 4 Optional kraken2_raw disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional kraken2_raw docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Optional kraken2_raw kraken2_db File The database used to run Kraken2. Must contain viral and human sequences. gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz Optional kraken2_raw memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional kraken2_raw read2 File Internal component, do not modify Optional ncbi_scrub_se cpu Int Number of CPUs to allocate to the task 4 Optional ncbi_scrub_se disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ncbi_scrub_se docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ncbi/sra-human-scrubber:2.2.1 Optional ncbi_scrub_se memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional nextclade_output_parser cpu Int Number of CPUs to allocate to the task 2 Optional nextclade_output_parser disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional nextclade_output_parser docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/python/python:3.8.18-slim Optional nextclade_output_parser memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional nextclade_v3 auspice_reference_tree_json File An Auspice JSON phylogenetic reference tree which serves as a target for phylogenetic placement. Inherited from nextclade dataset Optional nextclade_v3 cpu Int Number of CPUs to allocate to the task 2 Optional nextclade_v3 custom_input_dataset File For H5N1 flu samples only. A custom Nextclade dataset in JSON format. If provided, this dataset will be used to process any H5N1 flu samples. If not provided, a custom dataset will be selected depending on the GenoFLU Genotype. Defaults are GenoFLU Genotype specific. Please find these default values here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional nextclade_v3 disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional nextclade_v3 docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.16.0 Optional nextclade_v3 gene_annotations_gff File A genome annotation to specify how to translate the nucleotide sequence to proteins (genome_annotation.gff3). specifying this enables codon-informed alignment and protein alignments. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/03-genome-annotation.html Inherited from nextclade dataset Optional nextclade_v3 input_ref File A nucleotide sequence which serves as a reference for the pairwise alignment of all input sequences. This is also the sequence which defines the coordinate system of the genome annotation. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/02-reference-sequence.html Inherited from nextclade dataset Optional nextclade_v3 memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional nextclade_v3 nextclade_pathogen_json File General dataset configuration file. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/05-pathogen-config.html Inherited from nextclade dataset Optional nextclade_v3 verbosity String other options are: \"off\" , \"error\" , \"info\" , \"debug\" , and \"trace\" (highest level of verbosity) warn Optional organism_parameters auspice_config File Auspice config file for customizing visualizations in the Augur_PHB workflow; takes priority over the other customization values available for augur_export. Defaults are set for various organisms &amp; flu segments. A minimal auspice config file is set in cases where organism is not specified and user does not provide an optional input config file. Optional organism_parameters clades_tsv File Internal component, do not modify Optional organism_parameters flu_genoflu_genotype String Internal component, do not modify N/A Optional organism_parameters flu_segment String Influenza genome segment being analyzed. Options: \"HA\" or \"NA\". Automatically determined. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs N/A Optional organism_parameters flu_subtype String The influenza subtype being analyzed. Options: \"Yamagata\", \"Victoria\", \"H1N1\", \"H3N2\", \"H5N1\". Automatically determined. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs N/A Optional organism_parameters gene_locations_bed_file File Use to provide locations of interest where average coverage will be calculated Default provided for SARS-CoV-2 (\"gs://theiagen-public-resources-rp/reference_data/viral/sars-cov-2/sc2_gene_locations.bed\") and mpox (\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/mpox_gene_locations.bed\") Optional organism_parameters genome_length_input Int Use to specify the expected genome length; provided by default for all supported organisms Default provided for SARS-CoV-2 (29903), mpox (197200), WNV (11000), flu (13000), RSV-A (16000), RSV-B (16000), HIV (primer versions 1 [9181] and 2 [9840]) Optional organism_parameters hiv_primer_version String The version of HIV primers used. Options are https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl#L156 and https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl#L164. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs v1 Optional organism_parameters lat_longs_tsv File Internal component, do not modify Optional organism_parameters min_date Float Internal component, do not modify Optional organism_parameters min_num_unambig Int Minimum number of called bases in genome to pass prefilter Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, the default value is 0 Optional organism_parameters narrow_bandwidth Float Internal component, do not modify Optional organism_parameters pangolin_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pangolin:4.3.1-pdata-1.34 Optional organism_parameters pivot_interval Int Internal component, do not modify Optional organism_parameters primer_bed_file File The bed file containing the primers used when sequencing was performed REQUIRED FOR SARS-CoV-2, MPOX, WNV, RSV-A &amp; RSV-B. Provided by default only for HIV primer versions 1 (\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/HIV-1_v1.0.primer.hyphen.bed\" and 2 (\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/HIV-1_v2.0.primer.hyphen400.1.bed\") Optional organism_parameters proportion_wide Float Internal component, do not modify Optional organism_parameters reference_genbank File Internal component, do not modify Optional organism_parameters reference_gff_file File Reference GFF file for the organism being analyzed Default provided for mpox (\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/Mpox-MT903345.1.reference.gff3\") and HIV (primer versions 1 [\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/NC_001802.1.gff3\"] and 2 [\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/AY228557.1.gff3\"]) Optional organism_parameters vadr_max_length Int Maximum length for the fasta-trim-terminal-ambigs.pl VADR script Default provided for SARS-CoV-2 (30000), mpox (210000), WNV (11000), flu (0), RSV-A (15500) and RSV-B (15500). Optional organism_parameters vadr_mem Int Amount of memory/RAM (in GB) to allocate to the task 32 (RSV-A, RSV-B, WNV) and 16 (all other TheiaCoV organisms) Optional organism_parameters vadr_model File Path to the a tar + gzipped VADR model file gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-sarscov2-1.3-2.tar.gz Optional organism_parameters vadr_options String Options for the v-annotate.pl VADR script --mkey sarscov2 --glsearch -s -r --nomisc --lowsim5seq 6 --lowsim3seq 6 --alt_fail lowscore,insertnn,deletinn --noseqnamemax --out_allfasta Optional organism_parameters vadr_skip_length Int Minimum assembly length (unambiguous) to run VADR 10000 Optional pangolin4 analysis_mode String Used to switch between usher and pangolearn analysis modes. Only use usher because pangolearn is no longer supported as of Pangolin v4.3 and higher versions. Optional pangolin4 cpu Int Number of CPUs to allocate to the task 4 Optional pangolin4 disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional pangolin4 expanded_lineage Boolean True/False that determines if a lineage should be expanded without aliases (e.g., BA.1 \u2192 B.1.1.529.1) TRUE Optional pangolin4 max_ambig Float The maximum proportion of Ns allowed for pangolin to attempt an assignment 0.5 Optional pangolin4 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional pangolin4 min_length Int Minimum query length allowed for pangolin to attempt an assignment 10000 Optional pangolin4 pangolin_arguments String Optional arguments for pangolin e.g. ''--skip-scorpio'' Optional pangolin4 skip_designation_cache Boolean A True/False option that determines if the designation cache should be used FALSE Optional pangolin4 skip_scorpio Boolean A True/False option that determines if scorpio should be skipped. FALSE Optional qc_check_task ani_highest_percent Float Internal component, do not modify Optional qc_check_task ani_highest_percent_bases_aligned Float Internal component, do not modify Optional qc_check_task assembly_length Int Internal component, do not modify Optional qc_check_task busco_results String Internal component, do not modify Optional qc_check_task combined_mean_q_clean Float Internal component, do not modify Optional qc_check_task combined_mean_q_raw Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task cpu Int Number of CPUs to allocate to the task 4 Optional qc_check_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional qc_check_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional qc_check_task est_coverage_clean Float Internal component, do not modify Optional qc_check_task est_coverage_raw Float Internal component, do not modify Optional qc_check_task gambit_predicted_taxon String Internal component, do not modify Optional qc_check_task kraken_sc2 Float Internal component, do not modify Optional qc_check_task kraken_sc2_dehosted Float Internal component, do not modify Optional qc_check_task kraken_target_organism Float Internal component, do not modify Optional qc_check_task kraken_target_organism_dehosted Float Internal component, do not modify Optional qc_check_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional qc_check_task midas_secondary_genus_abundance Float Internal component, do not modify Optional qc_check_task midas_secondary_genus_coverage Float Internal component, do not modify Optional qc_check_task n50_value Int Internal component, do not modify Optional qc_check_task num_reads_clean2 Int Internal component, do not modify Optional qc_check_task num_reads_raw2 Int Internal component, do not modify Optional qc_check_task number_contigs Int Internal component, do not modify Optional qc_check_task quast_gc_percent Float Internal component, do not modify Optional qc_check_task r1_mean_q_clean Float Internal component, do not modify Optional qc_check_task r1_mean_q_raw Float Internal component, do not modify Optional qc_check_task r1_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task r1_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task r2_mean_q_clean Float Internal component, do not modify Optional qc_check_task r2_mean_q_raw Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task sc2_s_gene_mean_coverage Float Internal component, do not modify Optional qc_check_task sc2_s_gene_percent_coverage Float Internal component, do not modify Optional stats_n_coverage cpu Int Number of CPUs to allocate to the task 2 Optional stats_n_coverage disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional stats_n_coverage docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional stats_n_coverage memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional stats_n_coverage_primtrim cpu Int Number of CPUs to allocate to the task 2 Optional stats_n_coverage_primtrim disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional stats_n_coverage_primtrim docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional stats_n_coverage_primtrim memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional theiacov_clearlabs medaka_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/artic-ncov2019:1.3.0-medaka-1.4.3 Optional theiacov_clearlabs nextclade_dataset_name String Nextclade organism dataset names. However, if organism input is set correctly, this input will be automatically assigned the corresponding dataset name. See organism defaults for more information Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional theiacov_clearlabs nextclade_dataset_tag String Nextclade dataset tag. Used for pulling up-to-date reference genomes and associated information specific to nextclade datasets (QC thresholds, organism-specific information like SARS-CoV-2 clade &amp; lineage information, etc.) that is required for running the Nextclade tool. Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional theiacov_clearlabs normalise Int Used to normalize the amount of reads to the indicated level before variant calling 20000 Optional theiacov_clearlabs organism String The organism that is being analyzed. Options: \"sars-cov-2\", \"MPXV\", \"WNV\", \"HIV\", \"flu\", \"rsv_a\", \"rsv_b\". However, \"flu\" is not available for TheiaCoV_Illumina_SE sars-cov-2 Optional theiacov_clearlabs qc_check_table File TSV value with taxons for rows and QC values for columns; internal cells represent user-determined QC thresholds; if provided, turns on the QC Check task. See below for an example QC Check table. Optional theiacov_clearlabs reference_genome File An optional reference genome used for consensus assembly and QC Optional theiacov_clearlabs seq_method String The sequencing methodology used to generate the input read data; for TheiaProk workflows, this input will be used in the \"seq_id\" column in any taxon-specific tables created in the Export Taxon Tables task OXFORD_NANOPORE Optional theiacov_clearlabs target_organism String The organism whose abundance the user wants to check in their reads. This should be a proper taxonomic name recognized by the Kraken database. Optional vadr cpu Int Number of CPUs to allocate to the task 4 Optional vadr disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional vadr docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/vadr:1.6.4 Optional vadr min_length Int Minimum length subsequence to possibly replace Ns for the fasta-trim-terminal-ambigs.pl VADR script 50 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status theiacov_fasta_batch assembly_fastas Array[File] The assembly files for your samples in FASTA format Required theiacov_fasta_batch bucket_name String The GCP bucket for the workspace where the TheiaCoV_FASTA_Batch output files are saved. We recommend using a unique GSURI for the bucket associated with your Terra workspace. The root GSURI is accessible in the Dashboard page of your workspace in the \"Cloud Information\" section.Do not include the prefix gs:// in the stringExample: \"\"fc-c526190d-4332-409b-8086-be7e1af9a0b6/theiacov_fasta_batch-2024-04-15-seq-run-1/ Required theiacov_fasta_batch project_name String The name of the Terra project where the data can be found. Example: \"my-terra-project\" Required theiacov_fasta_batch samplenames Array[String] The names of the samples being analyzed Required theiacov_fasta_batch table_name String The name of the Terra table where the data can be found. Example: \"sars-cov-2-sample\" Required theiacov_fasta_batch workspace_name String The name of the Terra workspace where the data can be found. Example \"my-terra-workspace\" Required cat_files_fasta cpu Int Number of CPUs to allocate to the task 2 Optional cat_files_fasta disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional cat_files_fasta docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional cat_files_fasta memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional nextclade_v3 auspice_reference_tree_json File An Auspice JSON phylogenetic reference tree which serves as a target for phylogenetic placement. Inherited from nextclade dataset Optional nextclade_v3 cpu Int Number of CPUs to allocate to the task 2 Optional nextclade_v3 custom_input_dataset File For H5N1 flu samples only. A custom Nextclade dataset in JSON format. If provided, this dataset will be used to process any H5N1 flu samples. If not provided, a custom dataset will be selected depending on the GenoFLU Genotype. Defaults are GenoFLU Genotype specific. Please find these default values here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl Optional nextclade_v3 disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional nextclade_v3 docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.16.0 Optional nextclade_v3 gene_annotations_gff File A genome annotation to specify how to translate the nucleotide sequence to proteins (genome_annotation.gff3). specifying this enables codon-informed alignment and protein alignments. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/03-genome-annotation.html Inherited from nextclade dataset Optional nextclade_v3 input_ref File A nucleotide sequence which serves as a reference for the pairwise alignment of all input sequences. This is also the sequence which defines the coordinate system of the genome annotation. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/02-reference-sequence.html Inherited from nextclade dataset Optional nextclade_v3 memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional nextclade_v3 nextclade_pathogen_json File General dataset configuration file. See here for more info: https://docs.nextstrain.org/projects/nextclade/en/latest/user/input-files/05-pathogen-config.html Inherited from nextclade dataset Optional nextclade_v3 verbosity String other options are: \"off\" , \"error\" , \"info\" , \"debug\" , and \"trace\" (highest level of verbosity) warn Optional organism_parameters auspice_config File Auspice config file for customizing visualizations in the Augur_PHB workflow; takes priority over the other customization values available for augur_export. Defaults are set for various organisms &amp; flu segments. A minimal auspice config file is set in cases where organism is not specified and user does not provide an optional input config file. Optional organism_parameters clades_tsv File Internal component, do not modify Optional organism_parameters flu_genoflu_genotype String Internal component, do not modify N/A Optional organism_parameters flu_segment String Influenza genome segment being analyzed. Options: \"HA\" or \"NA\". Automatically determined. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs N/A Optional organism_parameters flu_subtype String The influenza subtype being analyzed. Options: \"Yamagata\", \"Victoria\", \"H1N1\", \"H3N2\", \"H5N1\". Automatically determined. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs N/A Optional organism_parameters gene_locations_bed_file File Use to provide locations of interest where average coverage will be calculated Default provided for SARS-CoV-2 (\"gs://theiagen-public-resources-rp/reference_data/viral/sars-cov-2/sc2_gene_locations.bed\") and mpox (\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/mpox_gene_locations.bed\") Optional organism_parameters genome_length_input Int Use to specify the expected genome length; provided by default for all supported organisms Default provided for SARS-CoV-2 (29903), mpox (197200), WNV (11000), flu (13000), RSV-A (16000), RSV-B (16000), HIV (primer versions 1 [9181] and 2 [9840]) Optional organism_parameters hiv_primer_version String The version of HIV primers used. Options are https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl#L156 and https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl#L164. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs v1 Optional organism_parameters kraken_target_organism_input String The organism whose abundance the user wants to check in their reads. This should be a proper taxonomic name recognized by the Kraken database. Default provided for mpox (Monkeypox virus), WNV (West Nile virus), and HIV (Human immunodeficiency virus 1) Optional organism_parameters lat_longs_tsv File Internal component, do not modify Optional organism_parameters min_date Float Internal component, do not modify Optional organism_parameters min_num_unambig Int Minimum number of called bases in genome to pass prefilter Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, the default value is 0 Optional organism_parameters narrow_bandwidth Float Internal component, do not modify Optional organism_parameters pivot_interval Int Internal component, do not modify Optional organism_parameters primer_bed_file File The bed file containing the primers used when sequencing was performed REQUIRED FOR SARS-CoV-2, MPOX, WNV, RSV-A &amp; RSV-B. Provided by default only for HIV primer versions 1 (\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/HIV-1_v1.0.primer.hyphen.bed\" and 2 (\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/HIV-1_v2.0.primer.hyphen400.1.bed\") Optional organism_parameters proportion_wide Float Internal component, do not modify Optional organism_parameters reference_genbank File Internal component, do not modify Optional organism_parameters reference_genome File An optional reference genome used for consensus assembly and QC Optional organism_parameters reference_gff_file File Reference GFF file for the organism being analyzed Default provided for mpox (\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/Mpox-MT903345.1.reference.gff3\") and HIV (primer versions 1 [\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/NC_001802.1.gff3\"] and 2 [\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/AY228557.1.gff3\"]) Optional organism_parameters vadr_max_length Int Maximum length for the fasta-trim-terminal-ambigs.pl VADR script Default provided for SARS-CoV-2 (30000), mpox (210000), WNV (11000), flu (0), RSV-A (15500) and RSV-B (15500). Optional organism_parameters vadr_mem Int Amount of memory/RAM (in GB) to allocate to the task 32 (RSV-A, RSV-B, WNV) and 16 (all other TheiaCoV organisms) Optional organism_parameters vadr_model File Path to the a tar + gzipped VADR model file gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-sarscov2-1.3-2.tar.gz Optional organism_parameters vadr_options String Options for the v-annotate.pl VADR script --mkey sarscov2 --glsearch -s -r --nomisc --lowsim5seq 6 --lowsim3seq 6 --alt_fail lowscore,insertnn,deletinn --noseqnamemax --out_allfasta Optional organism_parameters vadr_skip_length Int Minimum assembly length (unambiguous) to run VADR 10000 Optional pangolin4 analysis_mode String Used to switch between usher and pangolearn analysis modes. Only use usher because pangolearn is no longer supported as of Pangolin v4.3 and higher versions. Optional pangolin4 cpu Int Number of CPUs to allocate to the task 4 Optional pangolin4 disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional pangolin4 expanded_lineage Boolean True/False that determines if a lineage should be expanded without aliases (e.g., BA.1 \u2192 B.1.1.529.1) TRUE Optional pangolin4 max_ambig Float The maximum proportion of Ns allowed for pangolin to attempt an assignment 0.5 Optional pangolin4 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional pangolin4 min_length Int Minimum query length allowed for pangolin to attempt an assignment 10000 Optional pangolin4 pangolin_arguments String Optional arguments for pangolin e.g. ''--skip-scorpio'' Optional pangolin4 skip_designation_cache Boolean A True/False option that determines if the designation cache should be used FALSE Optional pangolin4 skip_scorpio Boolean A True/False option that determines if scorpio should be skipped. FALSE Optional sm_theiacov_fasta_wrangling cpu Int Number of CPUs to allocate to the task 8 Optional sm_theiacov_fasta_wrangling disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional sm_theiacov_fasta_wrangling docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-08-28-v4 Optional sm_theiacov_fasta_wrangling memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional theiacov_fasta_batch nextclade_dataset_name String Nextclade organism dataset name. Options: \"nextstrain/sars-cov-2/wuhan-hu-1/orfs\" However, if organism input is set correctly, this input will be automatically assigned the corresponding dataset name. sars-cov-2 Optional theiacov_fasta_batch nextclade_dataset_tag String Nextclade dataset tag. Used for pulling up-to-date reference genomes and associated information specific to nextclade datasets (QC thresholds, organism-specific information like SARS-CoV-2 clade &amp; lineage information, etc.) that is required for running the Nextclade tool. 2024-06-13--23-42-47Z Optional theiacov_fasta_batch organism String The organism that is being analyzed. Options: \"sars-cov-2\" sars-cov-2 Optional theiacov_fasta_batch pangolin_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pangolin:4.3.1-pdata-1.34 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/genomic_characterization/theiacov/#org-specific","title":"Organism-Specific Parameters","text":"<p>The <code>organism_parameters</code> sub-workflow is the first step in all TheiaCoV workflows. This step automatically sets the different parameters needed for each downstream tool to the appropriate value for the user-designated organism (by default, <code>\"sars-cov-2\"</code> is the default organism).</p> <p>The following tables include the relevant organism-specific parameters; all of these default values can be overwritten by providing a value for the \"Overwrite Variable Name\" field.</p> SARS-CoV-2MpoxWest Nile VirusInfluenzaRSV-ARSV-BHIVMeaslesMumpsRubella Overwrite Variable Name Organism Default Value gene_locations_bed_file sars-cov-2 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/sars-cov-2/sc2_gene_locations.bed\"</code> genome_length_input sars-cov-2 <code>29903</code> kraken_target_organism_input sars-cov-2 <code>\"Severe acute respiratory syndrome coronavirus 2\"</code> nextclade_dataset_name_input sars-cov-2 <code>\"nextstrain/sars-cov-2/wuhan-hu-1/orfs\"</code> pangolin_docker_image sars-cov-2 <code>\"us-docker.pkg.dev/general-theiagen/staphb/pangolin:4.3.1-pdata-1.34 \"</code> nextclade_dataset_tag_input sars-cov-2 <code>\"2025-08-02--08-55-17Z\"</code> reference_genome sars-cov-2 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/sars-cov-2/MN908947.fasta\"</code> vadr_max_length sars-cov-2 <code>30000</code> vadr_skip_length sars-cov-2 <code>10000</code> vadr_mem sars-cov-2 <code>8</code> vadr_options sars-cov-2 <code>\"--mkey sarscov2 --glsearch -s -r --nomisc --lowsim5seq 6 --lowsim3seq 6 --alt_fail lowscore,insertnn,deletinn --noseqnamemax --out_allfasta\"</code> vadr_model_file sars-cov-2 <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-sarscov2-1.3-2.tar.gz\"</code> Overwrite Variable Name Organism Default Value gene_locations_bed_file MPXV <code>\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/mpox_gene_locations.bed\"</code> genome_length_input MPXV <code>197200</code> kraken_target_organism_input MPXV <code>\"Monkeypox virus\"</code> nextclade_dataset_name_input MPXV <code>\"nextstrain/mpox/lineage-b.1\"</code> nextclade_dataset_tag_input MPXV <code>\"2025-04-25--12-24-24Z\"</code> primer_bed_file MPXV <code>\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/MPXV.primer.bed\"</code> reference_genome MPXV <code>\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/MPXV.MT903345.reference.fasta\"</code> reference_gff_file MPXV <code>\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/Mpox-MT903345.1.reference.gff3\"</code> vadr_max_length MPXV <code>210000</code> vadr_skip_length MPXV <code>65480</code> vadr_mem MPXV <code>8</code> vadr_options MPXV <code>\"--mkey mpxv --glsearch --minimap2 -s -r --nomisc --r_lowsimok --r_lowsimxd 100 --r_lowsimxl 2000 --alt_pass discontn,dupregin --s_overhang 150 --out_allfasta\"</code> vadr_model_file MPXV <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-mpxv-1.4.2-1.tar.gz\"</code> Overwrite Variable Name Organism Default Value Notes genome_length_input WNV <code>11000</code> kraken_target_organism_input WNV <code>\"West Nile virus</code>\" nextclade_dataset_name_input WNV <code>\"NA\"</code> TheiaCoV's Nextclade currently does not support WNV nextclade_dataset_tag_input WNV <code>\"NA\"</code> TheiaCoV's Nextclade currently does not support WNV primer_bed_file WNV <code>\"gs://theiagen-public-resources-rp/reference_data/viral/wnv/al/wnv/WNV-L1_primer.bed\"</code> reference_genome WNV <code>\"gs://theiagen-public-resources-rp/reference_data/viral/wnv/NC_009942.1_wnv_L1.fasta\"</code> vadr_max_length WNV <code>11000</code> vadr_skip_length WNV <code>3000</code> vadr_mem WNV <code>8</code> vadr_options WNV <code>\"--mkey flavi --nomisc --noprotid --out_allfasta\"</code> vadr_model_file WNV <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-flavi-1.2-1.tar.gz\"</code> Overwrite Variable Name Organism Flu Segment Flu Subtype Default Value Notes flu_segment flu all all N/A TheiaCoV will attempt to automatically assign a flu segment flu_subtype flu all all N/A TheiaCoV will attempt to automatically assign a flu subtype genome_length_input flu all all <code>13500</code> vadr_max_length flu all all <code>13500</code> vadr_skip_length flu all all <code>500</code> vadr_mem flu all all <code>8</code> vadr_options flu all all <code>\"--mkey flu --atgonly --xnocomp --nomisc --alt_fail extrant5,extrant3\"</code> vadr_model_file flu all all <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-flu-1.6.3-2.tar.gz\"</code> nextclade_dataset_name_input flu ha h1n1 <code>\"nextstrain/flu/h1n1pdm/ha/MW626062\"</code> nextclade_dataset_tag_input flu ha h1n1 <code>\"2025-08-07--09-22-32Z\"</code> reference_genome flu ha h1n1 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_h1n1pdm_ha.fasta\"</code> nextclade_dataset_name_input flu ha h3n2 <code>\"nextstrain/flu/h3n2/ha/EPI1857216\"</code> nextclade_dataset_tag_input flu ha h3n2 <code>\"2025-08-07--09-22-32Z\"</code> reference_genome flu ha h3n2 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_h3n2_ha.fasta\"</code> nextclade_dataset_name_input flu ha victoria <code>\"nextstrain/flu/vic/ha/KX058884\"</code> nextclade_dataset_tag_input flu ha victoria <code>\"2025-08-07--09-22-32Z\"</code> reference_genome flu ha victoria <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_vic_ha.fasta\"</code> nextclade_dataset_name_input flu ha yamagata <code>\"nextstrain/flu/yam/ha/JN993010\"</code> nextclade_dataset_tag_input flu ha yamagata <code>\"2024-01-30--16-34-55Z\"</code> reference_genome flu ha yamagata <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_yam_ha.fasta\"</code> nextclade_dataset_name_input flu ha h5n1 <code>\"community/moncla-lab/iav-h5/ha/all-clades\"</code> nextclade_dataset_tag_input flu ha h5n1 <code>\"2025-08-07--09-22-32Z\"</code> reference_genome flu ha h5n1 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_h5n1_ha.fasta\"</code> nextclade_dataset_name_input flu na h1n1 <code>\"nextstrain/flu/h1n1pdm/na/MW626056\"</code> nextclade_dataset_tag_input flu na h1n1 <code>\"2025-08-07--09-22-32Z\"</code> reference_genome flu na h1n1 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_h1n1pdm_na.fasta\"</code> nextclade_dataset_name_input flu na h3n2 <code>\"nextstrain/flu/h3n2/na/EPI1857215\"</code> nextclade_dataset_tag_input flu na h3n2 <code>\"2025-08-07--09-22-32Z\"</code> reference_genome flu na h3n2 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_h3n2_na.fasta\"</code> nextclade_dataset_name_input flu na victoria <code>\"nextstrain/flu/vic/na/CY073894\"</code> nextclade_dataset_tag_input flu na victoria <code>\"2025-08-07--09-22-32Z\"</code> reference_genome flu na victoria <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_vic_na.fasta\"</code> nextclade_dataset_name_input flu na yamagata <code>\"NA\"</code> nextclade_dataset_tag_input flu na yamagata <code>\"NA\"</code> reference_genome flu na yamagata <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_yam_na.fasta\"</code> <p>H5N1 Additional Defaults</p> <p>If the sample is designated as H5N1 by either ABRicate or IRMA, an H5N1-specific Nextclade task will run with the following datasets depending on the GenoFLU genotype. </p> <p>Alternatively, if a <code>nextclade_custom_input_dataset</code> variable is provided (available under the <code>flu_track</code> task name), the workflow will run that custom dataset on all H5N1 samples, regardless of the GenoFLU genotype.</p> Overwrite Variable Name GenoFLU Genotype Default Value Notes nextclade_custom_input_dataset B3.13 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/nextclade_avian-flu_h5n1-cattle-outbreak_h5n1-b3.13_2025-06-24.json\"</code> Extracted from nextclade/avian-flu/h5n1-cattle-outbreak on 2025-06-24 nextclade_custom_input_dataset D1.1 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/nextclade_avian-flu_h5n1-d1.1_2025-06-24.json\"</code> Extracted from nextclade/avian-flu/h5n1-d1.1 on 2025-06-24 Overwrite Variable Name Organism Default Value genome_length_input rsv_a <code>16000</code> kraken_target_organism rsv_a <code>\"Human respiratory syncytial virus A\"</code> nextclade_dataset_name_input rsv_a <code>nextstrain/rsv/a/EPI_ISL_412866</code> nextclade_dataset_tag_input rsv_a <code>\"2024-11-27--02-51-00Z\"</code> reference_genome rsv_a <code>\"gs://theiagen-public-resources-rp/reference_data/viral/rsv/reference_rsv_a.EPI_ISL_412866.fasta\"</code> vadr_max_length rsv_a <code>15500</code> vadr_skip_length rsv_a <code>5000</code> vadr_mem rsv_a <code>32</code> vadr_options rsv_a <code>\"--mkey rsv --xnocomp -r\"</code> vadr_model_file rsv_a <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-rsv-1.5-2.tar.gz\"</code> Overwrite Variable Name Organism Default Value genome_length_input rsv_b <code>16000</code> kraken_target_organism rsv_b <code>\"human respiratory syncytial virus\"</code> nextclade_dataset_name_input rsv_b <code>nextstrain/rsv/b/EPI_ISL_1653999</code> nextclade_dataset_tag_input rsv_b <code>\"2025-03-04--17-31-25Z\"</code> reference_genome rsv_b <code>\"gs://theiagen-public-resources-rp/reference_data/viral/rsv/reference_rsv_b.EPI_ISL_1653999.fasta\"</code> vadr_max_length rsv_b <code>15500</code> vadr_mem rsv_b <code>32</code> vadr_options rsv_b <code>\"--mkey rsv --xnocomp -r\"</code> vadr_model_file rsv_b <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-rsv-1.5-2.tar.gz\"</code> Overwrite Variable Name Organism Default Value Notes kraken_target_organism_input HIV <code>\"Human immunodeficiency virus 1\"</code> genome_length_input HIV-v1 <code>9181</code> This version of HIV originates from Oregon primer_bed_file HIV-v1 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/HIV-1_v1.0.primer.hyphen.bed\"</code> This version of HIV originates from Oregon reference_genome HIV-v1 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/NC_001802.1.fasta\"</code> This version of HIV originates from Oregon reference_gff_file HIV-v1 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/NC_001802.1.gff3\"</code> This version of HIV originates from Oregon genome_length_input HIV-v2 <code>9840</code> This version of HIV originates from Southern Africa primer_bed_file HIV-v2 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/HIV-1_v2.0.primer.hyphen400.1.bed\"</code> This version of HIV originates from Southern Africa reference_genome HIV-v2 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/AY228557.1.headerchanged.fasta\"</code> This version of HIV originates from Southern Africa reference_gff_file HIV-v2 <code>\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/AY228557.1.gff3\"</code> This version of HIV originates from Southern Africa Overwrite Variable Name Organism Default Value kraken_target_organism_input measles <code>\"Measles morbillivirus\"</code> genome_length_input measles <code>16000</code> nextclade_dataset_name_input measles <code>\"nextstrain/measles/genome/WHO-2012\"</code> nextclade_dataset_tag_input measles <code>\"2025-08-11--19-06-01Z\"</code> reference_genome measles <code>\"gs://theiagen-public-resources-rp/reference_data/viral/measles/NC_001498.1_measles_reference.fasta\"</code> vadr_max_length measles <code>18000</code> vadr_skip_length measles <code>0</code> vadr_mem measles <code>24</code> vadr_options measles <code>\"--mkey mev -r --indefclass 0.01\"</code> vadr_model_file measles <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-mev-1.02.tar.gz\"</code> Overwrite Variable Name Organism Default Value reference_genome mumps <code>\"gs://theiagen-public-resources-rp/reference_data/viral/mumps/NC_002200.1_mumps_reference.fasta\"</code> genome_length_input mumps <code>15300</code> vadr_options mumps <code>\"--mkey muv -r --indefclass 0.025\"</code> vadr_max_length mumps <code>18000</code> vadr_skip_length mumps <code>0</code> vadr_mem mumps <code>16</code> vadr_model_file mumps <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-muv-1.01.tar.gz\"</code> Overwrite Variable Name Organism Default Value reference_genome rubella <code>\"gs://theiagen-public-resources-rp/reference_data/viral/rubella/NC_001545.2_rubella_reference.fasta\"</code> genome_length_input rubella <code>9800</code> vadr_options rubella <code>\"--mkey ruv -r\"</code> vadr_max_length rubella <code>10000</code> vadr_skip_length rubella <code>0</code> vadr_mem rubella <code>16</code> vadr_model_file rubella <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-ruv-1.01.tar.gz\"</code>"},{"location":"workflows/genomic_characterization/theiacov/#core-tasks","title":"Core Tasks","text":"<p>These tasks are performed for all organisms. They include tasks that are performed regardless of and specific for the input data type. They perform read trimming and assembly appropriate to the input data type.</p> <code>versioning</code>: Version Capture <p>The <code>versioning</code> task captures the workflow version from the GitHub (code repository) version.</p> <p>Version Capture Technical details</p> Links Task task_versioning.wdl"},{"location":"workflows/genomic_characterization/theiacov/#assembly-tasks","title":"Assembly Tasks","text":"TheiaCoV_Illumina_PETheiaCoV_Illumina_SETheiaCoV_ONTTheiaCoV_ClearLabsTheiaCoV_FASTA <code>read_QC_trim</code>: Read Quality Trimming, Adapter Removal, Quantification, and Identification <p><code>read_QC_trim</code> is a sub-workflow that removes low-quality reads, low-quality regions of reads, and sequencing adapters to improve data quality. It uses a number of tasks, described below. The differences between the PE and SE versions of the <code>read_QC_trim</code> sub-workflow lie in the default parameters, the use of two or one input read file(s), and the different output files.</p> <code>HRRT</code>: Human Host Sequence Removal <p>All reads of human origin are removed, including their mates, by using NCBI's human read removal tool (HRRT). </p> <p>HRRT is based on the SRA Taxonomy Analysis Tool and employs a k-mer database constructed of k-mers from Eukaryota derived from all human RefSeq records with any k-mers found in non-Eukaryota RefSeq records subtracted from the database.</p> <p>NCBI-Scrub Technical Details</p> Links Task task_ncbi_scrub.wdl Software Source Code HRRT on GitHub Software Documentation HRRT on NCBI <p>By default, <code>read_processing</code> is set to <code>\"trimmomatic\"</code>. To use <code>fastp</code> instead, set <code>read_processing</code> to <code>\"fastp\"</code>. These tasks are mutually exclusive.</p> <code>Trimmomatic</code>: Read Trimming (default) <p>Read proccessing is available via <code>Trimmomatic</code> by default.</p> <p>Trimmomatic trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>Trimmomatic</code> Technical Details</p> Links Task task_trimmomatic.wdl Software Source Code Trimmomatic on GitHub Software Documentation Trimmomatic Website Original Publication(s) Trimmomatic: a flexible trimmer for Illumina sequence data <code>fastp</code>: Read Trimming (alternative) <p>To activate this task, set <code>read_processing</code> to <code>\"fastp\"</code>.</p> <p><code>fastp</code> trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>fastp</code> also has additional default parameters and features that are not a part of <code>trimmomatic</code>'s default configuration.</p> <code>fastp</code> default read-trimming parameters Parameter Explanation -g enables polyG tail trimming -5 20 enables read end-trimming -3 20 enables read end-trimming --detect_adapter_for_pe enables adapter-trimming only for paired-end reads <p>Additional arguments can be passed using the <code>fastp_args</code> optional parameter.</p> <p>Trimmomatic and fastp Technical Details</p> Links Task task_fastp.wdl Software Source Code fastp on GitHub Software Documentation fastp on GitHub Original Publication(s) fastp: an ultra-fast all-in-one FASTQ preprocessor <code>BBDuk</code>: Adapter Trimming and PhiX Removal <p>Adapters are manufactured oligonucleotide sequences attached to DNA fragments during the library preparation process. In Illumina sequencing, these adapter sequences are required for attaching reads to flow cells. You can read more about Illumina adapters here. For genome analysis, it's important to remove these sequences since they're not actually from your sample. If you don't remove them, the downstream analysis may be affected.</p> <p>The <code>bbduk</code> task removes adapters from sequence reads. To do this:</p> <ul> <li>Repair from the BBTools package reorders reads in paired fastq files to ensure the forward and reverse reads of a pair are in the same position in the two fastq files (it re-pairs).</li> <li>BBDuk  (\"Bestus Bioinformaticus\" Decontamination Using Kmers) is then used to trim the adapters and filter out all reads that have a 31-mer match to PhiX, which is commonly added to Illumina sequencing runs to monitor and/or improve overall run quality.</li> </ul> <p>BBDuk Technical Details</p> Links Task task_bbduk.wdl Software Source Code BBMap on SourceForge Software Documentation BBDuk Guide (archived) <p>By default, <code>read_qc</code> is set to <code>\"fastq_scan\"</code>. To use <code>fastqc</code> instead, set <code>read_qc</code> to <code>\"fastqc\"</code>. These tasks are mutually exclusive.</p> <code>fastq-scan</code>: Read Quantification (default) <p>Read quantification is available via <code>fastq-scan</code> by default.</p> <p><code>fastq-scan</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p><code>fastq-scan</code> Technical Details</p> Links Task task_fastq_scan.wdl Software Source Code fastq-scan on GitHub Software Documentation fastq-scan on GitHub <code>FastQC</code>: Read Quantification (alternative) <p>To activate this task, set <code>read_qc</code> to <code>\"fastqc\"</code>.</p> <p><code>FastQC</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>This tool also provides a graphical visualization of the read quality.</p> <p><code>FastQC</code> Technical Details</p> Links Task task_fastqc.wdl Software Source Code FastQC on Github Software Documentation FastQC Website <code>Kraken2</code>: Read Identification <p><code>Kraken2</code> is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>Kraken2 is run on both the raw and clean reads.</p> <p>Database-dependent</p> <p>This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz</code>.</p> <p>Kraken2 Technical Details</p> Links Task task_kraken2.wdl Software Source Code Kraken2 on GitHub Software Documentation Kraken2 Documentation Original Publication(s) Improved metagenomic analysis with Kraken 2 <p>read_QC_trim Technical Details</p> Links Subworkflow wf_read_QC_trim_pe.wdlwf_read_QC_trim_se.wdl <p>If non-influenza</p> <code>ivar_consensus</code>: Alignment, Consensus, Variant Detection, and Assembly Statistics <p><code>iVar Consensus</code> is a sub-workflow within TheiaCoV that performs reference-based consensus assembly using the iVar tool by Nathan Grubaugh from the Andersen lab.</p> <code>bwa</code>: Read Alignment to the Reference <p>BWA (Burrow-Wheeler Aligner) is used to align the cleaned read files to a reference genome, either  determined by the user or provided by the organism-specific parameters section (see above). The resulting BAM file is used for primer trimming, variant calling, and consensus generation in downstream tasks.</p> <p>BWA Technical Details</p> Links Task task_bwa.wdl Software Source Code BWA on GitHub Software Documentation BWA Documentation Original Publication(s) Fast and accurate short read alignment with Burrows-Wheeler transform <code>ivar_trim</code>: Primer Trimming (optional) <p>To deactivate this task, set <code>trim_primers</code> to <code>false</code>.</p> <p>Using the user-provided (or, more rarely, a organism-specific parameters-determined) <code>primer_bed</code> file, iVar soft-clips primer sequences from an aligned and sorted BAM file and then trims the reads based on a quality threshold of 20 using a sliding window approach. If the resulting read is greater than 30 bp, the read is written to a a new BAM file consisting of only trimmed reads (or reads that did not have a primer identified).</p> <p>iVar Trim Technical Details</p> Links Task task_ivar_primer_trim.wdl Software Source Code iVar on GitHub Software Documentation iVar on GitHub Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar <code>assembly_metrics</code>: Mapping Statistics <p>The <code>assembly_metrics</code> task generates mapping statistics from a BAM file. It uses samtools to generate a summary of the mapping statistics, which includes coverage, depth, average base quality, average mapping quality, and other relevant metrics.</p> <p>This task is run twice: once on the untrimmed reads and, if primer trimming is enabled, once on the primer-trimmed reads. This allows for a comparison of mapping statistics before and after primer trimming, which can be useful for assessing the impact of primer trimming on the quality of the alignment and subsequent analyses.</p> <p><code>assembly_metrics</code> Technical Details</p> Links Task task_assembly_metrics.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <code>ivar_consensus</code>: Consensus Assembly <p>iVar's <code>consensus</code> tool generates a reference-based consensus assembly. Several parameters can be set that determine the stringency of the consensus assembly, including minimum quality, minimum allele frequency, and minimum depth.</p> <p>For TheiaCoV, the following default parameters are used:</p> <ul> <li>minimum quality: 20</li> <li>minimum depth: 100</li> <li>minimum allele frequency: 0.6</li> </ul> <p>iVar Technical Details</p> Links Task task_ivar_consensus.wdl Software Source Code Ivar on GitHub Software Documentation Ivar Documentation Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar <code>ivar_variants</code>: Variant Calling <p>iVar uses the outputs of <code>samtools mpileup</code> to call single nucleotide variants (SNVs) and insertions/deletions (indels). Several key parameters can be set to determine the stringency of variant calling, including minimum quality, minimum allele frequency, and minimum depth.</p> <p>This task returns a VCF file containing all called variants, the number of detected variants, and the proportion of those variants with allele frequencies between 0.6 and 0.9 (also known as intermediate variants).</p> <p>For TheiaCoV, the following default parameters are used:</p> <ul> <li>minimum quality: 20</li> <li>minimum depth: 100</li> <li>minimum allele frequency: 0.06</li> </ul> <p>iVar Technical Details</p> Links Task task_ivar_variant_call.wdl Software Source Code Ivar on GitHub Software Documentation Ivar Documentation Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar <p>iVar Consensus Technical Details</p> Links Subworkflow wf_ivar_consensus.wdl <p>If influenza</p> <code>irma</code>: Assembly and Characterization <p>Cleaned reads are assembled using <code>irma</code> which stands for Iterative Refinement Meta-Assembler. IRMA first sorts reads to Flu genome segments using LABEL, then iteratively maps read to collection of reference sequences (in this case for Influenza virus) and iteratively edits the references to account for high population diversity and mutational rates that are characteristic of Influenza genomes. Assemblies produced by <code>irma</code> will be ordered from largest to smallest assembled flu segment. <code>irma</code> also performs typing and subtyping as part of the assembly process. Note: IRMA does not differentiate between Flu B Victoria and Yamagata lineages. For determining this information, please review the <code>abricate</code> task outputs which will provide this information.</p> <p>Due to the segmented nature of the Influenza genome and the various downstream bioinformatics tools that require the genome assembly, the IRMA task &amp; TheiaCoV workflows output various genome assembly files. Briefly they are:</p> <ul> <li><code>assembly_fasta</code> - The full genome assembly in FASTA format, with 1 FASTA entry per genome segment. There should be 8 segments in total, but depending on the quality and depth of sequence data, some segments may not be assembled and nor present in this output file.</li> <li><code>irma_assembly_fasta_concatenated</code> - The full genome assembly in FASTA format, but with all segments concatenated into a single FASTA entry. This is not your typical FASTA file and is purposely created to be used with a custom Nextclade dataset for the H5N1 B3.13 genotype that is based on a concatenated reference genome.</li> <li><code>irma_&lt;segment-abbreviation&gt;_segment_fasta</code> - Individual FASTA files that only contain the sequence for 1 segment, for example the HA segment. There are 8 of these in total.</li> </ul> <p>General statistics about the assembly are generated with the <code>consensus_qc</code> task (task_assembly_metrics.wdl).</p> <p>IRMA Technical Details</p> Links Task task_irma.wdl Software Documentation IRMA website Original Publication(s) Viral deep sequencing needs an adaptive approach: IRMA, the iterative refinement meta-assembler <code>read_QC_trim</code>: Read Quality Trimming, Adapter Removal, Quantification, and Identification <p><code>read_QC_trim</code> is a sub-workflow that removes low-quality reads, low-quality regions of reads, and sequencing adapters to improve data quality. It uses a number of tasks, described below. The differences between the PE and SE versions of the <code>read_QC_trim</code> sub-workflow lie in the default parameters, the use of two or one input read file(s), and the different output files.</p> <code>HRRT</code>: Human Host Sequence Removal <p>All reads of human origin are removed, including their mates, by using NCBI's human read removal tool (HRRT). </p> <p>HRRT is based on the SRA Taxonomy Analysis Tool and employs a k-mer database constructed of k-mers from Eukaryota derived from all human RefSeq records with any k-mers found in non-Eukaryota RefSeq records subtracted from the database.</p> <p>NCBI-Scrub Technical Details</p> Links Task task_ncbi_scrub.wdl Software Source Code HRRT on GitHub Software Documentation HRRT on NCBI <p>By default, <code>read_processing</code> is set to <code>\"trimmomatic\"</code>. To use <code>fastp</code> instead, set <code>read_processing</code> to <code>\"fastp\"</code>. These tasks are mutually exclusive.</p> <code>Trimmomatic</code>: Read Trimming (default) <p>Read proccessing is available via <code>Trimmomatic</code> by default.</p> <p>Trimmomatic trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>Trimmomatic</code> Technical Details</p> Links Task task_trimmomatic.wdl Software Source Code Trimmomatic on GitHub Software Documentation Trimmomatic Website Original Publication(s) Trimmomatic: a flexible trimmer for Illumina sequence data <code>fastp</code>: Read Trimming (alternative) <p>To activate this task, set <code>read_processing</code> to <code>\"fastp\"</code>.</p> <p><code>fastp</code> trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>fastp</code> also has additional default parameters and features that are not a part of <code>trimmomatic</code>'s default configuration.</p> <code>fastp</code> default read-trimming parameters Parameter Explanation -g enables polyG tail trimming -5 20 enables read end-trimming -3 20 enables read end-trimming --detect_adapter_for_pe enables adapter-trimming only for paired-end reads <p>Additional arguments can be passed using the <code>fastp_args</code> optional parameter.</p> <p>Trimmomatic and fastp Technical Details</p> Links Task task_fastp.wdl Software Source Code fastp on GitHub Software Documentation fastp on GitHub Original Publication(s) fastp: an ultra-fast all-in-one FASTQ preprocessor <code>BBDuk</code>: Adapter Trimming and PhiX Removal <p>Adapters are manufactured oligonucleotide sequences attached to DNA fragments during the library preparation process. In Illumina sequencing, these adapter sequences are required for attaching reads to flow cells. You can read more about Illumina adapters here. For genome analysis, it's important to remove these sequences since they're not actually from your sample. If you don't remove them, the downstream analysis may be affected.</p> <p>The <code>bbduk</code> task removes adapters from sequence reads. To do this:</p> <ul> <li>Repair from the BBTools package reorders reads in paired fastq files to ensure the forward and reverse reads of a pair are in the same position in the two fastq files (it re-pairs).</li> <li>BBDuk  (\"Bestus Bioinformaticus\" Decontamination Using Kmers) is then used to trim the adapters and filter out all reads that have a 31-mer match to PhiX, which is commonly added to Illumina sequencing runs to monitor and/or improve overall run quality.</li> </ul> <p>BBDuk Technical Details</p> Links Task task_bbduk.wdl Software Source Code BBMap on SourceForge Software Documentation BBDuk Guide (archived) <p>By default, <code>read_qc</code> is set to <code>\"fastq_scan\"</code>. To use <code>fastqc</code> instead, set <code>read_qc</code> to <code>\"fastqc\"</code>. These tasks are mutually exclusive.</p> <code>fastq-scan</code>: Read Quantification (default) <p>Read quantification is available via <code>fastq-scan</code> by default.</p> <p><code>fastq-scan</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p><code>fastq-scan</code> Technical Details</p> Links Task task_fastq_scan.wdl Software Source Code fastq-scan on GitHub Software Documentation fastq-scan on GitHub <code>FastQC</code>: Read Quantification (alternative) <p>To activate this task, set <code>read_qc</code> to <code>\"fastqc\"</code>.</p> <p><code>FastQC</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>This tool also provides a graphical visualization of the read quality.</p> <p><code>FastQC</code> Technical Details</p> Links Task task_fastqc.wdl Software Source Code FastQC on Github Software Documentation FastQC Website <code>Kraken2</code>: Read Identification <p><code>Kraken2</code> is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>Kraken2 is run on both the raw and clean reads.</p> <p>Database-dependent</p> <p>This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz</code>.</p> <p>Kraken2 Technical Details</p> Links Task task_kraken2.wdl Software Source Code Kraken2 on GitHub Software Documentation Kraken2 Documentation Original Publication(s) Improved metagenomic analysis with Kraken 2 <p>read_QC_trim Technical Details</p> Links Subworkflow wf_read_QC_trim_pe.wdlwf_read_QC_trim_se.wdl <code>ivar_consensus</code>: Alignment, Consensus, Variant Detection, and Assembly Statistics <p><code>iVar Consensus</code> is a sub-workflow within TheiaCoV that performs reference-based consensus assembly using the iVar tool by Nathan Grubaugh from the Andersen lab.</p> <code>bwa</code>: Read Alignment to the Reference <p>BWA (Burrow-Wheeler Aligner) is used to align the cleaned read files to a reference genome, either  determined by the user or provided by the organism-specific parameters section (see above). The resulting BAM file is used for primer trimming, variant calling, and consensus generation in downstream tasks.</p> <p>BWA Technical Details</p> Links Task task_bwa.wdl Software Source Code BWA on GitHub Software Documentation BWA Documentation Original Publication(s) Fast and accurate short read alignment with Burrows-Wheeler transform <code>ivar_trim</code>: Primer Trimming (optional) <p>To deactivate this task, set <code>trim_primers</code> to <code>false</code>.</p> <p>Using the user-provided (or, more rarely, a organism-specific parameters-determined) <code>primer_bed</code> file, iVar soft-clips primer sequences from an aligned and sorted BAM file and then trims the reads based on a quality threshold of 20 using a sliding window approach. If the resulting read is greater than 30 bp, the read is written to a a new BAM file consisting of only trimmed reads (or reads that did not have a primer identified).</p> <p>iVar Trim Technical Details</p> Links Task task_ivar_primer_trim.wdl Software Source Code iVar on GitHub Software Documentation iVar on GitHub Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar <code>assembly_metrics</code>: Mapping Statistics <p>The <code>assembly_metrics</code> task generates mapping statistics from a BAM file. It uses samtools to generate a summary of the mapping statistics, which includes coverage, depth, average base quality, average mapping quality, and other relevant metrics.</p> <p>This task is run twice: once on the untrimmed reads and, if primer trimming is enabled, once on the primer-trimmed reads. This allows for a comparison of mapping statistics before and after primer trimming, which can be useful for assessing the impact of primer trimming on the quality of the alignment and subsequent analyses.</p> <p><code>assembly_metrics</code> Technical Details</p> Links Task task_assembly_metrics.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <code>ivar_consensus</code>: Consensus Assembly <p>iVar's <code>consensus</code> tool generates a reference-based consensus assembly. Several parameters can be set that determine the stringency of the consensus assembly, including minimum quality, minimum allele frequency, and minimum depth.</p> <p>For TheiaCoV, the following default parameters are used:</p> <ul> <li>minimum quality: 20</li> <li>minimum depth: 100</li> <li>minimum allele frequency: 0.6</li> </ul> <p>iVar Technical Details</p> Links Task task_ivar_consensus.wdl Software Source Code Ivar on GitHub Software Documentation Ivar Documentation Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar <code>ivar_variants</code>: Variant Calling <p>iVar uses the outputs of <code>samtools mpileup</code> to call single nucleotide variants (SNVs) and insertions/deletions (indels). Several key parameters can be set to determine the stringency of variant calling, including minimum quality, minimum allele frequency, and minimum depth.</p> <p>This task returns a VCF file containing all called variants, the number of detected variants, and the proportion of those variants with allele frequencies between 0.6 and 0.9 (also known as intermediate variants).</p> <p>For TheiaCoV, the following default parameters are used:</p> <ul> <li>minimum quality: 20</li> <li>minimum depth: 100</li> <li>minimum allele frequency: 0.06</li> </ul> <p>iVar Technical Details</p> Links Task task_ivar_variant_call.wdl Software Source Code Ivar on GitHub Software Documentation Ivar Documentation Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar <p>iVar Consensus Technical Details</p> Links Subworkflow wf_ivar_consensus.wdl <code>read_QC_trim_ont</code>: Read Quality Trimming, Quantification, and Identification <p><code>read_QC_trim_ont</code> is a sub-workflow that filters low-quality reads and trims low-quality regions of reads. It uses several tasks, described below.</p> <code>HRRT</code>: Human Host Sequence Removal <p>All reads of human origin are removed, including their mates, by using NCBI's human read removal tool (HRRT). </p> <p>HRRT is based on the SRA Taxonomy Analysis Tool and employs a k-mer database constructed of k-mers from Eukaryota derived from all human RefSeq records with any k-mers found in non-Eukaryota RefSeq records subtracted from the database.</p> <p>NCBI-Scrub Technical Details</p> Links Task task_ncbi_scrub.wdl Software Source Code HRRT on GitHub Software Documentation HRRT on NCBI <code>artic_guppyplex</code>: Read Filtering <p>Reads are filtered by length with <code>artic_guppyplex</code>, which is a part of the <code>ARTIC</code> protocol. Since TheiaCoV was developed primarily for amplicon-based viral sequencing, this task is included to remove chimeric reads that are either too short or too long.</p> <p>artic_guppyplex Technical Details</p> Links Task task_artic_guppyplex.wdl Software Source Code ARTIC on GitHub Software Documentation ARTIC Documentation <code>Kraken2</code>: Read Identification <p><code>Kraken2</code> is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>Kraken2 is run on both the raw and clean reads.</p> <p>Database-dependent</p> <p>This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz</code>.</p> <p>Kraken2 Technical Details</p> Links Task task_kraken2.wdl Software Source Code Kraken2 on GitHub Software Documentation Kraken2 Documentation Original Publication(s) Improved metagenomic analysis with Kraken 2 <code>NanoPlot</code>: Read Quantification <p>NanoPlot is used for the determination of mean quality scores, read lengths, and number of reads. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>While this task currently is run outside of the <code>read_QC_trim_ont</code> workflow, it is being included here as it calculates statistics on the read data. This is done so that the actual assembly genome lengths can be used (if an estimated genome length is not provided by the user) to ensure the estimated coverage statistics are accurate.</p> <p>NanoPlot Technical Details</p> Links Task task_nanoplot.wdl Software Source Code NanoPlot on GitHub Software Documentation NanoPlot Documentation Original Publication(s) NanoPack2: population-scale evaluation of long-read sequencing data <p>read_QC_trim_ont Technical Details</p> Links Subworkflow wf_read_QC_trim_ont.wdl <p>If non-influenza</p> <code>artic_consensus</code>: Alignment, Primer Trimming, Variant Detection, and Consensus <p>This task runs the <code>Artic minion</code> command which is a pipeline with a number of stages, described in detail in the ARTIC documentation. Briefly, these stages are as follows:</p> <p>Input reads are aligned to the appropriate reference and only mapped reads are retained. Alignment post-processing occurs, where primers are removed and various trimming steps are undertaken. Variants are detected, and a consensus assembly file is generated.</p> <p>Please note that the Medaka model is set by default to <code>\"r941_min_high_g360\"</code> which may not be suitable for your sequencing data. Please be sure to change this parameter if needed.</p> <p>Read-trimming is performed on raw read data generated on the ClearLabs instrument and thus not a required step in the TheiaCoV_ClearLabs workflow.</p> <p>Artic Consensus Technical Details</p> Links Task task_artic_consensus.wdl Software Source Code ARTIC on GitHub Software Documentation ARTIC Documentation <code>assembly_metrics</code>: Mapping Statistics <p>The <code>assembly_metrics</code> task generates mapping statistics from a BAM file. It uses samtools to generate a summary of the mapping statistics, which includes coverage, depth, average base quality, average mapping quality, and other relevant metrics.</p> <p>This task is run twice: once on the untrimmed reads and, if primer trimming is enabled, once on the primer-trimmed reads. This allows for a comparison of mapping statistics before and after primer trimming, which can be useful for assessing the impact of primer trimming on the quality of the alignment and subsequent analyses.</p> <p><code>assembly_metrics</code> Technical Details</p> Links Task task_assembly_metrics.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <p>If influenza</p> <code>irma</code>: Assembly and Characterization <p>Cleaned reads are assembled using <code>irma</code> which stands for Iterative Refinement Meta-Assembler. IRMA first sorts reads to Flu genome segments using LABEL, then iteratively maps read to collection of reference sequences (in this case for Influenza virus) and iteratively edits the references to account for high population diversity and mutational rates that are characteristic of Influenza genomes. Assemblies produced by <code>irma</code> will be ordered from largest to smallest assembled flu segment. <code>irma</code> also performs typing and subtyping as part of the assembly process. Note: IRMA does not differentiate between Flu B Victoria and Yamagata lineages. For determining this information, please review the <code>abricate</code> task outputs which will provide this information.</p> <p>Due to the segmented nature of the Influenza genome and the various downstream bioinformatics tools that require the genome assembly, the IRMA task &amp; TheiaCoV workflows output various genome assembly files. Briefly they are:</p> <ul> <li><code>assembly_fasta</code> - The full genome assembly in FASTA format, with 1 FASTA entry per genome segment. There should be 8 segments in total, but depending on the quality and depth of sequence data, some segments may not be assembled and nor present in this output file.</li> <li><code>irma_assembly_fasta_concatenated</code> - The full genome assembly in FASTA format, but with all segments concatenated into a single FASTA entry. This is not your typical FASTA file and is purposely created to be used with a custom Nextclade dataset for the H5N1 B3.13 genotype that is based on a concatenated reference genome.</li> <li><code>irma_&lt;segment-abbreviation&gt;_segment_fasta</code> - Individual FASTA files that only contain the sequence for 1 segment, for example the HA segment. There are 8 of these in total.</li> </ul> <p>General statistics about the assembly are generated with the <code>consensus_qc</code> task (task_assembly_metrics.wdl).</p> <p>IRMA Technical Details</p> Links Task task_irma.wdl Software Documentation IRMA website Original Publication(s) Viral deep sequencing needs an adaptive approach: IRMA, the iterative refinement meta-assembler <code>assembly_metrics</code>: Mapping Statistics <p>The <code>assembly_metrics</code> task generates mapping statistics from a BAM file. It uses samtools to generate a summary of the mapping statistics, which includes coverage, depth, average base quality, average mapping quality, and other relevant metrics.</p> <p>This task is run twice: once on the untrimmed reads and, if primer trimming is enabled, once on the primer-trimmed reads. This allows for a comparison of mapping statistics before and after primer trimming, which can be useful for assessing the impact of primer trimming on the quality of the alignment and subsequent analyses.</p> <p><code>assembly_metrics</code> Technical Details</p> Links Task task_assembly_metrics.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <code>HRRT</code>: Human Host Sequence Removal <p>All reads of human origin are removed, including their mates, by using NCBI's human read removal tool (HRRT). </p> <p>HRRT is based on the SRA Taxonomy Analysis Tool and employs a k-mer database constructed of k-mers from Eukaryota derived from all human RefSeq records with any k-mers found in non-Eukaryota RefSeq records subtracted from the database.</p> <p>NCBI-Scrub Technical Details</p> Links Task task_ncbi_scrub.wdl Software Source Code HRRT on GitHub Software Documentation HRRT on NCBI <code>fastq-scan</code>: Read Quantification <p><code>fastq-scan</code> quantifies the reads in the FASTQ files. This task is run once with raw reads as input and once with dehosted reads as input. If QC has been performed correctly, you should expect fewer dehosted (or \"clean\") reads than raw reads.</p> <p><code>fastq-scan</code> Technical Details</p> Links Task task_fastq_scan.wdl Software Source Code fastq-scan on GitHub Software Documentation fastq-scan on GitHub <code>Kraken2</code>: Read Identification <p><code>Kraken2</code> is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>Kraken2 is run on both the raw and clean reads.</p> <p>Database-dependent</p> <p>This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz</code>.</p> <p>Kraken2 Technical Details</p> Links Task task_kraken2.wdl Software Source Code Kraken2 on GitHub Software Documentation Kraken2 Documentation Original Publication(s) Improved metagenomic analysis with Kraken 2 <code>artic_consensus</code>: Alignment, Primer Trimming, Variant Detection, and Consensus <p>This task runs the <code>Artic minion</code> command which is a pipeline with a number of stages, described in detail in the ARTIC documentation. Briefly, these stages are as follows:</p> <p>Input reads are aligned to the appropriate reference and only mapped reads are retained. Alignment post-processing occurs, where primers are removed and various trimming steps are undertaken. Variants are detected, and a consensus assembly file is generated.</p> <p>Please note that the Medaka model is set by default to <code>\"r941_min_high_g360\"</code> which may not be suitable for your sequencing data. Please be sure to change this parameter if needed.</p> <p>Read-trimming is performed on raw read data generated on the ClearLabs instrument and thus not a required step in the TheiaCoV_ClearLabs workflow.</p> <p>Artic Consensus Technical Details</p> Links Task task_artic_consensus.wdl Software Source Code ARTIC on GitHub Software Documentation ARTIC Documentation <code>assembly_metrics</code>: Mapping Statistics <p>The <code>assembly_metrics</code> task generates mapping statistics from a BAM file. It uses samtools to generate a summary of the mapping statistics, which includes coverage, depth, average base quality, average mapping quality, and other relevant metrics.</p> <p>This task is run twice: once on the untrimmed reads and, if primer trimming is enabled, once on the primer-trimmed reads. This allows for a comparison of mapping statistics before and after primer trimming, which can be useful for assessing the impact of primer trimming on the quality of the alignment and subsequent analyses.</p> <p><code>assembly_metrics</code> Technical Details</p> Links Task task_assembly_metrics.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <p>Since this workflow requires FASTA files as input, no assembly or read trimming is performed, and the workflow proceeds directly to the \"post-assembly tasks\" section below.</p>"},{"location":"workflows/genomic_characterization/theiacov/#post-assembly-tasks","title":"Post-Assembly Tasks","text":"<p>These tasks are performed for all organisms after assembly (or directly after input for TheiaCoV_FASTA).</p> <code>consensus_qc</code>: Assembly Statistics <p>The consensus_qc task generates a summary of genomic statistics from a consensus genome. This includes the total number of bases, \"N\" bases, degenerate bases, and an estimate of the percent coverage to the reference genome.</p> <p><code>consensus_qc</code> Technical Details</p> Links Task task_consensus_qc.wdl <code>qc_check</code>: Check QC Metrics Against User-Defined Thresholds (optional) <p>To activate this task, provide a <code>qc_check_table</code> as input.</p> <p>The <code>qc_check</code> task compares generated QC metrics against user-defined thresholds for each metric. This task will run if the user provides a <code>qc_check_table</code> TSV file. If all QC metrics meet the threshold, the <code>qc_check</code> output variable will read <code>QC_PASS</code>. Otherwise, the output will read <code>QC_NA</code> if the task could not proceed or <code>QC_ALERT</code> followed by a string indicating what metric failed.</p> <p>The <code>qc_check</code> task applies quality thresholds according to the specified organism, which should match the standardized <code>organism</code> input in the TheiaCoV workflows.</p> Formatting the qc_check_table.tsv <ul> <li>The first column of the qc_check_table lists the <code>organism</code> that the task will assess and the header of this column must be \"taxon\".</li> <li>Each subsequent column indicates a QC metric and lists a threshold for each organism that will be checked. The column names must exactly match expected values, so we highly recommend copy and pasting the header from the template file below as a starting place.</li> </ul> Template qc_check_table.tsv files <ul> <li>TheiaCoV_Illumina_PE: TheiaCoV_Illumina_PE_qc_check_template.tsv</li> </ul> <p>Example Purposes Only</p> <p>The QC threshold values shown in the file above are for example purposes only and should not be presumed to be sufficient for every dataset.</p> <p>qc_check Technical Details</p> Links Task task_qc_check_phb.wdl"},{"location":"workflows/genomic_characterization/theiacov/#org-specific-tasks","title":"Organism-specific Characterization Tasks","text":"<p>The following tasks are organism-specific. The following table summarizes the characterization tools that are run for the indicated organism.</p> SARS-CoV-2 Mpox West Nile Virus Influenza RSV-A RSV-B HIV Measles Mumps Rubella Pangolin \u2705 \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c \u274c Nextclade \u2705 \u2705 \u274c \u2705 \u2705 \u2705 \u274c \u2705 \u274c \u274c VADR \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u274c \u2705 \u2705 \u2705 VADR Flu Segments \u274c \u274c \u274c \u2705 \u274c \u274c \u274c \u274c \u274c \u274c Quasitools HyDRA \u274c \u274c \u274c \u274c \u274c \u274c \u2705 \u274c \u274c \u274c IRMA \u274c \u274c \u274c \u2705 \u274c \u274c \u274c \u274c \u274c \u274c Abricate \u274c \u274c \u274c \u2705 \u274c \u274c \u274c \u274c \u274c \u274c % Gene Coverage \u2705 \u2705 \u2795 \u2795 \u2795 \u2795 \u2795 \u2795 \u2795 \u2795 Antiviral Detection \u274c \u274c \u274c \u2705 \u274c \u274c \u274c \u274c \u274c \u274c GenoFLU \u274c \u274c \u274c \u2705 \u274c \u274c \u274c \u274c \u274c \u274c <p>\u2705 This task runs automatically for these organisms \u2795 This task can run for these organisms if optional parameter(s) are provided; see task description for details. \u274c This task will not run for these organisms</p> SARS-CoV-2MpoxWest Nile VirusInfluenzaRSV-ARSV-BHIVMeaslesMumpsRubella <code>pangolin</code> <p>Pangolin (Phylogenetic Assignment of Named Global Outbreak Lineages) was developed to implement a dynamic nomenclature for designating SARS-CoV-2 lineage assignments and is used by researchers and public health agencies worldwide to track the spread and transmission of SARS-CoV-2.</p> <p>Pangolin aligns input sequences against an early SARS-CoV-2 reference and generates a unique hash for the alignment. The hash is checked against a designation cache to see if it matches any previously identified lineages, and is checked via scorpio (Serious Constellations of Reoccuring Phylogenetically-Independent Origin) to determine if the hash matches any variant of concern (VOC) constellations, which are groups of functionally meaningful mutations that can independently evolve. Following a QC check, an inference pipeline is run: either pangoLEARN or UShER (which is the default inference model). The final lineage report is then generated.</p> <p>Pangolin Technical Details</p> Links Task task_pangolin.wdl Software Source Code Pangolin on GitHub Software Documentation Pangolin on cov-lineages.org Original Publication(s) A dynamic nomenclature proposal for SARS-CoV-2 lineages to assist genomic epidemiology <code>nextclade</code> <p>Nextclade is an open-source project used to analyze viral genomes, particularly for clade assignment and mutation calling. Simply, Nextclade works by aligning viral genomes to a reference genome, calling variants between the two sequences, and then assigning clades based on those identified mutations. </p> <p>Clade assignment is performed via phylogenetic placement. Phylogenetic placement compares the mutations of the provided sequence to the mutations of each node found in a reference tree, where the root of that tree is the reference genome. The node that is most similar to the sample is used to both assign a clade designation and calculate where the sample should be placed in the phylogenetic tree.</p> <p>Nextclade Technical Details</p> Links Task task_nextclade.wdl Software Source Code https://github.com/nextstrain/nextclade Software Documentation Nextclade Original Publication(s) Nextclade: clade assignment, mutation calling and quality control for viral genomes. <code>vadr</code> <p>VADR (Viral Annotation DefineR) annotates and validates completed assembly files. For details on VADR default models/parameters, see the organism-specific parameters and logic section. It was primarily developed to test viral sequences to confirm they would be accepted to NCBI's GenBank data repository, but has found wide usage in general sequence validation and annotation.</p> <p>As part of the analysis of the assemblies, more than 70 types of unexpected characteristics, also known as alerts, can be reported. Any identified alerts can be found in the <code>vadr_alerts_list</code> output. Fatal alerts indicate that the sample is unlikely to be accepted to GenBank; non-fatal alerts are designated as passing sequences, but may still require further investigation. A full description of the potential alerts can be found on the VADR README here, including details on how to allow sequencecs to pass despite having fatal alerts.</p> <p>VADR Technical Details</p> Links Task task_vadr.wdl Software Source Code https://github.com/ncbi/vadr Software Documentation https://github.com/ncbi/vadr/wiki Original Publication(s) For SARS-CoV-2: Faster SARS-CoV-2 sequence validation and annotation for GenBank using VADR For non-SARS_CoV-2: VADR: validation and annotation of virus sequence submissions to GenBank <code>gene_coverage</code> <p>This task calculates the percent of a region (typically genes) covered above a minimum depth using <code>samtools</code> and basic arithmetic. By default, this task runs for SARS-CoV-2 and Mpox, but if a BED file is provided with regions of interest, this task can run for other organisms as well.</p> <p>Gene Coverage Technical Details</p> Links Task task_gene_coverage.wdl Software Source Code SAMtools on GitHub Software Documentation SAMTools Manual Original Publication(s) Twelve years of SAMtools and BCFtools <code>nextclade</code> <p>Nextclade is an open-source project used to analyze viral genomes, particularly for clade assignment and mutation calling. Simply, Nextclade works by aligning viral genomes to a reference genome, calling variants between the two sequences, and then assigning clades based on those identified mutations. </p> <p>Clade assignment is performed via phylogenetic placement. Phylogenetic placement compares the mutations of the provided sequence to the mutations of each node found in a reference tree, where the root of that tree is the reference genome. The node that is most similar to the sample is used to both assign a clade designation and calculate where the sample should be placed in the phylogenetic tree.</p> <p>Nextclade Technical Details</p> Links Task task_nextclade.wdl Software Source Code https://github.com/nextstrain/nextclade Software Documentation Nextclade Original Publication(s) Nextclade: clade assignment, mutation calling and quality control for viral genomes. <code>vadr</code> <p>VADR (Viral Annotation DefineR) annotates and validates completed assembly files. For details on VADR default models/parameters, see the organism-specific parameters and logic section. It was primarily developed to test viral sequences to confirm they would be accepted to NCBI's GenBank data repository, but has found wide usage in general sequence validation and annotation.</p> <p>As part of the analysis of the assemblies, more than 70 types of unexpected characteristics, also known as alerts, can be reported. Any identified alerts can be found in the <code>vadr_alerts_list</code> output. Fatal alerts indicate that the sample is unlikely to be accepted to GenBank; non-fatal alerts are designated as passing sequences, but may still require further investigation. A full description of the potential alerts can be found on the VADR README here, including details on how to allow sequencecs to pass despite having fatal alerts.</p> <p>VADR Technical Details</p> Links Task task_vadr.wdl Software Source Code https://github.com/ncbi/vadr Software Documentation https://github.com/ncbi/vadr/wiki Original Publication(s) For SARS-CoV-2: Faster SARS-CoV-2 sequence validation and annotation for GenBank using VADR For non-SARS_CoV-2: VADR: validation and annotation of virus sequence submissions to GenBank <code>gene_coverage</code> <p>This task calculates the percent of a region (typically genes) covered above a minimum depth using <code>samtools</code> and basic arithmetic. By default, this task runs for SARS-CoV-2 and Mpox, but if a BED file is provided with regions of interest, this task can run for other organisms as well.</p> <p>Gene Coverage Technical Details</p> Links Task task_gene_coverage.wdl Software Source Code SAMtools on GitHub Software Documentation SAMTools Manual Original Publication(s) Twelve years of SAMtools and BCFtools <code>vadr</code> <p>VADR (Viral Annotation DefineR) annotates and validates completed assembly files. For details on VADR default models/parameters, see the organism-specific parameters and logic section. It was primarily developed to test viral sequences to confirm they would be accepted to NCBI's GenBank data repository, but has found wide usage in general sequence validation and annotation.</p> <p>As part of the analysis of the assemblies, more than 70 types of unexpected characteristics, also known as alerts, can be reported. Any identified alerts can be found in the <code>vadr_alerts_list</code> output. Fatal alerts indicate that the sample is unlikely to be accepted to GenBank; non-fatal alerts are designated as passing sequences, but may still require further investigation. A full description of the potential alerts can be found on the VADR README here, including details on how to allow sequencecs to pass despite having fatal alerts.</p> <p>VADR Technical Details</p> Links Task task_vadr.wdl Software Source Code https://github.com/ncbi/vadr Software Documentation https://github.com/ncbi/vadr/wiki Original Publication(s) For SARS-CoV-2: Faster SARS-CoV-2 sequence validation and annotation for GenBank using VADR For non-SARS_CoV-2: VADR: validation and annotation of virus sequence submissions to GenBank <code>nextclade</code> <p>Nextclade is an open-source project used to analyze viral genomes, particularly for clade assignment and mutation calling. Simply, Nextclade works by aligning viral genomes to a reference genome, calling variants between the two sequences, and then assigning clades based on those identified mutations. </p> <p>Clade assignment is performed via phylogenetic placement. Phylogenetic placement compares the mutations of the provided sequence to the mutations of each node found in a reference tree, where the root of that tree is the reference genome. The node that is most similar to the sample is used to both assign a clade designation and calculate where the sample should be placed in the phylogenetic tree.</p> <p>Nextclade Technical Details</p> Links Task task_nextclade.wdl Software Source Code https://github.com/nextstrain/nextclade Software Documentation Nextclade Original Publication(s) Nextclade: clade assignment, mutation calling and quality control for viral genomes. <code>vadr</code> <p>VADR (Viral Annotation DefineR) annotates and validates completed assembly files. For details on VADR default models/parameters, see the organism-specific parameters and logic section. It was primarily developed to test viral sequences to confirm they would be accepted to NCBI's GenBank data repository, but has found wide usage in general sequence validation and annotation.</p> <p>As part of the analysis of the assemblies, more than 70 types of unexpected characteristics, also known as alerts, can be reported. Any identified alerts can be found in the <code>vadr_alerts_list</code> output. Fatal alerts indicate that the sample is unlikely to be accepted to GenBank; non-fatal alerts are designated as passing sequences, but may still require further investigation. A full description of the potential alerts can be found on the VADR README here, including details on how to allow sequencecs to pass despite having fatal alerts.</p> <p>VADR Technical Details</p> Links Task task_vadr.wdl Software Source Code https://github.com/ncbi/vadr Software Documentation https://github.com/ncbi/vadr/wiki Original Publication(s) For SARS-CoV-2: Faster SARS-CoV-2 sequence validation and annotation for GenBank using VADR For non-SARS_CoV-2: VADR: validation and annotation of virus sequence submissions to GenBank <code>vadr_flu_segments</code> <p>This task processes a full or partial influenza genome assembly in multifasta format, along with the output <code>.tar.gz</code> file from a VADR run. It extracts each segment into its own fasta file and also generates a concatenated fasta containing all segments combined into a single sequence. Segment names are assigned based on the specified flu type (A or B) and the segment classification found in the VADR .sqc file.</p> <p>Note: Results may be unreliable if segment lengths deviate from those expected for Influenza A or B. For best results, the input assembly should contain all 8 segments as separate contigs. If the assembly is partial, the task will still extract available segments but may not produce a complete concatenated sequence. Empty fasta files will be created for missing segments.</p> <p>VADR Flu Segments Technical Details</p> Links Task task_vadr_flu_segments.wdl <code>irma</code> <p>Cleaned reads are assembled using <code>irma</code> which stands for Iterative Refinement Meta-Assembler. IRMA first sorts reads to Flu genome segments using LABEL, then iteratively maps read to collection of reference sequences (in this case for Influenza virus) and iteratively edits the references to account for high population diversity and mutational rates that are characteristic of Influenza genomes. Assemblies produced by <code>irma</code> will be ordered from largest to smallest assembled flu segment. <code>irma</code> also performs typing and subtyping as part of the assembly process. Note: IRMA does not differentiate between Flu B Victoria and Yamagata lineages. For determining this information, please review the <code>abricate</code> task outputs which will provide this information.</p> <p>IRMA Technical Details</p> Links Task task_irma.wdl Software Documentation IRMA website Original Publication(s) Viral deep sequencing needs an adaptive approach: IRMA, the iterative refinement meta-assembler <code>abricate</code> <p>ABRicate assigns types and subtype/lineages for flu samples using a version of the INSaFLU (\"INSide the FLU\") database described here. </p> <p>ABRicate typically works by screening contigs for the presence of acquired resistance genes, but when using the INSaFLU database, the algorithm works by assigning contigs to the most closely corresponding viral segment in the INSaFLU database, which is used to call the flu type and subtype.</p> <p>ABRicate Technical Details</p> Links Task task_abricate.wdl (abricate_flu subtask) Software Source Code ABRicate on GitHub Software Documentation ABRicate on GitHub Original Publication(s) INSaFLU database: INSaFLU: an automated open web-based bioinformatics suite \"from-reads\" for influenza whole-genome-sequencing-based surveillance <code>flu_antiviral_substitutions</code> <p>This subworkflow determines if any antiviral mutations are present in the HA, NA, and MP segments of H1N1 or H3N2 flu sample, or any in non-subtype-specific PA, PB1, and PB2 segments.</p> <p>These mutations are identified by generating a multiple sequence alignment (MSA) between each individual flu segment and the respective reference genome using MAFFT. Amino acid mutations are then called from the MSA. The resulting mutations are compared against a list of known amino-acid substitutions associated with antiviral resistance and any matches are reported. </p> <p>This list of amino-acid substitutions includes both substitutions reported in the scientific literature and those inferred to potentially cause antiviral resistance based on analogous antiviral mutations in other flu subtypes. A table with the explanation for each amino-acid substitution in the antiviral resistance task is available here.</p> <p>The list of known amino-acid substitutions associated with resistance can be expanded via optional user input <code>antiviral_aa_subs</code> in the format \"<code>NA:V95A,HA:I97V</code>\", i.e. <code>Protein:AAPositionAA</code>. </p> Currently, the default mutations considered confer resistance to the following antivirals <ul> <li>A_315675</li> <li>Amantadine</li> <li>Compound_367</li> <li>Favipiravir</li> <li>Fludase</li> <li>L_742_001</li> <li>Laninamivir</li> <li>Oseltamivir (tamiflu)</li> <li>Peramivir</li> <li>Pimodivir</li> <li>Rimantadine</li> <li>Xofluza</li> <li>Zanamivir</li> </ul> <p>Antiviral Substitutions Technical Details</p> Links Sub-workflow wf_influenza_antiviral_substitutions.wdl Tasks task_mafft.wdltask_flu_antiviral_subs.wdl Original Publication(s) MAFFT Multiple Sequence Alignment Software Version 7: Improvements in Performance and UsabilityNext-Generation Sequencing: An Eye-Opener for the Surveillance of Antiviral Resistance in Influenza <code>genoflu</code> <p>This task determines the whole-genome genotype of a H5N1 (currently only for the 2.3.4.4b clade of H5N1) flu sample by comparing each segment of the sample against a curated database of H5N1 references. Each segment is assigned a type, and the whole-genome genotype is assigned based on the combination of segment types, according to the GenoFLU reference table.</p> <p>GenoFLU Technical Details</p> Links Task task_genoflu.wdl Software Source Code GenoFLU on GitHub Software Documentation GenoFLU on GitHub Original Publication(s) H5N1 highly pathogenic avian influenza clade 2.3.4.4b in wild and domestic birds: Introductions into the United States and reassortments, December 2021-April 2022 <code>nextclade</code> <p>Nextclade is an open-source project used to analyze viral genomes, particularly for clade assignment and mutation calling. Simply, Nextclade works by aligning viral genomes to a reference genome, calling variants between the two sequences, and then assigning clades based on those identified mutations. </p> <p>Clade assignment is performed via phylogenetic placement. Phylogenetic placement compares the mutations of the provided sequence to the mutations of each node found in a reference tree, where the root of that tree is the reference genome. The node that is most similar to the sample is used to both assign a clade designation and calculate where the sample should be placed in the phylogenetic tree.</p> <p>Nextclade Technical Details</p> Links Task task_nextclade.wdl Software Source Code https://github.com/nextstrain/nextclade Software Documentation Nextclade Original Publication(s) Nextclade: clade assignment, mutation calling and quality control for viral genomes. <code>vadr</code> <p>VADR (Viral Annotation DefineR) annotates and validates completed assembly files. For details on VADR default models/parameters, see the organism-specific parameters and logic section. It was primarily developed to test viral sequences to confirm they would be accepted to NCBI's GenBank data repository, but has found wide usage in general sequence validation and annotation.</p> <p>As part of the analysis of the assemblies, more than 70 types of unexpected characteristics, also known as alerts, can be reported. Any identified alerts can be found in the <code>vadr_alerts_list</code> output. Fatal alerts indicate that the sample is unlikely to be accepted to GenBank; non-fatal alerts are designated as passing sequences, but may still require further investigation. A full description of the potential alerts can be found on the VADR README here, including details on how to allow sequencecs to pass despite having fatal alerts.</p> <p>VADR Technical Details</p> Links Task task_vadr.wdl Software Source Code https://github.com/ncbi/vadr Software Documentation https://github.com/ncbi/vadr/wiki Original Publication(s) For SARS-CoV-2: Faster SARS-CoV-2 sequence validation and annotation for GenBank using VADR For non-SARS_CoV-2: VADR: validation and annotation of virus sequence submissions to GenBank <code>nextclade</code> <p>Nextclade is an open-source project used to analyze viral genomes, particularly for clade assignment and mutation calling. Simply, Nextclade works by aligning viral genomes to a reference genome, calling variants between the two sequences, and then assigning clades based on those identified mutations. </p> <p>Clade assignment is performed via phylogenetic placement. Phylogenetic placement compares the mutations of the provided sequence to the mutations of each node found in a reference tree, where the root of that tree is the reference genome. The node that is most similar to the sample is used to both assign a clade designation and calculate where the sample should be placed in the phylogenetic tree.</p> <p>Nextclade Technical Details</p> Links Task task_nextclade.wdl Software Source Code https://github.com/nextstrain/nextclade Software Documentation Nextclade Original Publication(s) Nextclade: clade assignment, mutation calling and quality control for viral genomes. <code>vadr</code> <p>VADR (Viral Annotation DefineR) annotates and validates completed assembly files. For details on VADR default models/parameters, see the organism-specific parameters and logic section. It was primarily developed to test viral sequences to confirm they would be accepted to NCBI's GenBank data repository, but has found wide usage in general sequence validation and annotation.</p> <p>As part of the analysis of the assemblies, more than 70 types of unexpected characteristics, also known as alerts, can be reported. Any identified alerts can be found in the <code>vadr_alerts_list</code> output. Fatal alerts indicate that the sample is unlikely to be accepted to GenBank; non-fatal alerts are designated as passing sequences, but may still require further investigation. A full description of the potential alerts can be found on the VADR README here, including details on how to allow sequencecs to pass despite having fatal alerts.</p> <p>VADR Technical Details</p> Links Task task_vadr.wdl Software Source Code https://github.com/ncbi/vadr Software Documentation https://github.com/ncbi/vadr/wiki Original Publication(s) For SARS-CoV-2: Faster SARS-CoV-2 sequence validation and annotation for GenBank using VADR For non-SARS_CoV-2: VADR: validation and annotation of virus sequence submissions to GenBank <code>quasitools</code> <p><code>quasitools</code> performs genomic characterization for HIV by using the HyDRA module for identifying drug resistance mutations in HIV-1 samples based on the Stanford HIV Drug Resistance Database and the 2009 WHO list for Surveillance of Transmitted HIVDR; see also the papers linked below.</p> <p>The HyDRA module in quasitools maps the sample sequence against an annotated HIV-1 reference and performs variant calling. Those variants are compared to the databases described above, and any matches are reported, along with the complete list of variants. </p> <p>quasitools Technical Details</p> Links Task task_quasitools.wdl Software Source Code quasitools on GitHub Software Documentation quasitools HyDRA README Original Publication(s) quasitools preprint: quasitools: A Collection of Tools for Viral Quasispecies AnalysisWHO 2009 Database: Drug resistance mutations for surveillance of transmitted HIV-1 drug-resistance: 2009 updateStanford Database: Human immunodeficiency virus reverse transcriptase and protease sequence database <code>nextclade</code> <p>Nextclade is an open-source project used to analyze viral genomes, particularly for clade assignment and mutation calling. Simply, Nextclade works by aligning viral genomes to a reference genome, calling variants between the two sequences, and then assigning clades based on those identified mutations. </p> <p>Clade assignment is performed via phylogenetic placement. Phylogenetic placement compares the mutations of the provided sequence to the mutations of each node found in a reference tree, where the root of that tree is the reference genome. The node that is most similar to the sample is used to both assign a clade designation and calculate where the sample should be placed in the phylogenetic tree.</p> <p>Nextclade Technical Details</p> Links Task task_nextclade.wdl Software Source Code https://github.com/nextstrain/nextclade Software Documentation Nextclade Original Publication(s) Nextclade: clade assignment, mutation calling and quality control for viral genomes. <code>vadr</code> <p>VADR (Viral Annotation DefineR) annotates and validates completed assembly files. For details on VADR default models/parameters, see the organism-specific parameters and logic section. It was primarily developed to test viral sequences to confirm they would be accepted to NCBI's GenBank data repository, but has found wide usage in general sequence validation and annotation.</p> <p>As part of the analysis of the assemblies, more than 70 types of unexpected characteristics, also known as alerts, can be reported. Any identified alerts can be found in the <code>vadr_alerts_list</code> output. Fatal alerts indicate that the sample is unlikely to be accepted to GenBank; non-fatal alerts are designated as passing sequences, but may still require further investigation. A full description of the potential alerts can be found on the VADR README here, including details on how to allow sequencecs to pass despite having fatal alerts.</p> <p>VADR Technical Details</p> Links Task task_vadr.wdl Software Source Code https://github.com/ncbi/vadr Software Documentation https://github.com/ncbi/vadr/wiki Original Publication(s) For SARS-CoV-2: Faster SARS-CoV-2 sequence validation and annotation for GenBank using VADR For non-SARS_CoV-2: VADR: validation and annotation of virus sequence submissions to GenBank <code>vadr</code> <p>VADR (Viral Annotation DefineR) annotates and validates completed assembly files. For details on VADR default models/parameters, see the organism-specific parameters and logic section. It was primarily developed to test viral sequences to confirm they would be accepted to NCBI's GenBank data repository, but has found wide usage in general sequence validation and annotation.</p> <p>As part of the analysis of the assemblies, more than 70 types of unexpected characteristics, also known as alerts, can be reported. Any identified alerts can be found in the <code>vadr_alerts_list</code> output. Fatal alerts indicate that the sample is unlikely to be accepted to GenBank; non-fatal alerts are designated as passing sequences, but may still require further investigation. A full description of the potential alerts can be found on the VADR README here, including details on how to allow sequencecs to pass despite having fatal alerts.</p> <p>VADR Technical Details</p> Links Task task_vadr.wdl Software Source Code https://github.com/ncbi/vadr Software Documentation https://github.com/ncbi/vadr/wiki Original Publication(s) For SARS-CoV-2: Faster SARS-CoV-2 sequence validation and annotation for GenBank using VADR For non-SARS_CoV-2: VADR: validation and annotation of virus sequence submissions to GenBank <code>vadr</code> <p>VADR (Viral Annotation DefineR) annotates and validates completed assembly files. For details on VADR default models/parameters, see the organism-specific parameters and logic section. It was primarily developed to test viral sequences to confirm they would be accepted to NCBI's GenBank data repository, but has found wide usage in general sequence validation and annotation.</p> <p>As part of the analysis of the assemblies, more than 70 types of unexpected characteristics, also known as alerts, can be reported. Any identified alerts can be found in the <code>vadr_alerts_list</code> output. Fatal alerts indicate that the sample is unlikely to be accepted to GenBank; non-fatal alerts are designated as passing sequences, but may still require further investigation. A full description of the potential alerts can be found on the VADR README here, including details on how to allow sequencecs to pass despite having fatal alerts.</p> <p>VADR Technical Details</p> Links Task task_vadr.wdl Software Source Code https://github.com/ncbi/vadr Software Documentation https://github.com/ncbi/vadr/wiki Original Publication(s) For SARS-CoV-2: Faster SARS-CoV-2 sequence validation and annotation for GenBank using VADR For non-SARS_CoV-2: VADR: validation and annotation of virus sequence submissions to GenBank"},{"location":"workflows/genomic_characterization/theiacov/#outputs","title":"Outputs","text":"TheiaCoV_Illumina_PETheiaCoV_Illumina_SETheiaCoV_ONTTheiaCoV_FASTATheiaCoV_ClearLabsTheiaCoV_FASTA_Batch Variable Type Description abricate_flu_database String ABRicate database used for analysis abricate_flu_results File File containing all results from ABRicate abricate_flu_subtype String Flu subtype as determined by ABRicate abricate_flu_type String Flu type as determined by ABRicate abricate_flu_version String Version of ABRicate aligned_bai String Index companion file to the bam file generated during the consensus assembly process aligned_bam String Sorted BAM file containing the alignments of reads to the reference genome assembly_fasta String Consensus genome assembly; for lower quality flu samples, the output may state \"Assembly could not be generated\" when there is too little and/or too low quality data for IRMA to produce an assembly. Contigs will be ordered from largest to smallest when IRMA is used. assembly_length_unambiguous Int Number of unambiguous basecalls within the consensus assembly assembly_mean_coverage String Mean sequencing depth throughout the consensus assembly. Generated after performing primer trimming and calculated using the SAMtools coverage command assembly_method String Method employed to generate consensus assembly auspice_json File Auspice-compatable JSON output generated from Nextclade analysis that includes the Nextclade default samples for clade-typing and the single sample placed on this tree auspice_json_flu_h5n1 File Auspice-compatable JSON output generated from Nextclade analysis on Influenza H5N1 whole genome that includes the samples included in the \"avian-flu/h5n1-cattle-outbreak\" nextstrain build that is focused on B3.13 genotype and the single sample placed on this tree auspice_json_flu_ha File Auspice-compatable JSON output generated from Nextclade analysis on Influenza HA segment that includes the Nextclade default samples for clade-typing and the single sample placed on this tree auspice_json_flu_na File Auspice-compatable JSON output generated from Nextclade analysis on Influenza NA segment that includes the Nextclade default samples for clade-typing and the single sample placed on this tree bbduk_docker String The Docker image for bbduk, which was used to remove the adapters from the sequences bwa_version String Version of BWA software used consensus_flagstat File Output from the SAMtools flagstat command to assess quality of the alignment file (BAM) consensus_n_variant_min_depth Int Minimum read depth to call variants for iVar consensus and iVar variants. Also represents the minimum consensus support threshold used by IRMA with Illumina Influenza data. consensus_stats File Output from the SAMtools stats command to assess quality of the alignment file (BAM) est_percent_gene_coverage_tsv File Percent coverage for each gene in the organism being analyzed (depending on the organism input) fastp_html_report File The HTML report made with fastp fastp_version String The version of fastp used fastq_scan_clean1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about clean forward read quality and length fastq_scan_clean2_json File The JSON file output from <code>fastq-scan</code> containing summary stats about clean reverse read quality and length fastq_scan_num_reads_clean1 Int The number of forward reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_clean2 Int The number of reverse reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_clean_pairs String The number of read pairs after cleaning as calculated by fastq_scan fastq_scan_num_reads_raw1 Int The number of input forward reads as calculated by fastq_scan fastq_scan_num_reads_raw2 Int The number of input reserve reads as calculated by fastq_scan fastq_scan_num_reads_raw_pairs String The number of input read pairs as calculated by fastq_scan fastq_scan_raw1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about raw forward read quality and length fastq_scan_raw2_json File The JSON file output from <code>fastq-scan</code> containing summary stats about raw reverse read quality and length fastq_scan_version String The version of fastq_scan fastqc_clean1_html File An HTML file that provides a graphical visualization of clean forward read quality from fastqc to open in an internet browser fastqc_clean2_html File An HTML file that provides a graphical visualization of clean reverse read quality from fastqc to open in an internet browser fastqc_docker String The Docker container used for fastqc fastqc_num_reads_clean1 Int The number of forward reads after cleaning by fastqc fastqc_num_reads_clean2 Int The number of reverse reads after cleaning by fastqc fastqc_num_reads_clean_pairs String The number of read pairs after cleaning by fastqc fastqc_num_reads_raw1 Int The number of input forward reads by fastqc before cleaning fastqc_num_reads_raw2 Int The number of input reverse reads by fastqc before cleaning fastqc_num_reads_raw_pairs String The number of input read pairs by fastqc before cleaning fastqc_raw1_html File An HTML file that provides a graphical visualization of raw forward read quality from fastqc to open in an internet browser fastqc_raw2_html File An HTML file that provides a graphical visualization of raw reverse read quality from fastqc to open in an internet browser fastqc_version String Version of fastqc software used flu_A_315675_resistance String resistance mutations to A_315675 flu_L_742_001_resistance String resistance mutations to L_742_001 flu_amantadine_resistance String resistance mutations to amantadine flu_compound_367_resistance String resistance mutations to compound_367 flu_favipiravir_resistance String resistance mutations to favipiravir flu_fludase_resistance String resistance mutations to fludase flu_laninamivir_resistance String resistance mutations to laninamivir flu_oseltamivir_resistance String resistance mutations to oseltamivir (Tamiflu\u00ae) flu_peramivir_resistance String resistance mutations to peramivir (Rapivab\u00ae) flu_pimodivir_resistance String resistance mutations to pimodivir flu_rimantadine_resistance String resistance mutations to rimantadine flu_xofluza_resistance String resistance mutations to xofluza (Baloxavir marboxil) flu_zanamivir_resistance String resistance mutations to zanamivir (Relenza\u00ae) genoflu_all_segments String The genotypes for each individual flu segment genoflu_genotype String The genotype of the whole genome, based off of the individual segments types genoflu_output_tsv File The output file from GenoFLU genoflu_version String The version of GenoFLU used irma_assembly_fasta_concatenated File Assembly FASTA file of all Influenza genome segments concatenated into one sequence/FASTA entry irma_docker String Docker image used to run IRMA irma_ha_segment_fasta File HA (Haemagglutinin) assembly fasta file irma_mp_segment_fasta File MP (Matrix Protein) assembly fasta file irma_na_segment_fasta File NA (Neuraminidase) assembly fasta file irma_np_segment_fasta File NP (Nucleoprotein) assembly fasta file irma_ns_segment_fasta File NS (Nonstructural) assembly fasta file irma_pa_segment_fasta File PA (Polymerase acidic) assembly fasta file irma_pb1_segment_fasta File PB1 (Polymerase basic 1) assembly fasta file irma_pb2_segment_fasta File PB2 (Polymerase basic 2) assembly fasta file irma_subtype String Flu subtype as determined by IRMA irma_subtype_notes String Helpful note to user about Flu B subtypes. Output will be blank for Flu A samples. For Flu B samples it will state: \"IRMA does not differentiate Victoria and Yamagata Flu B lineages. See abricate_flu_subtype output column\" irma_type String Flu type as determined by IRMA irma_version String Version of IRMA used ivar_tsv File Variant descriptor file generated by iVar variants ivar_variant_proportion_intermediate String The proportion of variants of intermediate frequency ivar_variant_version String Version of iVar for running the iVar variants command ivar_vcf File iVar tsv output converted to VCF format ivar_version_consensus String Version of iVar for running the iVar consensus command ivar_version_primtrim String Version of iVar for running the iVar trim command kraken_human Float Percent of human read data detected using the Kraken2 software kraken_human_dehosted Float Percent of human read data detected using the Kraken2 software after host removal kraken_report File Full Kraken report kraken_report_dehosted File Full Kraken report after host removal kraken_sc2 String Percent of SARS-CoV-2 read data detected using the Kraken2 software kraken_sc2_dehosted String Percent of SARS-CoV-2 read data detected using the Kraken2 software after host removal kraken_target_organism String Percent of target organism read data detected using the Kraken2 software kraken_target_organism_dehosted String Percent of target organism read data detected using the Kraken2 software after host removal kraken_target_organism_name String The name of the target organism; e.g., \"Monkeypox\" or \"Human immunodeficiency virus\" kraken_version String Version of Kraken software used meanbaseq_trim String Mean quality of the nucleotide basecalls aligned to the reference genome after primer trimming meanmapq_trim String Mean quality of the mapped reads to the reference genome after primer trimming nextclade_aa_dels String Amino-acid deletions as detected by NextClade. Will be blank for Flu nextclade_aa_dels_flu_h5n1 String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for H5N1 whole genome nextclade_aa_dels_flu_h5n1 String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for H5N1 whole genome nextclade_aa_dels_flu_ha String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for HA segment nextclade_aa_dels_flu_ha String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for HA segment nextclade_aa_dels_flu_na String Amino-acid deletions as detected by NextClade. Specific to Flu; it includes deletions for NA segment nextclade_aa_dels_flu_na String Amino-acid deletions as detected by NextClade. Specific to Flu; it includes deletions for NA segment nextclade_aa_subs String Amino-acid substitutions as detected by Nextclade. Will be blank for Flu nextclade_aa_subs_flu_h5n1 String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for H5N1 whole genome nextclade_aa_subs_flu_h5n1 String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for H5N1 whole genome nextclade_aa_subs_flu_ha String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for HA segment nextclade_aa_subs_flu_ha String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for HA segment nextclade_aa_subs_flu_na String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for NA segment nextclade_aa_subs_flu_na String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for NA segment nextclade_clade String Nextclade clade designation, will be blank for Flu. nextclade_clade_flu_h5n1 String Nextclade clade designation, specific to Flu 5N1 whole genome. NOTE: Output will be blank or <code>NA</code> since this nextclade dataset does assign clades nextclade_clade_flu_ha String Nextclade clade designation, specific to Flu NA segment nextclade_clade_flu_na String Nextclade clade designation, specific to Flu HA segment nextclade_docker String Docker image used to run Nextclade nextclade_ds_tag String Dataset tag used to run Nextclade. Will be blank for Flu nextclade_ds_tag_flu_ha String Dataset tag used to run Nextclade, specific to Flu HA segment nextclade_ds_tag_flu_na String Dataset tag used to run Nextclade, specific to Flu NA segment nextclade_json File Nextclade output in JSON file format. Will be blank for Flu nextclade_json_flu_h5n1 File Nextclade output in JSON file format, specific to Flu H5N1 whole genome nextclade_json_flu_ha File Nextclade output in JSON file format, specific to Flu HA segment nextclade_json_flu_na File Nextclade output in JSON file format, specific to Flu NA segment nextclade_lineage String Nextclade lineage designation nextclade_qc String QC metric as determined by Nextclade. Will be blank for Flu nextclade_qc_flu_h5n1 String QC metric as determined by Nextclade, specific to Flu H5N1 whole genome nextclade_qc_flu_h5n1 String QC metric as determined by Nextclade, specific to Flu H5N1 whole genome nextclade_qc_flu_ha String QC metric as determined by Nextclade, specific to Flu HA segment nextclade_qc_flu_ha String QC metric as determined by Nextclade, specific to Flu HA segment nextclade_qc_flu_na String QC metric as determined by Nextclade, specific to Flu NA segment nextclade_qc_flu_na String QC metric as determined by Nextclade, specific to Flu NA segment nextclade_tsv File Nextclade output in TSV file format. Will be blank for Flu nextclade_tsv_flu_h5n1 File Nextclade output in TSV file format, specific to Flu H5N1 whole genome nextclade_tsv_flu_ha File Nextclade output in TSV file format, specific to Flu HA segment nextclade_tsv_flu_na File Nextclade output in TSV file format, specific to Flu NA segment nextclade_version String The version of Nextclade software used number_Degenerate Int Number of degenerate basecalls within the consensus assembly number_N Int Number of fully ambiguous basecalls within the consensus assembly number_Total Int Total number of nucleotides within the consensus assembly pango_lineage String Pango lineage as determined by Pangolin pango_lineage_expanded String Pango lineage without use of aliases; e.g., \"BA.1\" \u2192 \"B.1.1.529.1\" pango_lineage_report File Full Pango lineage report generated by Pangolin pangolin_assignment_version String The version of the pangolin software (e.g. PANGO or PUSHER) used for lineage assignment pangolin_conflicts String Number of lineage conflicts as determined by Pangolin pangolin_docker String Docker image used to run Pangolin pangolin_notes String Lineage notes as determined by Pangolin pangolin_versions String All Pangolin software and database versions percent_reference_coverage Float Percent coverage of the reference genome after performing primer trimming; calculated as assembly_length_unambiguous / length of the reference genome (SC2: 29903) x 100 percentage_mapped_reads String Percentage of reads that successfully aligned to the reference genome. This value is calculated by number of mapped reads / total number of reads x 100. primer_bed_name String Name of the primer bed files used for primer trimming primer_trimmed_read_percent Float Percentage of read data with primers trimmed as determined by iVar trim qc_check String A string that indicates whether or not the sample passes a set of pre-determined and user-provided QC thresholds qc_standard File The file used in the QC Check task containing the QC thresholds. quasitools_coverage_file File The coverage report created by Quasitools HyDRA quasitools_date String Date of Quasitools analysis quasitools_dr_report File Drug resistance report created by Quasitools HyDRA quasitools_hydra_vcf File The VCF created by Quasitools HyDRA quasitools_mutations_report File The mutation report created by Quasitools HyDRA quasitools_version String Version of Quasitools used read1_aligned File Forward read file of only aligned reads read1_clean File Forward read file after quality trimming and adapter removal read1_dehosted File The dehosted forward reads file; suggested read file for SRA submission read1_unaligned File Forward read file of unaligned reads read2_aligned File Reverse read file of only aligned reads read2_clean File Reverse read file after quality trimming and adapter removal read2_dehosted File The dehosted reverse reads file; suggested read file for SRA submission read2_unaligned File Reverse read file of unaligned reads read_screen_clean String PASS or FAIL result from clean read screening; FAIL accompanied by the reason(s) for failure read_screen_clean_tsv File Clean read screening report TSV depicting read counts, total read base pairs, and estimated genome length read_screen_raw String PASS or FAIL result from raw read screening; FAIL accompanied by the reason(s) for failure read_screen_raw_tsv File Raw read screening report TSV depicting read counts, total read base pairs, and estimated genome length samtools_version String The version of SAMtools used to sort and index the alignment file samtools_version_consensus String The version of SAMtools used to create the pileup before running iVar consensus samtools_version_primtrim String The version of SAMtools used to create the pileup before running iVar trim samtools_version_stats String The version of SAMtools used to assess the quality of read mapping sc2_s_gene_mean_coverage Float Mean read depth for the S gene in SARS-CoV-2 sc2_s_gene_percent_coverage Float Percent coverage of the S gene in SARS-CoV-2 seq_platform String Description of the sequencing methodology used to generate the input read data sorted_bam_unaligned File A BAM file that only contains reads that did not align to the reference sorted_bam_unaligned_bai File Index companion file to a BAM file that only contains reads that did not align to the reference theiacov_illumina_pe_analysis_date String Date of analysis theiacov_illumina_pe_version String Version of PHB used for running the workflow trimmomatic_docker String The docker image used for the trimmomatic module in this workflow trimmomatic_version String The version of Trimmomatic used vadr_alerts_list File A file containing all of the fatal alerts as determined by VADR vadr_all_outputs_tar_gz File A .tar.gz file (gzip-compressed tar archive file) containing all outputs from the VADR command v-annotate.pl. This file must be uncompressed &amp; extracted to see the many files within. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description of all files present within the archive. Useful when deeply investigating a sample's genome &amp; annotations. vadr_classification_summary_file File Per-sequence tabular classification file. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#explanation-of-sqc-suffixed-output-files for more complete description. vadr_docker String Docker image used to run VADR vadr_fastas_zip_archive File Zip archive containing all fasta files created during VADR analysis vadr_feature_tbl_fail File 5 column feature table output for failing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_feature_tbl_pass File 5 column feature table output for passing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_num_alerts String Number of fatal alerts as determined by VADR Variable Type Description aligned_bai File Index companion file to the bam file generated during the consensus assembly process aligned_bam File Sorted BAM file containing the alignments of reads to the reference genome assembly_fasta File Consensus genome assembly; for lower quality flu samples, the output may state \"Assembly could not be generated\" when there is too little and/or too low quality data for IRMA to produce an assembly. Contigs will be ordered from largest to smallest when IRMA is used. assembly_length_unambiguous Int Number of unambiguous basecalls within the consensus assembly assembly_mean_coverage Float Mean sequencing depth throughout the consensus assembly. Generated after performing primer trimming and calculated using the SAMtools coverage command assembly_method String Method employed to generate consensus assembly auspice_json File Auspice-compatable JSON output generated from Nextclade analysis that includes the Nextclade default samples for clade-typing and the single sample placed on this tree bbduk_docker String The Docker image for bbduk, which was used to remove the adapters from the sequences bwa_version String Version of BWA software used consensus_flagstat File Output from the SAMtools flagstat command to assess quality of the alignment file (BAM) consensus_n_variant_min_depth Int Minimum read depth to call variants for iVar consensus and iVar variants. Also represents the minimum consensus support threshold used by IRMA with Illumina Influenza data. consensus_stats File Output from the SAMtools stats command to assess quality of the alignment file (BAM) est_percent_gene_coverage_tsv File Percent coverage for each gene in the organism being analyzed (depending on the organism input) fastp_html_report File The HTML report made with fastp fastp_version String The version of fastp used fastq_scan_clean1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about clean forward read quality and length fastq_scan_num_reads_clean1 Int The number of forward reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_raw1 Int The number of input forward reads as calculated by fastq_scan fastq_scan_raw1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about raw forward read quality and length fastq_scan_version String The version of fastq_scan fastqc_clean1_html File An HTML file that provides a graphical visualization of clean forward read quality from fastqc to open in an internet browser fastqc_docker String The Docker container used for fastqc fastqc_num_reads_clean1 Int The number of forward reads after cleaning by fastqc fastqc_num_reads_raw1 Int The number of input forward reads by fastqc before cleaning fastqc_raw1_html File An HTML file that provides a graphical visualization of raw forward read quality from fastqc to open in an internet browser fastqc_version String Version of fastqc software used ivar_tsv File Variant descriptor file generated by iVar variants ivar_variant_proportion_intermediate String The proportion of variants of intermediate frequency ivar_variant_version String Version of iVar for running the iVar variants command ivar_vcf File iVar tsv output converted to VCF format ivar_version_consensus String Version of iVar for running the iVar consensus command ivar_version_primtrim String Version of iVar for running the iVar trim command kraken_human Float Percent of human read data detected using the Kraken2 software kraken_human_dehosted Float Percent of human read data detected using the Kraken2 software after host removal kraken_report File Full Kraken report kraken_report_dehosted File Full Kraken report after host removal kraken_sc2 String Percent of SARS-CoV-2 read data detected using the Kraken2 software kraken_sc2_dehosted String Percent of SARS-CoV-2 read data detected using the Kraken2 software after host removal kraken_target_organism String Percent of target organism read data detected using the Kraken2 software kraken_target_organism_dehosted String Percent of target organism read data detected using the Kraken2 software after host removal kraken_target_organism_name String The name of the target organism; e.g., \"Monkeypox\" or \"Human immunodeficiency virus\" kraken_version String Version of Kraken software used meanbaseq_trim Float Mean quality of the nucleotide basecalls aligned to the reference genome after primer trimming meanmapq_trim Float Mean quality of the mapped reads to the reference genome after primer trimming nextclade_aa_dels String Amino-acid deletions as detected by NextClade. Will be blank for Flu nextclade_aa_subs String Amino-acid substitutions as detected by Nextclade. Will be blank for Flu nextclade_clade String Nextclade clade designation, will be blank for Flu. nextclade_docker String Docker image used to run Nextclade nextclade_ds_tag String Dataset tag used to run Nextclade. Will be blank for Flu nextclade_json File Nextclade output in JSON file format. Will be blank for Flu nextclade_lineage String Nextclade lineage designation nextclade_qc String QC metric as determined by Nextclade. Will be blank for Flu nextclade_tsv File Nextclade output in TSV file format. Will be blank for Flu nextclade_version String The version of Nextclade software used number_Degenerate Int Number of degenerate basecalls within the consensus assembly number_N Int Number of fully ambiguous basecalls within the consensus assembly number_Total Int Total number of nucleotides within the consensus assembly pango_lineage String Pango lineage as determined by Pangolin pango_lineage_expanded String Pango lineage without use of aliases; e.g., \"BA.1\" \u2192 \"B.1.1.529.1\" pango_lineage_report File Full Pango lineage report generated by Pangolin pangolin_assignment_version String The version of the pangolin software (e.g. PANGO or PUSHER) used for lineage assignment pangolin_conflicts String Number of lineage conflicts as determined by Pangolin pangolin_docker String Docker image used to run Pangolin pangolin_notes String Lineage notes as determined by Pangolin pangolin_versions String All Pangolin software and database versions percent_reference_coverage Float Percent coverage of the reference genome after performing primer trimming; calculated as assembly_length_unambiguous / length of the reference genome (SC2: 29903) x 100 percentage_mapped_reads String Percentage of reads that successfully aligned to the reference genome. This value is calculated by number of mapped reads / total number of reads x 100. primer_bed_name String Name of the primer bed files used for primer trimming primer_trimmed_read_percent Float Percentage of read data with primers trimmed as determined by iVar trim qc_check String A string that indicates whether or not the sample passes a set of pre-determined and user-provided QC thresholds qc_standard File The file used in the QC Check task containing the QC thresholds. read1_aligned File Forward read file of only aligned reads read1_clean File Forward read file after quality trimming and adapter removal read1_unaligned File Forward read file of unaligned reads read_screen_clean String PASS or FAIL result from clean read screening; FAIL accompanied by the reason(s) for failure read_screen_clean_tsv File Clean read screening report TSV depicting read counts, total read base pairs, and estimated genome length read_screen_raw String PASS or FAIL result from raw read screening; FAIL accompanied by the reason(s) for failure read_screen_raw_tsv File Raw read screening report TSV depicting read counts, total read base pairs, and estimated genome length samtools_version String The version of SAMtools used to sort and index the alignment file samtools_version_consensus String The version of SAMtools used to create the pileup before running iVar consensus samtools_version_primtrim String The version of SAMtools used to create the pileup before running iVar trim samtools_version_stats String The version of SAMtools used to assess the quality of read mapping sc2_s_gene_mean_coverage Float Mean read depth for the S gene in SARS-CoV-2 sc2_s_gene_percent_coverage Float Percent coverage of the S gene in SARS-CoV-2 seq_platform String Description of the sequencing methodology used to generate the input read data sorted_bam_unaligned File A BAM file that only contains reads that did not align to the reference sorted_bam_unaligned_bai File Index companion file to a BAM file that only contains reads that did not align to the reference theiacov_illumina_se_analysis_date String Date of analysis theiacov_illumina_se_version String Version of PHB used for running the workflow trimmomatic_docker String The docker image used for the trimmomatic module in this workflow trimmomatic_version String The version of Trimmomatic used vadr_alerts_list File A file containing all of the fatal alerts as determined by VADR vadr_all_outputs_tar_gz File A .tar.gz file (gzip-compressed tar archive file) containing all outputs from the VADR command v-annotate.pl. This file must be uncompressed &amp; extracted to see the many files within. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description of all files present within the archive. Useful when deeply investigating a sample's genome &amp; annotations. vadr_classification_summary_file File Per-sequence tabular classification file. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#explanation-of-sqc-suffixed-output-files for more complete description. vadr_docker String Docker image used to run VADR vadr_fastas_zip_archive File Zip archive containing all fasta files created during VADR analysis vadr_feature_tbl_fail File 5 column feature table output for failing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_feature_tbl_pass File 5 column feature table output for passing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_num_alerts String Number of fatal alerts as determined by VADR Variable Type Description abricate_flu_database String ABRicate database used for analysis abricate_flu_results File File containing all results from ABRicate abricate_flu_subtype String Flu subtype as determined by ABRicate abricate_flu_type String Flu type as determined by ABRicate abricate_flu_version String Version of ABRicate aligned_bai File Index companion file to the bam file generated during the consensus assembly process aligned_bam File Sorted BAM file containing the alignments of reads to the reference genome artic_docker String Docker image utilized for read trimming and consensus genome assembly artic_version String Version of the Artic software utilized for read trimming and conesnsus genome assembly assembly_fasta String Consensus genome assembly; for lower quality flu samples, the output may state \"Assembly could not be generated\" when there is too little and/or too low quality data for IRMA to produce an assembly. Contigs will be ordered from largest to smallest when IRMA is used. assembly_length_unambiguous Int Number of unambiguous basecalls within the consensus assembly assembly_mean_coverage String Mean sequencing depth throughout the consensus assembly. Generated after performing primer trimming and calculated using the SAMtools coverage command assembly_method String Method employed to generate consensus assembly auspice_json File Auspice-compatable JSON output generated from Nextclade analysis that includes the Nextclade default samples for clade-typing and the single sample placed on this tree auspice_json_flu_h5n1 File Auspice-compatable JSON output generated from Nextclade analysis on Influenza H5N1 whole genome that includes the samples included in the \"avian-flu/h5n1-cattle-outbreak\" nextstrain build that is focused on B3.13 genotype and the single sample placed on this tree auspice_json_flu_ha File Auspice-compatable JSON output generated from Nextclade analysis on Influenza HA segment that includes the Nextclade default samples for clade-typing and the single sample placed on this tree auspice_json_flu_na File Auspice-compatable JSON output generated from Nextclade analysis on Influenza NA segment that includes the Nextclade default samples for clade-typing and the single sample placed on this tree consensus_flagstat File Output from the SAMtools flagstat command to assess quality of the alignment file (BAM) consensus_stats File Output from the SAMtools stats command to assess quality of the alignment file (BAM) est_coverage_clean Float Estimated coverage calculated from clean reads and genome length est_coverage_raw Float Estimated coverage calculated from raw reads and genome length est_percent_gene_coverage_tsv File Percent coverage for each gene in the organism being analyzed (depending on the organism input) flu_A_315675_resistance String resistance mutations to A_315675 flu_L_742_001_resistance String resistance mutations to L_742_001 flu_amantadine_resistance String resistance mutations to amantadine flu_compound_367_resistance String resistance mutations to compound_367 flu_favipiravir_resistance String resistance mutations to favipiravir flu_fludase_resistance String resistance mutations to fludase flu_laninamivir_resistance String resistance mutations to laninamivir flu_oseltamivir_resistance String resistance mutations to oseltamivir (Tamiflu\u00ae) flu_peramivir_resistance String resistance mutations to peramivir (Rapivab\u00ae) flu_pimodivir_resistance String resistance mutations to pimodivir flu_rimantadine_resistance String resistance mutations to rimantadine flu_xofluza_resistance String resistance mutations to xofluza (Baloxavir marboxil) flu_zanamivir_resistance String resistance mutations to zanamivir (Relenza\u00ae) genoflu_all_segments String The genotypes for each individual flu segment genoflu_genotype String The genotype of the whole genome, based off of the individual segments types genoflu_output_tsv File The output file from GenoFLU genoflu_version String The version of GenoFLU used irma_assembly_fasta_concatenated File Assembly FASTA file of all Influenza genome segments concatenated into one sequence/FASTA entry irma_docker String Docker image used to run IRMA irma_ha_segment_fasta File HA (Haemagglutinin) assembly fasta file irma_min_consensus_support_threshold Int Minimum consensus support threshold used by IRMA with ONT data. For illumina data, see output called <code>consensus_n_variant_min_depth</code> for this value irma_mp_segment_fasta File MP (Matrix Protein) assembly fasta file irma_na_segment_fasta File NA (Neuraminidase) assembly fasta file irma_np_segment_fasta File NP (Nucleoprotein) assembly fasta file irma_ns_segment_fasta File NS (Nonstructural) assembly fasta file irma_pa_segment_fasta File PA (Polymerase acidic) assembly fasta file irma_pb1_segment_fasta File PB1 (Polymerase basic 1) assembly fasta file irma_pb2_segment_fasta File PB2 (Polymerase basic 2) assembly fasta file irma_subtype String Flu subtype as determined by IRMA irma_subtype_notes String Helpful note to user about Flu B subtypes. Output will be blank for Flu A samples. For Flu B samples it will state: \"IRMA does not differentiate Victoria and Yamagata Flu B lineages. See abricate_flu_subtype output column\" irma_type String Flu type as determined by IRMA irma_version String Version of IRMA used kraken_human Float Percent of human read data detected using the Kraken2 software kraken_human_dehosted Float Percent of human read data detected using the Kraken2 software after host removal kraken_report File Full Kraken report kraken_report_dehosted File Full Kraken report after host removal kraken_sc2 String Percent of SARS-CoV-2 read data detected using the Kraken2 software kraken_sc2_dehosted String Percent of SARS-CoV-2 read data detected using the Kraken2 software after host removal kraken_target_organism String Percent of target organism read data detected using the Kraken2 software kraken_target_organism_dehosted String Percent of target organism read data detected using the Kraken2 software after host removal kraken_target_organism_name String The name of the target organism; e.g., \"Monkeypox\" or \"Human immunodeficiency virus\" kraken_version String Version of Kraken software used meanbaseq_trim Float Mean quality of the nucleotide basecalls aligned to the reference genome after primer trimming meanmapq_trim Float Mean quality of the mapped reads to the reference genome after primer trimming medaka_reference String Reference sequence used in medaka task medaka_vcf File A VCF file containing the identified variants nanoplot_docker String Docker image for nanoplot nanoplot_html_clean File An HTML report describing the clean reads nanoplot_html_raw File An HTML report describing the raw reads nanoplot_num_reads_clean1 Int Number of clean reads nanoplot_num_reads_raw1 Int Number of raw reads nanoplot_r1_est_coverage_clean Float Estimated coverage on the clean reads by nanoplot nanoplot_r1_est_coverage_raw Float Estimated coverage on the raw reads by nanoplot nanoplot_r1_mean_q_clean Float Mean quality score of clean forward reads nanoplot_r1_mean_q_raw Float Mean quality score of raw forward reads nanoplot_r1_mean_readlength_clean Float Mean read length of clean forward reads nanoplot_r1_mean_readlength_raw Float Mean read length of raw forward reads nanoplot_r1_median_q_clean Float Median quality score of clean forward reads nanoplot_r1_median_q_raw Float Median quality score of raw forward reads nanoplot_r1_median_readlength_clean Float Median read length of clean forward reads nanoplot_r1_median_readlength_raw Float Median read length of raw forward reads nanoplot_r1_n50_clean Float N50 of clean forward reads nanoplot_r1_n50_raw Float N50 of raw forward reads nanoplot_r1_stdev_readlength_clean Float Standard deviation read length of clean forward reads nanoplot_r1_stdev_readlength_raw Float Standard deviation read length of raw forward reads nanoplot_tsv_clean File A TSV report describing the clean reads nanoplot_tsv_raw File A TSV report describing the raw reads nanoplot_version String Version of nanoplot used for analysis nextclade_aa_dels String Amino-acid deletions as detected by NextClade. Will be blank for Flu nextclade_aa_dels_flu_h5n1 String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for H5N1 whole genome nextclade_aa_dels_flu_h5n1 String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for H5N1 whole genome nextclade_aa_dels_flu_ha String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for HA segment nextclade_aa_dels_flu_ha String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for HA segment nextclade_aa_dels_flu_na String Amino-acid deletions as detected by NextClade. Specific to Flu; it includes deletions for NA segment nextclade_aa_dels_flu_na String Amino-acid deletions as detected by NextClade. Specific to Flu; it includes deletions for NA segment nextclade_aa_subs String Amino-acid substitutions as detected by Nextclade. Will be blank for Flu nextclade_aa_subs_flu_h5n1 String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for H5N1 whole genome nextclade_aa_subs_flu_h5n1 String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for H5N1 whole genome nextclade_aa_subs_flu_ha String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for HA segment nextclade_aa_subs_flu_ha String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for HA segment nextclade_aa_subs_flu_na String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for NA segment nextclade_aa_subs_flu_na String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for NA segment nextclade_clade String Nextclade clade designation, will be blank for Flu. nextclade_clade_flu_h5n1 String Nextclade clade designation, specific to Flu 5N1 whole genome. NOTE: Output will be blank or <code>NA</code> since this nextclade dataset does assign clades nextclade_clade_flu_ha String Nextclade clade designation, specific to Flu NA segment nextclade_clade_flu_na String Nextclade clade designation, specific to Flu HA segment nextclade_docker String Docker image used to run Nextclade nextclade_ds_tag String Dataset tag used to run Nextclade. Will be blank for Flu nextclade_ds_tag_flu_ha String Dataset tag used to run Nextclade, specific to Flu HA segment nextclade_ds_tag_flu_na String Dataset tag used to run Nextclade, specific to Flu NA segment nextclade_json File Nextclade output in JSON file format. Will be blank for Flu nextclade_json_flu_h5n1 File Nextclade output in JSON file format, specific to Flu H5N1 whole genome nextclade_json_flu_ha File Nextclade output in JSON file format, specific to Flu HA segment nextclade_json_flu_na File Nextclade output in JSON file format, specific to Flu NA segment nextclade_lineage String Nextclade lineage designation nextclade_qc String QC metric as determined by Nextclade. Will be blank for Flu nextclade_qc_flu_h5n1 String QC metric as determined by Nextclade, specific to Flu H5N1 whole genome nextclade_qc_flu_h5n1 String QC metric as determined by Nextclade, specific to Flu H5N1 whole genome nextclade_qc_flu_ha String QC metric as determined by Nextclade, specific to Flu HA segment nextclade_qc_flu_ha String QC metric as determined by Nextclade, specific to Flu HA segment nextclade_qc_flu_na String QC metric as determined by Nextclade, specific to Flu NA segment nextclade_qc_flu_na String QC metric as determined by Nextclade, specific to Flu NA segment nextclade_tsv File Nextclade output in TSV file format. Will be blank for Flu nextclade_tsv_flu_h5n1 File Nextclade output in TSV file format, specific to Flu H5N1 whole genome nextclade_tsv_flu_ha File Nextclade output in TSV file format, specific to Flu HA segment nextclade_tsv_flu_na File Nextclade output in TSV file format, specific to Flu NA segment nextclade_version String The version of Nextclade software used number_Degenerate Int Number of degenerate basecalls within the consensus assembly number_N Int Number of fully ambiguous basecalls within the consensus assembly number_Total Int Total number of nucleotides within the consensus assembly pango_lineage String Pango lineage as determined by Pangolin pango_lineage_expanded String Pango lineage without use of aliases; e.g., \"BA.1\" \u2192 \"B.1.1.529.1\" pango_lineage_report File Full Pango lineage report generated by Pangolin pangolin_assignment_version String The version of the pangolin software (e.g. PANGO or PUSHER) used for lineage assignment pangolin_conflicts String Number of lineage conflicts as determined by Pangolin pangolin_docker String Docker image used to run Pangolin pangolin_notes String Lineage notes as determined by Pangolin pangolin_versions String All Pangolin software and database versions percent_reference_coverage Float Percent coverage of the reference genome after performing primer trimming; calculated as assembly_length_unambiguous / length of the reference genome (SC2: 29903) x 100 percentage_mapped_reads String Percentage of reads that successfully aligned to the reference genome. This value is calculated by number of mapped reads / total number of reads x 100. primer_bed_name String Name of the primer bed files used for primer trimming qc_check String A string that indicates whether or not the sample passes a set of pre-determined and user-provided QC thresholds qc_standard File The file used in the QC Check task containing the QC thresholds. quasitools_coverage_file File The coverage report created by Quasitools HyDRA quasitools_date String Date of Quasitools analysis quasitools_dr_report File Drug resistance report created by Quasitools HyDRA quasitools_hydra_vcf File The VCF created by Quasitools HyDRA quasitools_mutations_report File The mutation report created by Quasitools HyDRA quasitools_version String Version of Quasitools used read1_aligned File Forward read file of only aligned reads read1_dehosted File The dehosted forward reads file; suggested read file for SRA submission read1_trimmed File Forward read file after quality trimming and adapter removal read_screen_clean String PASS or FAIL result from clean read screening; FAIL accompanied by the reason(s) for failure read_screen_clean_tsv File Clean read screening report TSV depicting read counts, total read base pairs, and estimated genome length read_screen_raw String PASS or FAIL result from raw read screening; FAIL accompanied by the reason(s) for failure read_screen_raw_tsv File Raw read screening report TSV depicting read counts, total read base pairs, and estimated genome length samtools_version String The version of SAMtools used to sort and index the alignment file sc2_s_gene_mean_coverage Float Mean read depth for the S gene in SARS-CoV-2 sc2_s_gene_percent_coverage Float Percent coverage of the S gene in SARS-CoV-2 seq_platform String Description of the sequencing methodology used to generate the input read data theiacov_ont_analysis_date String Date of analysis theiacov_ont_version String Version of PHB used for running the workflow vadr_alerts_list File A file containing all of the fatal alerts as determined by VADR vadr_all_outputs_tar_gz File A .tar.gz file (gzip-compressed tar archive file) containing all outputs from the VADR command v-annotate.pl. This file must be uncompressed &amp; extracted to see the many files within. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description of all files present within the archive. Useful when deeply investigating a sample's genome &amp; annotations. vadr_classification_summary_file File Per-sequence tabular classification file. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#explanation-of-sqc-suffixed-output-files for more complete description. vadr_docker String Docker image used to run VADR vadr_fastas_zip_archive File Zip archive containing all fasta files created during VADR analysis vadr_feature_tbl_fail File 5 column feature table output for failing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_feature_tbl_pass File 5 column feature table output for passing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_num_alerts String Number of fatal alerts as determined by VADR Variable Type Description abricate_flu_database String ABRicate database used for analysis abricate_flu_results File File containing all results from ABRicate abricate_flu_subtype String Flu subtype as determined by ABRicate abricate_flu_type String Flu type as determined by ABRicate abricate_flu_version String Version of ABRicate assembly_length_unambiguous Int Number of unambiguous basecalls within the consensus assembly assembly_method String Method employed to generate consensus assembly auspice_json File Auspice-compatable JSON output generated from Nextclade analysis that includes the Nextclade default samples for clade-typing and the single sample placed on this tree auspice_json_flu_h5n1 File Auspice-compatable JSON output generated from Nextclade analysis on Influenza H5N1 whole genome that includes the samples included in the \"avian-flu/h5n1-cattle-outbreak\" nextstrain build that is focused on B3.13 genotype and the single sample placed on this tree auspice_json_flu_ha File Auspice-compatable JSON output generated from Nextclade analysis on Influenza HA segment that includes the Nextclade default samples for clade-typing and the single sample placed on this tree auspice_json_flu_na File Auspice-compatable JSON output generated from Nextclade analysis on Influenza NA segment that includes the Nextclade default samples for clade-typing and the single sample placed on this tree flu_A_315675_resistance String resistance mutations to A_315675 flu_L_742_001_resistance String resistance mutations to L_742_001 flu_amantadine_resistance String resistance mutations to amantadine flu_compound_367_resistance String resistance mutations to compound_367 flu_favipiravir_resistance String resistance mutations to favipiravir flu_fludase_resistance String resistance mutations to fludase flu_laninamivir_resistance String resistance mutations to laninamivir flu_oseltamivir_resistance String resistance mutations to oseltamivir (Tamiflu\u00ae) flu_peramivir_resistance String resistance mutations to peramivir (Rapivab\u00ae) flu_pimodivir_resistance String resistance mutations to pimodivir flu_rimantadine_resistance String resistance mutations to rimantadine flu_xofluza_resistance String resistance mutations to xofluza (Baloxavir marboxil) flu_zanamivir_resistance String resistance mutations to zanamivir (Relenza\u00ae) genoflu_all_segments String The genotypes for each individual flu segment genoflu_genotype String The genotype of the whole genome, based off of the individual segments types genoflu_output_tsv File The output file from GenoFLU genoflu_version String The version of GenoFLU used nextclade_aa_dels String Amino-acid deletions as detected by NextClade. Will be blank for Flu nextclade_aa_dels_flu_h5n1 String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for H5N1 whole genome nextclade_aa_dels_flu_h5n1 String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for H5N1 whole genome nextclade_aa_dels_flu_ha String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for HA segment nextclade_aa_dels_flu_ha String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for HA segment nextclade_aa_dels_flu_na String Amino-acid deletions as detected by NextClade. Specific to Flu; it includes deletions for NA segment nextclade_aa_dels_flu_na String Amino-acid deletions as detected by NextClade. Specific to Flu; it includes deletions for NA segment nextclade_aa_subs String Amino-acid substitutions as detected by Nextclade. Will be blank for Flu nextclade_aa_subs_flu_h5n1 String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for H5N1 whole genome nextclade_aa_subs_flu_h5n1 String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for H5N1 whole genome nextclade_aa_subs_flu_ha String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for HA segment nextclade_aa_subs_flu_ha String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for HA segment nextclade_aa_subs_flu_na String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for NA segment nextclade_aa_subs_flu_na String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for NA segment nextclade_clade String Nextclade clade designation, will be blank for Flu. nextclade_clade_flu_h5n1 String Nextclade clade designation, specific to Flu 5N1 whole genome. NOTE: Output will be blank or <code>NA</code> since this nextclade dataset does assign clades nextclade_clade_flu_ha String Nextclade clade designation, specific to Flu NA segment nextclade_clade_flu_na String Nextclade clade designation, specific to Flu HA segment nextclade_docker String Docker image used to run Nextclade nextclade_ds_tag String Dataset tag used to run Nextclade. Will be blank for Flu nextclade_ds_tag_flu_ha String Dataset tag used to run Nextclade, specific to Flu HA segment nextclade_ds_tag_flu_na String Dataset tag used to run Nextclade, specific to Flu NA segment nextclade_json File Nextclade output in JSON file format. Will be blank for Flu nextclade_json_flu_h5n1 File Nextclade output in JSON file format, specific to Flu H5N1 whole genome nextclade_json_flu_ha File Nextclade output in JSON file format, specific to Flu HA segment nextclade_json_flu_na File Nextclade output in JSON file format, specific to Flu NA segment nextclade_lineage String Nextclade lineage designation nextclade_qc String QC metric as determined by Nextclade. Will be blank for Flu nextclade_qc_flu_h5n1 String QC metric as determined by Nextclade, specific to Flu H5N1 whole genome nextclade_qc_flu_h5n1 String QC metric as determined by Nextclade, specific to Flu H5N1 whole genome nextclade_qc_flu_ha String QC metric as determined by Nextclade, specific to Flu HA segment nextclade_qc_flu_ha String QC metric as determined by Nextclade, specific to Flu HA segment nextclade_qc_flu_na String QC metric as determined by Nextclade, specific to Flu NA segment nextclade_qc_flu_na String QC metric as determined by Nextclade, specific to Flu NA segment nextclade_tsv File Nextclade output in TSV file format. Will be blank for Flu nextclade_tsv_flu_h5n1 File Nextclade output in TSV file format, specific to Flu H5N1 whole genome nextclade_tsv_flu_ha File Nextclade output in TSV file format, specific to Flu HA segment nextclade_tsv_flu_na File Nextclade output in TSV file format, specific to Flu NA segment nextclade_version String The version of Nextclade software used number_Degenerate Int Number of degenerate basecalls within the consensus assembly number_N Int Number of fully ambiguous basecalls within the consensus assembly number_Total Int Total number of nucleotides within the consensus assembly pango_lineage String Pango lineage as determined by Pangolin pango_lineage_expanded String Pango lineage without use of aliases; e.g., \"BA.1\" \u2192 \"B.1.1.529.1\" pango_lineage_report File Full Pango lineage report generated by Pangolin pangolin_assignment_version String The version of the pangolin software (e.g. PANGO or PUSHER) used for lineage assignment pangolin_conflicts String Number of lineage conflicts as determined by Pangolin pangolin_docker String Docker image used to run Pangolin pangolin_notes String Lineage notes as determined by Pangolin pangolin_versions String All Pangolin software and database versions percent_reference_coverage Float Percent coverage of the reference genome after performing primer trimming; calculated as assembly_length_unambiguous / length of the reference genome (SC2: 29903) x 100 qc_check String A string that indicates whether or not the sample passes a set of pre-determined and user-provided QC thresholds qc_standard File The file used in the QC Check task containing the QC thresholds. seq_platform String Description of the sequencing methodology used to generate the input read data theiacov_fasta_analysis_date String Date of analysis theiacov_fasta_version String Version of PHB used for running the workflow vadr_alerts_list File A file containing all of the fatal alerts as determined by VADR vadr_all_outputs_tar_gz File A .tar.gz file (gzip-compressed tar archive file) containing all outputs from the VADR command v-annotate.pl. This file must be uncompressed &amp; extracted to see the many files within. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description of all files present within the archive. Useful when deeply investigating a sample's genome &amp; annotations. vadr_classification_summary_file File Per-sequence tabular classification file. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#explanation-of-sqc-suffixed-output-files for more complete description. vadr_docker String Docker image used to run VADR vadr_fastas_zip_archive File Zip archive containing all fasta files created during VADR analysis vadr_feature_tbl_fail File 5 column feature table output for failing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_feature_tbl_pass File 5 column feature table output for passing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_flu_ha_segment_fasta File HA (Haemagglutinin) assembly fasta file vadr_flu_mp_segment_fasta File MP (Matrix Protein) assembly fasta file vadr_flu_na_segment_fasta File NA (Neuraminidase) assembly fasta file vadr_flu_np_segment_fasta File NP (Nucleoprotein) assembly fasta file vadr_flu_ns_segment_fasta File NS (Nonstructural) assembly fasta file vadr_flu_pa_segment_fasta File PA (Polymerase acidic) assembly fasta file vadr_flu_pb1_segment_fasta File PB1 (Polymerase basic 1) assembly fasta file vadr_flu_pb2_segment_fasta File PB2 (Polymerase basic 2) assembly fasta file vadr_flu_segment_concatenated_fasta File Assembly FASTA file of all Influenza genome segments concatenated into one sequence/FASTA entry vadr_num_alerts String Number of fatal alerts as determined by VADR Variable Type Description aligned_bai File Index companion file to the bam file generated during the consensus assembly process aligned_bam File Sorted BAM file containing the alignments of reads to the reference genome artic_docker String Docker image utilized for read trimming and consensus genome assembly artic_version String Version of the Artic software utilized for read trimming and conesnsus genome assembly assembly_fasta File Consensus genome assembly; for lower quality flu samples, the output may state \"Assembly could not be generated\" when there is too little and/or too low quality data for IRMA to produce an assembly. Contigs will be ordered from largest to smallest when IRMA is used. assembly_length_unambiguous Int Number of unambiguous basecalls within the consensus assembly assembly_mean_coverage Float Mean sequencing depth throughout the consensus assembly. Generated after performing primer trimming and calculated using the SAMtools coverage command assembly_method String Method employed to generate consensus assembly auspice_json File Auspice-compatable JSON output generated from Nextclade analysis that includes the Nextclade default samples for clade-typing and the single sample placed on this tree consensus_flagstat File Output from the SAMtools flagstat command to assess quality of the alignment file (BAM) consensus_stats File Output from the SAMtools stats command to assess quality of the alignment file (BAM) est_percent_gene_coverage_tsv File Percent coverage for each gene in the organism being analyzed (depending on the organism input) fastq_scan_clean1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about clean forward read quality and length fastq_scan_num_reads_clean1 Int The number of forward reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_raw1 Int The number of input forward reads as calculated by fastq_scan fastq_scan_raw1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about raw forward read quality and length fastq_scan_version String The version of fastq_scan kraken_human Float Percent of human read data detected using the Kraken2 software kraken_human_dehosted Float Percent of human read data detected using the Kraken2 software after host removal kraken_report File Full Kraken report kraken_report_dehosted File Full Kraken report after host removal kraken_sc2 String Percent of SARS-CoV-2 read data detected using the Kraken2 software kraken_sc2_dehosted String Percent of SARS-CoV-2 read data detected using the Kraken2 software after host removal kraken_target_organism String Percent of target organism read data detected using the Kraken2 software kraken_target_organism_dehosted String Percent of target organism read data detected using the Kraken2 software after host removal kraken_target_organism_name String The name of the target organism; e.g., \"Monkeypox\" or \"Human immunodeficiency virus\" kraken_version String Version of Kraken software used meanbaseq_trim Float Mean quality of the nucleotide basecalls aligned to the reference genome after primer trimming meanmapq_trim Float Mean quality of the mapped reads to the reference genome after primer trimming medaka_reference String Reference sequence used in medaka task nextclade_aa_dels String Amino-acid deletions as detected by NextClade. Will be blank for Flu nextclade_aa_subs String Amino-acid substitutions as detected by Nextclade. Will be blank for Flu nextclade_clade String Nextclade clade designation, will be blank for Flu. nextclade_docker String Docker image used to run Nextclade nextclade_ds_tag String Dataset tag used to run Nextclade. Will be blank for Flu nextclade_json File Nextclade output in JSON file format. Will be blank for Flu nextclade_lineage String Nextclade lineage designation nextclade_qc String QC metric as determined by Nextclade. Will be blank for Flu nextclade_tsv File Nextclade output in TSV file format. Will be blank for Flu nextclade_version String The version of Nextclade software used number_Degenerate Int Number of degenerate basecalls within the consensus assembly number_N Int Number of fully ambiguous basecalls within the consensus assembly number_Total Int Total number of nucleotides within the consensus assembly pango_lineage String Pango lineage as determined by Pangolin pango_lineage_expanded String Pango lineage without use of aliases; e.g., \"BA.1\" \u2192 \"B.1.1.529.1\" pango_lineage_report File Full Pango lineage report generated by Pangolin pangolin_assignment_version String The version of the pangolin software (e.g. PANGO or PUSHER) used for lineage assignment pangolin_conflicts String Number of lineage conflicts as determined by Pangolin pangolin_docker String Docker image used to run Pangolin pangolin_notes String Lineage notes as determined by Pangolin pangolin_versions String All Pangolin software and database versions percent_reference_coverage Float Percent coverage of the reference genome after performing primer trimming; calculated as assembly_length_unambiguous / length of the reference genome (SC2: 29903) x 100 percentage_mapped_reads Float Percentage of reads that successfully aligned to the reference genome. This value is calculated by number of mapped reads / total number of reads x 100. primer_bed_name String Name of the primer bed files used for primer trimming qc_check String A string that indicates whether or not the sample passes a set of pre-determined and user-provided QC thresholds qc_standard File The file used in the QC Check task containing the QC thresholds. read1_aligned File Forward read file of only aligned reads read1_dehosted File The dehosted forward reads file; suggested read file for SRA submission samtools_version_stats String The version of SAMtools used to assess the quality of read mapping sc2_s_gene_mean_coverage Float Mean read depth for the S gene in SARS-CoV-2 sc2_s_gene_percent_coverage Float Percent coverage of the S gene in SARS-CoV-2 seq_platform String Description of the sequencing methodology used to generate the input read data theiacov_clearlabs_analysis_date String Date of analysis theiacov_clearlabs_version String Version of PHB used for running the workflow vadr_alerts_list File A file containing all of the fatal alerts as determined by VADR vadr_all_outputs_tar_gz File A .tar.gz file (gzip-compressed tar archive file) containing all outputs from the VADR command v-annotate.pl. This file must be uncompressed &amp; extracted to see the many files within. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description of all files present within the archive. Useful when deeply investigating a sample's genome &amp; annotations. vadr_classification_summary_file File Per-sequence tabular classification file. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#explanation-of-sqc-suffixed-output-files for more complete description. vadr_docker String Docker image used to run VADR vadr_fastas_zip_archive File Zip archive containing all fasta files created during VADR analysis vadr_feature_tbl_fail File 5 column feature table output for failing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_feature_tbl_pass File 5 column feature table output for passing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_num_alerts String Number of fatal alerts as determined by VADR variants_from_ref_vcf File Number of variants relative to the reference genome <p>Overwrite Warning</p> <p>TheiaCoV_FASTA_Batch_PHB workflow will output results to the set-level data table in addition to overwriting the Pangolin &amp; Nextclade output columns in the sample-level data table. Users can view the set-level workflow output TSV file called <code>\"Datatable\"</code> to view exactly which columns were overwritten in the sample-level data table.</p> Variable Type Description datatable File Sample-level data table TSV file that was used to update the original sample-level data table in the last step of the TheiaCoV_FASTA_Batch workflow. nextclade_json File Nextclade output in JSON file format. Will be blank for Flu nextclade_tsv File Nextclade output in TSV file format. Will be blank for Flu pango_lineage_report File Full Pango lineage report generated by Pangolin theiacov_fasta_batch_analysis_date String Date that the workflow was run. theiacov_fasta_batch_version String Version of the workflow that was used."},{"location":"workflows/genomic_characterization/theiaeuk/","title":"TheiaEuk Workflow Series","text":""},{"location":"workflows/genomic_characterization/theiaeuk/#theiaeuk-workflow-series","title":"TheiaEuk Workflow Series","text":""},{"location":"workflows/genomic_characterization/theiaeuk/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Genomic Characterization Mycotics vX.X.X Some optional features incompatible, Yes Sample-level TheiaEuk_Illumina_PE_PHB, TheiaEuk_ONT_PHB"},{"location":"workflows/genomic_characterization/theiaeuk/#theiaeuk-workflows","title":"TheiaEuk Workflows","text":"<p>The TheiaEuk workflows are for the assembly, quality assessment, and characterization of fungal genomes. It is designed to accept Illumina paired-end sequencing data or base-called ONT reads as the primary input. It is currently intended only for haploid fungal genomes like Candidozyma auris. Analyzing diploid genomes using TheiaEuk should be attempted only with expert attention to the resulting genome quality.</p> <p>All input reads are processed through \"core tasks\" in each workflow. The core tasks include raw read quality assessment, read cleaning (quality trimming and adapter removal), de novo assembly, assembly quality assessment, and species taxon identification. For some taxa identified, taxa-specific sub-workflows will be automatically activated, undertaking additional taxa-specific characterization steps, including clade-typing and/or antifungal resistance detection.</p> TheiaEuk_Illumina_PETheiaEuk_ONT <p>TheiaEuk Illumina PE Workflow Diagram</p> <p></p> <p>TheiaEuk ONT Workflow Diagram</p> <p></p> <p>Before running TheiaEuk</p> <p>TheiaEuk_Illumina_PE relies on Snippy to perform variant calling on the cleaned read dataset and then queries the resulting file for specific mutations that are known to confim antifugal resistance (see Organism-specific characterization section). This behaviour has been replicated in TheiaEuk_ONT but the variant calling is performed directly on the resulting assemblies. Therefore, the read support reported is, at the moment, non-reliable. Future improvements will include improvements on this module. </p>"},{"location":"workflows/genomic_characterization/theiaeuk/#inputs","title":"Inputs","text":"<p>Input Read Data</p> TheiaEuk_Illumina_PETheiaEuk_ONT <p>The TheiaEuk_Illumina_PE workflow takes in Illumina paired-end read data. Read file names should end with <code>.fastq</code> or <code>.fq</code>, with the optional addition of <code>.gz</code>. When possible, Theiagen recommends zipping files with gzip before Terra uploads to minimize data upload time.</p> <p>By default, the workflow anticipates\u00a02 x 150bp\u00a0reads (i.e. the input reads were generated using a 300-cycle sequencing kit). Modifications to the optional parameter for <code>trim_minlen</code> may be required to accommodate shorter read data, such as the 2 x 75bp reads generated using a 150-cycle sequencing kit.</p> <p>The TheiaEuk_ONT workflow takes in base-called ONT read data. Read file names should end with <code>.fastq</code> or <code>.fq</code>, with the optional addition of <code>.gz</code>. When possible, Theiagen recommends zipping files with gzip before uploading to Terra to minimize data upload time.</p> <p>The ONT sequencing kit and base-calling approach can produce substantial variability in the amount and quality of read data. Genome assemblies produced by the TheiaEuk_ONT workflow must be quality assessed before reporting results.</p> TheiaEuk_Illumina_PETheiaEuk_ONT Terra Task Name Variable Type Description Default Value Terra Status theiaeuk_illumina_pe read1 File FASTQ file containing read1 sequences Required theiaeuk_illumina_pe read2 File FASTQ file containing read2 sequences Required theiaeuk_illumina_pe samplename String Sample name for the analysis Required busco cpu Int Number of CPUs to allocate to the task 2 Optional busco disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional cg_pipeline_clean cg_pipe_opts String Options to pass to CG-Pipeline for clean read assessment --fast Optional cg_pipeline_clean disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional cg_pipeline_clean docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/lyveset:1.1.4f Optional cg_pipeline_raw cg_pipe_opts String Options to pass to CG-Pipeline for raw read assessment --fast Optional cg_pipeline_raw disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional cg_pipeline_raw docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/lyveset:1.1.4f Optional clean_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional clean_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional clean_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional clean_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional digger_denovo assembler String Assembler to use (spades, skesa, megahit) skesa Optional digger_denovo assembler_options String Assembler-specific options that you might choose for the selected assembler Optional digger_denovo bwa_cpu Int Number of CPUs to allocate to the task 6 Optional digger_denovo bwa_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional digger_denovo bwa_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional digger_denovo bwa_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional digger_denovo call_pilon Boolean Whether to run Pilon polishing after assembly FALSE Optional digger_denovo filter_contigs_cpu Int Number of CPUs to allocate to the task 1 Optional digger_denovo filter_contigs_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional digger_denovo filter_contigs_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/shovilter:0.2 Optional digger_denovo filter_contigs_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional digger_denovo filter_contigs_min_coverage Float Minimum coverage threshold for contig filtering 2.0 Optional digger_denovo filter_contigs_skip_coverage_filter Boolean Skip filtering contigs based on coverage FALSE Optional digger_denovo filter_contigs_skip_homopolymer_filter Boolean Skip filtering contigs containing homopolymers FALSE Optional digger_denovo filter_contigs_skip_length_filter Boolean Skip filtering contigs based on length FALSE Optional digger_denovo kmers String K-mer sizes for assembly (comma-separated) Optional digger_denovo megahit_cpu Int Number of CPUs to allocate to the task 4 Optional digger_denovo megahit_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional digger_denovo megahit_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/megahit:1.2.9 Optional digger_denovo megahit_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional digger_denovo pilon_cpu Int Number of CPUs to allocate to the task 8 Optional digger_denovo pilon_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional digger_denovo pilon_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/pilon:1.24--hdfd78af_0 Optional digger_denovo pilon_fix String Potential issues with assembly to try and automatically fix (snps, indels, gaps, local, all, bases, none) bases Optional digger_denovo pilon_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional digger_denovo pilon_min_base_quality Int Minimum base quality to keep 3 Optional digger_denovo pilon_min_depth Float Minimum coverage threshold for variant calling: when set to a value \u22651, it requires that absolute depth of coverage; when set to a fraction &lt;1, it requires coverage at least that fraction of the mean coverage for the region 0.25 Optional digger_denovo pilon_min_mapping_quality Int Minimum mapping quality for a read to count in pileups 60 Optional digger_denovo run_filter_contigs Boolean Whether to run contig filtering step TRUE Optional digger_denovo skesa_cpu Int Number of CPUs to allocate to the task 4 Optional digger_denovo skesa_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional digger_denovo skesa_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/skesa:2.4.0 Optional digger_denovo skesa_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional digger_denovo spades_cpu Int Number of CPUs to allocate to the task 16 Optional digger_denovo spades_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional digger_denovo spades_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/spades:4.1.0 Optional digger_denovo spades_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional digger_denovo spades_type String SPAdes assembly mode (isolate, meta, rna, etc.), more can be found here isolate Optional gambit disk_size Int Amount of storage (in GB) to allocate to the task 20 Optional gambit docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Optional merlin_magic abricate_abaum_docker_image String Internal component, do not modify Optional merlin_magic abricate_abaum_min_percent_coverage Int Internal component, do not modify Optional merlin_magic abricate_abaum_min_percent_identity Int Internal component, do not modify 95 Optional merlin_magic abricate_vibrio_docker_image String Internal component, do not modify Optional merlin_magic abricate_vibrio_min_percent_coverage Int Internal component, do not modify 80 Optional merlin_magic abricate_vibrio_min_percent_identity Int Internal component, do not modify 80 Optional merlin_magic agrvate_agr_typing_only Boolean Internal component, do not modify Optional merlin_magic agrvate_docker_image String Internal component, do not modify Optional merlin_magic amr_search_cpu Int Number of CPUs to allocate to the task 2 Optional merlin_magic amr_search_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional merlin_magic amr_search_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/amrsearch:0.2.1 Optional merlin_magic amr_search_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional merlin_magic assembly_only Boolean Set to true if only analyzing input assembly FALSE Optional merlin_magic call_poppunk Boolean Internal component, do not modify TRUE Optional merlin_magic call_shigeifinder_reads_input Boolean Internal component, do not modify FALSE Optional merlin_magic call_stxtyper Boolean Internal component, do not modify FALSE Optional merlin_magic call_tbp_parser Boolean Internal component, do not modify FALSE Optional merlin_magic cauris_cladetyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Optional merlin_magic cladetyper_kmer_size Int Kmer size for cladtyper Optional merlin_magic cladetyper_max_distance Float The maximum GAMBIT distance to report a C. auris clade hit 0.1 Optional merlin_magic cladetyper_ref_clade1 File Reference genome FASTA for Candidozyma auris clade1 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade1_GCA_002759435.2_Cand_auris_B8441_V2_genomic.fasta Optional merlin_magic cladetyper_ref_clade1_annotated File Reference GBFF annotation for C. auris clade1 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade1_GCA_002759435_Cauris_B8441_V2_genomic.gbff Optional merlin_magic cladetyper_ref_clade2 File Reference genome FASTA for C. auris clade2 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade2_GCA_003013715.2_ASM301371v2_genomic.fasta Optional merlin_magic cladetyper_ref_clade2_annotated File Reference GBFF annotation for C. auris clade2 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade2_GCA_003013715.2_ASM301371v2_genomic.gbff Optional merlin_magic cladetyper_ref_clade3 File Reference genome FASTA for C. auris clade3 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade3_GCF_002775015.1_Cand_auris_B11221_V1_genomic.fasta Optional merlin_magic cladetyper_ref_clade3_annotated File Reference GBFF annotation for C. auris clade3 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade3_GCF_002775015.1_Cand_auris_B11221_V1_genomic.gbff Optional merlin_magic cladetyper_ref_clade4 File Reference genome FASTA for C. auris clade4 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade4_GCA_003014415.1_Cand_auris_B11243_genomic.fasta Optional merlin_magic cladetyper_ref_clade4_annotated File Reference GBFF annotation for C. auris clade4 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade4_GCA_003014415.1_Cand_auris_B11243_genomic.gbff Optional merlin_magic cladetyper_ref_clade5 File Reference genome FASTA for C. auris clade5 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade5_GCA_016809505.1_ASM1680950v1_genomic.fasta Optional merlin_magic cladetyper_ref_clade5_annotated File Reference GBFF annotation for C. auris clade5 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade5_GCA_016809505.1_ASM1680950v1_genomic.gbff Optional merlin_magic cladetyper_ref_clade6 File Reference genome FASTA for C. auris clade6 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade6_GCA_032714025.1_ASM3271402v1_genomic.fasta Optional merlin_magic cladetyper_ref_clade6_annotated File Reference GBFF annotation for C. auris clade6 Optional merlin_magic clockwork_docker_image String Internal component, do not modify Optional merlin_magic ectyper_docker_image String Internal component, do not modify Optional merlin_magic ectyper_h_min_percent_coverage Int Internal component, do not modify Optional merlin_magic ectyper_h_min_percent_identity Int Internal component, do not modify Optional merlin_magic ectyper_o_min_percent_coverage Int Internal component, do not modify Optional merlin_magic ectyper_o_min_percent_identity Int Internal component, do not modify Optional merlin_magic ectyper_print_alleles Boolean Internal component, do not modify Optional merlin_magic ectyper_verify Boolean Internal component, do not modify Optional merlin_magic emmtyper_align_diff Int Internal component, do not modify Optional merlin_magic emmtyper_cluster_distance Int Internal component, do not modify Optional merlin_magic emmtyper_culling_limit Int Internal component, do not modify Optional merlin_magic emmtyper_docker_image String Internal component, do not modify Optional merlin_magic emmtyper_gap Int Internal component, do not modify Optional merlin_magic emmtyper_max_size Int Internal component, do not modify Optional merlin_magic emmtyper_min_good Int Internal component, do not modify Optional merlin_magic emmtyper_min_percent_identity Int Internal component, do not modify Optional merlin_magic emmtyper_min_perfect Int Internal component, do not modify Optional merlin_magic emmtyper_mismatch Int Internal component, do not modify Optional merlin_magic emmtyper_wf String Internal component, do not modify Optional merlin_magic emmtypingtool_docker_image String Internal component, do not modify Optional merlin_magic genotyphi_docker_image String Internal component, do not modify Optional merlin_magic hicap_broken_gene_length Int Internal component, do not modify Optional merlin_magic hicap_docker_image String Internal component, do not modify Optional merlin_magic hicap_min_broken_gene_percent_identity Float Internal component, do not modify Optional merlin_magic hicap_min_gene_percent_coverage Float Internal component, do not modify Optional merlin_magic hicap_min_gene_percent_identity Float Internal component, do not modify Optional merlin_magic kaptive_docker_image String Internal component, do not modify Optional merlin_magic kaptive_low_gene_percent_identity Float Internal component, do not modify Optional merlin_magic kaptive_min_percent_coverage Float Internal component, do not modify Optional merlin_magic kaptive_min_percent_identity Float Internal component, do not modify Optional merlin_magic kaptive_start_end_margin Int Internal component, do not modify Optional merlin_magic kleborate_docker_image String Internal component, do not modify Optional merlin_magic kleborate_min_kaptive_confidence String Internal component, do not modify Optional merlin_magic kleborate_min_percent_coverage Float Internal component, do not modify Optional merlin_magic kleborate_min_percent_identity Float Internal component, do not modify Optional merlin_magic kleborate_min_spurious_percent_coverage Float Internal component, do not modify Optional merlin_magic kleborate_min_spurious_percent_identity Float Internal component, do not modify Optional merlin_magic kleborate_skip_kaptive Boolean Internal component, do not modify Optional merlin_magic kleborate_skip_resistance Boolean Internal component, do not modify Optional merlin_magic legsta_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/legsta:0.5.1--hdfd78af_2 Optional merlin_magic lissero_docker_image String Internal component, do not modify Optional merlin_magic lissero_min_percent_coverage Float Internal component, do not modify Optional merlin_magic lissero_min_percent_identity Float Internal component, do not modify Optional merlin_magic meningotype_docker_image String Internal component, do not modify Optional merlin_magic ngmaster_docker_image String Internal component, do not modify Optional merlin_magic ont_data Boolean Set to true if your data is ONT FASTQ files FALSE Optional merlin_magic paired_end Boolean Set to true if your data is paired-end FASTQ files TRUE Optional merlin_magic pasty_docker_image String Internal component, do not modify Optional merlin_magic pasty_min_percent_coverage Int Internal component, do not modify Optional merlin_magic pasty_min_percent_identity Int Internal component, do not modify Optional merlin_magic pbptyper_docker_image String Internal component, do not modify Optional merlin_magic pbptyper_min_percent_coverage Int Internal component, do not modify Optional merlin_magic pbptyper_min_percent_identity Int Internal component, do not modify Optional merlin_magic poppunk_docker_image String Internal component, do not modify Optional merlin_magic poppunk_gps_clusters_csv File Internal component, do not modify Optional merlin_magic poppunk_gps_dists_npy File Internal component, do not modify Optional merlin_magic poppunk_gps_dists_pkl File Internal component, do not modify Optional merlin_magic poppunk_gps_external_clusters_csv File Internal component, do not modify Optional merlin_magic poppunk_gps_fit_npz File Internal component, do not modify Optional merlin_magic poppunk_gps_fit_pkl File Internal component, do not modify Optional merlin_magic poppunk_gps_graph_gt File Internal component, do not modify Optional merlin_magic poppunk_gps_h5 File Internal component, do not modify Optional merlin_magic poppunk_gps_qcreport_txt File Internal component, do not modify Optional merlin_magic poppunk_gps_refs File Internal component, do not modify Optional merlin_magic poppunk_gps_refs_dists_npy File Internal component, do not modify Optional merlin_magic poppunk_gps_refs_dists_pkl File Internal component, do not modify Optional merlin_magic poppunk_gps_refs_graph_gt File Internal component, do not modify Optional merlin_magic poppunk_gps_refs_h5 File Internal component, do not modify Optional merlin_magic poppunk_gps_unword_clusters_csv File Internal component, do not modify Optional merlin_magic run_amr_search Boolean If set to true AMR_Search workflow will be run if species is part of supported taxon, see AMR_Search docs. FALSE Optional merlin_magic seqsero2_docker_image String Internal component, do not modify Optional merlin_magic seroba_docker_image String Internal component, do not modify Optional merlin_magic serotypefinder_docker_image String Internal component, do not modify Optional merlin_magic shigatyper_docker_image String Internal component, do not modify Optional merlin_magic shigeifinder_docker_image String Internal component, do not modify Optional merlin_magic sistr_cpu Int Internal component, do not modify Optional merlin_magic sistr_disk_size Int Internal component, do not modify Optional merlin_magic sistr_docker_image String Internal component, do not modify Optional merlin_magic sistr_memory Int Internal component, do not modify Optional merlin_magic sistr_use_full_cgmlst_db Boolean Internal component, do not modify Optional merlin_magic snippy_base_quality Int Minimum quality for a nucleotide to be used in variant calling 13 Optional merlin_magic snippy_gene_query_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Optional merlin_magic snippy_map_qual Int Minimum mapping quality to accept in variant calling 60 Optional merlin_magic snippy_maxsoft Int Number of bases of alignment to soft-clip before discarding the alignment 10 Optional merlin_magic snippy_min_coverage Int Minimum read coverage of a position to identify a mutation 10 Optional merlin_magic snippy_min_frac Float Minimum fraction of bases at a given position to identify a mutation 0 Optional merlin_magic snippy_min_quality Int Minimum VCF variant call \"quality\" 100 Optional merlin_magic snippy_query_gene String Provide a gene to search for using Snippy Default depend on detected organism Optional merlin_magic snippy_reference_afumigatus File Snippy reference for Aspergillus fumigatus gs://theiagen-public-resources-rp/reference_data/eukaryotic/aspergillus/Aspergillus_fumigatus_GCF_000002655.1_ASM265v1_genomic.gbff Optional merlin_magic snippy_reference_cryptoneo File Snippy reference for Cryptococcus neoformans gs://theiagen-public-resources-rp/reference_data/eukaryotic/cryptococcus/Cryptococcus_neoformans_GCF_000091045.1_ASM9104v1_genomic.gbff Optional merlin_magic snippy_variants_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snippy:4.6.0 Optional merlin_magic sonneityping_docker_image String Internal component, do not modify Optional merlin_magic sonneityping_mykrobe_opts String Internal component, do not modify Optional merlin_magic spatyper_do_enrich Boolean Internal component, do not modify Optional merlin_magic spatyper_docker_image String Internal component, do not modify Optional merlin_magic srst2_docker_image String Internal component, do not modify Optional merlin_magic srst2_gene_max_mismatch Int Internal component, do not modify 2000 Optional merlin_magic srst2_max_divergence Int Internal component, do not modify 20 Optional merlin_magic srst2_min_depth Int Internal component, do not modify 5 Optional merlin_magic srst2_min_edge_depth Int Internal component, do not modify 2 Optional merlin_magic srst2_min_percent_coverage Int Internal component, do not modify 80 Optional merlin_magic staphopia_sccmec_docker_image String Internal component, do not modify Optional merlin_magic stxtyper_cpu Int Internal component, do not modify Optional merlin_magic stxtyper_disk_size Int Internal component, do not modify Optional merlin_magic stxtyper_docker_image String Internal component, do not modify Optional merlin_magic stxtyper_enable_debug Boolean Internal component, do not modify Optional merlin_magic stxtyper_memory Int Internal component, do not modify Optional merlin_magic tbp_parser_add_cs_lims Boolean Internal component, do not modify Optional merlin_magic tbp_parser_config File Internal component, do not modify Optional merlin_magic tbp_parser_coverage_regions_bed File Internal component, do not modify Optional merlin_magic tbp_parser_debug Boolean Internal component, do not modify Optional merlin_magic tbp_parser_docker_image String Internal component, do not modify Optional merlin_magic tbp_parser_etha237_frequency Float Internal component, do not modify Optional merlin_magic tbp_parser_expert_rule_regions_bed File Internal component, do not modify Optional merlin_magic tbp_parser_min_depth Int Internal component, do not modify Optional merlin_magic tbp_parser_min_frequency Float Internal component, do not modify Optional merlin_magic tbp_parser_min_percent_coverage Float Internal component, do not modify Optional merlin_magic tbp_parser_min_read_support Int Internal component, do not modify Optional merlin_magic tbp_parser_operator String Internal component, do not modify Optional merlin_magic tbp_parser_output_seq_method_type String Internal component, do not modify WGS Optional merlin_magic tbp_parser_rpob449_frequency Float Internal component, do not modify Optional merlin_magic tbp_parser_rrl_frequency Float Internal component, do not modify Optional merlin_magic tbp_parser_rrl_read_support Int Internal component, do not modify Optional merlin_magic tbp_parser_rrs_frequency Float Internal component, do not modify Optional merlin_magic tbp_parser_rrs_read_support Int Internal component, do not modify Optional merlin_magic tbp_parser_tngs_data Boolean Internal component, do not modify Optional merlin_magic tbprofiler_additional_parameters String Internal component, do not modify Optional merlin_magic tbprofiler_custom_db File Internal component, do not modify Optional merlin_magic tbprofiler_docker_image String Internal component, do not modify Optional merlin_magic tbprofiler_mapper String Internal component, do not modify Optional merlin_magic tbprofiler_min_af Float Internal component, do not modify Optional merlin_magic tbprofiler_min_depth Int Internal component, do not modify Optional merlin_magic tbprofiler_run_cdph_db Boolean Internal component, do not modify FALSE Optional merlin_magic tbprofiler_run_custom_db Boolean Internal component, do not modify FALSE Optional merlin_magic tbprofiler_variant_caller String Internal component, do not modify Optional merlin_magic tbprofiler_variant_calling_params String Internal component, do not modify Optional merlin_magic vibecheck_docker_image String Internal component, do not modify Optional merlin_magic vibecheck_lineage_barcodes File Internal component, do not modify Optional merlin_magic vibecheck_skip_subsampling Boolean Internal component, do not modify Optional merlin_magic vibecheck_subsampling_fraction Float Internal component, do not modify Optional merlin_magic virulencefinder_database String Internal component, do not modify Optional merlin_magic virulencefinder_docker_image String Internal component, do not modify Optional merlin_magic virulencefinder_min_percent_coverage Float Internal component, do not modify Optional merlin_magic virulencefinder_min_percent_identity Float Internal component, do not modify Optional qc_check_task ani_highest_percent Float Internal component, do not modify Optional qc_check_task ani_highest_percent_bases_aligned Float Internal component, do not modify Optional qc_check_task assembly_length_unambiguous Int Internal component, do not modify Optional qc_check_task assembly_mean_coverage Float Internal component, do not modify Optional qc_check_task cpu Int Number of CPUs to allocate to the task 4 Optional qc_check_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional qc_check_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional qc_check_task kraken_human Float Internal component, do not modify Optional qc_check_task kraken_human_dehosted Float Internal component, do not modify Optional qc_check_task kraken_sc2 Float Internal component, do not modify Optional qc_check_task kraken_sc2_dehosted Float Internal component, do not modify Optional qc_check_task kraken_target_organism Float Internal component, do not modify Optional qc_check_task kraken_target_organism_dehosted Float Internal component, do not modify Optional qc_check_task meanbaseq_trim String Internal component, do not modify Optional qc_check_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional qc_check_task midas_secondary_genus_abundance Float Internal component, do not modify Optional qc_check_task midas_secondary_genus_coverage Float Internal component, do not modify Optional qc_check_task number_Degenerate Int Internal component, do not modify Optional qc_check_task number_N Int Internal component, do not modify Optional qc_check_task percent_reference_coverage Float Internal component, do not modify Optional qc_check_task sc2_s_gene_mean_coverage Float Internal component, do not modify Optional qc_check_task sc2_s_gene_percent_coverage Float Internal component, do not modify Optional qc_check_task vadr_num_alerts String Internal component, do not modify Optional quast disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional quast docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/quast:5.0.2 Optional quast min_contig_length Int Minimum length of contig for QUAST 500 Optional rasusa_task bases String Explicitly set the number of bases required e.g., 4.3kb, 7Tb, 9000, 4.1MB. If this option is given, --coverage and --genome-size are ignored Optional rasusa_task cpu Int Number of CPUs to allocate to the task 4 Optional rasusa_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional rasusa_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/rasusa:2.1.0 Optional rasusa_task frac Float Explicitly define the fraction of reads to keep in the subsample; when used, genome size and coverage are ignored; acceptable inputs include whole numbers and decimals, e.g. 50.0 will leave 50% of the reads in the subsample Optional rasusa_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional rasusa_task num Int Optional: explicitly define the number of reads in the subsample; when used, genome size and coverage are ignored; acceptable metric suffixes include: b, k, m, g, and t for base, kilo, mega, giga, and tera, respectively Optional rasusa_task seed Int Use to assign a name to the \"random seed\" that is used by the subsampler; i.e. this allows the exact same subsample to be produced from the same input file/s in subsequent runs when providing the seed identifier; do not input values for random downsampling Optional raw_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional raw_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional raw_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional raw_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional read_QC_trim adapters File File with adapter sequences to be removed Optional read_QC_trim bbduk_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim call_kraken Boolean True/False variable that determines if the Kraken2 task should be called; for non-TheiaCoV workflows, the <code>kraken_db</code> variable must be provided. FALSE Optional read_QC_trim call_midas Boolean Internal component, do not modify FALSE Optional read_QC_trim extract_unclassified Boolean Internal component, do not modify FALSE Optional read_QC_trim fastp_args String Additional arguments to use with fastp --detect_adapter_for_pe -g -5 20 -3 20 Optional read_QC_trim host String Internal component, do not modify Optional read_QC_trim host_complete_only Boolean Internal component, do not modify FALSE Optional read_QC_trim host_decontaminate_mem Int Internal component, do not modify 32 Optional read_QC_trim host_is_accession Boolean Internal component, do not modify FALSE Optional read_QC_trim host_refseq Boolean Internal component, do not modify TRUE Optional read_QC_trim kraken_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim kraken_db File A kraken2 database to use with the kraken2 optional task. The file must be a .tar.gz kraken2 database. Optional read_QC_trim kraken_disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional read_QC_trim kraken_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional read_QC_trim midas_db File Internal component, do not modify gs://theiagen-public-files-rp/terra/theiaprok-files/midas/midas_db_v1.2.tar.gz Optional read_QC_trim phix File A file containing the phix used during Illumina sequencing; used in the BBDuk task Optional read_QC_trim read_processing String The name of the tool to perform basic read processing; options: \"trimmomatic\" or \"fastp\" trimmomatic Optional read_QC_trim read_qc String The tool used for quality control (QC) of reads. Options are \"fastq_scan\" (default) and \"fastqc\" fastq_scan Optional read_QC_trim target_organism String This string is searched for in the kraken2 outputs to extract the read percentage Optional read_QC_trim taxon_id Int Internal component, do not modify 0 Optional read_QC_trim trimmomatic_args String Additional arguments to pass to trimmomatic. \"-phred33\" specifies the Phred Q score encoding which is almost always phred33 with modern sequence data. -phred33 Optional read_QC_trim workflow_series String Internal component, do not modify Optional theiaeuk_illumina_pe busco_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ezlabgva/busco:v5.3.2_cv1 Optional theiaeuk_illumina_pe busco_memory Int Amount of memory/RAM (in GB) to allocate to the task 24 Optional theiaeuk_illumina_pe call_rasusa Boolean If true, RASUSA will subsample raw reads to  a specified read depth (150X by default) TRUE Optional theiaeuk_illumina_pe cpu Int Number of CPUs to allocate to the task 8 Optional theiaeuk_illumina_pe expected_taxon String If provided, this input will override the taxonomic assignment made by GAMBIT and launch the relevant taxon-specific submodules. It will also modify the organism flag used by AMRFinderPlus. Example format: \"Salmonella enterica\" Optional theiaeuk_illumina_pe gambit_db_genomes File User-provided database of assembled query genomes; requires complementary signatures file. If not provided, uses default database, \"/gambit-db\" gs://gambit-databases-rp/fungal-version/1.0.0/gambit-fungal-metadata-1.0.0-20241213.gdb Optional theiaeuk_illumina_pe gambit_db_signatures File User-provided signatures file; requires complementary genomes file. If not specified, the file from the docker container will be used. gs://gambit-databases-rp/fungal-version/1.0.0/gambit-fungal-signatures-1.0.0-20241213.gs Optional theiaeuk_illumina_pe genome_length Int User-specified expected genome length to be used in genome statistics calculations Optional theiaeuk_illumina_pe max_genome_length Int Maximum genome size able to pass read screening 178000000 Optional theiaeuk_illumina_pe memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional theiaeuk_illumina_pe min_basepairs Int Minimum number of base pairs able to pass read screening 45000000 Optional theiaeuk_illumina_pe min_contig_length Int Minimum contig length for assembler 1000 Optional theiaeuk_illumina_pe min_coverage Int Minimum genome coverage able to pass read screening 10 Optional theiaeuk_illumina_pe min_genome_length Int Minimum genome size able to pass read screening 9000000 Optional theiaeuk_illumina_pe min_proportion Int Minimum proportion of total reads in each read file to pass read screening 40 Optional theiaeuk_illumina_pe min_reads Int Minimum number of reads to pass read screening 30000 Optional theiaeuk_illumina_pe qc_check_table File TSV value with taxons for rows and QC values for columns; internal cells represent user-determined QC thresholds; if provided, turns on the QC Check task. See below for an example QC Check table. Optional theiaeuk_illumina_pe seq_method String Sequencing method used for the samples ILLUMINA Optional theiaeuk_illumina_pe skip_screen Boolean Option to skip the read screening prior to analysis; if setting to true, please provide a value for the theiaeuk_pe genome_length optional input, OR set call_rasusa to false. Otherwise RASUSA will attempt to downsample to an expected genome size of 0 bp, and the workflow will fail. FALSE Optional theiaeuk_illumina_pe subsample_coverage Float Read depth for RASUSA task to subsample reads to 150 Optional theiaeuk_illumina_pe trim_min_length Int Specifies minimum length of each read after trimming to be kept 75 Optional theiaeuk_illumina_pe trim_quality_min_score Int Specifies the minimum average quality of bases in a sliding window to be kept 20 Optional theiaeuk_illumina_pe trim_window_size Int Size of the trimming window to use 10 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status theiaeuk_ont read1 File ONT read file in FASTQ file format (compression optional) Required theiaeuk_ont samplename String The name of the sample being analyzed Required busco cpu Int Number of CPUs to allocate to the task 2 Optional busco disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional clean_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional clean_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional clean_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional clean_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional clean_check_reads workflow_series String Internal component, do not modify theiaviral Optional flye_denovo auto_medaka_model Boolean If true, medaka will automatically select the best Medaka model for assembly TRUE Optional flye_denovo bandage_cpu Int Number of CPUs to allocate to the task 2 Optional flye_denovo bandage_disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional flye_denovo bandage_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional flye_denovo dnaapler_cpu Int Number of CPUs to allocate to the task 1 Optional flye_denovo dnaapler_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flye_denovo dnaapler_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional flye_denovo dnaapler_mode String Dnaapler-specific inputs all Optional flye_denovo filter_contigs_cpu Int Number of CPUs to allocate to the task 1 Optional flye_denovo filter_contigs_disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional flye_denovo filter_contigs_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional flye_denovo filter_contigs_min_length Int Minimum contig length to keep 1000 Optional flye_denovo flye_additional_parameters String Any extra Flye-specific parameters Optional flye_denovo flye_asm_coverage Int Reduced coverage for initial disjointig assembly Optional flye_denovo flye_cpu Int Number of CPUs to allocate to the task 4 Optional flye_denovo flye_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flye_denovo flye_genome_length Int User-specified expected genome length to be used in genome statistics calculations Optional flye_denovo flye_keep_haplotypes Boolean If true keep haplotypes FALSE Optional flye_denovo flye_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional flye_denovo flye_minimum_overlap Int Minimum overlap between reads Optional flye_denovo flye_no_alt_contigs Boolean If true, do not generate alternative contigs FALSE Optional flye_denovo flye_polishing_iterations Int Default polishing iterations 1 Optional flye_denovo flye_read_error_rate Float Maximum expected read error rate Optional flye_denovo flye_read_type String Specifies the type of sequencing reads. Options: --nano-hq (default), --nano-corr, --nano-raw, --pacbio-raw, --pacbio-corr, --pacbio-hifi. Refer to Flye documentation for details on each type. --nano-hq Optional flye_denovo flye_scaffold Boolean If true, scaffolding is enabled using graph FALSE Optional flye_denovo flye_uneven_coverage_mode Boolean sets the --meta option in the case of uneven coverage (or metagenomics) FALSE Optional flye_denovo illumina_read1 File If Illumina reads are provided, flye_denovo subworkflow will perform Illumina polishing Optional flye_denovo illumina_read2 File If Illumina reads are provided, flye_denovo subworkflow will perform Illumina polishing Optional flye_denovo medaka_cpu Int Number of CPUs to allocate to the task 4 Optional flye_denovo medaka_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flye_denovo medaka_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional flye_denovo medaka_model String In order to obtain the best results, the appropriate model must be set to match the sequencer's basecaller model; this string takes the format of {pore}{device}{caller variant}_{caller_version}. See also https://github.com/nanoporetech/medaka?tab=readme-ov-file#models. If this is being run on legacy data it is likely to be r941_min_hac_g507. r1041_e82_400bps_sup_v5.0.0 Optional flye_denovo polish_rounds Int The number of polishing rounds to conduct for medaka or racon (without Illumina) 1 Optional flye_denovo polisher String The polishing tool to use for assembly medaka Optional flye_denovo polypolish_careful Boolean Polypolish-specific inputs FALSE Optional flye_denovo polypolish_cpu Int Number of CPUs to allocate to the task 1 Optional flye_denovo polypolish_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flye_denovo polypolish_fraction_invalid Float Polypolish-specific inputs Optional flye_denovo polypolish_fraction_valid Float Polypolish-specific inputs Optional flye_denovo polypolish_high_percentile_threshold Float Polypolish-specific inputs Optional flye_denovo polypolish_low_percentile_threshold Float Polypolish-specific inputs Optional flye_denovo polypolish_maximum_errors Int Polypolish-specific inputs Optional flye_denovo polypolish_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional flye_denovo polypolish_minimum_depth Int Polypolish-specific inputs Optional flye_denovo polypolish_pair_orientation String Polypolish-specific inputs Optional flye_denovo porechop_cpu Int Number of CPUs to allocate to the task 4 Optional flye_denovo porechop_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flye_denovo porechop_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional flye_denovo porechop_trimopts String Options to pass to Porechop for trimming Optional flye_denovo racon_cpu Int Number of CPUs to allocate to the task 8 Optional flye_denovo racon_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flye_denovo racon_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional flye_denovo run_porechop Boolean If true, trims reads before assembly using Porechop FALSE Optional flye_denovo skip_polishing Boolean If true, skips polishing FALSE Optional gambit cpu Int Number of CPUs to allocate to the task 1 Optional gambit disk_size Int Amount of storage (in GB) to allocate to the task 20 Optional gambit docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Optional gambit memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional merlin_magic abricate_abaum_docker_image String Internal component, do not modify Optional merlin_magic abricate_abaum_min_percent_coverage Int Internal component, do not modify Optional merlin_magic abricate_abaum_min_percent_identity Int Internal component, do not modify 95 Optional merlin_magic abricate_vibrio_docker_image String Internal component, do not modify Optional merlin_magic abricate_vibrio_min_percent_coverage Int Internal component, do not modify 80 Optional merlin_magic abricate_vibrio_min_percent_identity Int Internal component, do not modify 80 Optional merlin_magic agrvate_agr_typing_only Boolean Internal component, do not modify Optional merlin_magic agrvate_docker_image String Internal component, do not modify Optional merlin_magic agrvate_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/agrvate:1.0.2--hdfd78af_0 Optional merlin_magic amr_search_cpu Int Number of CPUs to allocate to the task 2 Optional merlin_magic amr_search_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional merlin_magic amr_search_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/amrsearch:0.2.1 Optional merlin_magic amr_search_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional merlin_magic call_poppunk Boolean Internal component, do not modify TRUE Optional merlin_magic call_shigeifinder_reads_input Boolean Internal component, do not modify FALSE Optional merlin_magic call_stxtyper Boolean Internal component, do not modify FALSE Optional merlin_magic call_tbp_parser Boolean Internal component, do not modify FALSE Optional merlin_magic cauris_cladetyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Optional merlin_magic cladetyper_kmer_size Int Kmer size for cladtyper Optional merlin_magic cladetyper_max_distance Float The maximum GAMBIT distance to report a C. auris clade hit 0.1 Optional merlin_magic cladetyper_ref_clade1 File Reference genome FASTA for Candidozyma auris clade1 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade1_GCA_002759435.2_Cand_auris_B8441_V2_genomic.fasta Optional merlin_magic cladetyper_ref_clade1_annotated File Reference GBFF annotation for C. auris clade1 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade1_GCA_002759435_Cauris_B8441_V2_genomic.gbff Optional merlin_magic cladetyper_ref_clade2 File Reference genome FASTA for C. auris clade2 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade2_GCA_003013715.2_ASM301371v2_genomic.fasta Optional merlin_magic cladetyper_ref_clade2_annotated File Reference GBFF annotation for C. auris clade2 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade2_GCA_003013715.2_ASM301371v2_genomic.gbff Optional merlin_magic cladetyper_ref_clade3 File Reference genome FASTA for C. auris clade3 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade3_GCF_002775015.1_Cand_auris_B11221_V1_genomic.fasta Optional merlin_magic cladetyper_ref_clade3_annotated File Reference GBFF annotation for C. auris clade3 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade3_GCF_002775015.1_Cand_auris_B11221_V1_genomic.gbff Optional merlin_magic cladetyper_ref_clade4 File Reference genome FASTA for C. auris clade4 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade4_GCA_003014415.1_Cand_auris_B11243_genomic.fasta Optional merlin_magic cladetyper_ref_clade4_annotated File Reference GBFF annotation for C. auris clade4 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade4_GCA_003014415.1_Cand_auris_B11243_genomic.gbff Optional merlin_magic cladetyper_ref_clade5 File Reference genome FASTA for C. auris clade5 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade5_GCA_016809505.1_ASM1680950v1_genomic.fasta Optional merlin_magic cladetyper_ref_clade5_annotated File Reference GBFF annotation for C. auris clade5 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade5_GCA_016809505.1_ASM1680950v1_genomic.gbff Optional merlin_magic cladetyper_ref_clade6 File Reference genome FASTA for C. auris clade6 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade6_GCA_032714025.1_ASM3271402v1_genomic.fasta Optional merlin_magic cladetyper_ref_clade6_annotated File Reference GBFF annotation for C. auris clade6 Optional merlin_magic clockwork_docker_image String Internal component, do not modify Optional merlin_magic ectyper_docker_image String Internal component, do not modify Optional merlin_magic ectyper_h_min_percent_coverage Int Internal component, do not modify Optional merlin_magic ectyper_h_min_percent_identity Int Internal component, do not modify Optional merlin_magic ectyper_o_min_percent_coverage Int Internal component, do not modify Optional merlin_magic ectyper_o_min_percent_identity Int Internal component, do not modify Optional merlin_magic ectyper_print_alleles Boolean Internal component, do not modify Optional merlin_magic ectyper_verify Boolean Internal component, do not modify Optional merlin_magic emmtyper_align_diff Int Internal component, do not modify Optional merlin_magic emmtyper_cluster_distance Int Internal component, do not modify Optional merlin_magic emmtyper_culling_limit Int Internal component, do not modify Optional merlin_magic emmtyper_docker_image String Internal component, do not modify Optional merlin_magic emmtyper_gap Int Internal component, do not modify Optional merlin_magic emmtyper_max_size Int Internal component, do not modify Optional merlin_magic emmtyper_min_good Int Internal component, do not modify Optional merlin_magic emmtyper_min_percent_identity Int Internal component, do not modify Optional merlin_magic emmtyper_min_perfect Int Internal component, do not modify Optional merlin_magic emmtyper_mismatch Int Internal component, do not modify Optional merlin_magic emmtyper_wf String Internal component, do not modify Optional merlin_magic emmtypingtool_docker_image String Internal component, do not modify Optional merlin_magic genotyphi_docker_image String Internal component, do not modify Optional merlin_magic hicap_broken_gene_length Int Internal component, do not modify Optional merlin_magic hicap_docker_image String Internal component, do not modify Optional merlin_magic hicap_min_broken_gene_percent_identity Float Internal component, do not modify Optional merlin_magic hicap_min_gene_percent_coverage Float Internal component, do not modify Optional merlin_magic hicap_min_gene_percent_identity Float Internal component, do not modify Optional merlin_magic kaptive_docker_image String Internal component, do not modify Optional merlin_magic kaptive_low_gene_percent_identity Float Internal component, do not modify Optional merlin_magic kaptive_min_percent_coverage Float Internal component, do not modify Optional merlin_magic kaptive_min_percent_identity Float Internal component, do not modify Optional merlin_magic kaptive_start_end_margin Int Internal component, do not modify Optional merlin_magic kleborate_docker_image String Internal component, do not modify Optional merlin_magic kleborate_min_kaptive_confidence String Internal component, do not modify Optional merlin_magic kleborate_min_percent_coverage Float Internal component, do not modify Optional merlin_magic kleborate_min_percent_identity Float Internal component, do not modify Optional merlin_magic kleborate_min_spurious_percent_coverage Float Internal component, do not modify Optional merlin_magic kleborate_min_spurious_percent_identity Float Internal component, do not modify Optional merlin_magic kleborate_skip_kaptive Boolean Internal component, do not modify Optional merlin_magic kleborate_skip_resistance Boolean Internal component, do not modify Optional merlin_magic legsta_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/legsta:0.5.1--hdfd78af_2 Optional merlin_magic lissero_docker_image String Internal component, do not modify Optional merlin_magic lissero_min_percent_coverage Float Internal component, do not modify Optional merlin_magic lissero_min_percent_identity Float Internal component, do not modify Optional merlin_magic meningotype_docker_image String Internal component, do not modify Optional merlin_magic ngmaster_docker_image String Internal component, do not modify Optional merlin_magic paired_end Boolean Set to true if your data is paired-end FASTQ files TRUE Optional merlin_magic pasty_docker_image String Internal component, do not modify Optional merlin_magic pasty_min_percent_coverage Int Internal component, do not modify Optional merlin_magic pasty_min_percent_identity Int Internal component, do not modify Optional merlin_magic pbptyper_docker_image String Internal component, do not modify Optional merlin_magic pbptyper_min_percent_coverage Int Internal component, do not modify Optional merlin_magic pbptyper_min_percent_identity Int Internal component, do not modify Optional merlin_magic poppunk_docker_image String Internal component, do not modify Optional merlin_magic poppunk_gps_clusters_csv File Internal component, do not modify Optional merlin_magic poppunk_gps_dists_npy File Internal component, do not modify Optional merlin_magic poppunk_gps_dists_pkl File Internal component, do not modify Optional merlin_magic poppunk_gps_external_clusters_csv File Internal component, do not modify Optional merlin_magic poppunk_gps_fit_npz File Internal component, do not modify Optional merlin_magic poppunk_gps_fit_pkl File Internal component, do not modify Optional merlin_magic poppunk_gps_graph_gt File Internal component, do not modify Optional merlin_magic poppunk_gps_h5 File Internal component, do not modify Optional merlin_magic poppunk_gps_qcreport_txt File Internal component, do not modify Optional merlin_magic poppunk_gps_refs File Internal component, do not modify Optional merlin_magic poppunk_gps_refs_dists_npy File Internal component, do not modify Optional merlin_magic poppunk_gps_refs_dists_pkl File Internal component, do not modify Optional merlin_magic poppunk_gps_refs_graph_gt File Internal component, do not modify Optional merlin_magic poppunk_gps_refs_h5 File Internal component, do not modify Optional merlin_magic poppunk_gps_unword_clusters_csv File Internal component, do not modify Optional merlin_magic read1 File Internal component, do not modify Optional merlin_magic read2 File Internal component, do not modify Optional merlin_magic run_amr_search Boolean If set to true AMR_Search workflow will be run if species is part of supported taxon, see AMR_Search docs. FALSE Optional merlin_magic seqsero2_docker_image String Internal component, do not modify Optional merlin_magic seroba_docker_image String Internal component, do not modify Optional merlin_magic serotypefinder_docker_image String Internal component, do not modify Optional merlin_magic shigatyper_docker_image String Internal component, do not modify Optional merlin_magic shigeifinder_docker_image String Internal component, do not modify Optional merlin_magic sistr_cpu Int Internal component, do not modify Optional merlin_magic sistr_disk_size Int Internal component, do not modify Optional merlin_magic sistr_docker_image String Internal component, do not modify Optional merlin_magic sistr_memory Int Internal component, do not modify Optional merlin_magic sistr_use_full_cgmlst_db Boolean Internal component, do not modify Optional merlin_magic snippy_base_quality Int Minimum quality for a nucleotide to be used in variant calling 13 Optional merlin_magic snippy_gene_query_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Optional merlin_magic snippy_map_qual Int Minimum mapping quality to accept in variant calling 60 Optional merlin_magic snippy_maxsoft Int Number of bases of alignment to soft-clip before discarding the alignment 10 Optional merlin_magic snippy_min_coverage Int Minimum read coverage of a position to identify a mutation 10 Optional merlin_magic snippy_min_frac Float Minimum fraction of bases at a given position to identify a mutation 0 Optional merlin_magic snippy_min_quality Int Minimum VCF variant call \"quality\" 100 Optional merlin_magic snippy_query_gene String Provide a gene to search for using Snippy Default depend on detected organism Optional merlin_magic snippy_reference_afumigatus File Snippy reference for Aspergillus fumigatus gs://theiagen-public-resources-rp/reference_data/eukaryotic/aspergillus/Aspergillus_fumigatus_GCF_000002655.1_ASM265v1_genomic.gbff Optional merlin_magic snippy_reference_cryptoneo File Snippy reference for Cryptococcus neoformans gs://theiagen-public-resources-rp/reference_data/eukaryotic/cryptococcus/Cryptococcus_neoformans_GCF_000091045.1_ASM9104v1_genomic.gbff Optional merlin_magic snippy_variants_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snippy:4.6.0 Optional merlin_magic sonneityping_docker_image String Internal component, do not modify Optional merlin_magic sonneityping_mykrobe_opts String Internal component, do not modify Optional merlin_magic spatyper_do_enrich Boolean Internal component, do not modify Optional merlin_magic spatyper_docker_image String Internal component, do not modify Optional merlin_magic srst2_docker_image String Internal component, do not modify Optional merlin_magic srst2_gene_max_mismatch Int Internal component, do not modify 2000 Optional merlin_magic srst2_max_divergence Int Internal component, do not modify 20 Optional merlin_magic srst2_min_depth Int Internal component, do not modify 5 Optional merlin_magic srst2_min_edge_depth Int Internal component, do not modify 2 Optional merlin_magic srst2_min_percent_coverage Int Internal component, do not modify 80 Optional merlin_magic staphopia_sccmec_docker_image String Internal component, do not modify Optional merlin_magic stxtyper_cpu Int Internal component, do not modify Optional merlin_magic stxtyper_disk_size Int Internal component, do not modify Optional merlin_magic stxtyper_docker_image String Internal component, do not modify Optional merlin_magic stxtyper_enable_debug Boolean Internal component, do not modify Optional merlin_magic stxtyper_memory Int Internal component, do not modify Optional merlin_magic tbp_parser_add_cs_lims Boolean Internal component, do not modify Optional merlin_magic tbp_parser_config File Internal component, do not modify Optional merlin_magic tbp_parser_coverage_regions_bed File Internal component, do not modify Optional merlin_magic tbp_parser_debug Boolean Internal component, do not modify Optional merlin_magic tbp_parser_docker_image String Internal component, do not modify Optional merlin_magic tbp_parser_etha237_frequency Float Internal component, do not modify Optional merlin_magic tbp_parser_expert_rule_regions_bed File Internal component, do not modify Optional merlin_magic tbp_parser_min_depth Int Internal component, do not modify Optional merlin_magic tbp_parser_min_frequency Float Internal component, do not modify Optional merlin_magic tbp_parser_min_percent_coverage Float Internal component, do not modify Optional merlin_magic tbp_parser_min_read_support Int Internal component, do not modify Optional merlin_magic tbp_parser_operator String Internal component, do not modify Optional merlin_magic tbp_parser_output_seq_method_type String Internal component, do not modify WGS Optional merlin_magic tbp_parser_rpob449_frequency Float Internal component, do not modify Optional merlin_magic tbp_parser_rrl_frequency Float Internal component, do not modify Optional merlin_magic tbp_parser_rrl_read_support Int Internal component, do not modify Optional merlin_magic tbp_parser_rrs_frequency Float Internal component, do not modify Optional merlin_magic tbp_parser_rrs_read_support Int Internal component, do not modify Optional merlin_magic tbp_parser_tngs_data Boolean Internal component, do not modify Optional merlin_magic tbprofiler_additional_parameters String Internal component, do not modify Optional merlin_magic tbprofiler_custom_db File Internal component, do not modify Optional merlin_magic tbprofiler_docker_image String Internal component, do not modify Optional merlin_magic tbprofiler_mapper String Internal component, do not modify Optional merlin_magic tbprofiler_min_af Float Internal component, do not modify Optional merlin_magic tbprofiler_min_depth Int Internal component, do not modify Optional merlin_magic tbprofiler_run_cdph_db Boolean Internal component, do not modify FALSE Optional merlin_magic tbprofiler_run_custom_db Boolean Internal component, do not modify FALSE Optional merlin_magic tbprofiler_variant_caller String Internal component, do not modify Optional merlin_magic tbprofiler_variant_calling_params String Internal component, do not modify Optional merlin_magic vibecheck_docker_image String Internal component, do not modify Optional merlin_magic vibecheck_lineage_barcodes File Internal component, do not modify Optional merlin_magic vibecheck_skip_subsampling Boolean Internal component, do not modify Optional merlin_magic vibecheck_subsampling_fraction Float Internal component, do not modify Optional merlin_magic virulencefinder_database String Internal component, do not modify Optional merlin_magic virulencefinder_docker_image String Internal component, do not modify Optional merlin_magic virulencefinder_min_percent_coverage Float Internal component, do not modify Optional merlin_magic virulencefinder_min_percent_identity Float Internal component, do not modify Optional nanoplot_clean cpu Int Number of CPUs to allocate to the task 4 Optional nanoplot_clean disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoplot_clean docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Optional nanoplot_clean max_length Int The maximum length of clean reads, for which reads longer than the length specified will be hidden. 100000 Optional nanoplot_clean memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional nanoplot_raw cpu Int Number of CPUs to allocate to the task 4 Optional nanoplot_raw disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoplot_raw docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Optional nanoplot_raw max_length Int The maximum length of clean reads, for which reads longer than the length specified will be hidden. 100000 Optional nanoplot_raw memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional quast cpu Int Number of CPUs to allocate to the task 2 Optional quast disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional quast docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/quast:5.0.2 Optional quast memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional quast min_contig_length Int Minimum length of contig for QUAST 500 Optional raw_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional raw_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional raw_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional raw_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional raw_check_reads workflow_series String Internal component, do not modify theiaviral Optional read_QC_trim artic_guppyplex_cpu Int Internal component, do not modify Optional read_QC_trim artic_guppyplex_disk_size Int Internal component, do not modify Optional read_QC_trim artic_guppyplex_docker String Internal component, do not modify Optional read_QC_trim artic_guppyplex_memory Int Internal component, do not modify Optional read_QC_trim call_kraken Boolean Internal component, do not modify FALSE Optional read_QC_trim downsampling_coverage Float The desired coverage to sub-sample the reads to with RASUSA 150 Optional read_QC_trim kraken2_recalculate_abundances_cpu Int Internal component, do not modify Optional read_QC_trim kraken2_recalculate_abundances_disk_size Int Internal component, do not modify Optional read_QC_trim kraken2_recalculate_abundances_docker String Internal component, do not modify Optional read_QC_trim kraken2_recalculate_abundances_memory Int Internal component, do not modify Optional read_QC_trim kraken_cpu Int Internal component, do not modify Optional read_QC_trim kraken_db File Internal component, do not modify Optional read_QC_trim kraken_disk_size Int Internal component, do not modify Optional read_QC_trim kraken_docker_image String Internal component, do not modify Optional read_QC_trim kraken_memory Int Internal component, do not modify Optional read_QC_trim max_length Int Internal component, do not modify Optional read_QC_trim min_length Int Internal component, do not modify Optional read_QC_trim nanoq_cpu Int Number of CPUs to allocate to the task 2 Optional read_QC_trim nanoq_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim nanoq_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/nanoq:0.9.0--hec16e2b_1 Optional read_QC_trim nanoq_max_read_length Int The maximum read length to keep after trimming 100000 Optional read_QC_trim nanoq_max_read_qual Int The maximum read quality to keep after trimming 40 Optional read_QC_trim nanoq_memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional read_QC_trim nanoq_min_read_length Int The minimum read length to keep after trimming 500 Optional read_QC_trim nanoq_min_read_qual Int The minimum read quality to keep after trimming 10 Optional read_QC_trim ncbi_scrub_cpu Int Internal component, do not modify 4 Optional read_QC_trim ncbi_scrub_disk_size Int Internal component, do not modify 100 Optional read_QC_trim ncbi_scrub_docker String Internal component, do not modify us-docker.pkg.dev/general-theiagen/ncbi/sra-human-scrubber:2.2.1 Optional read_QC_trim ncbi_scrub_memory Int Internal component, do not modify 8 Optional read_QC_trim rasusa_bases String Explicitly set the number of bases required e.g., 4.3kb, 7Tb, 9000, 4.1MB. If this option is given, --coverage and --genome-size are ignored Optional read_QC_trim rasusa_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim rasusa_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim rasusa_docker String Internal component, do not modify Optional read_QC_trim rasusa_fraction_of_reads Float Subsample to a fraction of the reads - e.g., 0.5 samples half the reads Optional read_QC_trim rasusa_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim rasusa_number_of_reads Int Subsample to a specific number of reads Optional read_QC_trim rasusa_seed Int Random seed to use Optional read_QC_trim run_prefix String Internal component, do not modify Optional read_QC_trim target_organism String Internal component, do not modify Optional theiaeuk_ont busco_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ezlabgva/busco:v5.3.2_cv1 Optional theiaeuk_ont busco_memory Int Amount of memory/RAM (in GB) to allocate to the task 24 Optional theiaeuk_ont gambit_db_genomes File User-provided database of assembled query genomes; requires complementary signatures file. If not provided, uses default database, \"/gambit-db\" gs://gambit-databases-rp/fungal-version/1.0.0/gambit-fungal-metadata-1.0.0-20241213.gdb Optional theiaeuk_ont gambit_db_signatures File User-provided signatures file; requires complementary genomes file. If not specified, the file from the docker container will be used. gs://gambit-databases-rp/fungal-version/1.0.0/gambit-fungal-signatures-1.0.0-20241213.gs Optional theiaeuk_ont genome_length Int User-specified expected genome length to be used in genome statistics calculations 50000000 Optional theiaeuk_ont max_genome_length Int Maximum genome size able to pass read screening 178000000 Optional theiaeuk_ont min_basepairs Int Minimum number of base pairs able to pass read screening 45000000 Optional theiaeuk_ont min_coverage Int Minimum genome coverage able to pass read screening 5 Optional theiaeuk_ont min_genome_length Int Minimum genome size able to pass read screening 9000000 Optional theiaeuk_ont min_reads Int Minimum number of reads to pass read screening 5000 Optional theiaeuk_ont skip_mash Boolean If true, skips estimation of genome size and coverage using mash in read screening steps. As a result, providing true also prevents screening using these parameters. TRUE Optional theiaeuk_ont skip_screen Boolean Option to skip the read screening prior to analysis; if setting to true, please provide a value for the theiaeuk_pe genome_length optional input, OR set call_rasusa to false. Otherwise RASUSA will attempt to downsample to an expected genome size of 0 bp, and the workflow will fail. FALSE Optional theiaeuk_ont workflow_series String Internal component, do not modify theiaeuk Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/genomic_characterization/theiaeuk/#workflow-tasks","title":"Workflow Tasks","text":"<p>All input reads are processed through \"core tasks\" in the TheiaEuk workflows. These undertake read trimming and assembly appropriate to the input data type, currently only Illumina paired-end data. TheiaEuk workflow subsequently launch default genome characterization modules for quality assessment, and additional taxa-specific characterization steps. When setting up the workflow, users may choose to use \"optional tasks\" or alternatives to tasks run in the workflow by default.</p>"},{"location":"workflows/genomic_characterization/theiaeuk/#core-tasks","title":"Core tasks","text":"<p>These tasks are performed regardless of organism. They include tasks that are performed regardless of and specific for the input data type. They perform read trimming and assembly appropriate to the input data type.</p> <code>versioning</code>: Version Capture <p>The <code>versioning</code> task captures the workflow version from the GitHub (code repository) version.</p> <p>Version Capture Technical details</p> Links Task task_versioning.wdl TheiaEuk_Illumina_PETheiaEuk_ONT <code>screen</code>: Total Raw Read Quantification and Genome Size Estimation <p>The <code>screen</code> task ensures the quantity of sequence data is sufficient to undertake genomic analysis. It uses <code>fastq-scan</code> and bash commands for quantification of reads and base pairs, and mash sketching to estimate the genome size and its coverage. At each step, the results are assessed relative to pass/fail criteria and thresholds that may be defined by optional user inputs. Samples are run through all threshold checks, regardless of failures, and the workflow will terminate after the <code>screen</code> task if any thresholds are not met:</p> <ol> <li>Total number of reads: A sample will fail the read screening task if its total number of reads is less than or equal to <code>min_reads</code>.</li> <li>The proportion of basepairs reads in the forward and reverse read files: A sample will fail the read screening if fewer than <code>min_proportion</code> basepairs are in either the reads1 or read2 files.</li> <li>Number of basepairs: A sample will fail the read screening if there are fewer than <code>min_basepairs</code> basepairs</li> <li>Estimated genome size:  A sample will fail the read screening if the estimated genome size is smaller than <code>min_genome_size</code> or bigger than <code>max_genome_size</code>.</li> <li>Estimated genome coverage: A sample will fail the read screening if the estimated genome coverage is less than the <code>min_coverage</code>.</li> </ol> <p>Read screening is undertaken on both the raw and cleaned reads. The task may be skipped by setting the <code>skip_screen</code> variable to true.</p> <p>Default values vary between the PE, SE, and ONT workflows. The rationale for these default values can be found below. If two default values are shown, the first is for Illumina workflows and the second is for ONT.</p> <p>| Variable  | Rationale | | --- | --- | --- | | <code>skip_screen</code> | false | Set to true to skip the read screen from running. If you set this value to true, please provide a value for the theiaeuk_illumina_pe <code>genome_length</code> optional input, OR set the theiaeuk_illumina_pe <code>call_rasusa</code> optional input to false. Otherwise RASUSA will attempt to downsample to an expected genome size of 0 bp, and the workflow will fail. | | <code>min_reads</code> | 3000 | Calculated from the minimum number of base pairs required for 20x coverage of the Hansenula polymorpha genome, the smallest fungal genome as of 2015-04-02 (8.97 Mbp), divided by 300 (the longest Illumina read length) | | <code>min_basepairs</code> | 45000000 | Should be greater than 10x coverage of Hansenula polymorpha, the smallest fungal genome as of 2015-04-02 (8.97 Mbp)  | | <code>min_genome_length</code> | 9000000 | Based on the Hansenula polymorpha  genome - the smallest fungal genome as of 2015-04-02 (8.97 Mbp) | | <code>max_genome_length</code> | 178000000 | Based on the Cenococcum geophilum  genome, the largest pathogenic fungal genome (177.57 Mbp), plus an additional 2 Mbp to cater for potential extra genomic material | | <code>min_coverage</code> | 10 | A bare-minimum average per base coverage across the genome required for genome characterization. Higher coverage would be required for high-quality phylogenetics.| | <code>min_proportion</code> | 40 | Neither read1 nor read2 files should have less than 40% of the total number of reads. For paired-end data only. |</p> <p>Screen Technical Details</p> <p>There is a single WDL task for read screening. The <code>screen</code> task is run twice, once for raw reads and once for clean reads.</p> Links Task task_screen.wdl (PE sub-task)task_screen.wdl (SE sub-task) <code>Rasusa</code>: Read subsampling (optional, on by default) <p>To deactivate this task, set <code>call_rasusa</code> to <code>false</code>.</p> <p><code>Rasusa</code> is a tool to randomly subsample sequencing reads to a specified coverage without assuming that all reads are of equal length, making it especially suitable for long-read data while still being applicable to short-read data.</p> <p>The <code>Rasusa</code> task performs subsampling on the input raw reads. By default, this task will subsample TheiaProk_ONT reads to a depth of 150X using an estimated genome length of 5 million basepairs (0.7 Mb higher than the average bacterial genome length), and TheiaEuk_ONT reads using an estimated genome length of 50 million basepairs. The estimated genome length can be changed by the user by providing a different value for the <code>genome_length</code> input parameter. The target subsampling depth can also be adjusted by modifying the <code>subsample_coverage</code> variable.</p> <p>For TheiaEuk_Illumina_PE, the estimated genome length is determined by the <code>read_screen</code> task. Please note that the user can prevent the task from being launched by setting the <code>call_rasusa</code> variable to false.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs since it performs random subsampling. To ensure reproducibility, set a a value for the <code>rasusa_seed</code> optional input variable.</p> <p>Rasusa Technical Details</p> Links Task task_rasusa.wdl Software Source Code Rasusa on GitHub Software Documentation Rasusa on GitHub Original Publication(s) Rasusa: Randomly subsample sequencing reads to a specified coverage <code>read_QC_trim</code>: Read Quality Trimming, Adapter Removal, Quantification, and Identification <p><code>read_QC_trim</code> is a sub-workflow that removes low-quality reads, low-quality regions of reads, and sequencing adapters to improve data quality. It uses a number of tasks, described below. The differences between the PE and SE versions of the <code>read_QC_trim</code> sub-workflow lie in the default parameters, the use of two or one input read file(s), and the different output files.</p> <p>By default, <code>read_processing</code> is set to <code>\"trimmomatic\"</code>. To use <code>fastp</code> instead, set <code>read_processing</code> to <code>\"fastp\"</code>. These tasks are mutually exclusive.</p> <code>Trimmomatic</code>: Read Trimming (default) <p>Read proccessing is available via <code>Trimmomatic</code> by default.</p> <p>Trimmomatic trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>Trimmomatic</code> Technical Details</p> Links Task task_trimmomatic.wdl Software Source Code Trimmomatic on GitHub Software Documentation Trimmomatic Website Original Publication(s) Trimmomatic: a flexible trimmer for Illumina sequence data <code>fastp</code>: Read Trimming (alternative) <p>To activate this task, set <code>read_processing</code> to <code>\"fastp\"</code>.</p> <p><code>fastp</code> trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>fastp</code> also has additional default parameters and features that are not a part of <code>trimmomatic</code>'s default configuration.</p> <code>fastp</code> default read-trimming parameters Parameter Explanation -g enables polyG tail trimming -5 20 enables read end-trimming -3 20 enables read end-trimming --detect_adapter_for_pe enables adapter-trimming only for paired-end reads <p>Additional arguments can be passed using the <code>fastp_args</code> optional parameter.</p> <p>Trimmomatic and fastp Technical Details</p> Links Task task_fastp.wdl Software Source Code fastp on GitHub Software Documentation fastp on GitHub Original Publication(s) fastp: an ultra-fast all-in-one FASTQ preprocessor <code>BBDuk</code>: Adapter Trimming and PhiX Removal <p>Adapters are manufactured oligonucleotide sequences attached to DNA fragments during the library preparation process. In Illumina sequencing, these adapter sequences are required for attaching reads to flow cells. You can read more about Illumina adapters here. For genome analysis, it's important to remove these sequences since they're not actually from your sample. If you don't remove them, the downstream analysis may be affected.</p> <p>The <code>bbduk</code> task removes adapters from sequence reads. To do this:</p> <ul> <li>Repair from the BBTools package reorders reads in paired fastq files to ensure the forward and reverse reads of a pair are in the same position in the two fastq files (it re-pairs).</li> <li>BBDuk  (\"Bestus Bioinformaticus\" Decontamination Using Kmers) is then used to trim the adapters and filter out all reads that have a 31-mer match to PhiX, which is commonly added to Illumina sequencing runs to monitor and/or improve overall run quality.</li> </ul> <p>BBDuk Technical Details</p> Links Task task_bbduk.wdl Software Source Code BBMap on SourceForge Software Documentation BBDuk Guide (archived) <p>By default, <code>read_qc</code> is set to <code>\"fastq_scan\"</code>. To use <code>fastqc</code> instead, set <code>read_qc</code> to <code>\"fastqc\"</code>. These tasks are mutually exclusive.</p> <code>fastq-scan</code>: Read Quantification (default) <p>Read quantification is available via <code>fastq-scan</code> by default.</p> <p><code>fastq-scan</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p><code>fastq-scan</code> Technical Details</p> Links Task task_fastq_scan.wdl Software Source Code fastq-scan on GitHub Software Documentation fastq-scan on GitHub <code>FastQC</code>: Read Quantification (alternative) <p>To activate this task, set <code>read_qc</code> to <code>\"fastqc\"</code>.</p> <p><code>FastQC</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>This tool also provides a graphical visualization of the read quality.</p> <p><code>FastQC</code> Technical Details</p> Links Task task_fastqc.wdl Software Source Code FastQC on Github Software Documentation FastQC Website <code>Kraken2</code>: Read Identification (optional) <p>To activate this task, set <code>call_kraken</code> to <code>true</code> and provide a value for <code>kraken_db</code>.</p> <p><code>Kraken2</code> is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>Database-dependent</p> <p>This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz</code>.</p> <p>As an alternative to <code>MIDAS</code> (see above), the <code>Kraken2</code> task can also be turned on through setting the <code>call_kraken</code> input variable as <code>true</code> for the identification of reads to detect contamination with non-target taxa.</p> <p>A database must be provided if this optional module is activated, through the kraken_db optional input. A list of suggested databases can be found on Kraken2 standalone documentation.</p> <p>Kraken2 Technical Details</p> Links Task task_kraken2.wdl Software Source Code Kraken2 on GitHub Software Documentation Kraken2 Documentation Original Publication(s) Improved metagenomic analysis with Kraken 2 <p>read_QC_trim Technical Details</p> Links Subworkflow wf_read_QC_trim_pe.wdlwf_read_QC_trim_se.wdl <code>qc_check</code>: Check QC Metrics Against User-Defined Thresholds (optional) <p>To activate this task, provide a <code>qc_check_table</code> as input.</p> <p>The <code>qc_check</code> task compares generated QC metrics against user-defined thresholds for each metric. This task will run if the user provides a <code>qc_check_table</code> TSV file. If all QC metrics meet the threshold, the <code>qc_check</code> output variable will read <code>QC_PASS</code>. Otherwise, the output will read <code>QC_NA</code> if the task could not proceed or <code>QC_ALERT</code> followed by a string indicating what metric failed.</p> <p>The <code>qc_check</code> task applies quality thresholds according to the sample taxa. The sample taxa is taken from the <code>gambit_predicted_taxon</code> value inferred by the GAMBIT module OR can be manually provided by the user using the <code>expected_taxon</code> workflow input.</p> Formatting the qc_check_table.tsv <ul> <li>The first column of the qc_check_table lists the <code>organism</code> that the task will assess and the header of this column must be \"taxon\".</li> <li>Any genus or species can be included as a row of the qc_check_table. However, these taxa must uniquely match the sample taxa, meaning that the file can include multiple species from the same genus (Vibrio_cholerae and Vibrio_vulnificus), but not both a genus row and species within that genus (Vibrio and Vibrio cholerae). The taxa should be formatted with the first letter capitalized and underscores in lieu of spaces.</li> <li>Each subsequent column indicates a QC metric and lists a threshold for each organism that will be checked. The column names must exactly match expected values, so we highly recommend copy and pasting the header from the template file below as a starting place.</li> </ul> Template qc_check_table.tsv files <ul> <li>TheiaEuk_Illumina_PE_PHB: theiaeuk_qc_check_template.tsv</li> </ul> <p>Example Purposes Only</p> <p>The QC threshold values shown in the file above are for example purposes only and should not be presumed to be sufficient for every dataset.</p> <p>qc_check Technical Details</p> Links Task task_qc_check_phb.wdl <p>These tasks assemble the reads into a de novo assembly and assess the quality of the assembly.</p> <code>digger_denovo</code>: De novo Assembly <p>De novo  assembly is the process or product of attempting to reconstruct a genome from scratch (without prior knowledge of the genome) using sequence reads. Assembly of fungal genomes from short-reads will produce multiple contigs per chromosome rather than a single contiguous sequence for each chromosome.</p> <p>In TheiaProk and TheiaEuk Illumina workflows, de novo assembly is performed for samples that have sufficient read quantity and quality using digger_denovo, a subworkflow based off of Shovill pipeline. The name \"digger\" is a nod to Shovill and SPAdes.</p> De novo Assembly <p><code>assembler</code> with <code>skesa</code> (default), <code>spades</code>, or <code>megahit</code></p> <p>To activate a particular assembler, set the <code>assembler</code> input parameter to either <code>skesa</code> (default), <code>spades</code>, or <code>megahit</code>.</p> <p>These tasks are mutually exclusive.</p> <code>SKESA</code>: De novo Assembly (default) <p>This task is activated by default.</p> <p><code>SKESA</code> (Strategic K-mer Extension for Scrupulous Assemblies) is a de novo assembler that is fairly conservative and introduces breaks in the genome at repeat regions. This leads to higher sequence quality but more fragmented assemblies, which, depending on the final analysis goal, can be either highly preferred or detrimental. Designed for Illumina reads and haploid genomes, SKESA is the default assembler in the <code>digger_denovo</code> subworkflow.</p> <p>SKESA Technical Details</p> Links Task task_skesa.wdl Software Source Code SKESA on GitHub Software Documentation SKESA on GitHub Original Publication(s) SKESA: strategic k-mer externsion for scrupulous assemblies <code>SPAdes</code>: De novo Assembly (alternative) <p>To activate this task, set <code>assembler</code> to <code>spades</code>.</p> <p><code>SPAdes</code> (St. Petersburg genome assembler) is a de novo assembly tool that uses de Bruijn graphs to assemble genomes from Illumina short reads.</p> <p>In TheiaProk, SPAdes is run in <code>--isolate</code> mode, which is the recommended flag for high-coverage isolate and multi-cell Illumina data, which is typical of most bacterial sequencing projects. This method is optimized for improving assembly quality and decreasing runtime.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>MetaviralSPAdes Technical Details</p> Links Task task_spades.wdl Software Source Code SPAdes on GitHub Software Documentation SPAdes Manual Original Publication(s) TheiaProk: SPAdes: A New Genome Assembly Algorithm and Its Applications to Single-Cell SequencingTheiaViral: MetaviralSPAdes: assembly of viruses from metagenomic data <code>MEGAHIT</code>: De novo Assembly (alternative) <p>To activate this task, set <code>assembler</code> to <code>megahit</code>.</p> <p>The MEGAHIT assembler is a fast and memory-efficient de novo assembler that can handle large datasets. While optimized for metagenomics, MEGAHIT also performs well on single-genome assemblies, making it a versatile choice for various assembly tasks.</p> <p>MEGAHIT uses a multiple k-mer strategy that can be beneficial for assembling genomes with varying coverage levels, which is common in metagenomic samples. It constructs succinct de Bruijn graphs to efficiently represent the assembly process, allowing it to handle large and complex datasets with reduced memory usage.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>MEGAHIT Technical Details</p> Links Task task_megahit.wdl Software Source Code MEGAHIT on GitHub Software Documentation MEGAHIT on GitHub Original Publication(s) MEGAHIT: an ultra-fast single-node solution for large and complex metagenomics assembly via succinct de Bruijn graph Assembly Polishing (optional) <p>To activate assembly polishing, set <code>call_pilon</code> to <code>true</code>.</p> <code>bwa</code>: Read Alignment to the Assembly <p>BWA (Burrow-Wheeler Aligner) is used to align the cleaned read files to generated assembly file in order to generate an alignment. The resulting BAM file is directly passed to the Pilon task to polish the assembly for errors.</p> <p>BWA Technical Details</p> Links Task task_bwa.wdl Software Source Code BWA on GitHub Software Documentation BWA Documentation Original Publication(s) Fast and accurate short read alignment with Burrows-Wheeler transform <code>Pilon</code>: Assembly Polishing <p><code>Pilon</code> is a tool that uses read alignments to correct errors in an assembly.</p> <p>The <code>bwa</code>-generated alignment of the read data to the assembly is used to identify inconsistences between the reads and the assembly in order to correct them. <code>Pilon</code> will attempt to fix individual base errors and small indels using the read data. This can improve the overall quality of the assembly, especially when the assembler has made mistakes due to sequencing errors or low coverage regions.</p> <p>The default parameters were set to mimic the parameters used by Shovill: <code>--fix bases --minq 60 --minqual 3 --mindepth 0.25</code>. These can be modified by the user.</p> <p>Pilon Technical Details</p> Links Task task_pilon.wdl Software Source Code Pilon on GitHub Software Documentation Pilon Wiki Original Publication(s) Pilon: An Integrated Tool for Comprehensive Microbial Variant Detection and Genome Assembly Improvement Contig Filtering (optional) <code>Filter Contigs</code>: Contig Quality Control <p>To deactivate contig filtering, set <code>run_filter_contigs</code> to <code>false</code>.</p> <p>This task filters the created contigs based on a default minimum length threshold of 200 bp and a minimum coverage of 2.0. It also eliminates homopolymer contigs (contigs of any length that consist of a single nucleotide).</p> <p>Options are available to skip any of these filters by setting the respective parameters to <code>false</code>: <code>filter_contigs_skip_length_filter</code>, <code>filter_contigs_skip_coverage_filter</code>, and <code>filter_contigs_skip_homopolymer_filter</code>. The minimum length and coverage thresholds can be adjusted using the <code>filter_contigs_min_length</code> and <code>filter_contigs_min_coverage</code> parameters, respectively.</p> <p>This ensures high-quality assemblies by retaining only contigs that meet specified criteria. Detailed metrics on contig counts and sequence lengths before and after filtering are provided in the output.</p> <p>Filter Contigs Technical Details</p> Links WDL Task task_filter_contigs.wdl <p>Digger-Denovo Technical Details</p> Links Subworkflow wf_digger_denovo.wdl <code>quast</code>: Assembly Quality Assessment <p>QUAST stands for QUality ASsessment Tool. It evaluates genome/metagenome assemblies by computing various metrics without a reference being necessary. It includes useful metrics such as number of contigs, length of the largest contig and N50.</p> <p>QUAST Technical Details</p> Links Task task_quast.wdl Software Source Code QUAST on GitHub Software Documentation QUAST Manual on SourceForge Original Publication(s) QUAST: quality assessment tool for genome assemblies <code>CG-Pipeline</code>: Assessment of Read Quality, and Estimation of Genome Coverage <p>The<code>cg_pipeline</code> task generates metrics about read quality and estimates the coverage of the genome using the <code>run_assembly_readMetrics.pl</code> script from CG-Pipeline. The genome coverage estimates are calculated using both using raw and cleaned reads, using either a user-provided <code>genome_size</code> or the estimated genome length generated by QUAST.</p> <p>CG-Pipeline Technical Details</p> <p>The <code>cg_pipeline</code> task is run twice in this workflow, once with raw reads, and once with clean reads.</p> Links Task task_cg_pipeline.wdl Software Source Code CG-Pipeline on GitHub Software Documentation CG-Pipeline on GitHub Original Publication(s) A computational genomics pipeline for prokaryotic sequencing projects <code>read_QC_trim_ont</code>: Read Quality Trimming, Quantification, and Identification <p><code>read_QC_trim_ont</code> is a sub-workflow that filters low-quality reads and trims low-quality regions of reads. It uses several tasks, described below.</p> <p>A note on estimated genome length</p> <p>By default, the estimated genome length is set to 5 Mb, which is around 0.7 Mb higher than the average bacterial genome length, according to the information of thousands of NCBI bacterial assemblies collated here. This estimate can be overwritten by the user and is used by <code>Rasusa</code>.</p> <code>Rasusa</code>: Read Subsampling <p><code>Rasusa</code> is a tool to randomly subsample sequencing reads to a specified coverage without assuming that all reads are of equal length, making it especially suitable for long-read data while still being applicable to short-read data.</p> <p>The <code>Rasusa</code> task performs subsampling on the input raw reads. By default, this task will subsample TheiaProk_ONT reads to a depth of 150X using an estimated genome length of 5 million basepairs (0.7 Mb higher than the average bacterial genome length), and TheiaEuk_ONT reads using an estimated genome length of 50 million basepairs. The estimated genome length can be changed by the user by providing a different value for the <code>genome_length</code> input parameter. The target subsampling depth can also be adjusted by modifying the <code>subsample_coverage</code> variable.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs since it performs random subsampling. To ensure reproducibility, set a a value for the <code>rasusa_seed</code> optional input variable.</p> <p>Rasusa Technical Details</p> Links Task task_rasusa.wdl Software Source Code Rasusa on GitHub Software Documentation Rasusa on GitHub Original Publication(s) Rasusa: Randomly subsample sequencing reads to a specified coverage <code>Nanoq</code>: Read Filtering <p>Reads are filtered by length and quality using <code>nanoq</code>. By default, sequences with less than 500 basepairs and quality scores lower than 10 are filtered out to improve assembly accuracy. These defaults are able to be modified by the user.</p> <p>Nanoq Technical Details</p> Links Task task_nanoq.wdl Software Source Code Nanoq on GitHub Software Documentation Nanoq Documentation Original Publication(s) Nanoq: ultra-fast quality control for nanopore reads <code>Kraken2</code>: Read Identification (optional) <p>To activate this task, set <code>call_kraken</code> to <code>true</code> and provide a value for <code>kraken_db</code>.</p> <p><code>Kraken2</code> is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>Kraken2 is run on the raw read data.</p> <p>Database-dependent</p> <p>This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz</code>.</p> <p>A database must be provided if this optional module is activated, through the kraken_db optional input. A list of suggested databases can be found on Kraken2 standalone documentation.</p> <p>Kraken2 Technical Details</p> Links Task task_kraken2.wdl Software Source Code Kraken2 on GitHub Software Documentation Kraken2 Documentation Original Publication(s) Improved metagenomic analysis with Kraken 2 <code>NanoPlot</code>: Read Quantification <p>NanoPlot is used for the determination of mean quality scores, read lengths, and number of reads. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>While this task currently is run outside of the <code>read_QC_trim_ont</code> workflow, it is being included here as it calculates statistics on the read data. This is done so that the actual assembly genome lengths can be used (if an estimated genome length is not provided by the user) to ensure the estimated coverage statistics are accurate.</p> <p>NanoPlot Technical Details</p> Links Task task_nanoplot.wdl Software Source Code NanoPlot on GitHub Software Documentation NanoPlot Documentation Original Publication(s) NanoPack2: population-scale evaluation of long-read sequencing data <p>read_QC_trim_ont Technical Details</p> Links Subworkflow wf_read_QC_trim_ont.wdl <p>These tasks assemble the reads into a de novo assembly and assess the quality of the assembly.</p> <code>Flye</code>: De novo Assembly <p><code>flye_denovo</code> is a sub-workflow that performs de novo assembly using Flye for ONT data and supports additional polishing and visualization steps.</p> <p>Ensure correct medaka model is selected if performing medaka polishing</p> <p>In order to obtain the best results, the appropriate model must be set to match the sequencer's basecaller model; this string takes the format of {pore}_{device}_{caller variant}_{caller_version}. See also https://github.com/nanoporetech/medaka?tab=readme-ov-file#models. If <code>flye</code> is being run on legacy data the medaka model will likely be <code>r941_min_hac_g507</code>. Recently generated data will likely be suited by the default model of <code>r1041_e82_400bps_sup_v5.0.0</code>.</p> <p>The detailed steps and tasks are as follows:</p> <code>Porechop</code>: Read Trimming (optional; off by default) <p>Read trimming is optional and can be enabled by setting the <code>run_porchop</code> input variable to true.</p> <p>Porechop is a tool for finding and removing adapters from ONT data. Adapters on the ends of reads are trimmed, and when a read has an adapter in the middle, the read is split into two.</p> <p>Porechop Technical Details</p> Links WDL Task task_porechop.wdl Software Source Code Porechop on GitHub Software Documentation https://github.com/rrwick/Porechop#porechop <code>Flye</code>: De novo Assembly <p>Flye is a de novo assembler for long read data using repeat graphs. Compared to de Bruijn graphs, which require exact k-mer matches, repeat graphs can use approximate matches which better tolerates the error rate of ONT data.</p> <code>flye_read_type</code> input parameter <p>This input parameter specifies the type of sequencing reads being used for assembly. This parameter significantly impacts the assembly process and should match the characteristics of your input data. Below are the available options:</p> Parameter Explanation <code>--nano-hq</code> (default) Optimized for ONT high-quality reads, such as Guppy5+ SUP or Q20 (&lt;5% error). Recommended for ONT reads processed with Guppy5 or newer <code>--nano-raw</code> For ONT regular reads, pre-Guppy5 (&lt;20% error) <code>--nano-corr</code> ONT reads corrected with other methods (&lt;3% error) <code>--pacbio-raw</code> PacBio regular CLR reads (&lt;20% error) <code>--pacbio-corr</code> PacBio reads corrected with other methods (&lt;3% error) <code>--pacbio-hifi</code> PacBio HiFi reads (&lt;1% error) <p>Refer to the Flye documentation for detailed guidance on selecting the appropriate <code>flye_read_type</code> based on your sequencing data and additional optional paramaters.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>Flye Technical Details</p> Links WDL Task task_flye.wdl Software Source Code Flye on GitHub Software Documentation Flye Documentation Original Publication(s) Assembly of long, error-prone reads using repeat graphs <code>Bandage</code>: Graph Visualization <p>Bandage creates de novo assembly graphs containing the assembled contigs and the connections between those contigs. These graphs are useful for visualizing the assembly structure, identifying potential misassemblies, and understanding the relationships between contigs.</p> <p>Bandage Technical Details</p> Links WDL Task task_bandage_plot.wdl Software Source Code Bandage on GitHub Software Documentation Bandage Documentation Original Publication(s) Bandage: interactive visualization of de novo genome assemblies <code>Polypolish</code>: Hybrid Assembly Polishing for ONT and Illumina data <p>If short reads are provided with the optional <code>illumina_read1</code> and <code>illumina_read2</code> inputs, Polypolish will use those short-reads to correct errors in the long-read assemblies. Uniquely, Polypolish uses the short-read alignments where each read is aligned to all possible locations, meaning that even repeat regions will have error correction.</p> <p>Polypolish Technical Details</p> Links Task task_polypolish.wdl Software Source Code Polypolish on GitHub Software Documentation Polypolish Documentation Original Publication(s) Polypolish: short-read polishing of long-read bacterial genome assembliesHow low can you go? Short-read polishing of Oxford Nanopore bacterial genome assemblies <code>Medaka</code>: Polishing of Flye assembly (default; optional) <p>Polishing is optional and can be skipped by setting the <code>skip_polishing</code> variable to true. If polishing is skipped, then neither Medaka or Racon will run.</p> <p>Medaka is the default assembly polisher used in TheiaProk. Racon may be used alternatively, and if so, Medaka will not run. Medaka uses the raw reads to polish the assembly and generate a consensus sequence. </p> <p>Importantly, Medaka requires knowing the model that was used to generate the read data. There are several ways to provide this information:</p> <ul> <li>Automatic Model Selection: Automatically determines the most appropriate Medaka model based on the input data, ensuring optimal polishing results without manual intervention. </li> <li>User-Specified Model Override: Allows users to specify a particular <code>Medaka model</code> if automatic selection does not yield the desired outcome or for specialized use cases.</li> <li>Default Model: If both automatic model selection fails and no user-specified model is provided, Medaka defaults to the predefined fallback model <code>r1041_e82_400bps_sup_v5.0.0</code>. </li> </ul> <p>Medaka Model Resolution Process</p> <p>Medaka's automatic model selection uses the <code>medaka tools resolve_model</code> command to identify the appropriate model for polishing. This process relies on metadata embedded in the input file, which is typically generated by the basecaller. If the automatic selection fails to identify a suitable model, Medaka gracefully falls back to the default model to maintain workflow continuity. Users should verify the chosen model and consider specifying a model override if necessary.</p> <p>Medaka Technical Details</p> Links WDL Task task_medaka.wdl Software Source Code Medaka on GitHub Software Documentation Medaka Documentation <code>Racon</code>: Polishing of Flye assembly (alternative; optional) <p>Polishing is optional and can be skipped by setting the <code>skip_polishing</code> variable to true. If polishing is skipped, then neither Medaka or Racon will run.</p> <p><code>Racon</code> is an alternative to using <code>medaka</code> for assembly polishing, and can be run by setting the <code>polisher</code> input to \"racon\".  Racon is a consensus algorithm designed for refining raw de novo DNA assemblies generated from long, uncorrected sequencing reads.</p> <p>Racon Technical Details</p> Links WDL Task task_racon.wdl Software Source Code Racon on GitHub Software Documentation Racon Documentation Original Publication(s) Fast and accurate de novo genome assembly from long uncorrected reads <code>Filter Contigs</code>: Filter contigs below a threshold length and remove homopolymer contigs <p>This task filters the created contigs based on a user-defined minimum length threshold (default of 1000) and eliminates homopolymer contigs (contigs of any length that consist of a single nucleotide).</p> <p>This ensures high-quality assemblies by retaining only contigs that meet specified criteria. Detailed metrics on contig counts and sequence lengths before and after filtering are provided in the output.</p> <p>Filter Contigs Technical Details</p> Links WDL Task task_filter_contigs.wdl <code>Dnaapler</code>: Final Assembly Orientation <p>Dnaapler reorients contigs to start at specific reference points. Dnaapler supports the following modes, which can be indicated by filling the <code>dnaapler_mode</code> input variable with the desired mode. The default is <code>all</code>, which reorients contigs to start with <code>dnaA</code>, <code>terL</code>, <code>repA</code>, or <code>COG1474</code>.</p> <ul> <li>all: Reorients contigs to start with <code>dnaA</code>, <code>terL</code>, <code>repA</code>, or <code>COG1474</code> (Default)</li> <li>chromosome: Reorients to begin with the <code>dnaA</code> chromosomal replication initiator gene, commonly used for bacterial chromosome assemblies.</li> <li>plasmid: Reorients to start with the <code>repA</code> plasmid replication initiation gene, ideal for plasmid assemblie</li> <li>phage: Reorients to start with the <code>terL</code> large terminase subunit gene, used for bacteriophage assemblies</li> <li>archaea: Reorients to start with the <code>COG1474</code> archaeal Orc1/cdc6 gene, relevant for archaeal assemblies</li> <li>custom: Reorients based on a user-specified gene in amino acid FASTA format for experimental or unique workflows</li> <li>mystery: Reorients to start with a random CDS for exploratory purposes</li> <li>largest: Reorients to start with the largest CDS in the assembly, often useful for poorly annotated genomes</li> <li>nearest: Reorients to start with the first CDS nearest to the sequence start, resolving CDS breakpoints</li> <li>bulk: Processes multiple contigs to start with the desired start gene (<code>dnaA</code>, <code>terL</code>, <code>repA</code>, or custom)</li> </ul> <p>Dnaapler Technical Details</p> Links WDL Task task_dnaapler.wdl Software Source Code Dnaapler on GitHub Software Documentation Dnaapler Documentation Original Publication(s) Dnaapler: a tool to reorient circular microbial genomes <p>Flye-Denovo Technical Details</p> Links Subworkflow wf_flye_denovo.wdl"},{"location":"workflows/genomic_characterization/theiaeuk/#organism-agnostic-characterization","title":"Organism-agnostic characterization","text":"<p>These tasks are performed regardless of the organism and provide quality control and taxonomic assignment.</p> <code>GAMBIT</code>: Taxon Assignment <p><code>GAMBIT</code> determines the taxon of the genome assembly using a k-mer based approach to match the assembly sequence to the closest complete genome in a database, thereby predicting its identity. Sometimes, GAMBIT can confidently designate the organism to the species level. Other times, it is more conservative and assigns it to a higher taxonomic rank.</p> <p>For additional details regarding the GAMBIT tool and a list of available GAMBIT databases for analysis, please consult the GAMBIT tool documentation.</p> <p>GAMBIT Technical Details</p> Links Task task_gambit.wdl Software Source Code GAMBIT on GitHub Software Documentation GAMBIT ReadTheDocs Original Publication(s) GAMBIT (Genomic Approximation Method for Bacterial Identification and Tracking): A methodology to rapidly leverage whole genome sequencing of bacterial isolates for clinical identification <code>BUSCO</code>: Assembly Quality Assessment <p>BUSCO (Benchmarking Universal Single-Copy Orthologue) attempts to quantify the completeness and contamination of an assembly to generate quality assessment metrics. It uses taxa-specific databases containing genes that are all expected to occur in the given taxa, each in a single copy. BUSCO examines the presence or absence of these genes, whether they are fragmented, and whether they are duplicated (suggestive that additional copies came from contaminants).</p> <p>BUSCO notation </p> <p>Here is an example of BUSCO notation: <code>C:99.1%[S:98.9%,D:0.2%],F:0.0%,M:0.9%,n:440</code>. There are several abbreviations used in this output:</p> <ul> <li>Complete (C) - genes are considered \"complete\" when their lengths are within two standard deviations of the BUSCO group mean length.</li> <li>Single-copy (S) - genes that are complete and have only one copy.</li> <li>Duplicated (D) - genes that are complete and have more than one copy.</li> <li>Fragmented (F) - genes that are only partially recovered.</li> <li>Missing (M) - genes that were not recovered at all.</li> <li>Number of genes examined (n) - the number of genes examined.</li> </ul> <p>A high equity assembly will use the appropriate database for the taxa, have high complete (C) and single-copy (S) percentages, and low duplicated (D), fragmented (F) and missing (M) percentages. </p> <p>BUSCO Technical Details</p> Links Task task_busco.wdl Software Source Code BUSCO on GitLab Software Documentation https://busco.ezlab.org/ Orginal publication BUSCO: assessing genome assembly and annotation completeness with single-copy orthologs"},{"location":"workflows/genomic_characterization/theiaeuk/#organism-specific-characterization","title":"Organism-specific characterization","text":"<p>The TheiaEuk workflow automatically activates taxa-specific tasks after identification of the relevant taxa using <code>GAMBIT</code>. Many of these taxa-specific tasks do not require any additional inputs from the user.</p> Candidozyma auris (also known as Candida auris) <p>Three tools can be deployed when Candidozyma auris/Candida auris is  identified.</p> Cladetyping: clade determination <p>A custom GAMBIT database is created using six clade-specific Candidozyma auris reference genomes. Sequences undergo genomic signature comparison against this database, which then enables assignment to one of the six Candidozyma auris clades (Clade I to Clade VI) based on sequence similarity and phylogenetic relationships. This integrated approach ensures precise clade assignments, crucial for understanding the genetic diversity and epidemiology of Candidozyma auris.</p> <p>See more information on the reference information for the six clades below:</p> Clade Genome Accession Assembly Name Strain BioSample Accession Clade I GCA_002759435.3 Cand_auris_B8441_V3 B8441 SAMN05379624 Clade II GCA_003013715.2 ASM301371v2 B11220 SAMN05379608 Clade III GCA_002775015.1 Cand_auris_B11221_V1 B11221 SAMN05379609 Clade IV GCA_003014415.1 Cand_auris_B11243 B11243 SAMN05379619 Clade V GCA_016809505.1 ASM1680950v1 IFRC2087 SAMN11570381 Clade VI GCA_032714025.1 ASM3271402v1 F1580 SAMN36753179 <p>Clade VI annotation</p> <p>Clade VI does not have an available reference genome annotation at the time of adding the reference genome into Cladetyping. While Clade VI assignment is functional, downstream variant calling is not currently possible without an annotation. Users may provide a close relative annotation, such as Clade IV, though it is unknown if Clade VI variants can reliably be called with respect to such a reference. </p> <p>Cauris_Cladetyper Technical Details</p> Links Task task_cauris_cladetyper.wdl Software Source Code GAMBIT on GitHub Software Documentation GAMBIT Overview Original Publication(s) GAMBIT (Genomic Approximation Method for Bacterial Identification and Tracking): A methodology to rapidly leverage whole genome sequencing of bacterial isolates for clinical identification TheiaEuk: a species-agnostic bioinformatics workflow for fungal genomic characterization <code>amr_search</code>: Antimicrobial Resistance Profiling (optional) <p>To activate this task, set <code>run_amr_search</code> to be <code>true</code>.</p> <p>This task performs in silico antimicrobial resistance (AMR) profiling for supported species using AMRsearch, the primary tool used by Pathogenwatch to genotype and infer antimicrobial resistance (AMR) phenotypes from assembled microbial genomes.</p> <p>AMRsearch screens against Pathogenwatch's library of curated genotypes and inferred phenotypes, developed in collaboration with community experts. Resistance phenotypes are determined based on both resistance genes and mutations, and the system accounts for interactions between multiple SNPs, genes, and suppressors. Predictions follow S/I/R classification (Sensitive, Intermediate, Resistant).</p> <p>Currently, only a subset of species are supported by this task.</p> Supported Species <p>The following table shows the species name and the associated NCBI Code. If you are running AMR Search as part of TheiaProk and TheiaEuk, these codes will be automatically determined based on the GAMBIT predicted taxon, or the user-provided <code>expected_taxon</code> input.</p> Species NCBI Code Neisseria gonorrhoeae 485 Staphylococcus aureus 1280 Salmonella Typhi 90370 Streptococcus pneumoniae 1313 Klebisiella 570 Escherichia 561 Mycobacterium tuberculosis 1773 Candida auris 498019 Vibrio cholerae 666 Campylobacter 194 <p>Outputs:</p> <ul> <li>JSON Output: Contains the complete AMR profile, including detailed resistance state, detected resistance genes/mutations, and supporting BLAST results.</li> <li>CSV &amp; PDF Tables: An incorporated Python script, <code>parse_amr_json.py</code>, extracts and formats results into a CSV file and PDF summary table for easier visualization.</li> </ul> <p>amr_search Technical Details</p> Links Task task_amr_search.wdl Software Source Code AMRsearch on GitHub Software Documentation AMRsearch on GitHub Original Publication(s) PAARSNP: rapid genotypic resistance prediction for Neisseria gonorrhoeae <code>Snippy_Variants</code>: Antifungal Resistance Detection <p>To detect mutations that may confer antifungal resistance, <code>Snippy</code> is used to find all variants relative to the clade-specific reference, then these variants are queried for product names associated with resistance. It's important to note that unlike <code>amr_search</code>, this task reports all variants found in the searched targets.</p> <ul> <li>FKS1</li> <li>ERG11 (lanosterol 14-alpha demethylase)</li> <li>FUR1 (uracil phosphoribosyltransferase)</li> </ul> <p>We query <code>Snippy</code> results to see if any mutations were identified in those genes. By default, we automatically check for the following loci (which can be overwritten by the user). You will find the mutations next to the locus tag in the <code>theiaeuk_snippy_variants_hits</code> column corresponding gene name (see below):</p> TheiaEuk Search Term Corresponding Gene Name B9J08_005340 ERG6 B9J08_000401 FLO8 B9J08_005343 Hypothetical protein (PSK74852) B9J08_003102 MEC3 B9J08_003737 ERG3 lanosterol.14-alpha.demethylase ERG11 uracil.phosphoribosyltransferase FUR1 FKS1 FKS1 Known resistance-conferring mutations for Candidozyma auris <p>Mutations in these genes that are known to confer resistance are shown below</p> Organism Found in Gene name Gene locus AA mutation Drug Reference Candidozyma auris Human ERG11 Y132F Fluconazole Simultaneous Emergence of Multidrug-Resistant Candida auris on 3 Continents Confirmed by Whole-Genome Sequencing and Epidemiological Analyses Candidozyma auris Human ERG11 K143R Fluconazole Simultaneous Emergence of Multidrug-Resistant Candida auris on 3 Continents Confirmed by Whole-Genome Sequencing and Epidemiological Analyses Candidozyma auris Human ERG11 F126T Fluconazole Simultaneous Emergence of Multidrug-Resistant Candida auris on 3 Continents Confirmed by Whole-Genome Sequencing and Epidemiological Analyses Candidozyma auris Human FKS1 S639P Micafungin Activity of CD101, a long-acting echinocandin, against clinical isolates of Candida auris Candidozyma auris Human FKS1 S639P Caspofungin Activity of CD101, a long-acting echinocandin, against clinical isolates of Candida auris Candidozyma auris Human FKS1 S639P Anidulafungin Activity of CD101, a long-acting echinocandin, against clinical isolates of Candida auris Candidozyma auris Human FKS1 S639F Micafungin A multicentre study of antifungal susceptibility patterns among 350 Candida auris isolates (2009\u201317) in India: role of the ERG11 and FKS1 genes in azole and echinocandin resistance Candidozyma auris Human FKS1 S639F Caspofungin A multicentre study of antifungal susceptibility patterns among 350 Candida auris isolates (2009\u201317) in India: role of the ERG11 and FKS1 genes in azole and echinocandin resistance Candidozyma auris Human FKS1 S639F Anidulafungin A multicentre study of antifungal susceptibility patterns among 350 Candida auris isolates (2009\u201317) in India: role of the ERG11 and FKS1 genes in azole and echinocandin resistance Candidozyma auris Human FUR1 CAMJ_004922 F211I 5-flucytosine Genomic epidemiology of the UK outbreak of the emerging human fungal pathogen Candida auris Example Output Interpretation <p>For example, one sample may have the following output for the <code>theiaeuk_snippy_variants_hits</code> column:</p> <pre><code>lanosterol.14-alpha.demethylase: lanosterol 14-alpha demethylase (missense_variant c.428A&gt;G p.Lys143Arg; C:266 T:0),B9J08_000401: hypothetical protein (stop_gained c.424C&gt;T p.Gln142*; A:70 G:0)\n</code></pre> <p>Based on this, we can tell that ERG11 has a missense variant at position 143 (Lysine to Arginine) and B9J08_000401 (which is FLO8) has a stop-gained variant at position 142 (Glutamine to Stop).</p> <p>Snippy Variants Technical Details</p> Links Task task_snippy_variants.wdltask_snippy_gene_query.wdl Software Source Code Snippy on GitHub Software Documentation Snippy on GitHub Candida albicans <p>When this species is detected by the taxon ID tool, an antifungal resistance detection task is deployed.</p> <code>Snippy_Variants</code>: Antifungal Resistance Detection <p>To detect mutations that may confer antifungal resistance, <code>Snippy</code> is used to find all variants relative to the clade-specific reference, then these variants are queried for product names associated with resistance. It's important to note that unlike <code>amr_search</code>, this task reports all variants found in the searched targets.</p> <ul> <li>ERG11</li> <li>GCS1 (FKS1)</li> <li>FUR1</li> <li>RTA2</li> </ul> <p>We query <code>Snippy</code> results to see if any mutations were identified in those genes. By default, we automatically check for the following loci (which can be overwritten by the user). You will find the mutations next to the locus tag in the <code>theiaeuk_snippy_variants_hits</code> column corresponding gene name (see below):</p> TheiaEuk Search Term Corresponding Gene Name ERG11 ERG11 GCS1 FKS1 FUR1 FUR1 RTA2 RTA2 Example Output Interpretation <p>For example, one sample may have the following output for the <code>theiaeuk_snippy_variants_hits</code> column:</p> <pre><code>lanosterol.14-alpha.demethylase: lanosterol 14-alpha demethylase (missense_variant c.428A&gt;G p.Lys143Arg; C:266 T:0),B9J08_000401: hypothetical protein (stop_gained c.424C&gt;T p.Gln142*; A:70 G:0)\n</code></pre> <p>Based on this, we can tell that ERG11 has a missense variant at position 143 (Lysine to Arginine) and B9J08_000401 (which is FLO8) has a stop-gained variant at position 142 (Glutamine to Stop).</p> <p>Snippy Variants Technical Details</p> Links Task task_snippy_variants.wdltask_snippy_gene_query.wdl Software Source Code Snippy on GitHub Software Documentation Snippy on GitHub Aspergillus fumigatus <p>When this species is detected by the taxon ID tool an antifungal resistance detection task is deployed.</p> <code>Snippy_Variants</code>: Antifungal Resistance Detection <p>To detect mutations that may confer antifungal resistance, <code>Snippy</code> is used to find all variants relative to the clade-specific reference, then these variants are queried for product names associated with resistance. It's important to note that unlike <code>amr_search</code>, this task reports all variants found in the searched targets.</p> <ul> <li>Cyp51A</li> <li>HapE</li> <li>COX10 (AFUA_4G08340)</li> </ul> <p>We query <code>Snippy</code> results to see if any mutations were identified in those genes. By default, we automatically check for the following loci (which can be overwritten by the user). You will find the mutations next to the locus tag in the <code>theiaeuk_snippy_variants_hits</code> column corresponding gene name (see below):</p> TheiaEuk Search Term Corresponding Gene Name Cyp51A Cyp51A HapE HapE AFUA_4G08340 COX10 Example Output Interpretation <p>For example, one sample may have the following output for the <code>theiaeuk_snippy_variants_hits</code> column:</p> <pre><code>lanosterol.14-alpha.demethylase: lanosterol 14-alpha demethylase (missense_variant c.428A&gt;G p.Lys143Arg; C:266 T:0),B9J08_000401: hypothetical protein (stop_gained c.424C&gt;T p.Gln142*; A:70 G:0)\n</code></pre> <p>Based on this, we can tell that ERG11 has a missense variant at position 143 (Lysine to Arginine) and B9J08_000401 (which is FLO8) has a stop-gained variant at position 142 (Glutamine to Stop).</p> <p>Snippy Variants Technical Details</p> Links Task task_snippy_variants.wdltask_snippy_gene_query.wdl Software Source Code Snippy on GitHub Software Documentation Snippy on GitHub Cryptococcus neoformans <p>When this species is detected by the taxon ID tool an antifungal resistance detection task is deployed.</p> <code>Snippy_Variants</code>: Antifungal Resistance Detection <p>To detect mutations that may confer antifungal resistance, <code>Snippy</code> is used to find all variants relative to the clade-specific reference, then these variants are queried for product names associated with resistance. It's important to note that unlike <code>amr_search</code>, this task reports all variants found in the searched targets.</p> <ul> <li>ERG11 (CNA00300)</li> </ul> <p>We query <code>Snippy</code> results to see if any mutations were identified in those genes. By default, we automatically check for the following loci (which can be overwritten by the user). You will find the mutations next to the locus tag in the <code>theiaeuk_snippy_variants_hits</code> column corresponding gene name (see below):</p> TheiaEuk Search Term Corresponding Gene Name CNA00300 ERG11 Example Output Interpretation <p>For example, one sample may have the following output for the <code>theiaeuk_snippy_variants_hits</code> column:</p> <pre><code>lanosterol.14-alpha.demethylase: lanosterol 14-alpha demethylase (missense_variant c.428A&gt;G p.Lys143Arg; C:266 T:0),B9J08_000401: hypothetical protein (stop_gained c.424C&gt;T p.Gln142*; A:70 G:0)\n</code></pre> <p>Based on this, we can tell that ERG11 has a missense variant at position 143 (Lysine to Arginine) and B9J08_000401 (which is FLO8) has a stop-gained variant at position 142 (Glutamine to Stop).</p> <p>Snippy Variants Technical Details</p> Links Task task_snippy_variants.wdltask_snippy_gene_query.wdl Software Source Code Snippy on GitHub Software Documentation Snippy on GitHub"},{"location":"workflows/genomic_characterization/theiaeuk/#outputs","title":"Outputs","text":"TheiaEuk_Illumina_PETheiaEuk_ONT Variable Type Description amr_search_csv File CSV formatted AMR profile amr_search_docker String Docker image used to run AMR_Search amr_search_results File JSON formatted AMR profile including BLAST results amr_search_results_pdf File PDF formatted AMR profile amr_search_version String Version of AMR_Search libraries used assembler String Assembler used in digger_denovo subworkflow assembler_version String Version of the assembler used in digger_denovo assembly_fasta File De novo genome assembly in FASTA format assembly_length Int Length of assembly (total contig length) as determined by QUAST bbduk_docker String The Docker image for bbduk, which was used to remove the adapters from the sequences busco_database String BUSCO database used busco_docker String BUSCO docker image used busco_report File A plain text summary of the results in BUSCO notation busco_results String BUSCO results (see relevant toggle in this block) busco_version String BUSCO software version used cg_pipeline_docker String Docker file used for running CG-Pipeline on cleaned reads cg_pipeline_report_clean File TSV file of read metrics from clean reads, including average read length, number of reads, and estimated genome coverage cg_pipeline_report_raw File TSV file of read metrics from raw reads, including average read length, number of reads, and estimated genome coverage cladetyper_annotated_reference String The annotated reference file for the identified clade, \"None\" if no clade was identified/no annotation is inputted cladetyper_clade String The clade assigned to the input assembly cladetyper_docker_image String The Docker container used for the task cladetyper_gambit_version String The version of GAMBIT used for the analysis combined_mean_q_clean Float Mean quality score for the combined clean reads combined_mean_q_raw Float Mean quality score for the combined raw reads combined_mean_readlength_clean Float Mean read length for the combined clean reads combined_mean_readlength_raw Float Mean read length for the combined raw reads contigs_gfa File Assembly graph output generated by SPAdes (Illumina: PE, SE) or Flye (ONT), used to visualize and evaluate genome assembly results. est_coverage_clean Float Estimated coverage calculated from clean reads and genome length est_coverage_raw Float Estimated coverage calculated from raw reads and genome length fastp_html_report File The HTML report made with fastp fastp_version String The version of fastp used fastq_scan_clean1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about clean forward read quality and length fastq_scan_clean2_json File The JSON file output from <code>fastq-scan</code> containing summary stats about clean reverse read quality and length fastq_scan_num_reads_clean1 Int The number of forward reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_clean2 Int The number of reverse reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_clean_pairs String The number of read pairs after cleaning as calculated by fastq_scan fastq_scan_num_reads_raw1 Int The number of input forward reads as calculated by fastq_scan fastq_scan_num_reads_raw2 Int The number of input reserve reads as calculated by fastq_scan fastq_scan_num_reads_raw_pairs String The number of input read pairs as calculated by fastq_scan fastq_scan_raw1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about raw forward read quality and length fastq_scan_raw2_json File The JSON file output from <code>fastq-scan</code> containing summary stats about raw reverse read quality and length fastq_scan_version String The version of fastq_scan fastqc_clean1_html File An HTML file that provides a graphical visualization of clean forward read quality from fastqc to open in an internet browser fastqc_clean2_html File An HTML file that provides a graphical visualization of clean reverse read quality from fastqc to open in an internet browser fastqc_docker String The Docker container used for fastqc fastqc_num_reads_clean1 Int The number of forward reads after cleaning by fastqc fastqc_num_reads_clean2 Int The number of reverse reads after cleaning by fastqc fastqc_num_reads_clean_pairs String The number of read pairs after cleaning by fastqc fastqc_num_reads_raw1 Int The number of input forward reads by fastqc before cleaning fastqc_num_reads_raw2 Int The number of input reverse reads by fastqc before cleaning fastqc_num_reads_raw_pairs String The number of input read pairs by fastqc before cleaning fastqc_raw1_html File An HTML file that provides a graphical visualization of raw forward read quality from fastqc to open in an internet browser fastqc_raw2_html File An HTML file that provides a graphical visualization of raw reverse read quality from fastqc to open in an internet browser fastqc_version String Version of fastqc software used filtered_contigs_metrics File File containing metrics of contigs filtered gambit_closest_genomes File CSV file listing genomes in the GAMBIT database that are most similar to the query assembly gambit_db_version String Version of the GAMBIT database used gambit_docker String GAMBIT Docker used gambit_predicted_taxon String Taxon predicted by GAMBIT gambit_predicted_taxon_rank String Taxon rank of GAMBIT taxon prediction gambit_report File GAMBIT report in a machine-readable format gambit_version String Version of GAMBIT software used n50_value Int N50 of assembly calculated by QUAST number_contigs Int Total number of contigs in assembly qc_check String A string that indicates whether or not the sample passes a set of pre-determined and user-provided QC thresholds qc_standard File The file used in the QC Check task containing the QC thresholds. quast_gc_percent Float The GC percent of your sample quast_report File TSV report from QUAST quast_version String The version of QUAST r1_mean_q_raw Float Mean quality score of raw forward reads r1_mean_readlength_raw Float Mean read length of raw forward reads r2_mean_q_raw Float Mean quality score of raw reverse reads r2_mean_readlength_raw Float Mean read length of raw reverse reads rasusa_version String Version of RASUSA used for the analysis read1_clean File Forward read file after quality trimming and adapter removal read1_subsampled File Read1 FASTQ files downsampled to desired coverage read2_clean File Reverse read file after quality trimming and adapter removal read2_subsampled File Read2 FASTQ files downsampled to desired coverage read_screen_clean String PASS or FAIL result from clean read screening; FAIL accompanied by the reason(s) for failure read_screen_clean_tsv File Clean read screening report TSV depicting read counts, total read base pairs, and estimated genome length read_screen_raw String PASS or FAIL result from raw read screening; FAIL accompanied by the reason(s) for failure read_screen_raw_tsv File Raw read screening report TSV depicting read counts, total read base pairs, and estimated genome length seq_platform String Description of the sequencing methodology used to generate the input read data theiaeuk_illumina_pe_analysis_date String Date of TheiaEuk PE workflow execution theiaeuk_illumina_pe_version String TheiaEuk PE workflow version used theiaeuk_snippy_variants_bai String BAI file produced by the snippy module theiaeuk_snippy_variants_bam String BAM file produced by the snippy module theiaeuk_snippy_variants_coverage_tsv String TSV file containing coverage information for each base in the reference genome theiaeuk_snippy_variants_gene_query_results String File containing all lines from variants file matching gene query terms theiaeuk_snippy_variants_hits String String of all variant file entries matching gene query term theiaeuk_snippy_variants_num_reads_aligned String Number of reads aligned by snippy theiaeuk_snippy_variants_num_variants String Number of variants detected by snippy theiaeuk_snippy_variants_outdir_tarball String Tar compressed file containing full snippy output directory theiaeuk_snippy_variants_percent_ref_coverage String Percent of reference genome covered by snippy theiaeuk_snippy_variants_query String The gene query term(s) used to search variant theiaeuk_snippy_variants_query_check String Were the gene query terms present in the refence annotated genome file theiaeuk_snippy_variants_reference_genome String The reference genome used in the alignment and variant calling theiaeuk_snippy_variants_results String The variants file produced by snippy theiaeuk_snippy_variants_summary String A file summarizing the variants detected by snippy theiaeuk_snippy_variants_version String The version of the snippy_variants module being used trimmomatic_docker String The docker image used for the trimmomatic module in this workflow trimmomatic_version String The version of Trimmomatic used Variable Type Description amr_search_csv File CSV formatted AMR profile amr_search_docker String Docker image used to run AMR_Search amr_search_results File JSON formatted AMR profile including BLAST results amr_search_results_pdf File PDF formatted AMR profile amr_search_version String Version of AMR_Search libraries used assembly_fasta File De novo genome assembly in FASTA format assembly_length Int Length of assembly (total contig length) as determined by QUAST bandage_plot File Image file (PNG) visualizing the Flye assembly graph generated by Bandage bandage_version String Version of Bandage used busco_database String BUSCO database used busco_docker String BUSCO docker image used busco_report File A plain text summary of the results in BUSCO notation busco_results String BUSCO results (see relevant toggle in this block) busco_version String BUSCO software version used bwa_version String Version of BWA software used cladetype_annotated_ref String The annotated reference file for the identified clade, \"None\" if no clade was identified/no annotation is inputted cladetyper_clade String The clade assigned to the input assembly cladetyper_docker_image String The Docker container used for the task cladetyper_version String The version of Cladetyper used for the analysis contigs_gfa File Assembly graph output generated by SPAdes (Illumina: PE, SE) or Flye (ONT), used to visualize and evaluate genome assembly results. dnaapler_version String Version of dnaapler used est_coverage_clean Float Estimated coverage calculated from clean reads and genome length est_coverage_raw Float Estimated coverage calculated from raw reads and genome length est_genome_length Int Estimated genome length filtered_contigs_metrics File File containing metrics of contigs filtered flye_assembly_info String Information file from Flye assembly flye_version String Version of Flye software used gambit_closest_genomes_file File CSV file listing genomes in the GAMBIT database that are most similar to the query assembly gambit_db_version String Version of the GAMBIT database used gambit_docker String GAMBIT Docker used gambit_next_taxon String Next taxon predicted by GAMBIT gambit_next_taxon_rank String Next taxon rank predicted by GAMBIT gambit_predicted_taxon String Taxon predicted by GAMBIT gambit_predicted_taxon_rank String Taxon rank of GAMBIT taxon prediction gambit_report_file File GAMBIT report in a machine-readable format gambit_version String Version of GAMBIT software used medaka_model String Model used by Medaka medaka_version String Version of Medaka used merlin_tag String Merlin tag for the assembly n50_value Int N50 of assembly calculated by QUAST nanoplot_docker String Docker image for nanoplot nanoplot_html_clean File An HTML report describing the clean reads nanoplot_html_raw File An HTML report describing the raw reads nanoplot_num_reads_clean1 Int Number of clean reads nanoplot_num_reads_raw1 Int Number of raw reads nanoplot_r1_est_coverage_clean Float Estimated coverage on the clean reads by nanoplot nanoplot_r1_est_coverage_raw Float Estimated coverage on the raw reads by nanoplot nanoplot_r1_mean_q_clean Float Mean quality score of clean forward reads nanoplot_r1_mean_q_raw Float Mean quality score of raw forward reads nanoplot_r1_mean_readlength_clean Float Mean read length of clean forward reads nanoplot_r1_mean_readlength_raw Float Mean read length of raw forward reads nanoplot_r1_median_q_clean Float Median quality score of clean forward reads nanoplot_r1_median_q_raw Float Median quality score of raw forward reads nanoplot_r1_median_readlength_clean Float Median read length of clean forward reads nanoplot_r1_median_readlength_raw Float Median read length of raw forward reads nanoplot_r1_n50_clean Float N50 of clean forward reads nanoplot_r1_n50_raw Float N50 of raw forward reads nanoplot_r1_stdev_readlength_clean Float Standard deviation read length of clean forward reads nanoplot_r1_stdev_readlength_raw Float Standard deviation read length of raw forward reads nanoplot_tsv_clean File A TSV report describing the clean reads nanoplot_tsv_raw File A TSV report describing the raw reads nanoplot_version String Version of nanoplot used for analysis nanoq_version String Version of nanoq used in analysis number_contigs Int Total number of contigs in assembly polypolish_version String Version of Polypolish used porechop_version String Version of Porechop used quast_gc_percent Float The GC percent of your sample quast_report File TSV report from QUAST quast_version String The version of QUAST racon_version String Version of Racon used read1_clean File Forward read file after quality trimming and adapter removal read_screen_clean String PASS or FAIL result from clean read screening; FAIL accompanied by the reason(s) for failure read_screen_clean_tsv File Clean read screening report TSV depicting read counts, total read base pairs, and estimated genome length read_screen_raw String PASS or FAIL result from raw read screening; FAIL accompanied by the reason(s) for failure read_screen_raw_tsv File Raw read screening report TSV depicting read counts, total read base pairs, and estimated genome length theiaeuk_ont_analysis_date String Date of TheiaEuk_ONT workflow execution theiaeuk_ont_version String TheiaEuk_ONT workflow version used theiaeuk_snippy_variants_bai String BAI file produced by the snippy module theiaeuk_snippy_variants_bam String BAM file produced by the snippy module theiaeuk_snippy_variants_coverage_tsv String TSV file containing coverage information for each base in the reference genome theiaeuk_snippy_variants_gene_query_results String File containing all lines from variants file matching gene query terms theiaeuk_snippy_variants_hits String String of all variant file entries matching gene query term theiaeuk_snippy_variants_num_reads_aligned String Number of reads aligned by snippy theiaeuk_snippy_variants_num_variants String Number of variants detected by snippy theiaeuk_snippy_variants_outdir_tarball String Tar compressed file containing full snippy output directory theiaeuk_snippy_variants_percent_ref_coverage String Percent of reference genome covered by snippy theiaeuk_snippy_variants_query String The gene query term(s) used to search variant theiaeuk_snippy_variants_query_check String Were the gene query terms present in the refence annotated genome file theiaeuk_snippy_variants_results String The variants file produced by snippy theiaeuk_snippy_variants_summary String A file summarizing the variants detected by snippy theiaeuk_snippy_variants_version String The version of the snippy_variants module being used"},{"location":"workflows/genomic_characterization/theiameta/","title":"TheiaMeta","text":""},{"location":"workflows/genomic_characterization/theiameta/#theiameta","title":"TheiaMeta","text":""},{"location":"workflows/genomic_characterization/theiameta/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Genomic Characterization Any taxa v3.0.0 Yes Sample-level TheiaMeta_Illumina_PE_PHB"},{"location":"workflows/genomic_characterization/theiameta/#theiameta-workflows","title":"TheiaMeta Workflows","text":"<p>Genomic characterization of pathogens is an increasing priority for public health laboratories globally. The workflows in the TheiaMeta Genomic Characterization Series make the analysis of pathogens from metagenomic samples easy by taking raw next-generation sequencing (NGS) data and generating metagenome-assembled genomes (MAGs), either using a reference-genome or not.</p> <p>TheiaMeta can use one of two distinct methods for generating and processing the final assembly:</p> <ul> <li>If a reference genome is not provided, the de novo  assembly will be the final assembly. Additionally, go through a binning process where the contigs are separated into distinct files (\"bins\") according to composition and coverage such that each bin hopefully contains a single taxon.</li> <li>If a reference genome is provided by the user, the de novo  metagenomic assembly is filtered by mapping the contigs to the reference and those constitute the final assembly. No binning is necessary as the mapping will filter contigs that are likely the same taxon as the reference.</li> </ul> <p>TheiaMeta Workflow Diagram</p> <p></p>"},{"location":"workflows/genomic_characterization/theiameta/#inputs","title":"Inputs","text":"<p>The\u00a0TheiaMeta_Illumina_PE workflow\u00a0processes Illumina paired-end (PE) reads generated for metagenomic characterization (typically by shotgun). By default, this workflow will assume that input reads were generated using a 300-cycle sequencing kit (i.e. 2 x 150 bp reads). Modifications to the optional parameter for <code>trim_minlen</code> may be required to accommodate shorter read data, such as 2 x 75bp reads generated using a 150-cycle sequencing kit.</p> Terra Task Name Variable Type Description Default Value Terra Status theiameta_illumina_pe read1 File Illumina forward read file in FASTQ file format (compression optional) Required theiameta_illumina_pe read2 File Illumina reverse read file in FASTQ file format (compression optional) Required theiameta_illumina_pe samplename String The name of the sample being analyzed Required assembled_reads_percent cpu Int Number of CPUs to allocate to the task 2 Optional assembled_reads_percent disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional assembled_reads_percent docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Optional assembled_reads_percent memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional bwa cpu Int Number of CPUs to allocate to the task 6 Optional bwa disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional bwa docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional bwa memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional calculate_coverage cpu Int Number of CPUs to allocate to the task 2 Optional calculate_coverage disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional calculate_coverage docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/bedtools:2.31.0 Optional calculate_coverage memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional calculate_coverage_paf cpu Int Number of CPUs to allocate to the task 2 Optional calculate_coverage_paf disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional calculate_coverage_paf docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/quay/ubuntu:latest Optional calculate_coverage_paf memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional kraken2_clean cpu Int Number of CPUs to allocate to the task 4 Optional kraken2_clean disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional kraken2_clean docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Optional kraken2_clean memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional kraken2_raw cpu Int Number of CPUs to allocate to the task 4 Optional kraken2_raw disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional kraken2_raw docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Optional kraken2_raw memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional krona_clean cpu Int Number of CPUs to allocate to the task 2 Optional krona_clean disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional krona_clean docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/krona:2.8.1 Optional krona_clean memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional krona_raw cpu Int Number of CPUs to allocate to the task 2 Optional krona_raw disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional krona_raw docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/krona:2.8.1 Optional krona_raw memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional metaspades_pe cpu Int Number of CPUs to allocate to the task 4 Optional metaspades_pe disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional metaspades_pe docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/spades:3.12.0--h9ee0642_3 Optional metaspades_pe kmers String Kmers to use for the task Optional metaspades_pe memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional metaspades_pe metaspades_opts String Metaspades optional parameters Optional metaspades_pe phred_offset Int Phred offset to use for the task 33 Optional minimap2_assembly cpu Int Number of CPUs to allocate to the task 2 Optional minimap2_assembly disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional minimap2_assembly docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/minimap2:2.22 Optional minimap2_assembly memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional minimap2_assembly query2 File Internal component, do not modify Optional minimap2_assembly_correction cpu Int Number of CPUs to allocate to the task 2 Optional minimap2_assembly_correction disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional minimap2_assembly_correction docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/minimap2:2.22 Optional minimap2_assembly_correction long_read_flags Boolean Use long read sequencing specific flags for alignment FALSE Optional minimap2_assembly_correction memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional minimap2_reads cpu Int Number of CPUs to allocate to the task 2 Optional minimap2_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional minimap2_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/minimap2:2.22 Optional minimap2_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional pilon cpu Int Number of CPUs to allocate to the task 8 Optional pilon disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional pilon docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/pilon:1.24--hdfd78af_0 Optional pilon fix String Additional options for fixing assembly errors (all, snps, indels, gaps) Optional pilon memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional pilon min_base_quality Int Minimum base quality to consider a base for assembly Optional pilon min_depth Float Minimum depth to consider a region for assembly Optional pilon min_mapping_quality Int Minimum mapping quality to consider a read for assembly Optional quast cpu Int Number of CPUs to allocate to the task 2 Optional quast disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional quast docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/quast:5.0.2 Optional quast memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional read_QC_trim adapters File File with adapter sequences to be removed Optional read_QC_trim bbduk_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim call_midas Boolean True/False variable that determines if the MIDAS task should be called. FALSE Optional read_QC_trim extract_unclassified Boolean Internal component, do not modify FALSE Optional read_QC_trim fastp_args String Additional arguments to use with fastp --detect_adapter_for_pe -g -5 20 -3 20 Optional read_QC_trim host String Internal component, do not modify Optional read_QC_trim host_complete_only Boolean Internal component, do not modify FALSE Optional read_QC_trim host_decontaminate_mem Int Internal component, do not modify 32 Optional read_QC_trim host_is_accession Boolean Internal component, do not modify FALSE Optional read_QC_trim host_refseq Boolean Internal component, do not modify TRUE Optional read_QC_trim kraken_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim midas_db File The database used by the MIDAS task in .tar.gz format gs://theiagen-public-files-rp/terra/theiaprok-files/midas/midas_db_v1.2.tar.gz Optional read_QC_trim phix File A file containing the phix used during Illumina sequencing; used in the BBDuk task Optional read_QC_trim read_processing String The name of the tool to perform basic read processing; options: \"trimmomatic\" or \"fastp\" trimmomatic Optional read_QC_trim read_qc String The tool used for quality control (QC) of reads. Options are \"fastq_scan\" (default) and \"fastqc\" fastq_scan Optional read_QC_trim target_organism String Internal component, do not modify Optional read_QC_trim taxon_id Int Internal component, do not modify 0 Optional read_QC_trim trim_min_length Int Specifies minimum length of each read after trimming to be kept 75 Optional read_QC_trim trim_quality_min_score Int Specifies the average quality of bases in a sliding window to be kept 30 Optional read_QC_trim trim_window_size Int Specifies window size for trimming (the number of bases to average the quality across) 4 Optional read_QC_trim trimmomatic_args String Additional arguments to pass to trimmomatic. \"-phred33\" specifies the Phred Q score encoding which is almost always phred33 with modern sequence data. -phred33 Optional retrieve_aligned_contig_paf cpu Int Number of CPUs to allocate to the task 2 Optional retrieve_aligned_contig_paf disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional retrieve_aligned_contig_paf docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/seqkit:2.4.0--h9ee0642_0 Optional retrieve_aligned_contig_paf memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional retrieve_aligned_pe_reads_sam cpu Int Number of CPUs to allocate to the task 2 Optional retrieve_aligned_pe_reads_sam disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional retrieve_aligned_pe_reads_sam docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Optional retrieve_aligned_pe_reads_sam memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional retrieve_unaligned_pe_reads_sam cpu Int Number of CPUs to allocate to the task 2 Optional retrieve_unaligned_pe_reads_sam disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional retrieve_unaligned_pe_reads_sam docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Optional retrieve_unaligned_pe_reads_sam memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional sam_to_sorted_bam cpu Int Number of CPUs to allocate to the task 2 Optional sam_to_sorted_bam disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional sam_to_sorted_bam docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Optional sam_to_sorted_bam memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional sam_to_sorted_bam min_qual Int Minimum quality score for reads to be included in the analysis Optional semibin cpu Int Number of CPUs to allocate to the task 6 Optional semibin disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional semibin docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/semibin:2.0.2--pyhdfd78af_0 Optional semibin environment String Environment model to use. Options:\u2022 human_gut\u2022 dog_gut\u2022 ocean\u2022 soil\u2022 cat_gut\u2022 human_oral\u2022 mouse_gut\u2022 pig_gut\u2022 built_environment\u2022 wastewater\u2022 chicken_caecum\u2022 global global Optional semibin memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional semibin min_length Int Minimum contig length for binning 1000 Optional semibin ratio Float If the ratio of the number of base pairs of contigs between 1000-2500 bp smaller than this value, the minimal length will be set as 1000bp, otherwise 2500bp. 0.05 Optional sort_bam_assembly_correction cpu Int Number of CPUs to allocate to the task 2 Optional sort_bam_assembly_correction disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional sort_bam_assembly_correction docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Optional sort_bam_assembly_correction memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional sort_bam_assembly_correction min_qual Int Minimum quality score for reads to be included in the analysis Optional theiameta_illumina_pe kraken2_db File A Kraken2 database in .tar.gz format gs://theiagen-public-resources-rp/reference_data/databases/kraken2/k2_standard_08gb_20230605.tar.gz Optional theiameta_illumina_pe output_additional_files Boolean Output additional files such as aligned and unaligned reads to reference FALSE Optional theiameta_illumina_pe reference File Reference file for consensus calling, in FASTA format Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/genomic_characterization/theiameta/#workflow-tasks","title":"Workflow Tasks","text":"<code>versioning</code>: Version Capture <p>The <code>versioning</code> task captures the workflow version from the GitHub (code repository) version.</p> <p>Version Capture Technical details</p> Links Task task_versioning.wdl"},{"location":"workflows/genomic_characterization/theiameta/#read-cleaning-and-qc","title":"Read Cleaning and QC","text":"<code>HRRT</code>: Human Host Sequence Removal <p>All reads of human origin are removed, including their mates, by using NCBI's human read removal tool (HRRT). </p> <p>HRRT is based on the SRA Taxonomy Analysis Tool and employs a k-mer database constructed of k-mers from Eukaryota derived from all human RefSeq records with any k-mers found in non-Eukaryota RefSeq records subtracted from the database.</p> <p>NCBI-Scrub Technical Details</p> Links Task task_ncbi_scrub.wdl Software Source Code HRRT on GitHub Software Documentation HRRT on NCBI <code>read_QC_trim</code>: Read Quality Trimming, Adapter Removal, Quantification, and Identification <p><code>read_QC_trim</code> is a sub-workflow that removes low-quality reads, low-quality regions of reads, and sequencing adapters to improve data quality. It uses a number of tasks, described below. The differences between the PE and SE versions of the <code>read_QC_trim</code> sub-workflow lie in the default parameters, the use of two or one input read file(s), and the different output files.</p> <p>By default, <code>read_processing</code> is set to <code>\"trimmomatic\"</code>. To use <code>fastp</code> instead, set <code>read_processing</code> to <code>\"fastp\"</code>. These tasks are mutually exclusive.</p> <code>Trimmomatic</code>: Read Trimming (default) <p>Read proccessing is available via <code>Trimmomatic</code> by default.</p> <p>Trimmomatic trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>Trimmomatic</code> Technical Details</p> Links Task task_trimmomatic.wdl Software Source Code Trimmomatic on GitHub Software Documentation Trimmomatic Website Original Publication(s) Trimmomatic: a flexible trimmer for Illumina sequence data <code>fastp</code>: Read Trimming (alternative) <p>To activate this task, set <code>read_processing</code> to <code>\"fastp\"</code>.</p> <p><code>fastp</code> trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>fastp</code> also has additional default parameters and features that are not a part of <code>trimmomatic</code>'s default configuration.</p> <code>fastp</code> default read-trimming parameters Parameter Explanation -g enables polyG tail trimming -5 20 enables read end-trimming -3 20 enables read end-trimming --detect_adapter_for_pe enables adapter-trimming only for paired-end reads <p>Additional arguments can be passed using the <code>fastp_args</code> optional parameter.</p> <p>Trimmomatic and fastp Technical Details</p> Links Task task_fastp.wdl Software Source Code fastp on GitHub Software Documentation fastp on GitHub Original Publication(s) fastp: an ultra-fast all-in-one FASTQ preprocessor <code>BBDuk</code>: Adapter Trimming and PhiX Removal <p>Adapters are manufactured oligonucleotide sequences attached to DNA fragments during the library preparation process. In Illumina sequencing, these adapter sequences are required for attaching reads to flow cells. You can read more about Illumina adapters here. For genome analysis, it's important to remove these sequences since they're not actually from your sample. If you don't remove them, the downstream analysis may be affected.</p> <p>The <code>bbduk</code> task removes adapters from sequence reads. To do this:</p> <ul> <li>Repair from the BBTools package reorders reads in paired fastq files to ensure the forward and reverse reads of a pair are in the same position in the two fastq files (it re-pairs).</li> <li>BBDuk  (\"Bestus Bioinformaticus\" Decontamination Using Kmers) is then used to trim the adapters and filter out all reads that have a 31-mer match to PhiX, which is commonly added to Illumina sequencing runs to monitor and/or improve overall run quality.</li> </ul> <p>BBDuk Technical Details</p> Links Task task_bbduk.wdl Software Source Code BBMap on SourceForge Software Documentation BBDuk Guide (archived) <p>By default, <code>read_qc</code> is set to <code>\"fastq_scan\"</code>. To use <code>fastqc</code> instead, set <code>read_qc</code> to <code>\"fastqc\"</code>. These tasks are mutually exclusive.</p> <code>fastq-scan</code>: Read Quantification (default) <p>Read quantification is available via <code>fastq-scan</code> by default.</p> <p><code>fastq-scan</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p><code>fastq-scan</code> Technical Details</p> Links Task task_fastq_scan.wdl Software Source Code fastq-scan on GitHub Software Documentation fastq-scan on GitHub <code>FastQC</code>: Read Quantification (alternative) <p>To activate this task, set <code>read_qc</code> to <code>\"fastqc\"</code>.</p> <p><code>FastQC</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>This tool also provides a graphical visualization of the read quality.</p> <p><code>FastQC</code> Technical Details</p> Links Task task_fastqc.wdl Software Source Code FastQC on Github Software Documentation FastQC Website <code>MIDAS</code>: Read Identification (optional) <p>To activate this task, set <code>call_midas</code> to <code>true</code>.</p> <p>The <code>MIDAS</code> task is for the identification of reads to detect contamination with non-target taxa.</p> <p>The MIDAS tool was originally designed for metagenomic sequencing data but has been co-opted for use with bacterial isolate WGS methods. It can be used to detect contamination present in raw sequencing data by estimating bacterial species abundance in bacterial isolate WGS data. If a secondary genus is detected above a relative frequency of 0.01 (1%), then the sample should fail QC and be investigated further for potential contamination.</p> <p>This task is similar to those used in commercial software, BioNumerics, for estimating secondary species abundance.</p> How are the MIDAS output columns determined? <p>Example MIDAS report in the <code>midas_report</code> column:</p> species_id count_reads coverage relative_abundance Salmonella_enterica_58156 3309 89.88006645 0.855888033 Salmonella_enterica_58266 501 11.60606061 0.110519371 Salmonella_enterica_53987 99 2.232896237 0.021262881 Citrobacter_youngae_61659 46 0.995216227 0.009477003 Escherichia_coli_58110 5 0.123668877 0.001177644 <p>MIDAS report column descriptions:</p> <ul> <li>species_id: species identifier</li> <li>count_reads: number of reads mapped to marker genes</li> <li>coverage: estimated genome-coverage (i.e. read-depth) of species in metagenome</li> <li>relative_abundance: estimated relative abundance of species in metagenome</li> </ul> <p>The value in the <code>midas_primary_genus</code> column is derived by ordering the rows in order of \"relative_abundance\" and identifying the genus of top species in the \"species_id\" column (Salmonella). The value in the <code>midas_secondary_genus</code> column is derived from the genus of the second-most prevalent genus in the \"species_id\" column (Citrobacter). The <code>midas_secondary_genus_abundance</code> column is the \"relative_abundance\" of the second-most prevalent genus (0.009477003). The <code>midas_secondary_genus_coverage</code> is the \"coverage\" of the second-most prevalent genus (0.995216227).</p> <p>MIDAS Reference Database Overview</p> <p>The MIDAS reference database is a comprehensive tool for identifying bacterial species in metagenomic and bacterial isolate WGS data. It includes several layers of genomic data, helping detect species abundance and potential contaminants.</p> <p>Key Components of the MIDAS Database</p> <ol> <li> <p>Species Groups: </p> <ul> <li>MIDAS clusters bacterial genomes based on 96.5% sequence identity, forming over 5,950 species groups from 31,007 genomes. These groups align with the gold-standard species definition (95% ANI), ensuring highly accurate species identification.</li> </ul> </li> <li> <p>Genomic Data Structure:</p> <ul> <li>Marker Genes: Contains 15 universal single-copy genes used to estimate species abundance.</li> <li>Representative Genome: Each species group has a selected representative genome, which minimizes genetic variation and aids in accurate SNP identification.</li> <li>Pan-genome: The database includes clusters of non-redundant genes, with options for multi-level clustering (e.g., 99%, 95%, 90% identity), enabling MIDAS to identify gene content within strains at various clustering thresholds.</li> </ul> </li> <li> <p>Taxonomic Annotation: </p> <ul> <li>Genomes are annotated based on consensus Latin names. Discrepancies in name assignments may occur due to factors like unclassified genomes or genus-level ambiguities.</li> </ul> </li> </ol> <p>Using the Default MIDAS Database</p> <p>TheiaProk and TheiaEuk use the pre-loaded MIDAS database in Terra (see input table for current version) by default for bacterial species detection in metagenomic data, requiring no additional setup.</p> <p>Create a Custom MIDAS Database</p> <p>Users can also build their own custom MIDAS database if they want to include specific genomes or configurations. This custom database can replace the default MIDAS database used in Terra. To build a custom MIDAS database, follow the MIDAS GitHub guide on building a custom database. Once the database is built, users can upload it to a Google Cloud Storage bucket or Terra workkspace and provide the link to the database in the <code>midas_db</code> input variable.</p> <p>MIDAS Technical Details</p> Links Task task_midas.wdl Software Source Code MIDAS on GitHub Software Documentation MIDAS on GitHub Original Publication(s) An integrated metagenomics pipeline for strain profiling reveals novel patterns of bacterial transmission and biogeography <p>read_QC_trim Technical Details</p> Links Subworkflow wf_read_QC_trim_pe.wdlwf_read_QC_trim_se.wdl <p><code>Kraken2</code> is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>Database-dependent</p> <p>This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz</code>.</p> <p>Kraken2 is run on the set of raw reads, provided as input, as well as the set of clean reads that are resulted from the <code>read_QC_trim</code> workflow</p> <p>The Kraken2 software is database-dependent and taxonomic assignments are highly sensitive to the database used. An appropriate database should contain the expected organism(s) (e.g. Escherichia coli) and other taxa that may be present in the reads (e.g. Citrobacter freundii, a common contaminant).</p> <p>Kraken2 Technical Details</p> Links Task task_kraken2.wdl Software Source Code Kraken2 on GitHub Software Documentation Kraken2 Documentation Original Publication(s) Improved metagenomic analysis with Kraken 2"},{"location":"workflows/genomic_characterization/theiameta/#assembly","title":"Assembly","text":"<code>metaspades</code>: De Novo Metagenomic Assembly <p>While metagenomics has emerged as a technology of choice for analyzing bacterial populations, the assembly of metagenomic data remains challenging. A dedicated metagenomic assembly algorithm is necessary to circumvent the challenge of interpreting variation. metaSPAdes addresses various challenges of metagenomic assembly by capitalizing on computational ideas that proved to be useful in assemblies of single cells and highly polymorphic diploid genomes.</p> <p><code>metaspades</code> is a de novo assembler that first constructs a de Bruijn graph of all the reads using the SPAdes algorithm. Through various graph simplification procedures, paths in the assembly graph are reconstructed that correspond to long genomic fragments within the metagenome. For more details, please see the original publication.</p> <p>Common errors with SPAdes v4+</p> <p>We found that MetaSPAdes v4+ can raise segmentation fault errors using our validation set of metagenomic samples, so MetaSPAdes v3+ is called by TheiaMeta. A newer version can be called by referencing a more recent container (e.g. \"us-docker.pkg.dev/general-theiagen/staphb/spades:4.2.0\") via the <code>metaspades_pe</code> <code>docker</code> input.</p> <p>MetaSPAdes Technical Details</p> Links Task task_metaspades.wdl Software Source Code SPAdes on GitHub Software Documentation SPAdes Manual Original Publication(s) metaSPAdes: a new versatile metagenomic assembler <code>minimap2</code>: Assembly Correction <p><code>minimap2</code> is a popular aligner that is used to align reads (or assemblies) to an assembly file. In minimap2, \"modes\" are a group of preset options.</p> <p>The mode used in this task is <code>sr</code> which is intended for \"short single-end reads without splicing\". The <code>sr</code> mode indicates the following parameters should be used: <code>-k21 -w11 --sr --frag=yes -A2 -B8 -O12,32 -E2,1 -b0 -r100 -p.5 -N20 -f1000,5000 -n2 -m20 -s40 -g100 -2K50m --heap-sort=yes --secondary=no</code>. The output file is in SAM format.</p> <p>For more information regarding modes and the available options for <code>minimap2</code>, please see the minimap2 manpage</p> <p>minimap2 Technical Details</p> Links Task task_minimap2.wdl Software Source Code minimap2 on GitHub Software Documentation minimap2 Original Publication(s) Minimap2: pairwise alignment for nucleotide sequences <code>samtools</code>: SAM File Conversion  <p>This task converts the output SAM file from minimap2 and converts it to a BAM file. It then sorts the BAM based on the read names, and then generates an index file.</p> <p>samtools Technical Details</p> Links Task task_samtools.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <code>Pilon</code>: Assembly Polishing <p><code>Pilon</code> is a tool that uses read alignments to correct errors in an assembly.</p> <p>It is used to polish the assembly produced by metaSPAdes. The input to Pilon is the sorted BAM file produced by <code>samtools</code>, and the original draft assembly produced by <code>metaspades</code>.</p> <p>Pilon Technical Details</p> Links Task task_pilon.wdl Software Source Code Pilon on GitHub Software Documentation Pilon Wiki Original Publication(s) Pilon: An Integrated Tool for Comprehensive Microbial Variant Detection and Genome Assembly Improvement"},{"location":"workflows/genomic_characterization/theiameta/#reference-alignment-contig-filtering","title":"Reference Alignment &amp; Contig Filtering","text":"<p>These tasks only run if a reference is provided through the <code>reference</code> optional input.</p> <code>minimap2</code>: Assembly Alignment and Contig Filtering <p><code>minimap2</code> is a popular aligner that is used to align reads (or assemblies) to an assembly file. In minimap2, \"modes\" are a group of preset options.</p> <p>The mode used in this task is <code>asm20</code> which is intended for \"long assembly to reference mapping\". The <code>asm20</code> mode indicates the following parameters should be used: <code>-k19 -w10 -U50,500 --rmq -r100k -g10k -A1 -B4 -O6,26 -E2,1 -s200 -z200 -N50</code>. The output file is in PAF format.</p> <p>For more information regarding modes and the available options for <code>minimap2</code>, please see the minimap2 manpage</p> <p>minimap2 Technical Details</p> Links Task task_minimap2.wdl Software Source Code minimap2 on GitHub Software Documentation minimap2 Original Publication(s) Minimap2: pairwise alignment for nucleotide sequences Parsing the PAF file into a FASTA file <p>Following the <code>minimap2</code> alignment, the output PAF file is parsed into a FASTA file using <code>seqkit</code> and then coverage is calculated using <code>awk</code>.</p> <p><code>parse_mapping</code> Technical Details</p> Links Task task_parse_mapping.wdl#retrieve_aligned_contig_paftask_parse_mapping.wdl#calculate_coverage_paf Software Source Code seqkit on GitHub Software Documentation seqkit Original Publication(s) SeqKit: A Cross-Platform and Ultrafast Toolkit for FASTA/Q File ManipulationSeqKit2: A Swiss army knife for sequence and alignment processing"},{"location":"workflows/genomic_characterization/theiameta/#assembly-qc","title":"Assembly QC","text":"<p>This task is run on either:</p> <ul> <li>the reference-aligned contigs (if a reference was provided), or </li> <li>the Pilon-polished assembly_fasta (if no reference was provided).</li> </ul> <code>quast</code>: Assembly Quality Assessment <p>QUAST stands for QUality ASsessment Tool. It evaluates genome/metagenome assemblies by computing various metrics without a reference being necessary. It includes useful metrics such as number of contigs, length of the largest contig and N50. </p> <p>QUAST Technical Details</p> Links Task task_quast.wdl Software Source Code QUAST on GitHub Software Documentation https://quast.sourceforge.net/ Original Publication(s) QUAST: quality assessment tool for genome assemblies"},{"location":"workflows/genomic_characterization/theiameta/#binning","title":"Binning","text":"<p>These tasks only run if a reference is not provided.</p> <code>bwa</code>: Read alignment to the assembly <p>If a reference is not provided, BWA (Burrow-Wheeler Aligner) is used to align the clean reads to the Pilon-polished assembly_fasta.</p> <p>BWA Technical Details</p> Links Task task_bwa.wdl Software Source Code BWA on GitHub Software Documentation BWA Documentation Original Publication(s) Fast and accurate short read alignment with Burrows-Wheeler transform <code>semibin2</code>: Metagenomic binning <p>After the alignment, the resulting BAM file and index and the Pilon-polished assembly_fasta will be binned with <code>semibin2</code>, a command-line tool for metagenomic binning with deep learning. Specifically, it uses a semi-supervised siamese neural network that uses knowledge from reference genomes while maintaining reference-exclusive bins. By default, the <code>global</code> environemnt model is used, though a variety of options that may be better suited for your sample are available, and are listed in the relevant inputs section.</p> <p>SemiBin2 Technical Details</p> Links Task task_semibin2.wdl Software Source Code SemiBin2 on GitHub Software Documenttation SemiBin2 ReadTheDocs Original Publication(s) A deep siamese neural network improves metagenome-assembled genomes in microbiome datasets across different environments"},{"location":"workflows/genomic_characterization/theiameta/#additional-outputs","title":"Additional Outputs","text":"<p>These tasks only run if <code>output_additional_files</code> is set to <code>true</code> (default is <code>false</code>).</p> <code>minimap2</code>: Read Alignment to the Assembly <p><code>minimap2</code> is a popular aligner that is used to align reads (or assemblies) to an assembly file. In minimap2, \"modes\" are a group of preset options.</p> <p>The mode used in this task is <code>sr</code> which is intended for \"short single-end reads without splicing\". The <code>sr</code> mode indicates the following parameters should be used: <code>-k21 -w11 --sr --frag=yes -A2 -B8 -O12,32 -E2,1 -b0 -r100 -p.5 -N20 -f1000,5000 -n2 -m20 -s40 -g100 -2K50m --heap-sort=yes --secondary=no</code>. The output file is in SAM format.</p> <p>For more information regarding modes and the available options for <code>minimap2</code>, please see the minimap2 manpage</p> <p>minimap2 Technical Details</p> Links Task task_minimap2.wdl Software Source Code minimap2 on GitHub Software Documentation minimap2 Original Publication(s) Minimap2: pairwise alignment for nucleotide sequences <code>samtools</code>: SAM File Conversion (Round 2) <p>This task converts the output SAM file from minimap2 and converts it to a BAM file. It then sorts the BAM based on the read names, and then generates an index file.</p> <p>samtools Technical Details</p> Links Task task_samtools.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools Parsing the BAM file <p>Several tasks follow that perform the following functions:</p> <ol> <li>Calculates the average depth of coverage of the assembly using <code>bedtools</code>.</li> <li>Retrieves from the BAM file any unaligned reads using <code>samtools</code>.</li> <li>Retrieves from the BAM file any aligned reads using <code>samtools</code>.</li> <li>Calculates the percentage of reads that were assembled using <code>samtools</code>.</li> </ol> <p><code>parse_mapping</code> Technical Details</p> Links Task task_parse_mapping.wdl#calculate_coveragetask_parse_mapping.wdl#retrieve_pe_reads_bamtask_parse_mapping.wdl#assembled_reads_percent Software Source Code bedtools on GitHubsamtools on GitHub Software Documentation bedtools ReadTheDocssamtools Original Publication(s) BEDTools: a flexible suite of utilities for comparing genomic featuresThe Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools"},{"location":"workflows/genomic_characterization/theiameta/#outputs","title":"Outputs","text":"Variable Type Description assembly_fasta File The final recovered metagenome-assembled genome (MAG). \"A MAG represents a microbial genome by a group of sequences from genome assembly with similar characteristics. It enables [the identification of] novel species [to] understand their potential functions in a dynamic ecosystem\"<sup>1</sup> assembly_length Int Length of assembly (total contig length) as determined by QUAST assembly_mean_coverage Float Mean sequencing depth throughout the consensus assembly. Generated after performing primer trimming and calculated using the SAMtools coverage command average_read_length Float Average read length bbduk_docker String The Docker image for bbduk, which was used to remove the adapters from the sequences bedtools_docker String The Docker image for bedtools, which was used to calculate coverage bedtools_version String The version of bedtools, which was used to calculate coverage contig_number Int The number of contigs in the assembly_fasta (see description for <code>assembly_fasta</code>) fastp_html_report File The HTML report made with fastp fastp_version String The version of fastp used fastq_scan_clean1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about clean forward read quality and length fastq_scan_clean2_json File The JSON file output from <code>fastq-scan</code> containing summary stats about clean reverse read quality and length fastq_scan_docker String The Docker image of fastq_scan fastq_scan_num_reads_clean1 Int The number of forward reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_clean2 Int The number of reverse reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_clean_pairs String The number of read pairs after cleaning as calculated by fastq_scan fastq_scan_num_reads_raw1 Int The number of input forward reads as calculated by fastq_scan fastq_scan_num_reads_raw2 Int The number of input reserve reads as calculated by fastq_scan fastq_scan_num_reads_raw_pairs String The number of input read pairs as calculated by fastq_scan fastq_scan_raw1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about raw forward read quality and length fastq_scan_raw2_json File The JSON file output from <code>fastq-scan</code> containing summary stats about raw reverse read quality and length fastq_scan_version String The version of fastq_scan fastqc_clean1_html File An HTML file that provides a graphical visualization of clean forward read quality from fastqc to open in an internet browser fastqc_clean2_html File An HTML file that provides a graphical visualization of clean reverse read quality from fastqc to open in an internet browser fastqc_docker String The Docker container used for fastqc fastqc_num_reads_clean1 Int The number of forward reads after cleaning by fastqc fastqc_num_reads_clean2 Int The number of reverse reads after cleaning by fastqc fastqc_num_reads_clean_pairs String The number of read pairs after cleaning by fastqc fastqc_num_reads_raw1 Int The number of input forward reads by fastqc before cleaning fastqc_num_reads_raw2 Int The number of input reverse reads by fastqc before cleaning fastqc_num_reads_raw_pairs String The number of input read pairs by fastqc before cleaning fastqc_raw1_html File An HTML file that provides a graphical visualization of raw forward read quality from fastqc to open in an internet browser fastqc_raw2_html File An HTML file that provides a graphical visualization of raw reverse read quality from fastqc to open in an internet browser fastqc_version String Version of fastqc software used kraken2_docker String Docker image used to run kraken2 kraken2_percent_human_clean Float The percentage of human-classified reads in the sample's clean reads kraken2_percent_human_raw Float The percentage of human-classified reads in the sample's raw reads kraken2_report_clean File The full Kraken report for the sample's clean reads kraken2_report_raw File The full Kraken report for the sample's raw reads kraken2_version String The version of kraken2 used krona_docker String The docker image of Krona krona_html_clean File The KronaPlot after reads are cleaned krona_html_raw File The KronaPlot before reads are cleaned krona_version String The version of Krona largest_contig Int The size of the largest contig in basepairs metaspades_docker String The Docker image of metaspades metaspades_version String The version of metaspades midas_primary_genus String The primary genus detected by MIDAS midas_report File TSV report of full MIDAS results minimap2_docker String The Docker image of minimap2 minimap2_version String The version of minimap2 ncbi_scrub_docker String The Docker image for NCBI's HRRT (human read removal tool) percent_coverage Float The percentage coverage of the reference genome provided if one was provided percentage_mapped_reads Float Percentage of reads that successfully aligned to the reference genome. This value is calculated by number of mapped reads / total number of reads x 100. pilon_docker String The Docker image for pilon pilon_version String The version of pilon quast_docker String The Docker image of QUAST quast_version String The version of QUAST read1_clean File Forward read file after quality trimming and adapter removal read1_dehosted File The dehosted forward reads file; suggested read file for SRA submission read1_mapped File The mapped forward reads to the assembly read1_unmapped File The unmapped forwards reads to the assembly read2_clean File Reverse read file after quality trimming and adapter removal read2_dehosted File The dehosted reverse reads file; suggested read file for SRA submission read2_mapped File The mapped reverse reads to the assembly read2_unmapped File The unmapped reverse reads to the assembly samtools_docker String The Docker image of samtools samtools_version String The version of SAMtools used to sort and index the alignment file semibin_bins Array[File] An array of binned metagenomic assembled genome files semibin_docker String The Docker image of semibin semibin_version String The version of Semibin used theiameta_illumina_pe_analysis_date String The date of analysis theiameta_illumina_pe_version String The version of TheiaMeta used during execution trimmomatic_docker String The docker image used for the trimmomatic module in this workflow trimmomatic_version String The version of Trimmomatic used"},{"location":"workflows/genomic_characterization/theiameta/#references","title":"References","text":"<p>Human read removal tool (HRRT): https://github.com/ncbi/sra-human-scrubber</p> <p>Trimmomatic: Anthony M. Bolger\u00a0and others, Trimmomatic: a flexible trimmer for Illumina sequence data,\u00a0Bioinformatics, Volume 30, Issue 15, August 2014, Pages 2114\u20132120,\u00a0https://doi.org/10.1093/bioinformatics/btu170</p> <p>Fastq-Scan: https://github.com/rpetit3/fastq-scan</p> <p>metaSPAdes: Sergey Nurk and others, metaSPAdes: a new versatile metagenomic assembler,\u00a0Genome Res. 2017 May; 27(5): 824\u2013834.,\u00a0https://doi.org/10.1101%2Fgr.213959.116</p> <p>Pilon: Bruce J. Walker and others. Pilon: An Integrated Tool for Comprehensive Microbial Variant Detection and Genome Assembly Improvement. Plos One. November 19, 2014. https://doi.org/10.1371/journal.pone.0112963</p> <p>Minimap2: Heng Li, Minimap2: pairwise alignment for nucleotide sequences,\u00a0Bioinformatics, Volume 34, Issue 18, September 2018, Pages 3094\u20133100,\u00a0https://doi.org/10.1093/bioinformatics/bty191</p> <p>QUAST: Alexey Gurevich\u00a0and others, QUAST: quality assessment tool for genome assemblies,\u00a0Bioinformatics, Volume 29, Issue 8, April 2013, Pages 1072\u20131075,\u00a0https://doi.org/10.1093/bioinformatics/btt086</p> <p>Samtools: Li, Heng, Bob Handsaker, Alec Wysoker, Tim Fennell, Jue Ruan, Nils Homer, Gabor Marth, Goncalo Abecasis, Richard Durbin, and 1000 Genome Project Data Processing Subgroup. 2009. The Sequence Alignment/Map format and SAMtools. Bioinformatics 25(16): 2078-2079. https://doi.org/10.1093/bioinformatics/btp352</p> <p>BEDtools: Quinlan AR and Hall IM, 2010. BEDTools: a flexible suite of utilities for comparing genomic features. Bioinformatics. 26, 6, pp. 841\u2013842. https://doi.org/10.1093/bioinformatics/btq033</p> <p>Bcftools: Petr Danecek, James K Bonfield, Jennifer Liddle, John Marshall, Valeriu Ohan, Martin O Pollard, Andrew Whitwham, Thomas Keane, Shane A McCarthy, Robert M Davies, Heng Li. Twelve years of SAMtools and BCFtools. GigaScience, Volume 10, Issue 2, February 2021, giab008, https://doi.org/10.1093/gigascience/giab008</p> <p>Semibin2: Shaojun Pan, Xing-Ming Zhao, Luis Pedro Coelho, SemiBin2: self-supervised contrastive learning leads to better MAGs for short- and long-read sequencing,\u00a0Bioinformatics, Volume 39, Issue Supplement_1, June 2023, Pages i21\u2013i29,\u00a0https://doi.org/10.1093/bioinformatics/btad209</p> <ol> <li> <p>Direct quote from the abstract of Yang C, Chowdhury D, Zhang Z, Cheung WK, Lu A, Bian Z, Zhang L. A review of computational tools for generating metagenome-assembled genomes from metagenomic sequencing data. Comput Struct Biotechnol J. 2021;19:6301-14. doi: 10.1016/j.csbj.2021.11.028. This is a paper from 2021 that reviews some of the tools used in this workflow, though not all.\u00a0\u21a9</p> </li> </ol>"},{"location":"workflows/genomic_characterization/theiaprok/","title":"TheiaProk Workflow Series","text":""},{"location":"workflows/genomic_characterization/theiaprok/#theiaprok-workflow-series","title":"TheiaProk Workflow Series","text":""},{"location":"workflows/genomic_characterization/theiaprok/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Genomic Characterization Bacteria vX.X.X Some optional features incompatible, Yes Sample-level TheiaProk_Illumina_PE_PHB, TheiaProk_Illumina_SE_PHB, TheiaProk_ONT_PHB, TheiaProk_FASTA_PHB"},{"location":"workflows/genomic_characterization/theiaprok/#theiaprok-workflows","title":"TheiaProk Workflows","text":"<p>The TheiaProk workflows are for the assembly, quality assessment, and characterization of bacterial genomes. There are currently four TheiaProk workflows designed to accommodate different kinds of input data:</p> <ol> <li>Illumina paired-end sequencing (TheiaProk_Illumina_PE)</li> <li>Illumina single-end sequencing (TheiaProk_Illumina_SE)</li> <li>ONT sequencing (TheiaProk_ONT)</li> <li>Genome assemblies (TheiaProk_FASTA)</li> </ol> TheiaProk_Illumina_PETheiaProk_ONT <p>TheiaProk Illumina PE Workflow Diagram</p> <p></p> <p>TheiaProk ONT Workflow Diagram</p> <p></p> <p>All input reads are processed through \"core tasks\" in the TheiaProk Illumina and ONT workflows. These undertake read trimming and assembly appropriate to the input data type. TheiaProk workflows subsequently launch default genome characterization modules for quality assessment, species identification, antimicrobial resistance gene detection, sequence typing, and more. For some taxa identified, \"taxa-specific sub-workflows\" will be automatically activated, undertaking additional taxa-specific characterization steps. When setting up each workflow, users may choose to use \"optional tasks\" as additions or alternatives to tasks run in the workflow by default.</p>"},{"location":"workflows/genomic_characterization/theiaprok/#inputs","title":"Inputs","text":"<p>Input Data</p> TheiaProk_Illumina_PETheiaProk_Illumina_SETheiaProk_ONTTheiaProk_FASTA <p>The TheiaProk_Illumina_PE workflow takes in Illumina paired-end read data. Read file names should end with <code>.fastq</code> or <code>.fq</code>, with the optional addition of <code>.gz</code>. When possible, Theiagen recommends zipping files with gzip before Terra uploads to minimize data upload time.</p> <p>By default, the workflow anticipates\u00a02 x 150bp\u00a0reads (i.e. the input reads were generated using a 300-cycle sequencing kit). Modifications to the optional parameter for <code>trim_minlen</code> may be required to accommodate shorter read data, such as the 2 x 75bp reads generated using a 150-cycle sequencing kit.</p> <p>TheiaProk_Illumina_SE takes in Illumina single-end reads. Read file names should end with <code>.fastq</code> or <code>.fq</code>, with the optional addition of <code>.gz</code>. Theiagen highly recommends zipping files with gzip before uploading to Terra to minimize data upload time &amp; save on storage costs.</p> <p>By default, the workflow anticipates 1 x 35 bp reads  (i.e. the input reads were generated using a 70-cycle sequencing kit). Modifications to the optional parameter for <code>trim_minlen</code> may be required to accommodate longer read data.</p> <p>The TheiaProk_ONT workflow takes in base-called ONT read data. Read file names should end with <code>.fastq</code> or <code>.fq</code>, with the optional addition of <code>.gz</code>. When possible, Theiagen recommends zipping files with gzip before uploading to Terra to minimize data upload time.</p> <p>The ONT sequencing kit and base-calling approach can produce substantial variability in the amount and quality of read data. Genome assemblies produced by the TheiaProk_ONT workflow must be quality assessed before reporting results.</p> <p>The TheiaProk_FASTA workflow takes in assembly files in FASTA format.</p> <p>Skip Characterization</p> <p>Ever wanted to skip characterization? Now you can! Set the optional input <code>perform_characterization</code> to <code>false</code> to only generate an assembly and run assembly QC.</p> TheiaProk_Illumina_PETheiaProk_Illumina_SETheiaProk_ONTTheiaProk_FASTA Terra Task Name Variable Type Description Default Value Terra Status theiaprok_illumina_pe read1 File Illumina forward read file in FASTQ file format (compression optional) Required theiaprok_illumina_pe read2 File Illumina reverse read file in FASTQ file format (compression optional) Required theiaprok_illumina_pe samplename String The name of the sample being analyzed Required abricate cpu Int Number of CPUs to allocate to the task 2 Optional abricate disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional abricate docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid Optional abricate memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional abricate min_percent_coverage Int Minimum DNA %coverage for the Abricate task 80 Optional abricate min_percent_identity Int Minimum DNA %identity for the Abricate task 80 Optional amrfinderplus_task cpu Int Number of CPUs to allocate to the task 2 Optional amrfinderplus_task detailed_drug_class Boolean If set to true, amrfinderplus_amr_classes and amrfinderplus_amr_subclasses outputs will be created FALSE Optional amrfinderplus_task disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional amrfinderplus_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ncbi-amrfinderplus:4.0.23-2025-07-16.1 Optional amrfinderplus_task hide_point_mutations Boolean If set to true, point mutations are not reported FALSE Optional amrfinderplus_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional amrfinderplus_task min_percent_coverage Float Minimum proportion of reference gene covered for a BLAST-based hit (Methods BLAST or PARTIAL).\" Attribute should be a float ranging from 0-1, such as 0.6 (equal to 60% coverage) 0.5 Optional amrfinderplus_task min_percent_identity Float Minimum identity for a blast-based hit hit (Methods BLAST or PARTIAL). -1 means use a curated threshold if it exists and 0.9 otherwise. Setting this value to something other than -1 will override any curated similarity cutoffs. Attribute should be a float ranging from 0-1, such as 0.95 (equal to 95% identity) 0.9 Optional amrfinderplus_task separate_betalactam_genes Boolean Report beta-Lactam AMR genes separated out by all beta-lactam and the respective beta-lactam subclasses FALSE Optional ani ani_threshold Float ANI value threshold must be surpassed in order to output the ani_top_species_match. If a genome does not surpass this threshold (and the percent_bases_aligned_threshold) then the ani_top_species_match output String will show a warning instead of a genus &amp; species. 80.0 Optional ani cpu Int Number of CPUs to allocate to the task 4 Optional ani disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ani docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mummer:4.0.0-rgdv2 Optional ani mash_filter Float Mash distance threshold over which ANI is not calculated 0.9 Optional ani memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional ani percent_bases_aligned_threshold Float Threshold regarding the proportion of bases aligned between the query genome and reference genome. If a genome does not surpass this threshold (and the ani_threshold) then the ani_top_species_match output String will show a warning instead of a genus &amp; species. 70.0 Optional ani ref_genome File If not set, uses all 43 genomes in RGDv2 Optional arln_stats cpu Int Number of CPUs to allocate to the task 2 Optional arln_stats disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional arln_stats docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/arln_stats:1.0.0 Optional arln_stats memory Int Amount of memory/RAM (in GB) to allocate to the task 5 Optional bakta bakta_opts String Parameters to pass to bakta from https://github.com/oschwengers/bakta#usage Optional bakta compliant Boolean If true, forces Genbank/ENA/DDJB compliant headers in Bakta output files FALSE Optional bakta cpu Int Number of CPUs to allocate to the task 8 Optional bakta disk_size Int Amount of storage (in GB) to allocate to the task 200 Optional bakta docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/bakta:1.10.3 Optional bakta memory Int Amount of memory/RAM (in GB) to allocate to the task 24 Optional bakta prodigal_tf File Prodigal training file to use for CDS prediction by bakta Optional bakta proteins File Fasta file of trusted protein sequences for CDS annotation Optional busco cpu Int Number of CPUs to allocate to the task 2 Optional busco disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional busco docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ezlabgva/busco:v5.7.1_cv1 Optional busco eukaryote Boolean Assesses eukaryotic organisms, rather than prokaryotic organisms FALSE Optional busco memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional cg_pipeline_clean cg_pipe_opts String Options to pass to CG-Pipeline for clean read assessment --fast Optional cg_pipeline_clean cpu Int Number of CPUs to allocate to the task 1 Optional cg_pipeline_clean disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional cg_pipeline_clean docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/lyveset:1.1.4f Optional cg_pipeline_clean memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional cg_pipeline_raw cg_pipe_opts String Options to pass to CG-Pipeline for raw read assessment --fast Optional cg_pipeline_raw cpu Int Number of CPUs to allocate to the task 1 Optional cg_pipeline_raw disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional cg_pipeline_raw docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/lyveset:1.1.4f Optional cg_pipeline_raw memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional clean_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional clean_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional clean_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional clean_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional digger_denovo assembler String Assembler to use (spades, skesa, megahit) skesa Optional digger_denovo assembler_options String Assembler-specific options that you might choose for the selected assembler Optional digger_denovo bwa_cpu Int Number of CPUs to allocate to the task 6 Optional digger_denovo bwa_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional digger_denovo bwa_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional digger_denovo bwa_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional digger_denovo call_pilon Boolean Whether to run Pilon polishing after assembly FALSE Optional digger_denovo filter_contigs_cpu Int Number of CPUs to allocate to the task 1 Optional digger_denovo filter_contigs_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional digger_denovo filter_contigs_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/shovilter:0.2 Optional digger_denovo filter_contigs_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional digger_denovo filter_contigs_min_coverage Float Minimum coverage threshold for contig filtering 2.0 Optional digger_denovo filter_contigs_min_length Int Minimum length threshold for contig filtering 200 Optional digger_denovo filter_contigs_skip_coverage_filter Boolean Skip filtering contigs based on coverage FALSE Optional digger_denovo filter_contigs_skip_homopolymer_filter Boolean Skip filtering contigs containing homopolymers FALSE Optional digger_denovo filter_contigs_skip_length_filter Boolean Skip filtering contigs based on length FALSE Optional digger_denovo kmers String K-mer sizes for assembly (comma-separated) Optional digger_denovo megahit_cpu Int Number of CPUs to allocate to the task 4 Optional digger_denovo megahit_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional digger_denovo megahit_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/megahit:1.2.9 Optional digger_denovo megahit_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional digger_denovo min_contig_length Int Minimum contig length to retain in final assembly 200 Optional digger_denovo pilon_cpu Int Number of CPUs to allocate to the task 8 Optional digger_denovo pilon_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional digger_denovo pilon_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/pilon:1.24--hdfd78af_0 Optional digger_denovo pilon_fix String Potential issues with assembly to try and automatically fix (snps, indels, gaps, local, all, bases, none) bases Optional digger_denovo pilon_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional digger_denovo pilon_min_base_quality Int Minimum base quality to keep 3 Optional digger_denovo pilon_min_depth Float Minimum coverage threshold for variant calling: when set to a value \u22651, it requires that absolute depth of coverage; when set to a fraction &lt;1, it requires coverage at least that fraction of the mean coverage for the region 0.25 Optional digger_denovo pilon_min_mapping_quality Int Minimum mapping quality for a read to count in pileups 60 Optional digger_denovo run_filter_contigs Boolean Whether to run contig filtering step TRUE Optional digger_denovo skesa_cpu Int Number of CPUs to allocate to the task 4 Optional digger_denovo skesa_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional digger_denovo skesa_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/skesa:2.4.0 Optional digger_denovo skesa_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional digger_denovo spades_cpu Int Number of CPUs to allocate to the task 16 Optional digger_denovo spades_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional digger_denovo spades_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/spades:4.1.0 Optional digger_denovo spades_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional digger_denovo spades_type String SPAdes assembly mode (isolate, meta, rna, etc.), more can be found here isolate Optional export_taxon_table cpu Int Number of CPUs to allocate to the task 1 Optional export_taxon_table disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional export_taxon_table docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Optional export_taxon_table memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional gambit cpu Int Number of CPUs to allocate to the task 1 Optional gambit disk_size Int Amount of storage (in GB) to allocate to the task 20 Optional gambit docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Optional gambit gambit_db_genomes File Database of metadata for assembled query genomes; requires complementary signatures file. If not provided, uses default database \"/gambit-db\" gs://gambit-databases-rp/2.0.0/gambit-metadata-2.0.1-20250505.gdb Optional gambit gambit_db_signatures File Signatures file; requires complementary genomes file. If not specified, the file from the docker container will be used. gs://gambit-databases-rp/2.0.0/gambit-signatures-2.0.1-20250505.gs Optional gambit memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional gamma cpu Int Number of CPUs to allocate to the task 2 Optional gamma disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional gamma docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/gamma:2.2 Optional gamma extended_output Boolean GAMMA will provide the extended output when set to true FALSE Optional gamma gamma_db File Multifasta sequence database GAMMA is to use for gene matching gs://theiagen-public-resources-rp/reference_data/databases/gamma/default_ResFinderDB_Combined_05-06-20.fsa Optional gamma memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional gamma min_length_percent_gammas Int Threshold of match length percent used by GAMMA-s 20 Optional gamma min_percent_identity Int Threshold of identity for gene matches in percent 90 Optional gamma output_fasta Boolean Allows GAMMA to output gene matches in FASTA format TRUE Optional gamma output_gff Boolean Allows GAMMA to output gene matches in GFF format TRUE Optional gamma run_gammas Boolean Turns on GAMMA-S which runs GAMMA on nucleotide sequences rather than translating input sequences and matches FALSE Optional kmerfinder cpu Int Number of CPUs to allocate to the task 4 Optional kmerfinder disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional kmerfinder docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/kmerfinder:3.0.2--hdfd78af_0 Optional kmerfinder kmerfinder_args String Kmerfinder additional arguments Optional kmerfinder kmerfinder_db File Bacterial database for KmerFinder gs://theiagen-public-resources-rp/reference_data/databases/kmerfinder/kmerfinder_bacteria_20230911.tar.gz Optional kmerfinder memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional merlin_magic abricate_abaum_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid Optional merlin_magic abricate_abaum_min_percent_coverage Int Minimum DNA percent coverage Optional merlin_magic abricate_abaum_min_percent_identity Int Minimum DNA percent identity; set to 95 because there is a strict threshold of 95% identity for typing purposes 95 Optional merlin_magic abricate_vibrio_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid Optional merlin_magic abricate_vibrio_min_percent_coverage Int Minimum DNA percent coverage 80 Optional merlin_magic abricate_vibrio_min_percent_identity Int Minimum DNA percent identity 80 Optional merlin_magic agrvate_agr_typing_only Boolean Set to true to skip agr operon extraction and frameshift detection FALSE Optional merlin_magic agrvate_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/agrvate:1.0.2--hdfd78af_0 Optional merlin_magic amr_search_cpu Int Number of CPUs to allocate to the task 2 Optional merlin_magic amr_search_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional merlin_magic amr_search_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/amrsearch:0.2.1 Optional merlin_magic amr_search_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional merlin_magic assembly_only Boolean Set to true if only analyzing input assembly FALSE Optional merlin_magic call_poppunk Boolean If true, runs PopPUNK for GPSC cluster designation for S. pneumoniae TRUE Optional merlin_magic call_shigeifinder_reads_input Boolean If set to \"true\", the ShigEiFinder task will run again but using read files as input instead of the assembly file. Input is shown but not used for TheiaProk_FASTA. FALSE Optional merlin_magic call_stxtyper Boolean If set to \"true\", the StxTyper task will run on all samples regardless of the gambit_predicted_taxon output. Useful if you suspect a non-E.coli or non-Shigella sample contains stx genes. FALSE Optional merlin_magic call_tbp_parser Boolean If set to \"true\", activates the tbp_parser module and results in more outputs, including\u00a0tbp_parser_looker_report_csv, tbp_parser_laboratorian_report_csv,  tbp_parser_lims_report_csv, tbp_parser_coverage_report, and tbp_parser_genome_percent_coverage FALSE Optional merlin_magic cauris_cladetyper_docker_image String Internal component, do not modify us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Optional merlin_magic cladetyper_kmer_size Int Internal component, do not modify Optional merlin_magic cladetyper_max_distance Float Internal component, do not modify 0.1 Optional merlin_magic cladetyper_ref_clade1 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade1_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade2 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade2_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade3 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade3_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade4 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade4_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade5 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade5_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade6 File The reference assembly for clade 6 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade6_GCA_032714025.1_ASM3271402v1_genomic.fasta Optional merlin_magic cladetyper_ref_clade6_annotated File The path to the annotated reference for clade 6 Optional merlin_magic clockwork_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/cdcgov/varpipe_wgs_with_refs:2bc7234074bd53d9e92a1048b0485763cd9bbf6f4d12d5a1cc82bfec8ca7d75e Optional merlin_magic ectyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/ectyper:1.0.0--pyhdfd78af_1 Optional merlin_magic ectyper_h_min_percent_coverage Int Minumum percent coverage required for an H antigen allele match 50 Optional merlin_magic ectyper_h_min_percent_identity Int Percent identity required for an H antigen allele match 95 Optional merlin_magic ectyper_o_min_percent_coverage Int Minumum percent coverage required for an O antigen allele match 90 Optional merlin_magic ectyper_o_min_percent_identity Int Percent identity required for an O antigen allele match 90 Optional merlin_magic ectyper_print_alleles Boolean Set to true to print the allele sequences as the final column FALSE Optional merlin_magic ectyper_verify Boolean Set to true to enable E. coli species verification FALSE Optional merlin_magic emmtyper_align_diff Int Threshold for difference between alignment length and subject length in BLAST hit. Optional merlin_magic emmtyper_cluster_distance Int Distance between cluster of matches to consider as different clusters. Optional merlin_magic emmtyper_culling_limit Int Total hits to return in a position. Optional merlin_magic emmtyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/emmtyper:0.2.0--py_0 Optional merlin_magic emmtyper_gap Int Threshold gap to allow in BLAST hit. Optional merlin_magic emmtyper_max_size Int Maximum size of PCR product. Optional merlin_magic emmtyper_min_good Int Minimum size where there must be 2 matches for each mismatch. Optional merlin_magic emmtyper_min_percent_identity Int Minimal percent identity of sequence. Optional merlin_magic emmtyper_min_perfect Int Minimum size of perfect match at 3' primer end. Optional merlin_magic emmtyper_mismatch Int Threshold for number of mismatch to allow in BLAST hit. Optional merlin_magic emmtyper_wf String Choose workflow [blast pcr] merlin_magic emmtypingtool_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/emmtypingtool:0.0.1 Optional merlin_magic genotyphi_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.11.0 Optional merlin_magic hicap_broken_gene_length Int Minimum length to consider a broken gene 60 Optional merlin_magic hicap_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/hicap:1.0.3--py_0 Optional merlin_magic hicap_min_broken_gene_percent_identity Float Minimum percentage identity to consider a broken gene 0.8 Optional merlin_magic hicap_min_gene_percent_coverage Float Minimum percentage coverage to consider a single gene complete 0.8 Optional merlin_magic hicap_min_gene_percent_identity Float Minimum percentage identity to consider a single gene complete 0.7 Optional merlin_magic kaptive_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kaptive:2.0.3 Optional merlin_magic kaptive_low_gene_percent_identity Float Percent identity threshold for what counts as a low identity match in the gene BLAST search 95 Optional merlin_magic kaptive_min_percent_coverage Float Minimum required percent coverage for the gene BLAST search via tBLASTn 80 Optional merlin_magic kaptive_min_percent_identity Float Minimum required percent identity for the gene BLAST search via tBLASTn 90 Optional merlin_magic kaptive_start_end_margin Int Determines flexibility in identifying the start and end of a locus - if this value is 10, a locus match that is missing the first 8 base pairs will still count as capturing the start of the locus 10 Optional merlin_magic kleborate_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kleborate:2.2.0 Optional merlin_magic kleborate_min_kaptive_confidence String {None,Low,Good,High,Very_high,Perfect} Minimum Kaptive confidence to call K/O loci - confidence levels below this will be reported as unknown Good Optional merlin_magic kleborate_min_percent_coverage Float Minimum alignment percent coverage for main results 80 Optional merlin_magic kleborate_min_percent_identity Float Minimum alignment percent identity for main results 90 Optional merlin_magic kleborate_min_spurious_percent_coverage Float Minimum alignment percent coverage for spurious results 40 Optional merlin_magic kleborate_min_spurious_percent_identity Float Minimum alignment percent identity for spurious results 80 Optional merlin_magic kleborate_skip_kaptive Boolean Equivalent to --kaptive_k --kaptive_ FALSE Optional merlin_magic kleborate_skip_resistance Boolean Set to true to turn on resistance genes screening (default: no resistance gene screening) FALSE Optional merlin_magic legsta_docker_image String Internal component, do not modify Optional merlin_magic lissero_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/lissero:0.4.9--py_0 Optional merlin_magic lissero_min_percent_coverage Float Minimum percent coverage of the gene to accept a match 95 Optional merlin_magic lissero_min_percent_identity Float Minimum percent identity to accept a match 95 Optional merlin_magic meningotype_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/meningotype:0.8.5--pyhdfd78af_0 Optional merlin_magic ngmaster_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ngmaster:1.0.0 Optional merlin_magic ont_data Boolean Set to true if your data is ONT FASTQ files FALSE Optional merlin_magic paired_end Boolean Set to true if your data is paired-end FASTQ files TRUE Optional merlin_magic pasty_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pasty:1.0.3 Optional merlin_magic pasty_min_percent_coverage Int Minimum coverage of a O-antigen to be considered for serogrouping by pasty 95 Optional merlin_magic pasty_min_percent_identity Int Minimum percent identity for a blast hit to be considered for serogrouping 95 Optional merlin_magic pbptyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pbptyper:1.0.4 Optional merlin_magic pbptyper_min_percent_coverage Int Minimum percent coverage to count a hit 90 Optional merlin_magic pbptyper_min_percent_identity Int Minimum percent identity to count a hit 90 Optional merlin_magic poppunk_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/poppunk:2.4.0 Optional merlin_magic poppunk_gps_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_clusters.csv Optional merlin_magic poppunk_gps_dists_npy File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.dists.npy Optional merlin_magic poppunk_gps_dists_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.dists.pkl Optional merlin_magic poppunk_gps_external_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_external_clusters.csv Optional merlin_magic poppunk_gps_fit_npz File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_fit.npz Optional merlin_magic poppunk_gps_fit_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_fit.pkl Optional merlin_magic poppunk_gps_graph_gt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_graph.gt Optional merlin_magic poppunk_gps_h5 File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.h5 Optional merlin_magic poppunk_gps_qcreport_txt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_qcreport.txt Optional merlin_magic poppunk_gps_refs File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs Optional merlin_magic poppunk_gps_refs_dists_npy File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.dists.npy Optional merlin_magic poppunk_gps_refs_dists_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.dists.pkl Optional merlin_magic poppunk_gps_refs_graph_gt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6refs_graph.gt Optional merlin_magic poppunk_gps_refs_h5 File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.h5 Optional merlin_magic poppunk_gps_unword_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_unword_clusters.csv Optional merlin_magic run_amr_search Boolean If set to true AMR_Search workflow will be run if species is part of supported taxon, see AMR_Search docs. FALSE Optional merlin_magic seqsero2_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/seqsero2:1.2.1 Optional merlin_magic seroba_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/seroba:1.0.2 Optional merlin_magic serotypefinder_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/serotypefinder:2.0.1 Optional merlin_magic shigatyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/shigatyper:2.0.5 Optional merlin_magic shigeifinder_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/shigeifinder:1.3.5 Optional merlin_magic sistr_cpu Int Number of CPUs to allocate to the task 2 Optional merlin_magic sistr_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional merlin_magic sistr_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/sistr_cmd:1.1.1--pyh864c0ab_2 Optional merlin_magic sistr_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional merlin_magic sistr_use_full_cgmlst_db Boolean Set to true to use the full set of cgMLST alleles which can include highly similar alleles. By default the smaller \"centroid\" alleles or representative alleles are used for each marker FALSE Optional merlin_magic snippy_base_quality Int Internal component, do not modify Optional merlin_magic snippy_gene_query_docker_image String Internal component, do not modify Optional merlin_magic snippy_map_qual Int Internal component, do not modify Optional merlin_magic snippy_maxsoft Int Internal component, do not modify Optional merlin_magic snippy_min_coverage Int Internal component, do not modify Optional merlin_magic snippy_min_frac Float Internal component, do not modify Optional merlin_magic snippy_min_quality Int Internal component, do not modify Optional merlin_magic snippy_query_gene String Internal component, do not modify Optional merlin_magic snippy_reference_afumigatus File Internal component, do not modify gs://theiagen-public-resources-rp/reference_data/eukaryotic/aspergillus/Aspergillus_fumigatus_GCF_000002655.1_ASM265v1_genomic.gbff Optional merlin_magic snippy_reference_cryptoneo File Internal component, do not modify gs://theiagen-public-resources-rp/reference_data/eukaryotic/cryptococcus/Cryptococcus_neoformans_GCF_000091045.1_ASM9104v1_genomic.gbff Optional merlin_magic snippy_variants_docker_image String Internal component, do not modify Optional merlin_magic sonneityping_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Optional merlin_magic sonneityping_mykrobe_opts String Additional options for mykrobe in sonneityping Optional merlin_magic spatyper_do_enrich Boolean Set to true to enable PCR product enrichment FALSE Optional merlin_magic spatyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/spatyper:0.3.3--pyhdfd78af_3 Optional merlin_magic srst2_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/srst2:0.2.0-vcholerae Optional merlin_magic srst2_gene_max_mismatch Int Maximum number of mismatches for SRST2 to call a gene as present 2000 Optional merlin_magic srst2_max_divergence Int Maximum divergence, in percentage, for SRST2 to call a gene as present 20 Optional merlin_magic srst2_min_depth Int Minimum depth of coverage for SRST2 to call a gene as present 5 Optional merlin_magic srst2_min_edge_depth Int Minimum edge depth for SRST2 to call a gene as present 2 Optional merlin_magic srst2_min_percent_coverage Int Minimum breadth of coverage for SRST2 to call a gene as present 80 Optional merlin_magic staphopia_sccmec_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/staphopia-sccmec:1.0.0--hdfd78af_0 Optional merlin_magic stxtyper_cpu Int Number of CPUs to allocate to the task 1 Optional merlin_magic stxtyper_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional merlin_magic stxtyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/stxtyper:1.0.42 Optional merlin_magic stxtyper_enable_debug Boolean When enabled, additional messages are printed and files in $TMPDIR are not removed after running FALSE Optional merlin_magic stxtyper_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional merlin_magic tbp_parser_add_cs_lims Boolean Set to true add cycloserine results to the LIMS report FALSE Optional merlin_magic tbp_parser_config File The configuration file to use, in YAML format (overrides all other arguments except input_json and input_bam) Optional merlin_magic tbp_parser_coverage_regions_bed File A bed file that lists the regions to be considered for QC Optional merlin_magic tbp_parser_debug Boolean Activate the debug mode on tbp_parser; increases logging outputs TRUE Optional merlin_magic tbp_parser_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/tbp-parser:2.6.0 Optional merlin_magic tbp_parser_etha237_frequency Float Minimum frequency for a mutation in ethA at protein position 237 to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_expert_rule_regions_bed File A file that contains the regions where R mutations and expert rules are applied Optional merlin_magic tbp_parser_min_depth Int Minimum depth for a variant to pass QC in tbp_parser 10 Optional merlin_magic tbp_parser_min_frequency Float The minimum frequency for a mutation to pass QC 0.1 Optional merlin_magic tbp_parser_min_percent_coverage Float The minimum coverage for a region to pass QC in tbp_parser 100 Optional merlin_magic tbp_parser_min_read_support Int The minimum read support for a mutation to pass QC 10 Optional merlin_magic tbp_parser_operator String Fills the \"operator\" field in the tbp_parser output files Operator not provided Optional merlin_magic tbp_parser_output_seq_method_type String Fills out the \"seq_method\" field in the tbp_parser output files WGS Optional merlin_magic tbp_parser_rpob449_frequency Float Minimum frequency for a mutation at protein position 449 to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_rrl_frequency Float Minimum frequency for a mutation in rrl to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_rrl_read_support Int Minimum read support for a mutation in rrl to pass QC in tbp-parser 10 Optional merlin_magic tbp_parser_rrs_frequency Float Minimum frequency for a mutation in rrs to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_rrs_read_support Int Minimum read support for a mutation in rrs to pass QC in tbp-parser 10 Optional merlin_magic tbp_parser_tngs_data Boolean Set to true to enable tNGS-specific parameters and runs in tbp-parser FALSE Optional merlin_magic tbprofiler_additional_parameters String Additional parameters for TBProfiler Optional merlin_magic tbprofiler_custom_db File TBProfiler uses by default the TBDB database; if you have a custom database you wish to use, you must provide a custom database in this field and set tbprofiler_run_custom_db to true Optional merlin_magic tbprofiler_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/tbprofiler:6.6.3 Optional merlin_magic tbprofiler_mapper String The mapping tool used in TBProfiler to align the reads to the reference genome; see TBProfiler\u2019s original documentation for available options. bwa Optional merlin_magic tbprofiler_min_af Float The minimum allele frequency to call a variant 0.1 Optional merlin_magic tbprofiler_min_depth Int The minimum depth for a variant to be called. 10 Optional merlin_magic tbprofiler_run_cdph_db Boolean TBProfiler uses by default the TBDB database; set this value to \"true\" to use the WHO v2 database with customizations for CDPH FALSE Optional merlin_magic tbprofiler_run_custom_db Boolean TBProfiler uses by default the TBDB database; if you have a custom database you wish to use, you must set this value to true and provide a custom database in the tbprofiler_custom_db field FALSE Optional merlin_magic tbprofiler_variant_caller String Select a different variant caller for TBProfiler to use by writing it in this block; see TBProfiler\u2019s original documentation for available options. GATK Optional merlin_magic tbprofiler_variant_calling_params String Enter additional variant calling parameters in this free text input to customize how the variant caller works in TBProfiler Optional merlin_magic theiaeuk Boolean Internal component, do not modify FALSE Optional merlin_magic vibecheck_docker_image String The Docker container to use for the task watronfire/vibecheck:2025.02.24 Optional merlin_magic vibecheck_lineage_barcodes File Feather formatted lineage barcodes to use instead of default O1 barcodes Optional merlin_magic vibecheck_skip_subsampling Boolean When enabled, will not subsample reads prior to classification. Will increase computation time FALSE Optional merlin_magic vibecheck_subsampling_fraction Float Fraction of reads to use in classification. 0.2 Optional merlin_magic virulencefinder_database String The specific database to use virulence_ecoli Optional merlin_magic virulencefinder_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/virulencefinder:2.0.4 Optional merlin_magic virulencefinder_min_percent_coverage Float The threshold for minimum coverage Optional merlin_magic virulencefinder_min_percent_identity Float The threshold for minimum blast identity Optional plasmidfinder cpu Int Number of CPUs to allocate to the task 2 Optional plasmidfinder database String User-specified database Optional plasmidfinder database_path String Path to user-specified database Optional plasmidfinder disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional plasmidfinder docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/plasmidfinder:2.1.6 Optional plasmidfinder memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional plasmidfinder method_path String Path to files for a user-specified method to use (blast or kma) Optional plasmidfinder min_percent_coverage Float Threshold for minimum coverage, default threshold from PlasmidFinder CLI tool is used (0.60) 0.6 Optional plasmidfinder min_percent_identity Float Threshold for mininum blast identity, default threshold from PlasmidFinder CLI tool is used (0.90). This default differs from the default of the PlasmidFinder webtool (0.95) 0.9 Optional prokka compliant Boolean If true (default), forces Genbank/ENA/DDJB compliant headers in Prokka output files TRUE Optional prokka cpu Int Number of CPUs to allocate to the task 4 Optional prokka disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional prokka docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/prokka:1.14.5 Optional prokka memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional prokka prodigal_tf File https://github.com/tseemann/prokka#option---prodigaltf Optional prokka prokka_arguments String Any additional https://github.com/tseemann/prokka#command-line-options Optional prokka proteins Boolean FASTA file of trusted proteins for Prokka to first use for annotations FALSE Optional qc_check_task assembly_length_unambiguous Int Internal component, do not modify Optional qc_check_task assembly_mean_coverage Float Internal component, do not modify Optional qc_check_task cpu Int Number of CPUs to allocate to the task 4 Optional qc_check_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional qc_check_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional qc_check_task kraken_human Float Internal component, do not modify Optional qc_check_task kraken_human_dehosted Float Internal component, do not modify Optional qc_check_task kraken_sc2 Float Internal component, do not modify Optional qc_check_task kraken_sc2_dehosted Float Internal component, do not modify Optional qc_check_task kraken_target_organism Float Internal component, do not modify Optional qc_check_task kraken_target_organism_dehosted Float Internal component, do not modify Optional qc_check_task meanbaseq_trim String Internal component, do not modify Optional qc_check_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional qc_check_task number_Degenerate Int Internal component, do not modify Optional qc_check_task number_N Int Internal component, do not modify Optional qc_check_task percent_reference_coverage Float Internal component, do not modify Optional qc_check_task sc2_s_gene_mean_coverage Float Internal component, do not modify Optional qc_check_task sc2_s_gene_percent_coverage Float Internal component, do not modify Optional qc_check_task vadr_num_alerts String Internal component, do not modify Optional quast cpu Int Number of CPUs to allocate to the task 2 Optional quast disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional quast docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/quast:5.0.2 Optional quast memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional quast min_contig_length Int Minimum length of contig for QUAST 500 Optional raw_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional raw_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional raw_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional raw_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional read_QC_trim adapters File File with adapter sequences to be removed Optional read_QC_trim bbduk_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim call_kraken Boolean True/False variable that determines if the Kraken2 task should be called; for non-TheiaCoV workflows, the <code>kraken_db</code> variable must be provided. FALSE Optional read_QC_trim call_midas Boolean True/False variable that determines if the MIDAS task should be called. FALSE Optional read_QC_trim extract_unclassified Boolean Internal component, do not modify FALSE Optional read_QC_trim fastp_args String Additional arguments to use with fastp --detect_adapter_for_pe -g -5 20 -3 20 Optional read_QC_trim host String Internal component, do not modify Optional read_QC_trim host_complete_only Boolean Internal component, do not modify FALSE Optional read_QC_trim host_decontaminate_mem Int Internal component, do not modify 32 Optional read_QC_trim host_is_accession Boolean Internal component, do not modify FALSE Optional read_QC_trim host_refseq Boolean Internal component, do not modify TRUE Optional read_QC_trim kraken_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim kraken_db File A kraken2 database to use with the kraken2 optional task. The file must be a .tar.gz kraken2 database. Optional read_QC_trim kraken_disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional read_QC_trim kraken_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional read_QC_trim midas_db File The database used by the MIDAS task in .tar.gz format gs://theiagen-public-files-rp/terra/theiaprok-files/midas/midas_db_v1.2.tar.gz Optional read_QC_trim phix File A file containing the phix used during Illumina sequencing; used in the BBDuk task Optional read_QC_trim read_processing String The name of the tool to perform basic read processing; options: \"trimmomatic\" or \"fastp\" trimmomatic Optional read_QC_trim read_qc String The tool used for quality control (QC) of reads. Options are \"fastq_scan\" (default) and \"fastqc\" fastq_scan Optional read_QC_trim target_organism String This string is searched for in the kraken2 outputs to extract the read percentage Optional read_QC_trim taxon_id Int Internal component, do not modify 0 Optional read_QC_trim trimmomatic_args String Additional arguments to pass to trimmomatic. \"-phred33\" specifies the Phred Q score encoding which is almost always phred33 with modern sequence data. -phred33 Optional resfinder_task acquired Boolean Set to true to tell ResFinder to identify acquired resistance genes TRUE Optional resfinder_task call_pointfinder Boolean Set to true to enable detection of point mutations. FALSE Optional resfinder_task cpu Int Number of CPUs to allocate to the task 2 Optional resfinder_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional resfinder_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/resfinder:4.1.11 Optional resfinder_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional resfinder_task min_percent_coverage Float Minimum coverage breadth of a gene for it to be identified 0.5 Optional resfinder_task min_percent_identity Float Minimum identity for ResFinder to identify a gene 0.9 Optional theiaprok_illumina_pe abricate_db String Database to use with the Abricate tool. Options: NCBI, CARD, ARG-ANNOT, Resfinder, MEGARES, EcOH, PlasmidFinder, Ecoli_VF and VFDB vfdb Optional theiaprok_illumina_pe amrfinder_use_gff Boolean Whether or not to use the GFF and protein FASTA files for AMRFinderPlus FALSE Optional theiaprok_illumina_pe bakta_db String Database selection for Bakta annotation. Options: light (smaller, faster), full (more comprehensive), or a Google Storage URI (gs://...) pointing to a custom Bakta database archive (.tar.gz). The selected database will be extracted before annotation. full Optional theiaprok_illumina_pe call_abricate Boolean Set to true to enable the Abricate task FALSE Optional theiaprok_illumina_pe call_ani Boolean Set to true to enable the ANI task FALSE Optional theiaprok_illumina_pe call_arln_stats Boolean Set to true to enable the return of ARLN required Auto PASS/FAIL outputs FALSE Optional theiaprok_illumina_pe call_gamma Boolean Set to true in order to enable GAMMA task FALSE Optional theiaprok_illumina_pe call_kmerfinder Boolean Set to true to enable the kmerfinder task FALSE Optional theiaprok_illumina_pe call_plasmidfinder Boolean Set to true to enable the plasmidfinder task TRUE Optional theiaprok_illumina_pe call_resfinder Boolean Set to true to enable the ResFinder task FALSE Optional theiaprok_illumina_pe city String Will be used in the \"city\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_illumina_pe collection_date String Will be used in the \"collection_date\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_illumina_pe county String Will be used in the \"county\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_illumina_pe expected_taxon String If provided, this input will override the taxonomic assignment made by GAMBIT and launch the relevant taxon-specific submodules. It will also modify the organism flag used by AMRFinderPlus. Example format: \"Salmonella enterica\" Optional theiaprok_illumina_pe genome_annotation String If set to \"bakta\", TheiaProk will use Bakta rather than Prokka to annotate the genome prokka Optional theiaprok_illumina_pe genome_length Int User-specified expected genome length to be used in genome statistics calculations Optional theiaprok_illumina_pe max_genome_length Int Maximum genome length able to pass read screening. 18040666 Optional theiaprok_illumina_pe min_basepairs Int Minimum number of base pairs able to pass read screening 2241820 Optional theiaprok_illumina_pe min_coverage Int Minimum genome coverage able to pass read screening 10 Optional theiaprok_illumina_pe min_genome_length Int Minimum genome length able to pass read screening. 100000 Optional theiaprok_illumina_pe min_proportion Int Minimum proportion of total reads in each read file to pass read screening 40 Optional theiaprok_illumina_pe min_reads Int Minimum number of reads to pass read screening 7472 Optional theiaprok_illumina_pe mlst_run_secondary_scheme Boolean If true, will run secondary scheme if primary scheme is of ecoli or abaumannii, these two have multiple schemes that are relevant. FALSE Optional theiaprok_illumina_pe mlst_scheme_override Boolean If true, will force E. coli scheme to be used when Gambit predicts Escherichia coli, otherwise will return scheme MLST predicts. FALSE Optional theiaprok_illumina_pe originating_lab String Will be used in the \"originating_lab\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_illumina_pe perform_characterization Boolean Set to \"false\" if you want to only generate an assembly and relevant QC metrics and skip all characterization tasks TRUE Optional theiaprok_illumina_pe qc_check_table File TSV value with taxons for rows and QC values for columns; internal cells represent user-determined QC thresholds; if provided, turns on the QC Check task. See below for an example QC Check table. Optional theiaprok_illumina_pe read1_lane2 File If provided, the Concatenate_Illumina_Lanes subworkflow will concatenate all files from the same lane before doing any subsequent analysis Optional theiaprok_illumina_pe read1_lane3 File If provided, the Concatenate_Illumina_Lanes subworkflow will concatenate all files from the same lane before doing any subsequent analysis Optional theiaprok_illumina_pe read1_lane4 File If provided, the Concatenate_Illumina_Lanes subworkflow will concatenate all files from the same lane before doing any subsequent analysis Optional theiaprok_illumina_pe read2_lane2 File If provided, the Concatenate_Illumina_Lanes subworkflow will concatenate all files from the same lane before doing any subsequent analysis Optional theiaprok_illumina_pe read2_lane3 File If provided, the Concatenate_Illumina_Lanes subworkflow will concatenate all files from the same lane before doing any subsequent analysis Optional theiaprok_illumina_pe read2_lane4 File If provided, the Concatenate_Illumina_Lanes subworkflow will concatenate all files from the same lane before doing any subsequent analysis Optional theiaprok_illumina_pe run_id String Will be used in the \"run_id\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_illumina_pe seq_method String The sequencing methodology used to generate the input read data; for TheiaProk workflows, this input will be used in the \"seq_id\" column in any taxon-specific tables created in the Export Taxon Tables task ILLUMINA Optional theiaprok_illumina_pe skip_screen Boolean Set to True to skip the read screening prior to analysis FALSE Optional theiaprok_illumina_pe taxon_tables File File indicating data table names to copy samples of a particular taxon to Optional theiaprok_illumina_pe terra_project String The name of the Terra Project where you want the taxon tables written to NA Optional theiaprok_illumina_pe terra_workspace String The name of the Terra Workspace where you want the taxon tables written to NA Optional theiaprok_illumina_pe trim_min_length Int Specifies minimum length of each read after trimming to be kept 75 Optional theiaprok_illumina_pe trim_quality_min_score Int Specifies the minimum average quality of bases in a sliding window to be kept 20 Optional theiaprok_illumina_pe trim_window_size Int Specifies window size for trimming (the number of bases to average the quality across) 10 Optional theiaprok_illumina_pe zip String Will be used in the \"zip\" column in any taxon-specific tables created in the Export Taxon Tables task Optional ts_mlst cpu Int Number of CPUs to allocate to the task 1 Optional ts_mlst disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional ts_mlst docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mlst:2.23.0-2024-12-31 Optional ts_mlst memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional ts_mlst min_percent_coverage Float Minimum % breadth of coverage to report an MLST allele 10 Optional ts_mlst min_percent_identity Float Minimum % identity to known MLST gene to report an MLST allele 95 Optional ts_mlst minscore Float Minimum score https://github.com/tseemann/mlst#scoring-system to assign an MLST profile 50 Optional ts_mlst nopath Boolean true = use mlst --nopath. If set to false, filename paths are not stripped from FILE column in output TSV TRUE Optional ts_mlst scheme String Don\u2019t autodetect the MLST scheme; force this scheme on all inputs (see https://github.com/tseemann/mlst/blob/master/db/scheme_species_map.tab for accepted strings) None Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status theiaprok_illumina_se read1 File Illumina forward read file in FASTQ file format (compression optional) Required theiaprok_illumina_se samplename String The name of the sample being analyzed Required abricate cpu Int Number of CPUs to allocate to the task 2 Optional abricate disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional abricate docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid Optional abricate memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional abricate min_percent_coverage Int Minimum DNA %coverage for the Abricate task 80 Optional abricate min_percent_identity Int Minimum DNA %identity for the Abricate task 80 Optional amrfinderplus_task cpu Int Number of CPUs to allocate to the task 2 Optional amrfinderplus_task detailed_drug_class Boolean If set to true, amrfinderplus_amr_classes and amrfinderplus_amr_subclasses outputs will be created FALSE Optional amrfinderplus_task disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional amrfinderplus_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ncbi-amrfinderplus:4.0.23-2025-07-16.1 Optional amrfinderplus_task hide_point_mutations Boolean If set to true, point mutations are not reported FALSE Optional amrfinderplus_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional amrfinderplus_task min_percent_coverage Float Minimum proportion of reference gene covered for a BLAST-based hit (Methods BLAST or PARTIAL).\" Attribute should be a float ranging from 0-1, such as 0.6 (equal to 60% coverage) 0.5 Optional amrfinderplus_task min_percent_identity Float Minimum identity for a blast-based hit hit (Methods BLAST or PARTIAL). -1 means use a curated threshold if it exists and 0.9 otherwise. Setting this value to something other than -1 will override any curated similarity cutoffs. Attribute should be a float ranging from 0-1, such as 0.95 (equal to 95% identity) 0.9 Optional amrfinderplus_task separate_betalactam_genes Boolean Report beta-Lactam AMR genes separated out by all beta-lactam and the respective beta-lactam subclasses FALSE Optional ani ani_threshold Float ANI value threshold must be surpassed in order to output the ani_top_species_match. If a genome does not surpass this threshold (and the percent_bases_aligned_threshold) then the ani_top_species_match output String will show a warning instead of a genus &amp; species. 80.0 Optional ani cpu Int Number of CPUs to allocate to the task 4 Optional ani disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ani docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mummer:4.0.0-rgdv2 Optional ani mash_filter Float Mash distance threshold over which ANI is not calculated 0.9 Optional ani memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional ani percent_bases_aligned_threshold Float Threshold regarding the proportion of bases aligned between the query genome and reference genome. If a genome does not surpass this threshold (and the ani_threshold) then the ani_top_species_match output String will show a warning instead of a genus &amp; species. 70.0 Optional ani ref_genome File If not set, uses all 43 genomes in RGDv2 Optional arln_stats cpu Int Number of CPUs to allocate to the task 2 Optional arln_stats disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional arln_stats docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/arln_stats:1.0.0 Optional arln_stats memory Int Amount of memory/RAM (in GB) to allocate to the task 5 Optional arln_stats read2_clean File Internal component, do not modify Optional arln_stats read2_raw File Internal component, do not modify Optional bakta bakta_opts String Parameters to pass to bakta from https://github.com/oschwengers/bakta#usage Optional bakta compliant Boolean If true, forces Genbank/ENA/DDJB compliant headers in Bakta output files FALSE Optional bakta cpu Int Number of CPUs to allocate to the task 8 Optional bakta disk_size Int Amount of storage (in GB) to allocate to the task 200 Optional bakta docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/bakta:1.10.3 Optional bakta memory Int Amount of memory/RAM (in GB) to allocate to the task 24 Optional bakta prodigal_tf File Prodigal training file to use for CDS prediction by bakta Optional bakta proteins File Fasta file of trusted protein sequences for CDS annotation Optional busco cpu Int Number of CPUs to allocate to the task 2 Optional busco disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional busco docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ezlabgva/busco:v5.7.1_cv1 Optional busco eukaryote Boolean Assesses eukaryotic organisms, rather than prokaryotic organisms FALSE Optional busco memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional cg_pipeline_clean cg_pipe_opts String Options to pass to CG-Pipeline for clean read assessment --fast Optional cg_pipeline_clean cpu Int Number of CPUs to allocate to the task 1 Optional cg_pipeline_clean disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional cg_pipeline_clean docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/lyveset:1.1.4f Optional cg_pipeline_clean memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional cg_pipeline_clean read2 File Internal component, do not modify Optional cg_pipeline_raw cg_pipe_opts String Options to pass to CG-Pipeline for raw read assessment --fast Optional cg_pipeline_raw cpu Int Number of CPUs to allocate to the task 1 Optional cg_pipeline_raw disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional cg_pipeline_raw docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/lyveset:1.1.4f Optional cg_pipeline_raw memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional cg_pipeline_raw read2 File Internal component, do not modify Optional clean_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional clean_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional clean_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional clean_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional concatenate_illumina_lanes read2_lane1 File Internal component, do not modify Optional concatenate_illumina_lanes read2_lane2 File Internal component, do not modify Optional concatenate_illumina_lanes read2_lane3 File Internal component, do not modify Optional concatenate_illumina_lanes read2_lane4 File Internal component, do not modify Optional digger_denovo assembler String Assembler to use (spades, skesa, megahit) skesa Optional digger_denovo assembler_options String Assembler-specific options that you might choose for the selected assembler Optional digger_denovo bwa_cpu Int Number of CPUs to allocate to the task 6 Optional digger_denovo bwa_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional digger_denovo bwa_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional digger_denovo bwa_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional digger_denovo call_pilon Boolean Whether to run Pilon polishing after assembly FALSE Optional digger_denovo filter_contigs_cpu Int Number of CPUs to allocate to the task 1 Optional digger_denovo filter_contigs_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional digger_denovo filter_contigs_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/shovilter:0.2 Optional digger_denovo filter_contigs_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional digger_denovo filter_contigs_min_coverage Float Minimum coverage threshold for contig filtering 2.0 Optional digger_denovo filter_contigs_min_length Int Minimum length threshold for contig filtering 200 Optional digger_denovo filter_contigs_skip_coverage_filter Boolean Skip filtering contigs based on coverage FALSE Optional digger_denovo filter_contigs_skip_homopolymer_filter Boolean Skip filtering contigs containing homopolymers FALSE Optional digger_denovo filter_contigs_skip_length_filter Boolean Skip filtering contigs based on length FALSE Optional digger_denovo kmers String K-mer sizes for assembly (comma-separated) Optional digger_denovo megahit_cpu Int Number of CPUs to allocate to the task 4 Optional digger_denovo megahit_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional digger_denovo megahit_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/megahit:1.2.9 Optional digger_denovo megahit_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional digger_denovo min_contig_length Int Minimum contig length to retain in final assembly 200 Optional digger_denovo pilon_cpu Int Number of CPUs to allocate to the task 8 Optional digger_denovo pilon_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional digger_denovo pilon_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/pilon:1.24--hdfd78af_0 Optional digger_denovo pilon_fix String Potential issues with assembly to try and automatically fix (snps, indels, gaps, local, all, bases, none) bases Optional digger_denovo pilon_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional digger_denovo pilon_min_base_quality Int Minimum base quality to keep 3 Optional digger_denovo pilon_min_depth Float Minimum coverage threshold for variant calling: when set to a value \u22651, it requires that absolute depth of coverage; when set to a fraction &lt;1, it requires coverage at least that fraction of the mean coverage for the region 0.25 Optional digger_denovo pilon_min_mapping_quality Int Minimum mapping quality for a read to count in pileups 60 Optional digger_denovo read2 File Internal component, do not modify Optional digger_denovo run_filter_contigs Boolean Whether to run contig filtering step TRUE Optional digger_denovo skesa_cpu Int Number of CPUs to allocate to the task 4 Optional digger_denovo skesa_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional digger_denovo skesa_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/skesa:2.4.0 Optional digger_denovo skesa_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional digger_denovo spades_cpu Int Number of CPUs to allocate to the task 16 Optional digger_denovo spades_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional digger_denovo spades_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/spades:4.1.0 Optional digger_denovo spades_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional digger_denovo spades_type String SPAdes assembly mode (isolate, meta, rna, etc.), more can be found here isolate Optional export_taxon_table cpu Int Number of CPUs to allocate to the task 1 Optional export_taxon_table disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional export_taxon_table docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Optional export_taxon_table memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional gambit cpu Int Number of CPUs to allocate to the task 1 Optional gambit disk_size Int Amount of storage (in GB) to allocate to the task 20 Optional gambit docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Optional gambit gambit_db_genomes File Database of metadata for assembled query genomes; requires complementary signatures file. If not provided, uses default database \"/gambit-db\" gs://gambit-databases-rp/2.0.0/gambit-metadata-2.0.1-20250505.gdb Optional gambit gambit_db_signatures File Signatures file; requires complementary genomes file. If not specified, the file from the docker container will be used. gs://gambit-databases-rp/2.0.0/gambit-signatures-2.0.1-20250505.gs Optional gambit memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional gamma cpu Int Number of CPUs to allocate to the task 2 Optional gamma disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional gamma docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/gamma:2.2 Optional gamma extended_output Boolean GAMMA will provide the extended output when set to true FALSE Optional gamma gamma_db File Multifasta sequence database GAMMA is to use for gene matching gs://theiagen-public-resources-rp/reference_data/databases/gamma/default_ResFinderDB_Combined_05-06-20.fsa Optional gamma memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional gamma min_length_percent_gammas Int Threshold of match length percent used by GAMMA-s 20 Optional gamma min_percent_identity Int Threshold of identity for gene matches in percent 90 Optional gamma output_fasta Boolean Allows GAMMA to output gene matches in FASTA format TRUE Optional gamma output_gff Boolean Allows GAMMA to output gene matches in GFF format TRUE Optional gamma run_gammas Boolean Turns on GAMMA-S which runs GAMMA on nucleotide sequences rather than translating input sequences and matches FALSE Optional kmerfinder cpu Int Number of CPUs to allocate to the task 4 Optional kmerfinder disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional kmerfinder docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/kmerfinder:3.0.2--hdfd78af_0 Optional kmerfinder kmerfinder_args String Kmerfinder additional arguments Optional kmerfinder kmerfinder_db File Bacterial database for KmerFinder gs://theiagen-public-resources-rp/reference_data/databases/kmerfinder/kmerfinder_bacteria_20230911.tar.gz Optional kmerfinder memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional merlin_magic abricate_abaum_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid Optional merlin_magic abricate_abaum_min_percent_coverage Int Minimum DNA percent coverage Optional merlin_magic abricate_abaum_min_percent_identity Int Minimum DNA percent identity; set to 95 because there is a strict threshold of 95% identity for typing purposes 95 Optional merlin_magic abricate_vibrio_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid Optional merlin_magic abricate_vibrio_min_percent_coverage Int Minimum DNA percent coverage 80 Optional merlin_magic abricate_vibrio_min_percent_identity Int Minimum DNA percent identity 80 Optional merlin_magic agrvate_agr_typing_only Boolean Set to true to skip agr operon extraction and frameshift detection FALSE Optional merlin_magic agrvate_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/agrvate:1.0.2--hdfd78af_0 Optional merlin_magic amr_search_cpu Int Number of CPUs to allocate to the task 2 Optional merlin_magic amr_search_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional merlin_magic amr_search_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/amrsearch:0.2.1 Optional merlin_magic amr_search_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional merlin_magic assembly_only Boolean Set to true if only analyzing input assembly FALSE Optional merlin_magic call_poppunk Boolean If true, runs PopPUNK for GPSC cluster designation for S. pneumoniae TRUE Optional merlin_magic call_shigeifinder_reads_input Boolean If set to \"true\", the ShigEiFinder task will run again but using read files as input instead of the assembly file. Input is shown but not used for TheiaProk_FASTA. FALSE Optional merlin_magic call_stxtyper Boolean If set to \"true\", the StxTyper task will run on all samples regardless of the gambit_predicted_taxon output. Useful if you suspect a non-E.coli or non-Shigella sample contains stx genes. FALSE Optional merlin_magic call_tbp_parser Boolean If set to \"true\", activates the tbp_parser module and results in more outputs, including\u00a0tbp_parser_looker_report_csv, tbp_parser_laboratorian_report_csv,  tbp_parser_lims_report_csv, tbp_parser_coverage_report, and tbp_parser_genome_percent_coverage FALSE Optional merlin_magic cauris_cladetyper_docker_image String Internal component, do not modify us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Optional merlin_magic cladetyper_kmer_size Int Internal component, do not modify Optional merlin_magic cladetyper_max_distance Float Internal component, do not modify 0.1 Optional merlin_magic cladetyper_ref_clade1 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade1_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade2 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade2_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade3 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade3_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade4 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade4_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade5 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade5_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade6 File The reference assembly for clade 6 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade6_GCA_032714025.1_ASM3271402v1_genomic.fasta Optional merlin_magic cladetyper_ref_clade6_annotated File The path to the annotated reference for clade 6 Optional merlin_magic clockwork_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/cdcgov/varpipe_wgs_with_refs:2bc7234074bd53d9e92a1048b0485763cd9bbf6f4d12d5a1cc82bfec8ca7d75e Optional merlin_magic ectyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/ectyper:1.0.0--pyhdfd78af_1 Optional merlin_magic ectyper_h_min_percent_coverage Int Minumum percent coverage required for an H antigen allele match 50 Optional merlin_magic ectyper_h_min_percent_identity Int Percent identity required for an H antigen allele match 95 Optional merlin_magic ectyper_o_min_percent_coverage Int Minumum percent coverage required for an O antigen allele match 90 Optional merlin_magic ectyper_o_min_percent_identity Int Percent identity required for an O antigen allele match 90 Optional merlin_magic ectyper_print_alleles Boolean Set to true to print the allele sequences as the final column FALSE Optional merlin_magic ectyper_verify Boolean Set to true to enable E. coli species verification FALSE Optional merlin_magic emmtyper_align_diff Int Threshold for difference between alignment length and subject length in BLAST hit. Optional merlin_magic emmtyper_cluster_distance Int Distance between cluster of matches to consider as different clusters. Optional merlin_magic emmtyper_culling_limit Int Total hits to return in a position. Optional merlin_magic emmtyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/emmtyper:0.2.0--py_0 Optional merlin_magic emmtyper_gap Int Threshold gap to allow in BLAST hit. Optional merlin_magic emmtyper_max_size Int Maximum size of PCR product. Optional merlin_magic emmtyper_min_good Int Minimum size where there must be 2 matches for each mismatch. Optional merlin_magic emmtyper_min_percent_identity Int Minimal percent identity of sequence. Optional merlin_magic emmtyper_min_perfect Int Minimum size of perfect match at 3' primer end. Optional merlin_magic emmtyper_mismatch Int Threshold for number of mismatch to allow in BLAST hit. Optional merlin_magic emmtyper_wf String Choose workflow [blast pcr] merlin_magic emmtypingtool_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/emmtypingtool:0.0.1 Optional merlin_magic genotyphi_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.11.0 Optional merlin_magic hicap_broken_gene_length Int Minimum length to consider a broken gene 60 Optional merlin_magic hicap_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/hicap:1.0.3--py_0 Optional merlin_magic hicap_min_broken_gene_percent_identity Float Minimum percentage identity to consider a broken gene 0.8 Optional merlin_magic hicap_min_gene_percent_coverage Float Minimum percentage coverage to consider a single gene complete 0.8 Optional merlin_magic hicap_min_gene_percent_identity Float Minimum percentage identity to consider a single gene complete 0.7 Optional merlin_magic kaptive_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kaptive:2.0.3 Optional merlin_magic kaptive_low_gene_percent_identity Float Percent identity threshold for what counts as a low identity match in the gene BLAST search 95 Optional merlin_magic kaptive_min_percent_coverage Float Minimum required percent coverage for the gene BLAST search via tBLASTn 80 Optional merlin_magic kaptive_min_percent_identity Float Minimum required percent identity for the gene BLAST search via tBLASTn 90 Optional merlin_magic kaptive_start_end_margin Int Determines flexibility in identifying the start and end of a locus - if this value is 10, a locus match that is missing the first 8 base pairs will still count as capturing the start of the locus 10 Optional merlin_magic kleborate_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kleborate:2.2.0 Optional merlin_magic kleborate_min_kaptive_confidence String {None,Low,Good,High,Very_high,Perfect} Minimum Kaptive confidence to call K/O loci - confidence levels below this will be reported as unknown Good Optional merlin_magic kleborate_min_percent_coverage Float Minimum alignment percent coverage for main results 80 Optional merlin_magic kleborate_min_percent_identity Float Minimum alignment percent identity for main results 90 Optional merlin_magic kleborate_min_spurious_percent_coverage Float Minimum alignment percent coverage for spurious results 40 Optional merlin_magic kleborate_min_spurious_percent_identity Float Minimum alignment percent identity for spurious results 80 Optional merlin_magic kleborate_skip_kaptive Boolean Equivalent to --kaptive_k --kaptive_ FALSE Optional merlin_magic kleborate_skip_resistance Boolean Set to true to turn on resistance genes screening (default: no resistance gene screening) FALSE Optional merlin_magic legsta_docker_image String Internal component, do not modify Optional merlin_magic lissero_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/lissero:0.4.9--py_0 Optional merlin_magic lissero_min_percent_coverage Float Minimum percent coverage of the gene to accept a match 95 Optional merlin_magic lissero_min_percent_identity Float Minimum percent identity to accept a match 95 Optional merlin_magic meningotype_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/meningotype:0.8.5--pyhdfd78af_0 Optional merlin_magic ngmaster_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ngmaster:1.0.0 Optional merlin_magic ont_data Boolean Set to true if your data is ONT FASTQ files FALSE Optional merlin_magic pasty_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pasty:1.0.3 Optional merlin_magic pasty_min_percent_coverage Int Minimum coverage of a O-antigen to be considered for serogrouping by pasty 95 Optional merlin_magic pasty_min_percent_identity Int Minimum percent identity for a blast hit to be considered for serogrouping 95 Optional merlin_magic pbptyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pbptyper:1.0.4 Optional merlin_magic pbptyper_min_percent_coverage Int Minimum percent coverage to count a hit 90 Optional merlin_magic pbptyper_min_percent_identity Int Minimum percent identity to count a hit 90 Optional merlin_magic poppunk_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/poppunk:2.4.0 Optional merlin_magic poppunk_gps_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_clusters.csv Optional merlin_magic poppunk_gps_dists_npy File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.dists.npy Optional merlin_magic poppunk_gps_dists_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.dists.pkl Optional merlin_magic poppunk_gps_external_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_external_clusters.csv Optional merlin_magic poppunk_gps_fit_npz File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_fit.npz Optional merlin_magic poppunk_gps_fit_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_fit.pkl Optional merlin_magic poppunk_gps_graph_gt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_graph.gt Optional merlin_magic poppunk_gps_h5 File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.h5 Optional merlin_magic poppunk_gps_qcreport_txt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_qcreport.txt Optional merlin_magic poppunk_gps_refs File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs Optional merlin_magic poppunk_gps_refs_dists_npy File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.dists.npy Optional merlin_magic poppunk_gps_refs_dists_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.dists.pkl Optional merlin_magic poppunk_gps_refs_graph_gt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6refs_graph.gt Optional merlin_magic poppunk_gps_refs_h5 File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.h5 Optional merlin_magic poppunk_gps_unword_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_unword_clusters.csv Optional merlin_magic read2 File Internal component, do not modify Optional merlin_magic run_amr_search Boolean If set to true AMR_Search workflow will be run if species is part of supported taxon, see AMR_Search docs. FALSE Optional merlin_magic seqsero2_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/seqsero2:1.2.1 Optional merlin_magic seroba_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/seroba:1.0.2 Optional merlin_magic serotypefinder_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/serotypefinder:2.0.1 Optional merlin_magic shigatyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/shigatyper:2.0.5 Optional merlin_magic shigeifinder_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/shigeifinder:1.3.5 Optional merlin_magic sistr_cpu Int Number of CPUs to allocate to the task 2 Optional merlin_magic sistr_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional merlin_magic sistr_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/sistr_cmd:1.1.1--pyh864c0ab_2 Optional merlin_magic sistr_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional merlin_magic sistr_use_full_cgmlst_db Boolean Set to true to use the full set of cgMLST alleles which can include highly similar alleles. By default the smaller \"centroid\" alleles or representative alleles are used for each marker FALSE Optional merlin_magic snippy_base_quality Int Internal component, do not modify Optional merlin_magic snippy_gene_query_docker_image String Internal component, do not modify Optional merlin_magic snippy_map_qual Int Internal component, do not modify Optional merlin_magic snippy_maxsoft Int Internal component, do not modify Optional merlin_magic snippy_min_coverage Int Internal component, do not modify Optional merlin_magic snippy_min_frac Float Internal component, do not modify Optional merlin_magic snippy_min_quality Int Internal component, do not modify Optional merlin_magic snippy_query_gene String Internal component, do not modify Optional merlin_magic snippy_reference_afumigatus File Internal component, do not modify gs://theiagen-public-resources-rp/reference_data/eukaryotic/aspergillus/Aspergillus_fumigatus_GCF_000002655.1_ASM265v1_genomic.gbff Optional merlin_magic snippy_reference_cryptoneo File Internal component, do not modify gs://theiagen-public-resources-rp/reference_data/eukaryotic/cryptococcus/Cryptococcus_neoformans_GCF_000091045.1_ASM9104v1_genomic.gbff Optional merlin_magic snippy_variants_docker_image String Internal component, do not modify Optional merlin_magic sonneityping_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Optional merlin_magic sonneityping_mykrobe_opts String Additional options for mykrobe in sonneityping Optional merlin_magic spatyper_do_enrich Boolean Set to true to enable PCR product enrichment FALSE Optional merlin_magic spatyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/spatyper:0.3.3--pyhdfd78af_3 Optional merlin_magic srst2_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/srst2:0.2.0-vcholerae Optional merlin_magic srst2_gene_max_mismatch Int Maximum number of mismatches for SRST2 to call a gene as present 2000 Optional merlin_magic srst2_max_divergence Int Maximum divergence, in percentage, for SRST2 to call a gene as present 20 Optional merlin_magic srst2_min_depth Int Minimum depth of coverage for SRST2 to call a gene as present 5 Optional merlin_magic srst2_min_edge_depth Int Minimum edge depth for SRST2 to call a gene as present 2 Optional merlin_magic srst2_min_percent_coverage Int Minimum breadth of coverage for SRST2 to call a gene as present 80 Optional merlin_magic staphopia_sccmec_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/staphopia-sccmec:1.0.0--hdfd78af_0 Optional merlin_magic stxtyper_cpu Int Number of CPUs to allocate to the task 1 Optional merlin_magic stxtyper_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional merlin_magic stxtyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/stxtyper:1.0.42 Optional merlin_magic stxtyper_enable_debug Boolean When enabled, additional messages are printed and files in $TMPDIR are not removed after running FALSE Optional merlin_magic stxtyper_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional merlin_magic tbp_parser_add_cs_lims Boolean Set to true add cycloserine results to the LIMS report FALSE Optional merlin_magic tbp_parser_config File The configuration file to use, in YAML format (overrides all other arguments except input_json and input_bam) Optional merlin_magic tbp_parser_coverage_regions_bed File A bed file that lists the regions to be considered for QC Optional merlin_magic tbp_parser_debug Boolean Activate the debug mode on tbp_parser; increases logging outputs TRUE Optional merlin_magic tbp_parser_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/tbp-parser:2.6.0 Optional merlin_magic tbp_parser_etha237_frequency Float Minimum frequency for a mutation in ethA at protein position 237 to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_expert_rule_regions_bed File A file that contains the regions where R mutations and expert rules are applied Optional merlin_magic tbp_parser_min_depth Int Minimum depth for a variant to pass QC in tbp_parser 10 Optional merlin_magic tbp_parser_min_frequency Float The minimum frequency for a mutation to pass QC 0.1 Optional merlin_magic tbp_parser_min_percent_coverage Float The minimum coverage for a region to pass QC in tbp_parser 100 Optional merlin_magic tbp_parser_min_read_support Int The minimum read support for a mutation to pass QC 10 Optional merlin_magic tbp_parser_operator String Fills the \"operator\" field in the tbp_parser output files Operator not provided Optional merlin_magic tbp_parser_output_seq_method_type String Fills out the \"seq_method\" field in the tbp_parser output files WGS Optional merlin_magic tbp_parser_rpob449_frequency Float Minimum frequency for a mutation at protein position 449 to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_rrl_frequency Float Minimum frequency for a mutation in rrl to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_rrl_read_support Int Minimum read support for a mutation in rrl to pass QC in tbp-parser 10 Optional merlin_magic tbp_parser_rrs_frequency Float Minimum frequency for a mutation in rrs to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_rrs_read_support Int Minimum read support for a mutation in rrs to pass QC in tbp-parser 10 Optional merlin_magic tbp_parser_tngs_data Boolean Set to true to enable tNGS-specific parameters and runs in tbp-parser FALSE Optional merlin_magic tbprofiler_additional_parameters String Additional parameters for TBProfiler Optional merlin_magic tbprofiler_custom_db File TBProfiler uses by default the TBDB database; if you have a custom database you wish to use, you must provide a custom database in this field and set tbprofiler_run_custom_db to true Optional merlin_magic tbprofiler_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/tbprofiler:6.6.3 Optional merlin_magic tbprofiler_mapper String The mapping tool used in TBProfiler to align the reads to the reference genome; see TBProfiler\u2019s original documentation for available options. bwa Optional merlin_magic tbprofiler_min_af Float The minimum allele frequency to call a variant 0.1 Optional merlin_magic tbprofiler_min_depth Int The minimum depth for a variant to be called. 10 Optional merlin_magic tbprofiler_run_cdph_db Boolean TBProfiler uses by default the TBDB database; set this value to \"true\" to use the WHO v2 database with customizations for CDPH FALSE Optional merlin_magic tbprofiler_run_custom_db Boolean TBProfiler uses by default the TBDB database; if you have a custom database you wish to use, you must set this value to true and provide a custom database in the tbprofiler_custom_db field FALSE Optional merlin_magic tbprofiler_variant_caller String Select a different variant caller for TBProfiler to use by writing it in this block; see TBProfiler\u2019s original documentation for available options. GATK Optional merlin_magic tbprofiler_variant_calling_params String Enter additional variant calling parameters in this free text input to customize how the variant caller works in TBProfiler Optional merlin_magic theiaeuk Boolean Internal component, do not modify FALSE Optional merlin_magic vibecheck_docker_image String Internal component, do not modify Optional merlin_magic vibecheck_lineage_barcodes File Internal component, do not modify Optional merlin_magic vibecheck_skip_subsampling Boolean Internal component, do not modify Optional merlin_magic vibecheck_subsampling_fraction Float Internal component, do not modify Optional merlin_magic virulencefinder_database String The specific database to use virulence_ecoli Optional merlin_magic virulencefinder_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/virulencefinder:2.0.4 Optional merlin_magic virulencefinder_min_percent_coverage Float The threshold for minimum coverage Optional merlin_magic virulencefinder_min_percent_identity Float The threshold for minimum blast identity Optional plasmidfinder cpu Int Number of CPUs to allocate to the task 2 Optional plasmidfinder database String User-specified database Optional plasmidfinder database_path String Path to user-specified database Optional plasmidfinder disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional plasmidfinder docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/plasmidfinder:2.1.6 Optional plasmidfinder memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional plasmidfinder method_path String Path to files for a user-specified method to use (blast or kma) Optional plasmidfinder min_percent_coverage Float Threshold for minimum coverage, default threshold from PlasmidFinder CLI tool is used (0.60) 0.6 Optional plasmidfinder min_percent_identity Float Threshold for mininum blast identity, default threshold from PlasmidFinder CLI tool is used (0.90). This default differs from the default of the PlasmidFinder webtool (0.95) 0.9 Optional prokka compliant Boolean If true (default), forces Genbank/ENA/DDJB compliant headers in Prokka output files TRUE Optional prokka cpu Int Number of CPUs to allocate to the task 4 Optional prokka disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional prokka docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/prokka:1.14.5 Optional prokka memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional prokka prodigal_tf File https://github.com/tseemann/prokka#option---prodigaltf Optional prokka prokka_arguments String Any additional https://github.com/tseemann/prokka#command-line-options Optional prokka proteins Boolean FASTA file of trusted proteins for Prokka to first use for annotations FALSE Optional qc_check_task assembly_length_unambiguous Int Internal component, do not modify Optional qc_check_task assembly_mean_coverage Float Internal component, do not modify Optional qc_check_task combined_mean_q_clean Float Internal component, do not modify Optional qc_check_task combined_mean_q_raw Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task cpu Int Number of CPUs to allocate to the task 4 Optional qc_check_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional qc_check_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional qc_check_task kraken_human Float Internal component, do not modify Optional qc_check_task kraken_human_dehosted Float Internal component, do not modify Optional qc_check_task kraken_sc2 Float Internal component, do not modify Optional qc_check_task kraken_sc2_dehosted Float Internal component, do not modify Optional qc_check_task kraken_target_organism Float Internal component, do not modify Optional qc_check_task kraken_target_organism_dehosted Float Internal component, do not modify Optional qc_check_task meanbaseq_trim String Internal component, do not modify Optional qc_check_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional qc_check_task num_reads_clean2 Int Internal component, do not modify Optional qc_check_task num_reads_raw2 Int Internal component, do not modify Optional qc_check_task number_Degenerate Int Internal component, do not modify Optional qc_check_task number_N Int Internal component, do not modify Optional qc_check_task percent_reference_coverage Float Internal component, do not modify Optional qc_check_task r2_mean_q_clean Float Internal component, do not modify Optional qc_check_task r2_mean_q_raw Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task sc2_s_gene_mean_coverage Float Internal component, do not modify Optional qc_check_task sc2_s_gene_percent_coverage Float Internal component, do not modify Optional qc_check_task vadr_num_alerts String Internal component, do not modify Optional quast cpu Int Number of CPUs to allocate to the task 2 Optional quast disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional quast docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/quast:5.0.2 Optional quast memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional quast min_contig_length Int Minimum length of contig for QUAST 500 Optional raw_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional raw_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional raw_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional raw_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional read_QC_trim adapters File File with adapter sequences to be removed Optional read_QC_trim bbduk_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim call_kraken Boolean True/False variable that determines if the Kraken2 task should be called; for non-TheiaCoV workflows, the <code>kraken_db</code> variable must be provided. FALSE Optional read_QC_trim call_midas Boolean True/False variable that determines if the MIDAS task should be called. FALSE Optional read_QC_trim fastp_args String Additional arguments to use with fastp -g -5 20 -3 20 Optional read_QC_trim kraken_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim kraken_db File A kraken2 database to use with the kraken2 optional task. The file must be a .tar.gz kraken2 database. Optional read_QC_trim kraken_disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional read_QC_trim kraken_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional read_QC_trim midas_db File The database used by the MIDAS task in .tar.gz format gs://theiagen-public-files-rp/terra/theiaprok-files/midas/midas_db_v1.2.tar.gz Optional read_QC_trim phix File A file containing the phix used during Illumina sequencing; used in the BBDuk task Optional read_QC_trim read_processing String The name of the tool to perform basic read processing; options: \"trimmomatic\" or \"fastp\" trimmomatic Optional read_QC_trim read_qc String The tool used for quality control (QC) of reads. Options are \"fastq_scan\" (default) and \"fastqc\" fastq_scan Optional read_QC_trim target_organism String This string is searched for in the kraken2 outputs to extract the read percentage Optional read_QC_trim trimmomatic_args String Additional arguments to pass to trimmomatic. \"-phred33\" specifies the Phred Q score encoding which is almost always phred33 with modern sequence data. -phred33 Optional resfinder_task acquired Boolean Set to true to tell ResFinder to identify acquired resistance genes TRUE Optional resfinder_task call_pointfinder Boolean Set to true to enable detection of point mutations. FALSE Optional resfinder_task cpu Int Number of CPUs to allocate to the task 2 Optional resfinder_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional resfinder_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/resfinder:4.1.11 Optional resfinder_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional resfinder_task min_percent_coverage Float Minimum coverage breadth of a gene for it to be identified 0.5 Optional resfinder_task min_percent_identity Float Minimum identity for ResFinder to identify a gene 0.9 Optional theiaprok_illumina_se abricate_db String Database to use with the Abricate tool. Options: NCBI, CARD, ARG-ANNOT, Resfinder, MEGARES, EcOH, PlasmidFinder, Ecoli_VF and VFDB vfdb Optional theiaprok_illumina_se amrfinder_use_gff Boolean Whether or not to use the GFF and protein FASTA files for AMRFinderPlus FALSE Optional theiaprok_illumina_se bakta_db String Database selection for Bakta annotation. Options: light (smaller, faster), full (more comprehensive), or a Google Storage URI (gs://...) pointing to a custom Bakta database archive (.tar.gz). The selected database will be extracted before annotation. full Optional theiaprok_illumina_se call_abricate Boolean Set to true to enable the Abricate task FALSE Optional theiaprok_illumina_se call_ani Boolean Set to true to enable the ANI task FALSE Optional theiaprok_illumina_se call_arln_stats Boolean Set to true to enable the return of ARLN required Auto PASS/FAIL outputs FALSE Optional theiaprok_illumina_se call_gamma Boolean Set to true in order to enable GAMMA task FALSE Optional theiaprok_illumina_se call_kmerfinder Boolean Set to true to enable the kmerfinder task FALSE Optional theiaprok_illumina_se call_plasmidfinder Boolean Set to true to enable the plasmidfinder task TRUE Optional theiaprok_illumina_se call_resfinder Boolean Set to true to enable the ResFinder task FALSE Optional theiaprok_illumina_se city String Will be used in the \"city\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_illumina_se collection_date String Will be used in the \"collection_date\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_illumina_se county String Will be used in the \"county\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_illumina_se expected_taxon String If provided, this input will override the taxonomic assignment made by GAMBIT and launch the relevant taxon-specific submodules. It will also modify the organism flag used by AMRFinderPlus. Example format: \"Salmonella enterica\" Optional theiaprok_illumina_se genome_annotation String If set to \"bakta\", TheiaProk will use Bakta rather than Prokka to annotate the genome prokka Optional theiaprok_illumina_se genome_length Int User-specified expected genome length to be used in genome statistics calculations Optional theiaprok_illumina_se max_genome_length Int Maximum genome length able to pass read screening. 18040666 Optional theiaprok_illumina_se min_basepairs Int Minimum number of base pairs able to pass read screening 2241820 Optional theiaprok_illumina_se min_coverage Int Minimum genome coverage able to pass read screening 10 Optional theiaprok_illumina_se min_genome_length Int Minimum genome length able to pass read screening. 100000 Optional theiaprok_illumina_se min_reads Int Minimum number of reads to pass read screening 7472 Optional theiaprok_illumina_se mlst_run_secondary_scheme Boolean If true, will run secondary scheme if primary scheme is of ecoli or abaumannii, these two have multiple schemes that are relevant. FALSE Optional theiaprok_illumina_se mlst_scheme_override Boolean If true, will force E. coli scheme to be used when Gambit predicts Escherichia coli, otherwise will return scheme MLST predicts. FALSE Optional theiaprok_illumina_se originating_lab String Will be used in the \"originating_lab\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_illumina_se perform_characterization Boolean Set to \"false\" if you want to only generate an assembly and relevant QC metrics and skip all characterization tasks TRUE Optional theiaprok_illumina_se qc_check_table File TSV value with taxons for rows and QC values for columns; internal cells represent user-determined QC thresholds; if provided, turns on the QC Check task. See below for an example QC Check table. Optional theiaprok_illumina_se read1_lane2 File If provided, the Concatenate_Illumina_Lanes subworkflow will concatenate all files from the same lane before doing any subsequent analysis Optional theiaprok_illumina_se read1_lane3 File If provided, the Concatenate_Illumina_Lanes subworkflow will concatenate all files from the same lane before doing any subsequent analysis Optional theiaprok_illumina_se read1_lane4 File If provided, the Concatenate_Illumina_Lanes subworkflow will concatenate all files from the same lane before doing any subsequent analysis Optional theiaprok_illumina_se run_id String Will be used in the \"run_id\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_illumina_se seq_method String The sequencing methodology used to generate the input read data; for TheiaProk workflows, this input will be used in the \"seq_id\" column in any taxon-specific tables created in the Export Taxon Tables task ILLUMINA Optional theiaprok_illumina_se skip_mash Boolean If true, skips estimation of genome size and coverage using mash in read screening steps. As a result, providing true also prevents screening using these parameters. FALSE Optional theiaprok_illumina_se skip_screen Boolean Set to True to skip the read screening prior to analysis FALSE Optional theiaprok_illumina_se taxon_tables File File indicating data table names to copy samples of a particular taxon to Optional theiaprok_illumina_se terra_project String The name of the Terra Project where you want the taxon tables written to NA Optional theiaprok_illumina_se terra_workspace String The name of the Terra Workspace where you want the taxon tables written to NA Optional theiaprok_illumina_se trim_min_length Int Specifies minimum length of each read after trimming to be kept 25 Optional theiaprok_illumina_se trim_quality_min_score Int Specifies the average quality of bases in a sliding window to be kept 30 Optional theiaprok_illumina_se trim_window_size Int Specifies window size for trimming (the number of bases to average the quality across) 4 Optional theiaprok_illumina_se zip String Will be used in the \"zip\" column in any taxon-specific tables created in the Export Taxon Tables task Optional ts_mlst cpu Int Number of CPUs to allocate to the task 1 Optional ts_mlst disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional ts_mlst docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mlst:2.23.0-2024-12-31 Optional ts_mlst memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional ts_mlst min_percent_coverage Float Minimum % breadth of coverage to report an MLST allele 10 Optional ts_mlst min_percent_identity Float Minimum % identity to known MLST gene to report an MLST allele 95 Optional ts_mlst minscore Float Minimum score https://github.com/tseemann/mlst#scoring-system to assign an MLST profile 50 Optional ts_mlst nopath Boolean true = use mlst --nopath. If set to false, filename paths are not stripped from FILE column in output TSV TRUE Optional ts_mlst scheme String Don\u2019t autodetect the MLST scheme; force this scheme on all inputs (see https://github.com/tseemann/mlst/blob/master/db/scheme_species_map.tab for accepted strings) None Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status theiaprok_ont read1 File ONT read file in FASTQ file format (compression optional) Required theiaprok_ont samplename String The name of the sample being analyzed Required abricate cpu Int Number of CPUs to allocate to the task 2 Optional abricate disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional abricate docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid Optional abricate memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional abricate min_percent_coverage Int Minimum DNA %coverage for the Abricate task 80 Optional abricate min_percent_identity Int Minimum DNA %identity for the Abricate task 80 Optional amrfinderplus_task cpu Int Number of CPUs to allocate to the task 2 Optional amrfinderplus_task detailed_drug_class Boolean If set to true, amrfinderplus_amr_classes and amrfinderplus_amr_subclasses outputs will be created FALSE Optional amrfinderplus_task disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional amrfinderplus_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ncbi-amrfinderplus:4.0.23-2025-07-16.1 Optional amrfinderplus_task hide_point_mutations Boolean If set to true, point mutations are not reported FALSE Optional amrfinderplus_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional amrfinderplus_task min_percent_coverage Float Minimum proportion of reference gene covered for a BLAST-based hit (Methods BLAST or PARTIAL).\" Attribute should be a float ranging from 0-1, such as 0.6 (equal to 60% coverage) 0.5 Optional amrfinderplus_task min_percent_identity Float Minimum identity for a blast-based hit hit (Methods BLAST or PARTIAL). -1 means use a curated threshold if it exists and 0.9 otherwise. Setting this value to something other than -1 will override any curated similarity cutoffs. Attribute should be a float ranging from 0-1, such as 0.95 (equal to 95% identity) 0.9 Optional amrfinderplus_task separate_betalactam_genes Boolean Report beta-Lactam AMR genes separated out by all beta-lactam and the respective beta-lactam subclasses FALSE Optional ani ani_threshold Float ANI value threshold must be surpassed in order to output the ani_top_species_match. If a genome does not surpass this threshold (and the percent_bases_aligned_threshold) then the ani_top_species_match output String will show a warning instead of a genus &amp; species. 80.0 Optional ani cpu Int Number of CPUs to allocate to the task 4 Optional ani disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ani docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mummer:4.0.0-rgdv2 Optional ani mash_filter Float Mash distance threshold over which ANI is not calculated 0.9 Optional ani memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional ani percent_bases_aligned_threshold Float Threshold regarding the proportion of bases aligned between the query genome and reference genome. If a genome does not surpass this threshold (and the ani_threshold) then the ani_top_species_match output String will show a warning instead of a genus &amp; species. 70.0 Optional ani ref_genome File If not set, uses all 43 genomes in RGDv2 Optional arln_stats cpu Int Number of CPUs to allocate to the task 2 Optional arln_stats disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional arln_stats docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/arln_stats:1.0.0 Optional arln_stats memory Int Amount of memory/RAM (in GB) to allocate to the task 5 Optional arln_stats read2_clean File Internal component, do not modify Optional arln_stats read2_raw File Internal component, do not modify Optional bakta bakta_opts String Parameters to pass to bakta from https://github.com/oschwengers/bakta#usage Optional bakta compliant Boolean If true, forces Genbank/ENA/DDJB compliant headers in Bakta output files FALSE Optional bakta cpu Int Number of CPUs to allocate to the task 8 Optional bakta disk_size Int Amount of storage (in GB) to allocate to the task 200 Optional bakta docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/bakta:1.10.3 Optional bakta memory Int Amount of memory/RAM (in GB) to allocate to the task 24 Optional bakta prodigal_tf File Prodigal training file to use for CDS prediction by bakta Optional bakta proteins File Fasta file of trusted protein sequences for CDS annotation Optional busco cpu Int Number of CPUs to allocate to the task 2 Optional busco disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional busco docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ezlabgva/busco:v5.7.1_cv1 Optional busco eukaryote Boolean Assesses eukaryotic organisms, rather than prokaryotic organisms FALSE Optional busco memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional clean_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional clean_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional clean_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional clean_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional export_taxon_table cpu Int Number of CPUs to allocate to the task 1 Optional export_taxon_table disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional export_taxon_table docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Optional export_taxon_table memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional flye_denovo auto_medaka_model Boolean If true, medaka will automatically select the best Medaka model for assembly TRUE Optional flye_denovo bandage_cpu Int Number of CPUs to allocate to the task 2 Optional flye_denovo bandage_disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional flye_denovo bandage_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional flye_denovo dnaapler_cpu Int Number of CPUs to allocate to the task 1 Optional flye_denovo dnaapler_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flye_denovo dnaapler_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional flye_denovo dnaapler_mode String Dnaapler-specific inputs all Optional flye_denovo filter_contigs_cpu Int Number of CPUs to allocate to the task 1 Optional flye_denovo filter_contigs_disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional flye_denovo filter_contigs_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional flye_denovo filter_contigs_min_length Int Minimum contig length to keep 1000 Optional flye_denovo flye_additional_parameters String Any extra Flye-specific parameters Optional flye_denovo flye_asm_coverage Int Reduced coverage for initial disjointig assembly Optional flye_denovo flye_cpu Int Number of CPUs to allocate to the task 4 Optional flye_denovo flye_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flye_denovo flye_genome_length Int User-specified expected genome length to be used in genome statistics calculations Optional flye_denovo flye_keep_haplotypes Boolean If true keep haplotypes FALSE Optional flye_denovo flye_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional flye_denovo flye_minimum_overlap Int Minimum overlap between reads Optional flye_denovo flye_no_alt_contigs Boolean If true, do not generate alternative contigs FALSE Optional flye_denovo flye_polishing_iterations Int Default polishing iterations 1 Optional flye_denovo flye_read_error_rate Float Maximum expected read error rate Optional flye_denovo flye_read_type String Specifies the type of sequencing reads. Options: --nano-hq (default), --nano-corr, --nano-raw, --pacbio-raw, --pacbio-corr, --pacbio-hifi. Refer to Flye documentation for details on each type. --nano-hq Optional flye_denovo flye_scaffold Boolean If true, scaffolding is enabled using graph FALSE Optional flye_denovo flye_uneven_coverage_mode Boolean sets the --meta option in the case of uneven coverage (or metagenomics) FALSE Optional flye_denovo illumina_read1 File If Illumina reads are provided, flye_denovo subworkflow will perform Illumina polishing Optional flye_denovo illumina_read2 File If Illumina reads are provided, flye_denovo subworkflow will perform Illumina polishing Optional flye_denovo medaka_cpu Int Number of CPUs to allocate to the task 4 Optional flye_denovo medaka_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flye_denovo medaka_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional flye_denovo medaka_model String In order to obtain the best results, the appropriate model must be set to match the sequencer's basecaller model; this string takes the format of {pore}{device}{caller variant}_{caller_version}. See also https://github.com/nanoporetech/medaka?tab=readme-ov-file#models. If this is being run on legacy data it is likely to be r941_min_hac_g507. r1041_e82_400bps_sup_v5.0.0 Optional flye_denovo polish_rounds Int The number of polishing rounds to conduct for medaka or racon (without Illumina) 1 Optional flye_denovo polisher String The polishing tool to use for assembly medaka Optional flye_denovo polypolish_careful Boolean Polypolish-specific inputs FALSE Optional flye_denovo polypolish_cpu Int Number of CPUs to allocate to the task 1 Optional flye_denovo polypolish_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flye_denovo polypolish_fraction_invalid Float Polypolish-specific inputs Optional flye_denovo polypolish_fraction_valid Float Polypolish-specific inputs Optional flye_denovo polypolish_high_percentile_threshold Float Polypolish-specific inputs Optional flye_denovo polypolish_low_percentile_threshold Float Polypolish-specific inputs Optional flye_denovo polypolish_maximum_errors Int Polypolish-specific inputs Optional flye_denovo polypolish_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional flye_denovo polypolish_minimum_depth Int Polypolish-specific inputs Optional flye_denovo polypolish_pair_orientation String Polypolish-specific inputs Optional flye_denovo porechop_cpu Int Number of CPUs to allocate to the task 4 Optional flye_denovo porechop_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flye_denovo porechop_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional flye_denovo porechop_trimopts String Options to pass to Porechop for trimming Optional flye_denovo racon_cpu Int Number of CPUs to allocate to the task 8 Optional flye_denovo racon_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flye_denovo racon_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional flye_denovo run_porechop Boolean If true, trims reads before assembly using Porechop FALSE Optional flye_denovo skip_polishing Boolean If true, skips polishing FALSE Optional gambit cpu Int Number of CPUs to allocate to the task 1 Optional gambit disk_size Int Amount of storage (in GB) to allocate to the task 20 Optional gambit docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Optional gambit gambit_db_genomes File Database of metadata for assembled query genomes; requires complementary signatures file. If not provided, uses default database \"/gambit-db\" gs://gambit-databases-rp/2.0.0/gambit-metadata-2.0.1-20250505.gdb Optional gambit gambit_db_signatures File Signatures file; requires complementary genomes file. If not specified, the file from the docker container will be used. gs://gambit-databases-rp/2.0.0/gambit-signatures-2.0.1-20250505.gs Optional gambit memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional gamma cpu Int Number of CPUs to allocate to the task 2 Optional gamma disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional gamma docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/gamma:2.2 Optional gamma extended_output Boolean GAMMA will provide the extended output when set to true FALSE Optional gamma gamma_db File Multifasta sequence database GAMMA is to use for gene matching gs://theiagen-public-resources-rp/reference_data/databases/gamma/default_ResFinderDB_Combined_05-06-20.fsa Optional gamma memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional gamma min_length_percent_gammas Int Threshold of match length percent used by GAMMA-s 20 Optional gamma min_percent_identity Int Threshold of identity for gene matches in percent 90 Optional gamma output_fasta Boolean Allows GAMMA to output gene matches in FASTA format TRUE Optional gamma output_gff Boolean Allows GAMMA to output gene matches in GFF format TRUE Optional gamma run_gammas Boolean Turns on GAMMA-S which runs GAMMA on nucleotide sequences rather than translating input sequences and matches FALSE Optional kmerfinder cpu Int Number of CPUs to allocate to the task 4 Optional kmerfinder disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional kmerfinder docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/kmerfinder:3.0.2--hdfd78af_0 Optional kmerfinder kmerfinder_args String Kmerfinder additional arguments Optional kmerfinder kmerfinder_db File Bacterial database for KmerFinder gs://theiagen-public-resources-rp/reference_data/databases/kmerfinder/kmerfinder_bacteria_20230911.tar.gz Optional kmerfinder memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional merlin_magic abricate_abaum_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid Optional merlin_magic abricate_abaum_min_percent_coverage Int Minimum DNA percent coverage Optional merlin_magic abricate_abaum_min_percent_identity Int Minimum DNA percent identity; set to 95 because there is a strict threshold of 95% identity for typing purposes 95 Optional merlin_magic abricate_vibrio_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid Optional merlin_magic abricate_vibrio_min_percent_coverage Int Minimum DNA percent coverage 80 Optional merlin_magic abricate_vibrio_min_percent_identity Int Minimum DNA percent identity 80 Optional merlin_magic agrvate_agr_typing_only Boolean Set to true to skip agr operon extraction and frameshift detection FALSE Optional merlin_magic agrvate_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/agrvate:1.0.2--hdfd78af_0 Optional merlin_magic amr_search_cpu Int Number of CPUs to allocate to the task 2 Optional merlin_magic amr_search_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional merlin_magic amr_search_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/amrsearch:0.2.1 Optional merlin_magic amr_search_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional merlin_magic assembly_only Boolean Set to true if only analyzing input assembly FALSE Optional merlin_magic call_poppunk Boolean If true, runs PopPUNK for GPSC cluster designation for S. pneumoniae TRUE Optional merlin_magic call_shigeifinder_reads_input Boolean If set to \"true\", the ShigEiFinder task will run again but using read files as input instead of the assembly file. Input is shown but not used for TheiaProk_FASTA. FALSE Optional merlin_magic call_stxtyper Boolean If set to \"true\", the StxTyper task will run on all samples regardless of the gambit_predicted_taxon output. Useful if you suspect a non-E.coli or non-Shigella sample contains stx genes. FALSE Optional merlin_magic call_tbp_parser Boolean If set to \"true\", activates the tbp_parser module and results in more outputs, including\u00a0tbp_parser_looker_report_csv, tbp_parser_laboratorian_report_csv,  tbp_parser_lims_report_csv, tbp_parser_coverage_report, and tbp_parser_genome_percent_coverage FALSE Optional merlin_magic cauris_cladetyper_docker_image String Internal component, do not modify us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Optional merlin_magic cladetyper_kmer_size Int Internal component, do not modify Optional merlin_magic cladetyper_max_distance Float Internal component, do not modify 0.1 Optional merlin_magic cladetyper_ref_clade1 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade1_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade2 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade2_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade3 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade3_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade4 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade4_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade5 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade5_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade6 File The reference assembly for clade 6 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade6_GCA_032714025.1_ASM3271402v1_genomic.fasta Optional merlin_magic cladetyper_ref_clade6_annotated File The path to the annotated reference for clade 6 Optional merlin_magic clockwork_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/cdcgov/varpipe_wgs_with_refs:2bc7234074bd53d9e92a1048b0485763cd9bbf6f4d12d5a1cc82bfec8ca7d75e Optional merlin_magic ectyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/ectyper:1.0.0--pyhdfd78af_1 Optional merlin_magic ectyper_h_min_percent_coverage Int Minumum percent coverage required for an H antigen allele match 50 Optional merlin_magic ectyper_h_min_percent_identity Int Percent identity required for an H antigen allele match 95 Optional merlin_magic ectyper_o_min_percent_coverage Int Minumum percent coverage required for an O antigen allele match 90 Optional merlin_magic ectyper_o_min_percent_identity Int Percent identity required for an O antigen allele match 90 Optional merlin_magic ectyper_print_alleles Boolean Set to true to print the allele sequences as the final column FALSE Optional merlin_magic ectyper_verify Boolean Set to true to enable E. coli species verification FALSE Optional merlin_magic emmtyper_align_diff Int Threshold for difference between alignment length and subject length in BLAST hit. Optional merlin_magic emmtyper_cluster_distance Int Distance between cluster of matches to consider as different clusters. Optional merlin_magic emmtyper_culling_limit Int Total hits to return in a position. Optional merlin_magic emmtyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/emmtyper:0.2.0--py_0 Optional merlin_magic emmtyper_gap Int Threshold gap to allow in BLAST hit. Optional merlin_magic emmtyper_max_size Int Maximum size of PCR product. Optional merlin_magic emmtyper_min_good Int Minimum size where there must be 2 matches for each mismatch. Optional merlin_magic emmtyper_min_percent_identity Int Minimal percent identity of sequence. Optional merlin_magic emmtyper_min_perfect Int Minimum size of perfect match at 3' primer end. Optional merlin_magic emmtyper_mismatch Int Threshold for number of mismatch to allow in BLAST hit. Optional merlin_magic emmtyper_wf String Choose workflow [blast pcr] merlin_magic emmtypingtool_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/emmtypingtool:0.0.1 Optional merlin_magic genotyphi_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.11.0 Optional merlin_magic hicap_broken_gene_length Int Minimum length to consider a broken gene 60 Optional merlin_magic hicap_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/hicap:1.0.3--py_0 Optional merlin_magic hicap_min_broken_gene_percent_identity Float Minimum percentage identity to consider a broken gene 0.8 Optional merlin_magic hicap_min_gene_percent_coverage Float Minimum percentage coverage to consider a single gene complete 0.8 Optional merlin_magic hicap_min_gene_percent_identity Float Minimum percentage identity to consider a single gene complete 0.7 Optional merlin_magic kaptive_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kaptive:2.0.3 Optional merlin_magic kaptive_low_gene_percent_identity Float Percent identity threshold for what counts as a low identity match in the gene BLAST search 95 Optional merlin_magic kaptive_min_percent_coverage Float Minimum required percent coverage for the gene BLAST search via tBLASTn 80 Optional merlin_magic kaptive_min_percent_identity Float Minimum required percent identity for the gene BLAST search via tBLASTn 90 Optional merlin_magic kaptive_start_end_margin Int Determines flexibility in identifying the start and end of a locus - if this value is 10, a locus match that is missing the first 8 base pairs will still count as capturing the start of the locus 10 Optional merlin_magic kleborate_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kleborate:2.2.0 Optional merlin_magic kleborate_min_kaptive_confidence String {None,Low,Good,High,Very_high,Perfect} Minimum Kaptive confidence to call K/O loci - confidence levels below this will be reported as unknown Good Optional merlin_magic kleborate_min_percent_coverage Float Minimum alignment percent coverage for main results 80 Optional merlin_magic kleborate_min_percent_identity Float Minimum alignment percent identity for main results 90 Optional merlin_magic kleborate_min_spurious_percent_coverage Float Minimum alignment percent coverage for spurious results 40 Optional merlin_magic kleborate_min_spurious_percent_identity Float Minimum alignment percent identity for spurious results 80 Optional merlin_magic kleborate_skip_kaptive Boolean Equivalent to --kaptive_k --kaptive_ FALSE Optional merlin_magic kleborate_skip_resistance Boolean Set to true to turn on resistance genes screening (default: no resistance gene screening) FALSE Optional merlin_magic legsta_docker_image String Internal component, do not modify Optional merlin_magic lissero_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/lissero:0.4.9--py_0 Optional merlin_magic lissero_min_percent_coverage Float Minimum percent coverage of the gene to accept a match 95 Optional merlin_magic lissero_min_percent_identity Float Minimum percent identity to accept a match 95 Optional merlin_magic meningotype_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/meningotype:0.8.5--pyhdfd78af_0 Optional merlin_magic ngmaster_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ngmaster:1.0.0 Optional merlin_magic paired_end Boolean Set to true if your data is paired-end FASTQ files TRUE Optional merlin_magic pasty_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pasty:1.0.3 Optional merlin_magic pasty_min_percent_coverage Int Minimum coverage of a O-antigen to be considered for serogrouping by pasty 95 Optional merlin_magic pasty_min_percent_identity Int Minimum percent identity for a blast hit to be considered for serogrouping 95 Optional merlin_magic pbptyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pbptyper:1.0.4 Optional merlin_magic pbptyper_min_percent_coverage Int Minimum percent coverage to count a hit 90 Optional merlin_magic pbptyper_min_percent_identity Int Minimum percent identity to count a hit 90 Optional merlin_magic poppunk_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/poppunk:2.4.0 Optional merlin_magic poppunk_gps_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_clusters.csv Optional merlin_magic poppunk_gps_dists_npy File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.dists.npy Optional merlin_magic poppunk_gps_dists_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.dists.pkl Optional merlin_magic poppunk_gps_external_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_external_clusters.csv Optional merlin_magic poppunk_gps_fit_npz File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_fit.npz Optional merlin_magic poppunk_gps_fit_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_fit.pkl Optional merlin_magic poppunk_gps_graph_gt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_graph.gt Optional merlin_magic poppunk_gps_h5 File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.h5 Optional merlin_magic poppunk_gps_qcreport_txt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_qcreport.txt Optional merlin_magic poppunk_gps_refs File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs Optional merlin_magic poppunk_gps_refs_dists_npy File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.dists.npy Optional merlin_magic poppunk_gps_refs_dists_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.dists.pkl Optional merlin_magic poppunk_gps_refs_graph_gt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6refs_graph.gt Optional merlin_magic poppunk_gps_refs_h5 File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.h5 Optional merlin_magic poppunk_gps_unword_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_unword_clusters.csv Optional merlin_magic read2 File Internal component, do not modify Optional merlin_magic run_amr_search Boolean If set to true AMR_Search workflow will be run if species is part of supported taxon, see AMR_Search docs. FALSE Optional merlin_magic seqsero2_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/seqsero2:1.2.1 Optional merlin_magic seroba_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/seroba:1.0.2 Optional merlin_magic serotypefinder_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/serotypefinder:2.0.1 Optional merlin_magic shigatyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/shigatyper:2.0.5 Optional merlin_magic shigeifinder_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/shigeifinder:1.3.5 Optional merlin_magic sistr_cpu Int Number of CPUs to allocate to the task 2 Optional merlin_magic sistr_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional merlin_magic sistr_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/sistr_cmd:1.1.1--pyh864c0ab_2 Optional merlin_magic sistr_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional merlin_magic sistr_use_full_cgmlst_db Boolean Set to true to use the full set of cgMLST alleles which can include highly similar alleles. By default the smaller \"centroid\" alleles or representative alleles are used for each marker FALSE Optional merlin_magic snippy_base_quality Int Internal component, do not modify Optional merlin_magic snippy_gene_query_docker_image String Internal component, do not modify Optional merlin_magic snippy_map_qual Int Internal component, do not modify Optional merlin_magic snippy_maxsoft Int Internal component, do not modify Optional merlin_magic snippy_min_coverage Int Internal component, do not modify Optional merlin_magic snippy_min_frac Float Internal component, do not modify Optional merlin_magic snippy_min_quality Int Internal component, do not modify Optional merlin_magic snippy_query_gene String Internal component, do not modify Optional merlin_magic snippy_reference_afumigatus File Internal component, do not modify gs://theiagen-public-resources-rp/reference_data/eukaryotic/aspergillus/Aspergillus_fumigatus_GCF_000002655.1_ASM265v1_genomic.gbff Optional merlin_magic snippy_reference_cryptoneo File Internal component, do not modify gs://theiagen-public-resources-rp/reference_data/eukaryotic/cryptococcus/Cryptococcus_neoformans_GCF_000091045.1_ASM9104v1_genomic.gbff Optional merlin_magic snippy_variants_docker_image String Internal component, do not modify Optional merlin_magic sonneityping_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Optional merlin_magic sonneityping_mykrobe_opts String Additional options for mykrobe in sonneityping Optional merlin_magic spatyper_do_enrich Boolean Set to true to enable PCR product enrichment FALSE Optional merlin_magic spatyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/spatyper:0.3.3--pyhdfd78af_3 Optional merlin_magic srst2_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/srst2:0.2.0-vcholerae Optional merlin_magic srst2_gene_max_mismatch Int Maximum number of mismatches for SRST2 to call a gene as present 2000 Optional merlin_magic srst2_max_divergence Int Maximum divergence, in percentage, for SRST2 to call a gene as present 20 Optional merlin_magic srst2_min_depth Int Minimum depth of coverage for SRST2 to call a gene as present 5 Optional merlin_magic srst2_min_edge_depth Int Minimum edge depth for SRST2 to call a gene as present 2 Optional merlin_magic srst2_min_percent_coverage Int Minimum breadth of coverage for SRST2 to call a gene as present 80 Optional merlin_magic staphopia_sccmec_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/staphopia-sccmec:1.0.0--hdfd78af_0 Optional merlin_magic stxtyper_cpu Int Number of CPUs to allocate to the task 1 Optional merlin_magic stxtyper_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional merlin_magic stxtyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/stxtyper:1.0.42 Optional merlin_magic stxtyper_enable_debug Boolean When enabled, additional messages are printed and files in $TMPDIR are not removed after running FALSE Optional merlin_magic stxtyper_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional merlin_magic tbp_parser_add_cs_lims Boolean Set to true add cycloserine results to the LIMS report FALSE Optional merlin_magic tbp_parser_config File The configuration file to use, in YAML format (overrides all other arguments except input_json and input_bam) Optional merlin_magic tbp_parser_coverage_regions_bed File A bed file that lists the regions to be considered for QC Optional merlin_magic tbp_parser_debug Boolean Activate the debug mode on tbp_parser; increases logging outputs TRUE Optional merlin_magic tbp_parser_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/tbp-parser:2.6.0 Optional merlin_magic tbp_parser_etha237_frequency Float Minimum frequency for a mutation in ethA at protein position 237 to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_expert_rule_regions_bed File A file that contains the regions where R mutations and expert rules are applied Optional merlin_magic tbp_parser_min_depth Int Minimum depth for a variant to pass QC in tbp_parser 10 Optional merlin_magic tbp_parser_min_frequency Float The minimum frequency for a mutation to pass QC 0.1 Optional merlin_magic tbp_parser_min_percent_coverage Float The minimum coverage for a region to pass QC in tbp_parser 100 Optional merlin_magic tbp_parser_min_read_support Int The minimum read support for a mutation to pass QC 10 Optional merlin_magic tbp_parser_operator String Fills the \"operator\" field in the tbp_parser output files Operator not provided Optional merlin_magic tbp_parser_output_seq_method_type String Fills out the \"seq_method\" field in the tbp_parser output files WGS Optional merlin_magic tbp_parser_rpob449_frequency Float Minimum frequency for a mutation at protein position 449 to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_rrl_frequency Float Minimum frequency for a mutation in rrl to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_rrl_read_support Int Minimum read support for a mutation in rrl to pass QC in tbp-parser 10 Optional merlin_magic tbp_parser_rrs_frequency Float Minimum frequency for a mutation in rrs to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_rrs_read_support Int Minimum read support for a mutation in rrs to pass QC in tbp-parser 10 Optional merlin_magic tbp_parser_tngs_data Boolean Set to true to enable tNGS-specific parameters and runs in tbp-parser FALSE Optional merlin_magic tbprofiler_additional_parameters String Additional parameters for TBProfiler Optional merlin_magic tbprofiler_custom_db File TBProfiler uses by default the TBDB database; if you have a custom database you wish to use, you must provide a custom database in this field and set tbprofiler_run_custom_db to true Optional merlin_magic tbprofiler_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/tbprofiler:6.6.3 Optional merlin_magic tbprofiler_mapper String The mapping tool used in TBProfiler to align the reads to the reference genome; see TBProfiler\u2019s original documentation for available options. bwa Optional merlin_magic tbprofiler_min_af Float The minimum allele frequency to call a variant 0.1 Optional merlin_magic tbprofiler_min_depth Int The minimum depth for a variant to be called. 10 Optional merlin_magic tbprofiler_run_cdph_db Boolean TBProfiler uses by default the TBDB database; set this value to \"true\" to use the WHO v2 database with customizations for CDPH FALSE Optional merlin_magic tbprofiler_run_custom_db Boolean TBProfiler uses by default the TBDB database; if you have a custom database you wish to use, you must set this value to true and provide a custom database in the tbprofiler_custom_db field FALSE Optional merlin_magic tbprofiler_variant_caller String Select a different variant caller for TBProfiler to use by writing it in this block; see TBProfiler\u2019s original documentation for available options. GATK Optional merlin_magic tbprofiler_variant_calling_params String Enter additional variant calling parameters in this free text input to customize how the variant caller works in TBProfiler Optional merlin_magic theiaeuk Boolean Internal component, do not modify FALSE Optional merlin_magic vibecheck_docker_image String Internal component, do not modify Optional merlin_magic vibecheck_lineage_barcodes File Internal component, do not modify Optional merlin_magic vibecheck_skip_subsampling Boolean Internal component, do not modify Optional merlin_magic vibecheck_subsampling_fraction Float Internal component, do not modify Optional merlin_magic virulencefinder_database String The specific database to use virulence_ecoli Optional merlin_magic virulencefinder_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/virulencefinder:2.0.4 Optional merlin_magic virulencefinder_min_percent_coverage Float The threshold for minimum coverage Optional merlin_magic virulencefinder_min_percent_identity Float The threshold for minimum blast identity Optional nanoplot_clean cpu Int Number of CPUs to allocate to the task 4 Optional nanoplot_clean disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoplot_clean docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Optional nanoplot_clean max_length Int The maximum length of clean reads, for which reads longer than the length specified will be hidden. 100000 Optional nanoplot_clean memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional nanoplot_raw cpu Int Number of CPUs to allocate to the task 4 Optional nanoplot_raw disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoplot_raw docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Optional nanoplot_raw max_length Int The maximum length of clean reads, for which reads longer than the length specified will be hidden. 100000 Optional nanoplot_raw memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional plasmidfinder cpu Int Number of CPUs to allocate to the task 2 Optional plasmidfinder database String User-specified database Optional plasmidfinder database_path String Path to user-specified database Optional plasmidfinder disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional plasmidfinder docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/plasmidfinder:2.1.6 Optional plasmidfinder memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional plasmidfinder method_path String Path to files for a user-specified method to use (blast or kma) Optional plasmidfinder min_percent_coverage Float Threshold for minimum coverage, default threshold from PlasmidFinder CLI tool is used (0.60) 0.6 Optional plasmidfinder min_percent_identity Float Threshold for mininum blast identity, default threshold from PlasmidFinder CLI tool is used (0.90). This default differs from the default of the PlasmidFinder webtool (0.95) 0.9 Optional prokka compliant Boolean If true (default), forces Genbank/ENA/DDJB compliant headers in Prokka output files TRUE Optional prokka cpu Int Number of CPUs to allocate to the task 4 Optional prokka disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional prokka docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/prokka:1.14.5 Optional prokka memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional prokka prodigal_tf File https://github.com/tseemann/prokka#option---prodigaltf Optional prokka prokka_arguments String Any additional https://github.com/tseemann/prokka#command-line-options Optional prokka proteins Boolean FASTA file of trusted proteins for Prokka to first use for annotations FALSE Optional qc_check_task assembly_length_unambiguous Int Internal component, do not modify Optional qc_check_task assembly_mean_coverage Float Internal component, do not modify Optional qc_check_task combined_mean_q_clean Float Internal component, do not modify Optional qc_check_task combined_mean_q_raw Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task cpu Int Number of CPUs to allocate to the task 4 Optional qc_check_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional qc_check_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional qc_check_task kraken_human Float Internal component, do not modify Optional qc_check_task kraken_human_dehosted Float Internal component, do not modify Optional qc_check_task kraken_sc2 Float Internal component, do not modify Optional qc_check_task kraken_sc2_dehosted Float Internal component, do not modify Optional qc_check_task kraken_target_organism Float Internal component, do not modify Optional qc_check_task kraken_target_organism_dehosted Float Internal component, do not modify Optional qc_check_task meanbaseq_trim String Internal component, do not modify Optional qc_check_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional qc_check_task midas_secondary_genus_abundance Float Internal component, do not modify Optional qc_check_task midas_secondary_genus_coverage Float Internal component, do not modify Optional qc_check_task num_reads_clean2 Int Internal component, do not modify Optional qc_check_task num_reads_raw2 Int Internal component, do not modify Optional qc_check_task number_Degenerate Int Internal component, do not modify Optional qc_check_task number_N Int Internal component, do not modify Optional qc_check_task percent_reference_coverage Float Internal component, do not modify Optional qc_check_task r2_mean_q_clean Float Internal component, do not modify Optional qc_check_task r2_mean_q_raw Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task sc2_s_gene_mean_coverage Float Internal component, do not modify Optional qc_check_task sc2_s_gene_percent_coverage Float Internal component, do not modify Optional qc_check_task vadr_num_alerts String Internal component, do not modify Optional quast cpu Int Number of CPUs to allocate to the task 2 Optional quast disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional quast docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/quast:5.0.2 Optional quast memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional quast min_contig_length Int Minimum length of contig for QUAST 500 Optional raw_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional raw_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional raw_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional raw_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional read_QC_trim artic_guppyplex_cpu Int Internal component, do not modify Optional read_QC_trim artic_guppyplex_disk_size Int Internal component, do not modify Optional read_QC_trim artic_guppyplex_docker String Internal component, do not modify Optional read_QC_trim artic_guppyplex_memory Int Internal component, do not modify Optional read_QC_trim call_kraken Boolean True/False variable that determines if the Kraken2 task should be called; for non-TheiaCoV workflows, the <code>kraken_db</code> variable must be provided. FALSE Optional read_QC_trim downsampling_coverage Float The desired coverage to sub-sample the reads to with RASUSA 150 Optional read_QC_trim kraken2_recalculate_abundances_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim kraken2_recalculate_abundances_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim kraken2_recalculate_abundances_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-08-28-v4 Optional read_QC_trim kraken2_recalculate_abundances_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim kraken_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim kraken_db File A kraken2 database to use with the kraken2 optional task. The file must be a .tar.gz kraken2 database. Optional read_QC_trim kraken_disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional read_QC_trim kraken_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Optional read_QC_trim kraken_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional read_QC_trim max_length Int Internal component, do not modify Optional read_QC_trim min_length Int Internal component, do not modify Optional read_QC_trim nanoq_cpu Int Number of CPUs to allocate to the task 2 Optional read_QC_trim nanoq_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim nanoq_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/nanoq:0.9.0--hec16e2b_1 Optional read_QC_trim nanoq_max_read_length Int The maximum read length to keep after trimming 100000 Optional read_QC_trim nanoq_max_read_qual Int The maximum read quality to keep after trimming 40 Optional read_QC_trim nanoq_memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional read_QC_trim nanoq_min_read_length Int The minimum read length to keep after trimming 500 Optional read_QC_trim nanoq_min_read_qual Int The minimum read quality to keep after trimming 10 Optional read_QC_trim ncbi_scrub_cpu Int Internal component, do not modify 4 Optional read_QC_trim ncbi_scrub_disk_size Int Internal component, do not modify 100 Optional read_QC_trim ncbi_scrub_docker String Internal component, do not modify us-docker.pkg.dev/general-theiagen/ncbi/sra-human-scrubber:2.2.1 Optional read_QC_trim ncbi_scrub_memory Int Internal component, do not modify 8 Optional read_QC_trim rasusa_bases String Explicitly set the number of bases required e.g., 4.3kb, 7Tb, 9000, 4.1MB. If this option is given, --coverage and --genome-size are ignored Optional read_QC_trim rasusa_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim rasusa_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_QC_trim rasusa_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/rasusa:2.1.0 Optional read_QC_trim rasusa_fraction_of_reads Float Subsample to a fraction of the reads - e.g., 0.5 samples half the reads Optional read_QC_trim rasusa_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim rasusa_number_of_reads Int Subsample to a specific number of reads Optional read_QC_trim rasusa_seed Int Random seed to use Optional read_QC_trim run_prefix String Internal component, do not modify Optional read_QC_trim target_organism String Internal component, do not modify Optional resfinder_task acquired Boolean Set to true to tell ResFinder to identify acquired resistance genes TRUE Optional resfinder_task call_pointfinder Boolean Set to true to enable detection of point mutations. FALSE Optional resfinder_task cpu Int Number of CPUs to allocate to the task 2 Optional resfinder_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional resfinder_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/resfinder:4.1.11 Optional resfinder_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional resfinder_task min_percent_coverage Float Minimum coverage breadth of a gene for it to be identified 0.5 Optional resfinder_task min_percent_identity Float Minimum identity for ResFinder to identify a gene 0.9 Optional theiaprok_ont abricate_db String Database to use with the Abricate tool. Options: NCBI, CARD, ARG-ANNOT, Resfinder, MEGARES, EcOH, PlasmidFinder, Ecoli_VF and VFDB vfdb Optional theiaprok_ont amrfinder_use_gff Boolean Whether or not to use the GFF and protein FASTA files for AMRFinderPlus FALSE Optional theiaprok_ont bakta_db String Database selection for Bakta annotation. Options: light (smaller, faster), full (more comprehensive), or a Google Storage URI (gs://...) pointing to a custom Bakta database archive (.tar.gz). The selected database will be extracted before annotation. full Optional theiaprok_ont call_abricate Boolean Set to true to enable the Abricate task FALSE Optional theiaprok_ont call_ani Boolean Set to true to enable the ANI task FALSE Optional theiaprok_ont call_arln_stats Boolean Set to true to enable the return of ARLN required Auto PASS/FAIL outputs FALSE Optional theiaprok_ont call_gamma Boolean Set to true in order to enable GAMMA task FALSE Optional theiaprok_ont call_kmerfinder Boolean Set to true to enable the kmerfinder task FALSE Optional theiaprok_ont call_plasmidfinder Boolean Set to true to enable the plasmidfinder task TRUE Optional theiaprok_ont call_resfinder Boolean Set to true to enable the ResFinder task FALSE Optional theiaprok_ont city String Will be used in the \"city\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_ont collection_date String Will be used in the \"collection_date\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_ont county String Will be used in the \"county\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_ont expected_taxon String If provided, this input will override the taxonomic assignment made by GAMBIT and launch the relevant taxon-specific submodules. It will also modify the organism flag used by AMRFinderPlus. Example format: \"Salmonella enterica\" Optional theiaprok_ont genome_annotation String If set to \"bakta\", TheiaProk will use Bakta rather than Prokka to annotate the genome prokka Optional theiaprok_ont genome_length Int User-specified expected genome length to be used in genome statistics calculations Optional theiaprok_ont max_genome_length Int Maximum genome length able to pass read screening. For TheiaProk_ONT, screening using max_genome_length is skipped by default. 18040666 Optional theiaprok_ont min_basepairs Int Minimum number of base pairs able to pass read screening 2241820 Optional theiaprok_ont min_coverage Int Minimum genome coverage able to pass read screening. Screening using min_coverage is skipped by default. 5 Optional theiaprok_ont min_genome_length Int Minimum genome length able to pass read screening. For TheiaProk_ONT, screening using min_genome_length is skipped by default. 100000 Optional theiaprok_ont min_reads Int Minimum number of reads to pass read screening 5000 Optional theiaprok_ont mlst_run_secondary_scheme Boolean If true, will run secondary scheme if primary scheme is of ecoli or abaumannii, these two have multiple schemes that are relevant. FALSE Optional theiaprok_ont mlst_scheme_override Boolean If true, will force E. coli scheme to be used when Gambit predicts Escherichia coli, otherwise will return scheme MLST predicts. FALSE Optional theiaprok_ont originating_lab String Will be used in the \"originating_lab\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_ont perform_characterization Boolean Set to \"false\" if you want to only generate an assembly and relevant QC metrics and skip all characterization tasks TRUE Optional theiaprok_ont qc_check_table File TSV value with taxons for rows and QC values for columns; internal cells represent user-determined QC thresholds; if provided, turns on the QC Check task. See below for an example QC Check table. Optional theiaprok_ont run_id String Will be used in the \"run_id\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_ont seq_method String The sequencing methodology used to generate the input read data; for TheiaProk workflows, this input will be used in the \"seq_id\" column in any taxon-specific tables created in the Export Taxon Tables task ONT Optional theiaprok_ont skip_mash Boolean If true, skips estimation of genome size and coverage using mash in read screening steps. As a result, providing true also prevents screening using these parameters. TRUE Optional theiaprok_ont skip_screen Boolean Set to True to skip the read screening prior to analysis FALSE Optional theiaprok_ont taxon_tables File File indicating data table names to copy samples of a particular taxon to Optional theiaprok_ont terra_project String The name of the Terra Project where you want the taxon tables written to NA Optional theiaprok_ont terra_workspace String The name of the Terra Workspace where you want the taxon tables written to NA Optional theiaprok_ont zip String Will be used in the \"zip\" column in any taxon-specific tables created in the Export Taxon Tables task Optional ts_mlst cpu Int Number of CPUs to allocate to the task 1 Optional ts_mlst disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional ts_mlst docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mlst:2.23.0-2024-12-31 Optional ts_mlst memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional ts_mlst min_percent_coverage Float Minimum % breadth of coverage to report an MLST allele 10 Optional ts_mlst min_percent_identity Float Minimum % identity to known MLST gene to report an MLST allele 95 Optional ts_mlst minscore Float Minimum score https://github.com/tseemann/mlst#scoring-system to assign an MLST profile 50 Optional ts_mlst nopath Boolean true = use mlst --nopath. If set to false, filename paths are not stripped from FILE column in output TSV TRUE Optional ts_mlst scheme String Don\u2019t autodetect the MLST scheme; force this scheme on all inputs (see https://github.com/tseemann/mlst/blob/master/db/scheme_species_map.tab for accepted strings) None Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status theiaprok_fasta assembly_fasta File The assembly file for your sample in FASTA format Required theiaprok_fasta samplename String The name of the sample being analyzed Required abricate cpu Int Number of CPUs to allocate to the task 2 Optional abricate disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional abricate docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid Optional abricate memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional abricate min_percent_coverage Int Minimum DNA %coverage for the Abricate task 80 Optional abricate min_percent_identity Int Minimum DNA %identity for the Abricate task 80 Optional amrfinderplus_task cpu Int Number of CPUs to allocate to the task 2 Optional amrfinderplus_task detailed_drug_class Boolean If set to true, amrfinderplus_amr_classes and amrfinderplus_amr_subclasses outputs will be created FALSE Optional amrfinderplus_task disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional amrfinderplus_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ncbi-amrfinderplus:4.0.23-2025-07-16.1 Optional amrfinderplus_task hide_point_mutations Boolean If set to true, point mutations are not reported FALSE Optional amrfinderplus_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional amrfinderplus_task min_percent_coverage Float Minimum proportion of reference gene covered for a BLAST-based hit (Methods BLAST or PARTIAL).\" Attribute should be a float ranging from 0-1, such as 0.6 (equal to 60% coverage) 0.5 Optional amrfinderplus_task min_percent_identity Float Minimum identity for a blast-based hit hit (Methods BLAST or PARTIAL). -1 means use a curated threshold if it exists and 0.9 otherwise. Setting this value to something other than -1 will override any curated similarity cutoffs. Attribute should be a float ranging from 0-1, such as 0.95 (equal to 95% identity) 0.9 Optional amrfinderplus_task separate_betalactam_genes Boolean Report beta-Lactam AMR genes separated out by all beta-lactam and the respective beta-lactam subclasses FALSE Optional ani ani_threshold Float ANI value threshold must be surpassed in order to output the ani_top_species_match. If a genome does not surpass this threshold (and the percent_bases_aligned_threshold) then the ani_top_species_match output String will show a warning instead of a genus &amp; species. 80.0 Optional ani cpu Int Number of CPUs to allocate to the task 4 Optional ani disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ani docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mummer:4.0.0-rgdv2 Optional ani mash_filter Float Mash distance threshold over which ANI is not calculated 0.9 Optional ani memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional ani percent_bases_aligned_threshold Float Threshold regarding the proportion of bases aligned between the query genome and reference genome. If a genome does not surpass this threshold (and the ani_threshold) then the ani_top_species_match output String will show a warning instead of a genus &amp; species. 70.0 Optional ani ref_genome File If not set, uses all 43 genomes in RGDv2 Optional arln_stats cpu Int Number of CPUs to allocate to the task 2 Optional arln_stats disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional arln_stats docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/arln_stats:1.0.0 Optional arln_stats memory Int Amount of memory/RAM (in GB) to allocate to the task 5 Optional arln_stats read1_clean File Internal component, do not modify Optional arln_stats read1_raw File Internal component, do not modify Optional arln_stats read2_clean File Internal component, do not modify Optional arln_stats read2_raw File Internal component, do not modify Optional bakta bakta_opts String Parameters to pass to bakta from https://github.com/oschwengers/bakta#usage Optional bakta compliant Boolean If true, forces Genbank/ENA/DDJB compliant headers in Bakta output files FALSE Optional bakta cpu Int Number of CPUs to allocate to the task 8 Optional bakta disk_size Int Amount of storage (in GB) to allocate to the task 200 Optional bakta docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/bakta:1.10.3 Optional bakta memory Int Amount of memory/RAM (in GB) to allocate to the task 24 Optional bakta prodigal_tf File Prodigal training file to use for CDS prediction by bakta Optional bakta proteins File Fasta file of trusted protein sequences for CDS annotation Optional busco cpu Int Number of CPUs to allocate to the task 2 Optional busco disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional busco docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ezlabgva/busco:v5.7.1_cv1 Optional busco eukaryote Boolean Assesses eukaryotic organisms, rather than prokaryotic organisms FALSE Optional busco memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional export_taxon_table cpu Int Number of CPUs to allocate to the task 1 Optional export_taxon_table disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional export_taxon_table docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Optional export_taxon_table memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional gambit cpu Int Number of CPUs to allocate to the task 1 Optional gambit disk_size Int Amount of storage (in GB) to allocate to the task 20 Optional gambit docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Optional gambit gambit_db_genomes File Database of metadata for assembled query genomes; requires complementary signatures file. If not provided, uses default database \"/gambit-db\" gs://gambit-databases-rp/2.0.0/gambit-metadata-2.0.1-20250505.gdb Optional gambit gambit_db_signatures File Signatures file; requires complementary genomes file. If not specified, the file from the docker container will be used. gs://gambit-databases-rp/2.0.0/gambit-signatures-2.0.1-20250505.gs Optional gambit memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional gamma cpu Int Number of CPUs to allocate to the task 2 Optional gamma disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional gamma docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/gamma:2.2 Optional gamma extended_output Boolean GAMMA will provide the extended output when set to true FALSE Optional gamma gamma_db File Multifasta sequence database GAMMA is to use for gene matching gs://theiagen-public-resources-rp/reference_data/databases/gamma/default_ResFinderDB_Combined_05-06-20.fsa Optional gamma memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional gamma min_length_percent_gammas Int Threshold of match length percent used by GAMMA-s 20 Optional gamma min_percent_identity Int Threshold of identity for gene matches in percent 90 Optional gamma output_fasta Boolean Allows GAMMA to output gene matches in FASTA format TRUE Optional gamma output_gff Boolean Allows GAMMA to output gene matches in GFF format TRUE Optional gamma run_gammas Boolean Turns on GAMMA-S which runs GAMMA on nucleotide sequences rather than translating input sequences and matches FALSE Optional kmerfinder cpu Int Number of CPUs to allocate to the task 4 Optional kmerfinder disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional kmerfinder docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/kmerfinder:3.0.2--hdfd78af_0 Optional kmerfinder kmerfinder_args String Kmerfinder additional arguments Optional kmerfinder kmerfinder_db File Bacterial database for KmerFinder gs://theiagen-public-resources-rp/reference_data/databases/kmerfinder/kmerfinder_bacteria_20230911.tar.gz Optional kmerfinder memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional merlin_magic abricate_abaum_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid Optional merlin_magic abricate_abaum_min_percent_coverage Int Minimum DNA percent coverage Optional merlin_magic abricate_abaum_min_percent_identity Int Minimum DNA percent identity; set to 95 because there is a strict threshold of 95% identity for typing purposes 95 Optional merlin_magic abricate_vibrio_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-abaum-plasmid Optional merlin_magic abricate_vibrio_min_percent_coverage Int Minimum DNA percent coverage 80 Optional merlin_magic abricate_vibrio_min_percent_identity Int Minimum DNA percent identity 80 Optional merlin_magic agrvate_agr_typing_only Boolean Set to true to skip agr operon extraction and frameshift detection FALSE Optional merlin_magic agrvate_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/agrvate:1.0.2--hdfd78af_0 Optional merlin_magic amr_search_cpu Int Number of CPUs to allocate to the task 2 Optional merlin_magic amr_search_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional merlin_magic amr_search_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/amrsearch:0.2.1 Optional merlin_magic amr_search_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional merlin_magic call_poppunk Boolean If true, runs PopPUNK for GPSC cluster designation for S. pneumoniae TRUE Optional merlin_magic call_shigeifinder_reads_input Boolean If set to \"true\", the ShigEiFinder task will run again but using read files as input instead of the assembly file. Input is shown but not used for TheiaProk_FASTA. FALSE Optional merlin_magic call_stxtyper Boolean If set to \"true\", the StxTyper task will run on all samples regardless of the gambit_predicted_taxon output. Useful if you suspect a non-E.coli or non-Shigella sample contains stx genes. FALSE Optional merlin_magic call_tbp_parser Boolean If set to \"true\", activates the tbp_parser module and results in more outputs, including\u00a0tbp_parser_looker_report_csv, tbp_parser_laboratorian_report_csv,  tbp_parser_lims_report_csv, tbp_parser_coverage_report, and tbp_parser_genome_percent_coverage FALSE Optional merlin_magic cauris_cladetyper_docker_image String Internal component, do not modify us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Optional merlin_magic cladetyper_kmer_size Int Internal component, do not modify Optional merlin_magic cladetyper_max_distance Float Internal component, do not modify 0.1 Optional merlin_magic cladetyper_ref_clade1 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade1_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade2 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade2_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade3 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade3_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade4 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade4_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade5 File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade5_annotated File *Provide an empty file if running TheiaProk on the command-line Optional merlin_magic cladetyper_ref_clade6 File The reference assembly for clade 6 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade6_GCA_032714025.1_ASM3271402v1_genomic.fasta Optional merlin_magic cladetyper_ref_clade6_annotated File The path to the annotated reference for clade 6 Optional merlin_magic clockwork_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/cdcgov/varpipe_wgs_with_refs:2bc7234074bd53d9e92a1048b0485763cd9bbf6f4d12d5a1cc82bfec8ca7d75e Optional merlin_magic ectyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/ectyper:1.0.0--pyhdfd78af_1 Optional merlin_magic ectyper_h_min_percent_coverage Int Minumum percent coverage required for an H antigen allele match 50 Optional merlin_magic ectyper_h_min_percent_identity Int Percent identity required for an H antigen allele match 95 Optional merlin_magic ectyper_o_min_percent_coverage Int Minumum percent coverage required for an O antigen allele match 90 Optional merlin_magic ectyper_o_min_percent_identity Int Percent identity required for an O antigen allele match 90 Optional merlin_magic ectyper_print_alleles Boolean Set to true to print the allele sequences as the final column FALSE Optional merlin_magic ectyper_verify Boolean Set to true to enable E. coli species verification FALSE Optional merlin_magic emmtyper_align_diff Int Threshold for difference between alignment length and subject length in BLAST hit. Optional merlin_magic emmtyper_cluster_distance Int Distance between cluster of matches to consider as different clusters. Optional merlin_magic emmtyper_culling_limit Int Total hits to return in a position. Optional merlin_magic emmtyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/emmtyper:0.2.0--py_0 Optional merlin_magic emmtyper_gap Int Threshold gap to allow in BLAST hit. Optional merlin_magic emmtyper_max_size Int Maximum size of PCR product. Optional merlin_magic emmtyper_min_good Int Minimum size where there must be 2 matches for each mismatch. Optional merlin_magic emmtyper_min_percent_identity Int Minimal percent identity of sequence. Optional merlin_magic emmtyper_min_perfect Int Minimum size of perfect match at 3' primer end. Optional merlin_magic emmtyper_mismatch Int Threshold for number of mismatch to allow in BLAST hit. Optional merlin_magic emmtyper_wf String Choose workflow [blast pcr] merlin_magic emmtypingtool_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/emmtypingtool:0.0.1 Optional merlin_magic genotyphi_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.11.0 Optional merlin_magic hicap_broken_gene_length Int Minimum length to consider a broken gene 60 Optional merlin_magic hicap_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/hicap:1.0.3--py_0 Optional merlin_magic hicap_min_broken_gene_percent_identity Float Minimum percentage identity to consider a broken gene 0.8 Optional merlin_magic hicap_min_gene_percent_coverage Float Minimum percentage coverage to consider a single gene complete 0.8 Optional merlin_magic hicap_min_gene_percent_identity Float Minimum percentage identity to consider a single gene complete 0.7 Optional merlin_magic kaptive_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kaptive:2.0.3 Optional merlin_magic kaptive_low_gene_percent_identity Float Percent identity threshold for what counts as a low identity match in the gene BLAST search 95 Optional merlin_magic kaptive_min_percent_coverage Float Minimum required percent coverage for the gene BLAST search via tBLASTn 80 Optional merlin_magic kaptive_min_percent_identity Float Minimum required percent identity for the gene BLAST search via tBLASTn 90 Optional merlin_magic kaptive_start_end_margin Int Determines flexibility in identifying the start and end of a locus - if this value is 10, a locus match that is missing the first 8 base pairs will still count as capturing the start of the locus 10 Optional merlin_magic kleborate_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kleborate:2.2.0 Optional merlin_magic kleborate_min_kaptive_confidence String {None,Low,Good,High,Very_high,Perfect} Minimum Kaptive confidence to call K/O loci - confidence levels below this will be reported as unknown Good Optional merlin_magic kleborate_min_percent_coverage Float Minimum alignment percent coverage for main results 80 Optional merlin_magic kleborate_min_percent_identity Float Minimum alignment percent identity for main results 90 Optional merlin_magic kleborate_min_spurious_percent_coverage Float Minimum alignment percent coverage for spurious results 40 Optional merlin_magic kleborate_min_spurious_percent_identity Float Minimum alignment percent identity for spurious results 80 Optional merlin_magic kleborate_skip_kaptive Boolean Equivalent to --kaptive_k --kaptive_ FALSE Optional merlin_magic kleborate_skip_resistance Boolean Set to true to turn on resistance genes screening (default: no resistance gene screening) FALSE Optional merlin_magic legsta_docker_image String Internal component, do not modify Optional merlin_magic lissero_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/lissero:0.4.9--py_0 Optional merlin_magic lissero_min_percent_coverage Float Minimum percent coverage of the gene to accept a match 95 Optional merlin_magic lissero_min_percent_identity Float Minimum percent identity to accept a match 95 Optional merlin_magic meningotype_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/meningotype:0.8.5--pyhdfd78af_0 Optional merlin_magic ngmaster_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ngmaster:1.0.0 Optional merlin_magic ont_data Boolean Set to true if your data is ONT FASTQ files FALSE Optional merlin_magic pasty_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pasty:1.0.3 Optional merlin_magic pasty_min_percent_coverage Int Minimum coverage of a O-antigen to be considered for serogrouping by pasty 95 Optional merlin_magic pasty_min_percent_identity Int Minimum percent identity for a blast hit to be considered for serogrouping 95 Optional merlin_magic pbptyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pbptyper:1.0.4 Optional merlin_magic pbptyper_min_percent_coverage Int Minimum percent coverage to count a hit 90 Optional merlin_magic pbptyper_min_percent_identity Int Minimum percent identity to count a hit 90 Optional merlin_magic poppunk_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/poppunk:2.4.0 Optional merlin_magic poppunk_gps_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_clusters.csv Optional merlin_magic poppunk_gps_dists_npy File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.dists.npy Optional merlin_magic poppunk_gps_dists_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.dists.pkl Optional merlin_magic poppunk_gps_external_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_external_clusters.csv Optional merlin_magic poppunk_gps_fit_npz File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_fit.npz Optional merlin_magic poppunk_gps_fit_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_fit.pkl Optional merlin_magic poppunk_gps_graph_gt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_graph.gt Optional merlin_magic poppunk_gps_h5 File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.h5 Optional merlin_magic poppunk_gps_qcreport_txt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_qcreport.txt Optional merlin_magic poppunk_gps_refs File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs Optional merlin_magic poppunk_gps_refs_dists_npy File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.dists.npy Optional merlin_magic poppunk_gps_refs_dists_pkl File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.dists.pkl Optional merlin_magic poppunk_gps_refs_graph_gt File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6refs_graph.gt Optional merlin_magic poppunk_gps_refs_h5 File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6.refs.h5 Optional merlin_magic poppunk_gps_unword_clusters_csv File Poppunk database file *Provide an empty or local file if running TheiaProk on the command-line gs://theiagen-public-resources-rp/reference_data/databases/poppunk/GPS_v6/GPS_v6_unword_clusters.csv Optional merlin_magic read1 File Internal component, do not modify Optional merlin_magic read2 File Internal component, do not modify Optional merlin_magic run_amr_search Boolean If set to true AMR_Search workflow will be run if species is part of supported taxon, see AMR_Search docs. FALSE Optional merlin_magic seqsero2_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/seqsero2:1.2.1 Optional merlin_magic seroba_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/seroba:1.0.2 Optional merlin_magic serotypefinder_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/serotypefinder:2.0.1 Optional merlin_magic shigatyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/shigatyper:2.0.5 Optional merlin_magic shigeifinder_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/shigeifinder:1.3.5 Optional merlin_magic sistr_cpu Int Number of CPUs to allocate to the task 2 Optional merlin_magic sistr_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional merlin_magic sistr_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/sistr_cmd:1.1.1--pyh864c0ab_2 Optional merlin_magic sistr_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional merlin_magic sistr_use_full_cgmlst_db Boolean Set to true to use the full set of cgMLST alleles which can include highly similar alleles. By default the smaller \"centroid\" alleles or representative alleles are used for each marker FALSE Optional merlin_magic snippy_base_quality Int Internal component, do not modify Optional merlin_magic snippy_gene_query_docker_image String Internal component, do not modify Optional merlin_magic snippy_map_qual Int Internal component, do not modify Optional merlin_magic snippy_maxsoft Int Internal component, do not modify Optional merlin_magic snippy_min_coverage Int Internal component, do not modify Optional merlin_magic snippy_min_frac Float Internal component, do not modify Optional merlin_magic snippy_min_quality Int Internal component, do not modify Optional merlin_magic snippy_query_gene String Internal component, do not modify Optional merlin_magic snippy_reference_afumigatus File Internal component, do not modify gs://theiagen-public-resources-rp/reference_data/eukaryotic/aspergillus/Aspergillus_fumigatus_GCF_000002655.1_ASM265v1_genomic.gbff Optional merlin_magic snippy_reference_cryptoneo File Internal component, do not modify gs://theiagen-public-resources-rp/reference_data/eukaryotic/cryptococcus/Cryptococcus_neoformans_GCF_000091045.1_ASM9104v1_genomic.gbff Optional merlin_magic snippy_variants_docker_image String Internal component, do not modify Optional merlin_magic sonneityping_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Optional merlin_magic sonneityping_mykrobe_opts String Additional options for mykrobe in sonneityping Optional merlin_magic spatyper_do_enrich Boolean Set to true to enable PCR product enrichment FALSE Optional merlin_magic spatyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/spatyper:0.3.3--pyhdfd78af_3 Optional merlin_magic srst2_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/srst2:0.2.0-vcholerae Optional merlin_magic srst2_gene_max_mismatch Int Maximum number of mismatches for SRST2 to call a gene as present 2000 Optional merlin_magic srst2_max_divergence Int Maximum divergence, in percentage, for SRST2 to call a gene as present 20 Optional merlin_magic srst2_min_depth Int Minimum depth of coverage for SRST2 to call a gene as present 5 Optional merlin_magic srst2_min_edge_depth Int Minimum edge depth for SRST2 to call a gene as present 2 Optional merlin_magic srst2_min_percent_coverage Int Minimum breadth of coverage for SRST2 to call a gene as present 80 Optional merlin_magic staphopia_sccmec_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/staphopia-sccmec:1.0.0--hdfd78af_0 Optional merlin_magic stxtyper_cpu Int Number of CPUs to allocate to the task 1 Optional merlin_magic stxtyper_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional merlin_magic stxtyper_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/stxtyper:1.0.42 Optional merlin_magic stxtyper_enable_debug Boolean When enabled, additional messages are printed and files in $TMPDIR are not removed after running FALSE Optional merlin_magic stxtyper_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional merlin_magic tbp_parser_add_cs_lims Boolean Set to true add cycloserine results to the LIMS report FALSE Optional merlin_magic tbp_parser_config File The configuration file to use, in YAML format (overrides all other arguments except input_json and input_bam) Optional merlin_magic tbp_parser_coverage_regions_bed File A bed file that lists the regions to be considered for QC Optional merlin_magic tbp_parser_debug Boolean Activate the debug mode on tbp_parser; increases logging outputs TRUE Optional merlin_magic tbp_parser_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/tbp-parser:2.6.0 Optional merlin_magic tbp_parser_etha237_frequency Float Minimum frequency for a mutation in ethA at protein position 237 to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_expert_rule_regions_bed File A file that contains the regions where R mutations and expert rules are applied Optional merlin_magic tbp_parser_min_depth Int Minimum depth for a variant to pass QC in tbp_parser 10 Optional merlin_magic tbp_parser_min_frequency Float The minimum frequency for a mutation to pass QC 0.1 Optional merlin_magic tbp_parser_min_percent_coverage Float The minimum coverage for a region to pass QC in tbp_parser 100 Optional merlin_magic tbp_parser_min_read_support Int The minimum read support for a mutation to pass QC 10 Optional merlin_magic tbp_parser_operator String Fills the \"operator\" field in the tbp_parser output files Operator not provided Optional merlin_magic tbp_parser_output_seq_method_type String Fills out the \"seq_method\" field in the tbp_parser output files WGS Optional merlin_magic tbp_parser_rpob449_frequency Float Minimum frequency for a mutation at protein position 449 to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_rrl_frequency Float Minimum frequency for a mutation in rrl to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_rrl_read_support Int Minimum read support for a mutation in rrl to pass QC in tbp-parser 10 Optional merlin_magic tbp_parser_rrs_frequency Float Minimum frequency for a mutation in rrs to pass QC in tbp-parser 0.1 Optional merlin_magic tbp_parser_rrs_read_support Int Minimum read support for a mutation in rrs to pass QC in tbp-parser 10 Optional merlin_magic tbp_parser_tngs_data Boolean Set to true to enable tNGS-specific parameters and runs in tbp-parser FALSE Optional merlin_magic tbprofiler_additional_parameters String Additional parameters for TBProfiler Optional merlin_magic tbprofiler_custom_db File TBProfiler uses by default the TBDB database; if you have a custom database you wish to use, you must provide a custom database in this field and set tbprofiler_run_custom_db to true Optional merlin_magic tbprofiler_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/tbprofiler:6.6.3 Optional merlin_magic tbprofiler_mapper String The mapping tool used in TBProfiler to align the reads to the reference genome; see TBProfiler\u2019s original documentation for available options. bwa Optional merlin_magic tbprofiler_min_af Float The minimum allele frequency to call a variant 0.1 Optional merlin_magic tbprofiler_min_depth Int The minimum depth for a variant to be called. 10 Optional merlin_magic tbprofiler_run_cdph_db Boolean TBProfiler uses by default the TBDB database; set this value to \"true\" to use the WHO v2 database with customizations for CDPH FALSE Optional merlin_magic tbprofiler_run_custom_db Boolean TBProfiler uses by default the TBDB database; if you have a custom database you wish to use, you must set this value to true and provide a custom database in the tbprofiler_custom_db field FALSE Optional merlin_magic tbprofiler_variant_caller String Select a different variant caller for TBProfiler to use by writing it in this block; see TBProfiler\u2019s original documentation for available options. GATK Optional merlin_magic tbprofiler_variant_calling_params String Enter additional variant calling parameters in this free text input to customize how the variant caller works in TBProfiler Optional merlin_magic theiaeuk Boolean Internal component, do not modify FALSE Optional merlin_magic vibecheck_docker_image String Internal component, do not modify Optional merlin_magic vibecheck_lineage_barcodes File Internal component, do not modify Optional merlin_magic vibecheck_skip_subsampling Boolean Internal component, do not modify Optional merlin_magic vibecheck_subsampling_fraction Float Internal component, do not modify Optional merlin_magic virulencefinder_database String The specific database to use virulence_ecoli Optional merlin_magic virulencefinder_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/virulencefinder:2.0.4 Optional merlin_magic virulencefinder_min_percent_coverage Float The threshold for minimum coverage Optional merlin_magic virulencefinder_min_percent_identity Float The threshold for minimum blast identity Optional plasmidfinder cpu Int Number of CPUs to allocate to the task 2 Optional plasmidfinder database String User-specified database Optional plasmidfinder database_path String Path to user-specified database Optional plasmidfinder disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional plasmidfinder docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/plasmidfinder:2.1.6 Optional plasmidfinder memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional plasmidfinder method_path String Path to files for a user-specified method to use (blast or kma) Optional plasmidfinder min_percent_coverage Float Threshold for minimum coverage, default threshold from PlasmidFinder CLI tool is used (0.60) 0.6 Optional plasmidfinder min_percent_identity Float Threshold for mininum blast identity, default threshold from PlasmidFinder CLI tool is used (0.90). This default differs from the default of the PlasmidFinder webtool (0.95) 0.9 Optional prokka compliant Boolean If true (default), forces Genbank/ENA/DDJB compliant headers in Prokka output files TRUE Optional prokka cpu Int Number of CPUs to allocate to the task 4 Optional prokka disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional prokka docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/prokka:1.14.5 Optional prokka memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional prokka prodigal_tf File https://github.com/tseemann/prokka#option---prodigaltf Optional prokka prokka_arguments String Any additional https://github.com/tseemann/prokka#command-line-options Optional prokka proteins Boolean FASTA file of trusted proteins for Prokka to first use for annotations FALSE Optional qc_check_task assembly_length_unambiguous Int Internal component, do not modify Optional qc_check_task assembly_mean_coverage Float Internal component, do not modify Optional qc_check_task combined_mean_q_clean Float Internal component, do not modify Optional qc_check_task combined_mean_q_raw Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task combined_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task cpu Int Number of CPUs to allocate to the task 4 Optional qc_check_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional qc_check_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional qc_check_task est_coverage_clean Float Internal component, do not modify Optional qc_check_task est_coverage_raw Float Internal component, do not modify Optional qc_check_task kraken_human Float Internal component, do not modify Optional qc_check_task kraken_human_dehosted Float Internal component, do not modify Optional qc_check_task kraken_sc2 Float Internal component, do not modify Optional qc_check_task kraken_sc2_dehosted Float Internal component, do not modify Optional qc_check_task kraken_target_organism Float Internal component, do not modify Optional qc_check_task kraken_target_organism_dehosted Float Internal component, do not modify Optional qc_check_task meanbaseq_trim String Internal component, do not modify Optional qc_check_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional qc_check_task midas_secondary_genus_abundance Float Internal component, do not modify Optional qc_check_task midas_secondary_genus_coverage Float Internal component, do not modify Optional qc_check_task num_reads_clean1 Int Internal component, do not modify Optional qc_check_task num_reads_clean2 Int Internal component, do not modify Optional qc_check_task num_reads_raw1 Int Internal component, do not modify Optional qc_check_task num_reads_raw2 Int Internal component, do not modify Optional qc_check_task number_Degenerate Int Internal component, do not modify Optional qc_check_task number_N Int Internal component, do not modify Optional qc_check_task percent_reference_coverage Float Internal component, do not modify Optional qc_check_task r1_mean_q_clean Float Internal component, do not modify Optional qc_check_task r1_mean_q_raw Float Internal component, do not modify Optional qc_check_task r1_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task r1_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task r2_mean_q_clean Float Internal component, do not modify Optional qc_check_task r2_mean_q_raw Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_clean Float Internal component, do not modify Optional qc_check_task r2_mean_readlength_raw Float Internal component, do not modify Optional qc_check_task sc2_s_gene_mean_coverage Float Internal component, do not modify Optional qc_check_task sc2_s_gene_percent_coverage Float Internal component, do not modify Optional qc_check_task vadr_num_alerts String Internal component, do not modify Optional quast cpu Int Number of CPUs to allocate to the task 2 Optional quast disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional quast docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/quast:5.0.2 Optional quast memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional quast min_contig_length Int Minimum length of contig for QUAST 500 Optional resfinder_task acquired Boolean Set to true to tell ResFinder to identify acquired resistance genes TRUE Optional resfinder_task call_pointfinder Boolean Set to true to enable detection of point mutations. FALSE Optional resfinder_task cpu Int Number of CPUs to allocate to the task 2 Optional resfinder_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional resfinder_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/resfinder:4.1.11 Optional resfinder_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional resfinder_task min_percent_coverage Float Minimum coverage breadth of a gene for it to be identified 0.5 Optional resfinder_task min_percent_identity Float Minimum identity for ResFinder to identify a gene 0.9 Optional theiaprok_fasta abricate_db String Database to use with the Abricate tool. Options: NCBI, CARD, ARG-ANNOT, Resfinder, MEGARES, EcOH, PlasmidFinder, Ecoli_VF and VFDB vfdb Optional theiaprok_fasta amrfinder_use_gff Boolean Whether or not to use the GFF and protein FASTA files for AMRFinderPlus FALSE Optional theiaprok_fasta bakta_db String Database selection for Bakta annotation. Options: light (smaller, faster), full (more comprehensive), or a Google Storage URI (gs://...) pointing to a custom Bakta database archive (.tar.gz). The selected database will be extracted before annotation. full Optional theiaprok_fasta call_abricate Boolean Set to true to enable the Abricate task FALSE Optional theiaprok_fasta call_ani Boolean Set to true to enable the ANI task FALSE Optional theiaprok_fasta call_arln_stats Boolean Set to true to enable the return of ARLN required Auto PASS/FAIL outputs FALSE Optional theiaprok_fasta call_gamma Boolean Set to true in order to enable GAMMA task FALSE Optional theiaprok_fasta call_kmerfinder Boolean Set to true to enable the kmerfinder task FALSE Optional theiaprok_fasta call_plasmidfinder Boolean Set to true to enable the plasmidfinder task TRUE Optional theiaprok_fasta call_resfinder Boolean Set to true to enable the ResFinder task FALSE Optional theiaprok_fasta city String Will be used in the \"city\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_fasta collection_date String Will be used in the \"collection_date\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_fasta county String Will be used in the \"county\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_fasta expected_taxon String If provided, this input will override the taxonomic assignment made by GAMBIT and launch the relevant taxon-specific submodules. It will also modify the organism flag used by AMRFinderPlus. Example format: \"Salmonella enterica\" Optional theiaprok_fasta genome_annotation String If set to \"bakta\", TheiaProk will use Bakta rather than Prokka to annotate the genome prokka Optional theiaprok_fasta mlst_run_secondary_scheme Boolean If true, will run secondary scheme if primary scheme is of ecoli or abaumannii, these two have multiple schemes that are relevant. FALSE Optional theiaprok_fasta mlst_scheme_override Boolean If true, will force E. coli scheme to be used when Gambit predicts Escherichia coli, otherwise will return scheme MLST predicts. FALSE Optional theiaprok_fasta originating_lab String Will be used in the \"originating_lab\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_fasta perform_characterization Boolean Set to \"false\" if you want to only generate an assembly and relevant QC metrics and skip all characterization tasks TRUE Optional theiaprok_fasta qc_check_table File TSV value with taxons for rows and QC values for columns; internal cells represent user-determined QC thresholds; if provided, turns on the QC Check task. See below for an example QC Check table. Optional theiaprok_fasta run_id String Will be used in the \"run_id\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_fasta seq_method String The sequencing methodology used to generate the input read data; for TheiaProk workflows, this input will be used in the \"seq_id\" column in any taxon-specific tables created in the Export Taxon Tables task Optional theiaprok_fasta taxon_tables File File indicating data table names to copy samples of a particular taxon to Optional theiaprok_fasta terra_project String The name of the Terra Project where you want the taxon tables written to NA Optional theiaprok_fasta terra_workspace String The name of the Terra Workspace where you want the taxon tables written to NA Optional theiaprok_fasta zip String Will be used in the \"zip\" column in any taxon-specific tables created in the Export Taxon Tables task Optional ts_mlst cpu Int Number of CPUs to allocate to the task 1 Optional ts_mlst disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional ts_mlst docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mlst:2.23.0-2024-12-31 Optional ts_mlst memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional ts_mlst min_percent_coverage Float Minimum % breadth of coverage to report an MLST allele 10 Optional ts_mlst min_percent_identity Float Minimum % identity to known MLST gene to report an MLST allele 95 Optional ts_mlst minscore Float Minimum score https://github.com/tseemann/mlst#scoring-system to assign an MLST profile 50 Optional ts_mlst nopath Boolean true = use mlst --nopath. If set to false, filename paths are not stripped from FILE column in output TSV TRUE Optional ts_mlst scheme String Don\u2019t autodetect the MLST scheme; force this scheme on all inputs (see https://github.com/tseemann/mlst/blob/master/db/scheme_species_map.tab for accepted strings) None Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/genomic_characterization/theiaprok/#core-tasks","title":"Core Tasks","text":"<p>These tasks are performed regardless of organism. They include tasks that are performed regardless of and specific for the input data type. They perform read trimming and assembly appropriate to the input data type.</p> <code>versioning</code>: Version Capture <p>The <code>versioning</code> task captures the workflow version from the GitHub (code repository) version.</p> <p>Version Capture Technical details</p> Links Task task_versioning.wdl"},{"location":"workflows/genomic_characterization/theiaprok/#assembly-tasks","title":"Assembly Tasks","text":"TheiaProk_Illumina_PETheiaProk_Illumina_SETheiaProk_ONTTheiaProk_FASTA <code>concatenate_illumina_lanes</code>: Concatenate Multi-Lane Illumina FASTQs <p>The <code>concatenate_illumina_lanes</code> task concatenates Illumina FASTQ files from multiple lanes into a single file. This task only runs if the <code>read1_lane2</code> input file has been provided. All read1 lanes are concatenated together and are used in subsequent tasks, as are the read2 lanes if applicable. These concatenated files are also provided as output.</p> <p>Concatenate Illumina Lanes Technical Details</p> <p>The <code>concatenate_illumina_lanes</code> task is run before any downstream steps take place.</p> Links Subworkflow wf_concatenate_illumina_lanes.wdl <code>screen</code>: Total Raw Read Quantification and Genome Size Estimation <p>The <code>screen</code> task ensures the quantity of sequence data is sufficient to undertake genomic analysis. It uses <code>fastq-scan</code> and bash commands for quantification of reads and base pairs, and mash sketching to estimate the genome size and its coverage. At each step, the results are assessed relative to pass/fail criteria and thresholds that may be defined by optional user inputs. Samples are run through all threshold checks, regardless of failures, and the workflow will terminate after the <code>screen</code> task if any thresholds are not met:</p> <ol> <li>Total number of reads: A sample will fail the read screening task if its total number of reads is less than or equal to <code>min_reads</code>.</li> <li>The proportion of basepairs reads in the forward and reverse read files: A sample will fail the read screening if fewer than <code>min_proportion</code> basepairs are in either the reads1 or read2 files.</li> <li>Number of basepairs: A sample will fail the read screening if there are fewer than <code>min_basepairs</code> basepairs</li> <li>Estimated genome size:  A sample will fail the read screening if the estimated genome size is smaller than <code>min_genome_size</code> or bigger than <code>max_genome_size</code>.</li> <li>Estimated genome coverage: A sample will fail the read screening if the estimated genome coverage is less than the <code>min_coverage</code>.</li> </ol> <p>Read screening is undertaken on both the raw and cleaned reads. The task may be skipped by setting the <code>skip_screen</code> variable to true.</p> <p>Default values vary between the PE, SE, and ONT workflows. The rationale for these default values can be found below. If two default values are shown, the first is for Illumina workflows and the second is for ONT.</p> Variable Default Value Rationale <code>skip_screen</code> false Set to true to skip the read screen from running <code>min_reads</code> 7472 or 5000 Calculated from the minimum number of base pairs required for 20x coverage of the Nasuia deltocephalinicola genome, the smallest known bacterial genome as of 2019-08-07 (112,091 bp), divided by 300 (the longest Illumina read length) or 5000 (estimate of ONT read length) <code>min_basepairs</code> 2241820 Should be greater than 20x coverage of Nasuia deltocephalinicola, the smallest known bacterial genome (112,091 bp) <code>min_genome_length</code> 100000 Based on the Nasuia deltocephalinicola genome, the smallest known bacterial genome (112,091 bp) <code>max_genome_length</code> 18040666 Based on the Minicystis rosea genome, the largest known bacterial genome (16,040,666 bp), plus an additional 2 Mbp to cater for potential extra genomic material <code>min_coverage</code> 10 or 5 A bare-minimum average per base coverage across the genome required for genome characterization. Higher coverage would be required for high-quality phylogenetics. <code>min_proportion</code> 40 Neither read1 nor read2 files should have less than 40% of the total number of reads. For paired-end data only. <p>Screen Technical Details</p> <p>There is a single WDL task for read screening. The <code>screen</code> task is run twice, once for raw reads and once for clean reads.</p> Links Task task_screen.wdl (PE sub-task)task_screen.wdl (SE sub-task) <p>These tasks clean then assemble the reads into a de novo assembly and assess the quality of the assembly.</p> <code>read_QC_trim</code>: Read Quality Trimming, Adapter Removal, Quantification, and Identification <p><code>read_QC_trim</code> is a sub-workflow that removes low-quality reads, low-quality regions of reads, and sequencing adapters to improve data quality. It uses a number of tasks, described below. The differences between the PE and SE versions of the <code>read_QC_trim</code> sub-workflow lie in the default parameters, the use of two or one input read file(s), and the different output files.</p> <p>By default, <code>read_processing</code> is set to <code>\"trimmomatic\"</code>. To use <code>fastp</code> instead, set <code>read_processing</code> to <code>\"fastp\"</code>. These tasks are mutually exclusive.</p> <code>Trimmomatic</code>: Read Trimming (default) <p>Read proccessing is available via <code>Trimmomatic</code> by default.</p> <p>Trimmomatic trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>Trimmomatic</code> Technical Details</p> Links Task task_trimmomatic.wdl Software Source Code Trimmomatic on GitHub Software Documentation Trimmomatic Website Original Publication(s) Trimmomatic: a flexible trimmer for Illumina sequence data <code>fastp</code>: Read Trimming (alternative) <p>To activate this task, set <code>read_processing</code> to <code>\"fastp\"</code>.</p> <p><code>fastp</code> trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>fastp</code> also has additional default parameters and features that are not a part of <code>trimmomatic</code>'s default configuration.</p> <code>fastp</code> default read-trimming parameters Parameter Explanation -g enables polyG tail trimming -5 20 enables read end-trimming -3 20 enables read end-trimming --detect_adapter_for_pe enables adapter-trimming only for paired-end reads <p>Additional arguments can be passed using the <code>fastp_args</code> optional parameter.</p> <p>Trimmomatic and fastp Technical Details</p> Links Task task_fastp.wdl Software Source Code fastp on GitHub Software Documentation fastp on GitHub Original Publication(s) fastp: an ultra-fast all-in-one FASTQ preprocessor <code>BBDuk</code>: Adapter Trimming and PhiX Removal <p>Adapters are manufactured oligonucleotide sequences attached to DNA fragments during the library preparation process. In Illumina sequencing, these adapter sequences are required for attaching reads to flow cells. You can read more about Illumina adapters here. For genome analysis, it's important to remove these sequences since they're not actually from your sample. If you don't remove them, the downstream analysis may be affected.</p> <p>The <code>bbduk</code> task removes adapters from sequence reads. To do this:</p> <ul> <li>Repair from the BBTools package reorders reads in paired fastq files to ensure the forward and reverse reads of a pair are in the same position in the two fastq files (it re-pairs).</li> <li>BBDuk  (\"Bestus Bioinformaticus\" Decontamination Using Kmers) is then used to trim the adapters and filter out all reads that have a 31-mer match to PhiX, which is commonly added to Illumina sequencing runs to monitor and/or improve overall run quality.</li> </ul> <p>BBDuk Technical Details</p> Links Task task_bbduk.wdl Software Source Code BBMap on SourceForge Software Documentation BBDuk Guide (archived) <p>By default, <code>read_qc</code> is set to <code>\"fastq_scan\"</code>. To use <code>fastqc</code> instead, set <code>read_qc</code> to <code>\"fastqc\"</code>. These tasks are mutually exclusive.</p> <code>fastq-scan</code>: Read Quantification (default) <p>Read quantification is available via <code>fastq-scan</code> by default.</p> <p><code>fastq-scan</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p><code>fastq-scan</code> Technical Details</p> Links Task task_fastq_scan.wdl Software Source Code fastq-scan on GitHub Software Documentation fastq-scan on GitHub <code>FastQC</code>: Read Quantification (alternative) <p>To activate this task, set <code>read_qc</code> to <code>\"fastqc\"</code>.</p> <p><code>FastQC</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>This tool also provides a graphical visualization of the read quality.</p> <p><code>FastQC</code> Technical Details</p> Links Task task_fastqc.wdl Software Source Code FastQC on Github Software Documentation FastQC Website <code>MIDAS</code>: Read Identification (optional) <p>To activate this task, set <code>call_midas</code> to <code>true</code>.</p> <p>The <code>MIDAS</code> task is for the identification of reads to detect contamination with non-target taxa.</p> <p>The MIDAS tool was originally designed for metagenomic sequencing data but has been co-opted for use with bacterial isolate WGS methods. It can be used to detect contamination present in raw sequencing data by estimating bacterial species abundance in bacterial isolate WGS data. If a secondary genus is detected above a relative frequency of 0.01 (1%), then the sample should fail QC and be investigated further for potential contamination.</p> <p>This task is similar to those used in commercial software, BioNumerics, for estimating secondary species abundance.</p> How are the MIDAS output columns determined? <p>Example MIDAS report in the <code>midas_report</code> column:</p> species_id count_reads coverage relative_abundance Salmonella_enterica_58156 3309 89.88006645 0.855888033 Salmonella_enterica_58266 501 11.60606061 0.110519371 Salmonella_enterica_53987 99 2.232896237 0.021262881 Citrobacter_youngae_61659 46 0.995216227 0.009477003 Escherichia_coli_58110 5 0.123668877 0.001177644 <p>MIDAS report column descriptions:</p> <ul> <li>species_id: species identifier</li> <li>count_reads: number of reads mapped to marker genes</li> <li>coverage: estimated genome-coverage (i.e. read-depth) of species in metagenome</li> <li>relative_abundance: estimated relative abundance of species in metagenome</li> </ul> <p>The value in the <code>midas_primary_genus</code> column is derived by ordering the rows in order of \"relative_abundance\" and identifying the genus of top species in the \"species_id\" column (Salmonella). The value in the <code>midas_secondary_genus</code> column is derived from the genus of the second-most prevalent genus in the \"species_id\" column (Citrobacter). The <code>midas_secondary_genus_abundance</code> column is the \"relative_abundance\" of the second-most prevalent genus (0.009477003). The <code>midas_secondary_genus_coverage</code> is the \"coverage\" of the second-most prevalent genus (0.995216227).</p> <p>MIDAS Reference Database Overview</p> <p>The MIDAS reference database is a comprehensive tool for identifying bacterial species in metagenomic and bacterial isolate WGS data. It includes several layers of genomic data, helping detect species abundance and potential contaminants.</p> <p>Key Components of the MIDAS Database</p> <ol> <li> <p>Species Groups: </p> <ul> <li>MIDAS clusters bacterial genomes based on 96.5% sequence identity, forming over 5,950 species groups from 31,007 genomes. These groups align with the gold-standard species definition (95% ANI), ensuring highly accurate species identification.</li> </ul> </li> <li> <p>Genomic Data Structure:</p> <ul> <li>Marker Genes: Contains 15 universal single-copy genes used to estimate species abundance.</li> <li>Representative Genome: Each species group has a selected representative genome, which minimizes genetic variation and aids in accurate SNP identification.</li> <li>Pan-genome: The database includes clusters of non-redundant genes, with options for multi-level clustering (e.g., 99%, 95%, 90% identity), enabling MIDAS to identify gene content within strains at various clustering thresholds.</li> </ul> </li> <li> <p>Taxonomic Annotation: </p> <ul> <li>Genomes are annotated based on consensus Latin names. Discrepancies in name assignments may occur due to factors like unclassified genomes or genus-level ambiguities.</li> </ul> </li> </ol> <p>Using the Default MIDAS Database</p> <p>TheiaProk and TheiaEuk use the pre-loaded MIDAS database in Terra (see input table for current version) by default for bacterial species detection in metagenomic data, requiring no additional setup.</p> <p>Create a Custom MIDAS Database</p> <p>Users can also build their own custom MIDAS database if they want to include specific genomes or configurations. This custom database can replace the default MIDAS database used in Terra. To build a custom MIDAS database, follow the MIDAS GitHub guide on building a custom database. Once the database is built, users can upload it to a Google Cloud Storage bucket or Terra workkspace and provide the link to the database in the <code>midas_db</code> input variable.</p> <p>MIDAS Technical Details</p> Links Task task_midas.wdl Software Source Code MIDAS on GitHub Software Documentation MIDAS on GitHub Original Publication(s) An integrated metagenomics pipeline for strain profiling reveals novel patterns of bacterial transmission and biogeography <code>Kraken2</code>: Read Identification (optional) <p>To activate this task, set <code>call_kraken</code> to <code>true</code> and provide a value for <code>kraken_db</code>.</p> <p><code>Kraken2</code> is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>Database-dependent</p> <p>This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz</code>.</p> <p>As an alternative to <code>MIDAS</code> (see above), the <code>Kraken2</code> task can also be turned on through setting the <code>call_kraken</code> input variable as <code>true</code> for the identification of reads to detect contamination with non-target taxa.</p> <p>A database must be provided if this optional module is activated, through the kraken_db optional input. A list of suggested databases can be found on Kraken2 standalone documentation.</p> <p>Kraken2 Technical Details</p> Links Task task_kraken2.wdl Software Source Code Kraken2 on GitHub Software Documentation Kraken2 Documentation Original Publication(s) Improved metagenomic analysis with Kraken 2 <p>read_QC_trim Technical Details</p> Links Subworkflow wf_read_QC_trim_pe.wdlwf_read_QC_trim_se.wdl <code>CG-Pipeline</code>: Assessment of Read Quality, and Estimation of Genome Coverage <p>The<code>cg_pipeline</code> task generates metrics about read quality and estimates the coverage of the genome using the <code>run_assembly_readMetrics.pl</code> script from CG-Pipeline. The genome coverage estimates are calculated using both using raw and cleaned reads, using either a user-provided <code>genome_size</code> or the estimated genome length generated by QUAST.</p> <p>CG-Pipeline Technical Details</p> <p>The <code>cg_pipeline</code> task is run twice in this workflow, once with raw reads, and once with clean reads.</p> Links Task task_cg_pipeline.wdl Software Source Code CG-Pipeline on GitHub Software Documentation CG-Pipeline on GitHub Original Publication(s) A computational genomics pipeline for prokaryotic sequencing projects <code>digger_denovo</code>: De novo Assembly <p>De novo  assembly is the process or product of attempting to reconstruct a genome from scratch (without prior knowledge of the genome) using sequence reads. Assembly of fungal genomes from short-reads will produce multiple contigs per chromosome rather than a single contiguous sequence for each chromosome.</p> <p>In TheiaProk and TheiaEuk Illumina workflows, de novo assembly is performed for samples that have sufficient read quantity and quality using digger_denovo, a subworkflow based off of Shovill pipeline. The name \"digger\" is a nod to Shovill and SPAdes.</p> De novo Assembly <p><code>assembler</code> with <code>skesa</code> (default), <code>spades</code>, or <code>megahit</code></p> <p>To activate a particular assembler, set the <code>assembler</code> input parameter to either <code>skesa</code> (default), <code>spades</code>, or <code>megahit</code>.</p> <p>These tasks are mutually exclusive.</p> <code>SKESA</code>: De novo Assembly (default) <p>This task is activated by default.</p> <p><code>SKESA</code> (Strategic K-mer Extension for Scrupulous Assemblies) is a de novo assembler that is fairly conservative and introduces breaks in the genome at repeat regions. This leads to higher sequence quality but more fragmented assemblies, which, depending on the final analysis goal, can be either highly preferred or detrimental. Designed for Illumina reads and haploid genomes, SKESA is the default assembler in the <code>digger_denovo</code> subworkflow.</p> <p>SKESA Technical Details</p> Links Task task_skesa.wdl Software Source Code SKESA on GitHub Software Documentation SKESA on GitHub Original Publication(s) SKESA: strategic k-mer externsion for scrupulous assemblies <code>SPAdes</code>: De novo Assembly (alternative) <p>To activate this task, set <code>assembler</code> to <code>spades</code>.</p> <p><code>SPAdes</code> (St. Petersburg genome assembler) is a de novo assembly tool that uses de Bruijn graphs to assemble genomes from Illumina short reads.</p> <p>In TheiaProk, SPAdes is run in <code>--isolate</code> mode, which is the recommended flag for high-coverage isolate and multi-cell Illumina data, which is typical of most bacterial sequencing projects. This method is optimized for improving assembly quality and decreasing runtime.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>MetaviralSPAdes Technical Details</p> Links Task task_spades.wdl Software Source Code SPAdes on GitHub Software Documentation SPAdes Manual Original Publication(s) TheiaProk: SPAdes: A New Genome Assembly Algorithm and Its Applications to Single-Cell SequencingTheiaViral: MetaviralSPAdes: assembly of viruses from metagenomic data <code>MEGAHIT</code>: De novo Assembly (alternative) <p>To activate this task, set <code>assembler</code> to <code>megahit</code>.</p> <p>The MEGAHIT assembler is a fast and memory-efficient de novo assembler that can handle large datasets. While optimized for metagenomics, MEGAHIT also performs well on single-genome assemblies, making it a versatile choice for various assembly tasks.</p> <p>MEGAHIT uses a multiple k-mer strategy that can be beneficial for assembling genomes with varying coverage levels, which is common in metagenomic samples. It constructs succinct de Bruijn graphs to efficiently represent the assembly process, allowing it to handle large and complex datasets with reduced memory usage.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>MEGAHIT Technical Details</p> Links Task task_megahit.wdl Software Source Code MEGAHIT on GitHub Software Documentation MEGAHIT on GitHub Original Publication(s) MEGAHIT: an ultra-fast single-node solution for large and complex metagenomics assembly via succinct de Bruijn graph Assembly Polishing (optional) <p>To activate assembly polishing, set <code>call_pilon</code> to <code>true</code>.</p> <code>bwa</code>: Read Alignment to the Assembly <p>BWA (Burrow-Wheeler Aligner) is used to align the cleaned read files to generated assembly file in order to generate an alignment. The resulting BAM file is directly passed to the Pilon task to polish the assembly for errors.</p> <p>BWA Technical Details</p> Links Task task_bwa.wdl Software Source Code BWA on GitHub Software Documentation BWA Documentation Original Publication(s) Fast and accurate short read alignment with Burrows-Wheeler transform <code>Pilon</code>: Assembly Polishing <p><code>Pilon</code> is a tool that uses read alignments to correct errors in an assembly.</p> <p>The <code>bwa</code>-generated alignment of the read data to the assembly is used to identify inconsistences between the reads and the assembly in order to correct them. <code>Pilon</code> will attempt to fix individual base errors and small indels using the read data. This can improve the overall quality of the assembly, especially when the assembler has made mistakes due to sequencing errors or low coverage regions.</p> <p>The default parameters were set to mimic the parameters used by Shovill: <code>--fix bases --minq 60 --minqual 3 --mindepth 0.25</code>. These can be modified by the user.</p> <p>Pilon Technical Details</p> Links Task task_pilon.wdl Software Source Code Pilon on GitHub Software Documentation Pilon Wiki Original Publication(s) Pilon: An Integrated Tool for Comprehensive Microbial Variant Detection and Genome Assembly Improvement Contig Filtering (optional) <code>Filter Contigs</code>: Contig Quality Control <p>To deactivate contig filtering, set <code>run_filter_contigs</code> to <code>false</code>.</p> <p>This task filters the created contigs based on a default minimum length threshold of 200 bp and a minimum coverage of 2.0. It also eliminates homopolymer contigs (contigs of any length that consist of a single nucleotide).</p> <p>Options are available to skip any of these filters by setting the respective parameters to <code>false</code>: <code>filter_contigs_skip_length_filter</code>, <code>filter_contigs_skip_coverage_filter</code>, and <code>filter_contigs_skip_homopolymer_filter</code>. The minimum length and coverage thresholds can be adjusted using the <code>filter_contigs_min_length</code> and <code>filter_contigs_min_coverage</code> parameters, respectively.</p> <p>This ensures high-quality assemblies by retaining only contigs that meet specified criteria. Detailed metrics on contig counts and sequence lengths before and after filtering are provided in the output.</p> <p>Filter Contigs Technical Details</p> Links WDL Task task_filter_contigs.wdl <p>Digger-Denovo Technical Details</p> Links Subworkflow wf_digger_denovo.wdl <code>concatenate_illumina_lanes</code>: Concatenate Multi-Lane Illumina FASTQs <p>The <code>concatenate_illumina_lanes</code> task concatenates Illumina FASTQ files from multiple lanes into a single file. This task only runs if the <code>read1_lane2</code> input file has been provided. All read1 lanes are concatenated together and are used in subsequent tasks, as are the read2 lanes if applicable. These concatenated files are also provided as output.</p> <p>Concatenate Illumina Lanes Technical Details</p> <p>The <code>concatenate_illumina_lanes</code> task is run before any downstream steps take place.</p> Links Subworkflow wf_concatenate_illumina_lanes.wdl <code>screen</code>: Total Raw Read Quantification and Genome Size Estimation <p>The <code>screen</code> task ensures the quantity of sequence data is sufficient to undertake genomic analysis. It uses <code>fastq-scan</code> and bash commands for quantification of reads and base pairs, and mash sketching to estimate the genome size and its coverage. At each step, the results are assessed relative to pass/fail criteria and thresholds that may be defined by optional user inputs. Samples are run through all threshold checks, regardless of failures, and the workflow will terminate after the <code>screen</code> task if any thresholds are not met:</p> <ol> <li>Total number of reads: A sample will fail the read screening task if its total number of reads is less than or equal to <code>min_reads</code>.</li> <li>The proportion of basepairs reads in the forward and reverse read files: A sample will fail the read screening if fewer than <code>min_proportion</code> basepairs are in either the reads1 or read2 files.</li> <li>Number of basepairs: A sample will fail the read screening if there are fewer than <code>min_basepairs</code> basepairs</li> <li>Estimated genome size:  A sample will fail the read screening if the estimated genome size is smaller than <code>min_genome_size</code> or bigger than <code>max_genome_size</code>.</li> <li>Estimated genome coverage: A sample will fail the read screening if the estimated genome coverage is less than the <code>min_coverage</code>.</li> </ol> <p>Read screening is undertaken on both the raw and cleaned reads. The task may be skipped by setting the <code>skip_screen</code> variable to true.</p> <p>Default values vary between the PE, SE, and ONT workflows. The rationale for these default values can be found below. If two default values are shown, the first is for Illumina workflows and the second is for ONT.</p> Variable Default Value Rationale <code>skip_screen</code> false Set to true to skip the read screen from running <code>min_reads</code> 7472 or 5000 Calculated from the minimum number of base pairs required for 20x coverage of the Nasuia deltocephalinicola genome, the smallest known bacterial genome as of 2019-08-07 (112,091 bp), divided by 300 (the longest Illumina read length) or 5000 (estimate of ONT read length) <code>min_basepairs</code> 2241820 Should be greater than 20x coverage of Nasuia deltocephalinicola, the smallest known bacterial genome (112,091 bp) <code>min_genome_length</code> 100000 Based on the Nasuia deltocephalinicola genome, the smallest known bacterial genome (112,091 bp) <code>max_genome_length</code> 18040666 Based on the Minicystis rosea genome, the largest known bacterial genome (16,040,666 bp), plus an additional 2 Mbp to cater for potential extra genomic material <code>min_coverage</code> 10 or 5 A bare-minimum average per base coverage across the genome required for genome characterization. Higher coverage would be required for high-quality phylogenetics. <code>min_proportion</code> 40 Neither read1 nor read2 files should have less than 40% of the total number of reads. For paired-end data only. <p>Screen Technical Details</p> <p>There is a single WDL task for read screening. The <code>screen</code> task is run twice, once for raw reads and once for clean reads.</p> Links Task task_screen.wdl (PE sub-task)task_screen.wdl (SE sub-task) <p>These tasks clean then assemble the reads into a de novo assembly and assess the quality of the assembly.</p> <code>read_QC_trim</code>: Read Quality Trimming, Adapter Removal, Quantification, and Identification <p><code>read_QC_trim</code> is a sub-workflow that removes low-quality reads, low-quality regions of reads, and sequencing adapters to improve data quality. It uses a number of tasks, described below. The differences between the PE and SE versions of the <code>read_QC_trim</code> sub-workflow lie in the default parameters, the use of two or one input read file(s), and the different output files.</p> <p>By default, <code>read_processing</code> is set to <code>\"trimmomatic\"</code>. To use <code>fastp</code> instead, set <code>read_processing</code> to <code>\"fastp\"</code>. These tasks are mutually exclusive.</p> <code>Trimmomatic</code>: Read Trimming (default) <p>Read proccessing is available via <code>Trimmomatic</code> by default.</p> <p>Trimmomatic trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>Trimmomatic</code> Technical Details</p> Links Task task_trimmomatic.wdl Software Source Code Trimmomatic on GitHub Software Documentation Trimmomatic Website Original Publication(s) Trimmomatic: a flexible trimmer for Illumina sequence data <code>fastp</code>: Read Trimming (alternative) <p>To activate this task, set <code>read_processing</code> to <code>\"fastp\"</code>.</p> <p><code>fastp</code> trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>fastp</code> also has additional default parameters and features that are not a part of <code>trimmomatic</code>'s default configuration.</p> <code>fastp</code> default read-trimming parameters Parameter Explanation -g enables polyG tail trimming -5 20 enables read end-trimming -3 20 enables read end-trimming --detect_adapter_for_pe enables adapter-trimming only for paired-end reads <p>Additional arguments can be passed using the <code>fastp_args</code> optional parameter.</p> <p>Trimmomatic and fastp Technical Details</p> Links Task task_fastp.wdl Software Source Code fastp on GitHub Software Documentation fastp on GitHub Original Publication(s) fastp: an ultra-fast all-in-one FASTQ preprocessor <code>BBDuk</code>: Adapter Trimming and PhiX Removal <p>Adapters are manufactured oligonucleotide sequences attached to DNA fragments during the library preparation process. In Illumina sequencing, these adapter sequences are required for attaching reads to flow cells. You can read more about Illumina adapters here. For genome analysis, it's important to remove these sequences since they're not actually from your sample. If you don't remove them, the downstream analysis may be affected.</p> <p>The <code>bbduk</code> task removes adapters from sequence reads. To do this:</p> <ul> <li>Repair from the BBTools package reorders reads in paired fastq files to ensure the forward and reverse reads of a pair are in the same position in the two fastq files (it re-pairs).</li> <li>BBDuk  (\"Bestus Bioinformaticus\" Decontamination Using Kmers) is then used to trim the adapters and filter out all reads that have a 31-mer match to PhiX, which is commonly added to Illumina sequencing runs to monitor and/or improve overall run quality.</li> </ul> <p>BBDuk Technical Details</p> Links Task task_bbduk.wdl Software Source Code BBMap on SourceForge Software Documentation BBDuk Guide (archived) <p>By default, <code>read_qc</code> is set to <code>\"fastq_scan\"</code>. To use <code>fastqc</code> instead, set <code>read_qc</code> to <code>\"fastqc\"</code>. These tasks are mutually exclusive.</p> <code>fastq-scan</code>: Read Quantification (default) <p>Read quantification is available via <code>fastq-scan</code> by default.</p> <p><code>fastq-scan</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p><code>fastq-scan</code> Technical Details</p> Links Task task_fastq_scan.wdl Software Source Code fastq-scan on GitHub Software Documentation fastq-scan on GitHub <code>FastQC</code>: Read Quantification (alternative) <p>To activate this task, set <code>read_qc</code> to <code>\"fastqc\"</code>.</p> <p><code>FastQC</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>This tool also provides a graphical visualization of the read quality.</p> <p><code>FastQC</code> Technical Details</p> Links Task task_fastqc.wdl Software Source Code FastQC on Github Software Documentation FastQC Website <code>MIDAS</code>: Read Identification (optional) <p>To activate this task, set <code>call_midas</code> to <code>true</code>.</p> <p>The <code>MIDAS</code> task is for the identification of reads to detect contamination with non-target taxa.</p> <p>The MIDAS tool was originally designed for metagenomic sequencing data but has been co-opted for use with bacterial isolate WGS methods. It can be used to detect contamination present in raw sequencing data by estimating bacterial species abundance in bacterial isolate WGS data. If a secondary genus is detected above a relative frequency of 0.01 (1%), then the sample should fail QC and be investigated further for potential contamination.</p> <p>This task is similar to those used in commercial software, BioNumerics, for estimating secondary species abundance.</p> How are the MIDAS output columns determined? <p>Example MIDAS report in the <code>midas_report</code> column:</p> species_id count_reads coverage relative_abundance Salmonella_enterica_58156 3309 89.88006645 0.855888033 Salmonella_enterica_58266 501 11.60606061 0.110519371 Salmonella_enterica_53987 99 2.232896237 0.021262881 Citrobacter_youngae_61659 46 0.995216227 0.009477003 Escherichia_coli_58110 5 0.123668877 0.001177644 <p>MIDAS report column descriptions:</p> <ul> <li>species_id: species identifier</li> <li>count_reads: number of reads mapped to marker genes</li> <li>coverage: estimated genome-coverage (i.e. read-depth) of species in metagenome</li> <li>relative_abundance: estimated relative abundance of species in metagenome</li> </ul> <p>The value in the <code>midas_primary_genus</code> column is derived by ordering the rows in order of \"relative_abundance\" and identifying the genus of top species in the \"species_id\" column (Salmonella). The value in the <code>midas_secondary_genus</code> column is derived from the genus of the second-most prevalent genus in the \"species_id\" column (Citrobacter). The <code>midas_secondary_genus_abundance</code> column is the \"relative_abundance\" of the second-most prevalent genus (0.009477003). The <code>midas_secondary_genus_coverage</code> is the \"coverage\" of the second-most prevalent genus (0.995216227).</p> <p>MIDAS Reference Database Overview</p> <p>The MIDAS reference database is a comprehensive tool for identifying bacterial species in metagenomic and bacterial isolate WGS data. It includes several layers of genomic data, helping detect species abundance and potential contaminants.</p> <p>Key Components of the MIDAS Database</p> <ol> <li> <p>Species Groups: </p> <ul> <li>MIDAS clusters bacterial genomes based on 96.5% sequence identity, forming over 5,950 species groups from 31,007 genomes. These groups align with the gold-standard species definition (95% ANI), ensuring highly accurate species identification.</li> </ul> </li> <li> <p>Genomic Data Structure:</p> <ul> <li>Marker Genes: Contains 15 universal single-copy genes used to estimate species abundance.</li> <li>Representative Genome: Each species group has a selected representative genome, which minimizes genetic variation and aids in accurate SNP identification.</li> <li>Pan-genome: The database includes clusters of non-redundant genes, with options for multi-level clustering (e.g., 99%, 95%, 90% identity), enabling MIDAS to identify gene content within strains at various clustering thresholds.</li> </ul> </li> <li> <p>Taxonomic Annotation: </p> <ul> <li>Genomes are annotated based on consensus Latin names. Discrepancies in name assignments may occur due to factors like unclassified genomes or genus-level ambiguities.</li> </ul> </li> </ol> <p>Using the Default MIDAS Database</p> <p>TheiaProk and TheiaEuk use the pre-loaded MIDAS database in Terra (see input table for current version) by default for bacterial species detection in metagenomic data, requiring no additional setup.</p> <p>Create a Custom MIDAS Database</p> <p>Users can also build their own custom MIDAS database if they want to include specific genomes or configurations. This custom database can replace the default MIDAS database used in Terra. To build a custom MIDAS database, follow the MIDAS GitHub guide on building a custom database. Once the database is built, users can upload it to a Google Cloud Storage bucket or Terra workkspace and provide the link to the database in the <code>midas_db</code> input variable.</p> <p>MIDAS Technical Details</p> Links Task task_midas.wdl Software Source Code MIDAS on GitHub Software Documentation MIDAS on GitHub Original Publication(s) An integrated metagenomics pipeline for strain profiling reveals novel patterns of bacterial transmission and biogeography <code>Kraken2</code>: Read Identification (optional) <p>To activate this task, set <code>call_kraken</code> to <code>true</code> and provide a value for <code>kraken_db</code>.</p> <p><code>Kraken2</code> is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>Database-dependent</p> <p>This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz</code>.</p> <p>As an alternative to <code>MIDAS</code> (see above), the <code>Kraken2</code> task can also be turned on through setting the <code>call_kraken</code> input variable as <code>true</code> for the identification of reads to detect contamination with non-target taxa.</p> <p>A database must be provided if this optional module is activated, through the kraken_db optional input. A list of suggested databases can be found on Kraken2 standalone documentation.</p> <p>Kraken2 Technical Details</p> Links Task task_kraken2.wdl Software Source Code Kraken2 on GitHub Software Documentation Kraken2 Documentation Original Publication(s) Improved metagenomic analysis with Kraken 2 <p>read_QC_trim Technical Details</p> Links Subworkflow wf_read_QC_trim_pe.wdlwf_read_QC_trim_se.wdl <code>CG-Pipeline</code>: Assessment of Read Quality, and Estimation of Genome Coverage <p>The<code>cg_pipeline</code> task generates metrics about read quality and estimates the coverage of the genome using the <code>run_assembly_readMetrics.pl</code> script from CG-Pipeline. The genome coverage estimates are calculated using both using raw and cleaned reads, using either a user-provided <code>genome_size</code> or the estimated genome length generated by QUAST.</p> <p>CG-Pipeline Technical Details</p> <p>The <code>cg_pipeline</code> task is run twice in this workflow, once with raw reads, and once with clean reads.</p> Links Task task_cg_pipeline.wdl Software Source Code CG-Pipeline on GitHub Software Documentation CG-Pipeline on GitHub Original Publication(s) A computational genomics pipeline for prokaryotic sequencing projects <code>digger_denovo</code>: De novo Assembly <p>De novo  assembly is the process or product of attempting to reconstruct a genome from scratch (without prior knowledge of the genome) using sequence reads. Assembly of fungal genomes from short-reads will produce multiple contigs per chromosome rather than a single contiguous sequence for each chromosome.</p> <p>In TheiaProk and TheiaEuk Illumina workflows, de novo assembly is performed for samples that have sufficient read quantity and quality using digger_denovo, a subworkflow based off of Shovill pipeline. The name \"digger\" is a nod to Shovill and SPAdes.</p> De novo Assembly <p><code>assembler</code> with <code>skesa</code> (default), <code>spades</code>, or <code>megahit</code></p> <p>To activate a particular assembler, set the <code>assembler</code> input parameter to either <code>skesa</code> (default), <code>spades</code>, or <code>megahit</code>.</p> <p>These tasks are mutually exclusive.</p> <code>SKESA</code>: De novo Assembly (default) <p>This task is activated by default.</p> <p><code>SKESA</code> (Strategic K-mer Extension for Scrupulous Assemblies) is a de novo assembler that is fairly conservative and introduces breaks in the genome at repeat regions. This leads to higher sequence quality but more fragmented assemblies, which, depending on the final analysis goal, can be either highly preferred or detrimental. Designed for Illumina reads and haploid genomes, SKESA is the default assembler in the <code>digger_denovo</code> subworkflow.</p> <p>SKESA Technical Details</p> Links Task task_skesa.wdl Software Source Code SKESA on GitHub Software Documentation SKESA on GitHub Original Publication(s) SKESA: strategic k-mer externsion for scrupulous assemblies <code>SPAdes</code>: De novo Assembly (alternative) <p>To activate this task, set <code>assembler</code> to <code>spades</code>.</p> <p><code>SPAdes</code> (St. Petersburg genome assembler) is a de novo assembly tool that uses de Bruijn graphs to assemble genomes from Illumina short reads.</p> <p>In TheiaProk, SPAdes is run in <code>--isolate</code> mode, which is the recommended flag for high-coverage isolate and multi-cell Illumina data, which is typical of most bacterial sequencing projects. This method is optimized for improving assembly quality and decreasing runtime.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>MetaviralSPAdes Technical Details</p> Links Task task_spades.wdl Software Source Code SPAdes on GitHub Software Documentation SPAdes Manual Original Publication(s) TheiaProk: SPAdes: A New Genome Assembly Algorithm and Its Applications to Single-Cell SequencingTheiaViral: MetaviralSPAdes: assembly of viruses from metagenomic data <code>MEGAHIT</code>: De novo Assembly (alternative) <p>To activate this task, set <code>assembler</code> to <code>megahit</code>.</p> <p>The MEGAHIT assembler is a fast and memory-efficient de novo assembler that can handle large datasets. While optimized for metagenomics, MEGAHIT also performs well on single-genome assemblies, making it a versatile choice for various assembly tasks.</p> <p>MEGAHIT uses a multiple k-mer strategy that can be beneficial for assembling genomes with varying coverage levels, which is common in metagenomic samples. It constructs succinct de Bruijn graphs to efficiently represent the assembly process, allowing it to handle large and complex datasets with reduced memory usage.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>MEGAHIT Technical Details</p> Links Task task_megahit.wdl Software Source Code MEGAHIT on GitHub Software Documentation MEGAHIT on GitHub Original Publication(s) MEGAHIT: an ultra-fast single-node solution for large and complex metagenomics assembly via succinct de Bruijn graph Assembly Polishing (optional) <p>To activate assembly polishing, set <code>call_pilon</code> to <code>true</code>.</p> <code>bwa</code>: Read Alignment to the Assembly <p>BWA (Burrow-Wheeler Aligner) is used to align the cleaned read files to generated assembly file in order to generate an alignment. The resulting BAM file is directly passed to the Pilon task to polish the assembly for errors.</p> <p>BWA Technical Details</p> Links Task task_bwa.wdl Software Source Code BWA on GitHub Software Documentation BWA Documentation Original Publication(s) Fast and accurate short read alignment with Burrows-Wheeler transform <code>Pilon</code>: Assembly Polishing <p><code>Pilon</code> is a tool that uses read alignments to correct errors in an assembly.</p> <p>The <code>bwa</code>-generated alignment of the read data to the assembly is used to identify inconsistences between the reads and the assembly in order to correct them. <code>Pilon</code> will attempt to fix individual base errors and small indels using the read data. This can improve the overall quality of the assembly, especially when the assembler has made mistakes due to sequencing errors or low coverage regions.</p> <p>The default parameters were set to mimic the parameters used by Shovill: <code>--fix bases --minq 60 --minqual 3 --mindepth 0.25</code>. These can be modified by the user.</p> <p>Pilon Technical Details</p> Links Task task_pilon.wdl Software Source Code Pilon on GitHub Software Documentation Pilon Wiki Original Publication(s) Pilon: An Integrated Tool for Comprehensive Microbial Variant Detection and Genome Assembly Improvement Contig Filtering (optional) <code>Filter Contigs</code>: Contig Quality Control <p>To deactivate contig filtering, set <code>run_filter_contigs</code> to <code>false</code>.</p> <p>This task filters the created contigs based on a default minimum length threshold of 200 bp and a minimum coverage of 2.0. It also eliminates homopolymer contigs (contigs of any length that consist of a single nucleotide).</p> <p>Options are available to skip any of these filters by setting the respective parameters to <code>false</code>: <code>filter_contigs_skip_length_filter</code>, <code>filter_contigs_skip_coverage_filter</code>, and <code>filter_contigs_skip_homopolymer_filter</code>. The minimum length and coverage thresholds can be adjusted using the <code>filter_contigs_min_length</code> and <code>filter_contigs_min_coverage</code> parameters, respectively.</p> <p>This ensures high-quality assemblies by retaining only contigs that meet specified criteria. Detailed metrics on contig counts and sequence lengths before and after filtering are provided in the output.</p> <p>Filter Contigs Technical Details</p> Links WDL Task task_filter_contigs.wdl <p>Digger-Denovo Technical Details</p> Links Subworkflow wf_digger_denovo.wdl <code>screen</code>: Total Raw Read Quantification and Genome Size Estimation <p>The <code>screen</code> task ensures the quantity of sequence data is sufficient to undertake genomic analysis. It uses <code>fastq-scan</code> and bash commands for quantification of reads and base pairs, and mash sketching to estimate the genome size and its coverage. At each step, the results are assessed relative to pass/fail criteria and thresholds that may be defined by optional user inputs. Samples are run through all threshold checks, regardless of failures, and the workflow will terminate after the <code>screen</code> task if any thresholds are not met:</p> <ol> <li>Total number of reads: A sample will fail the read screening task if its total number of reads is less than or equal to <code>min_reads</code>.</li> <li>The proportion of basepairs reads in the forward and reverse read files: A sample will fail the read screening if fewer than <code>min_proportion</code> basepairs are in either the reads1 or read2 files.</li> <li>Number of basepairs: A sample will fail the read screening if there are fewer than <code>min_basepairs</code> basepairs</li> <li>Estimated genome size:  A sample will fail the read screening if the estimated genome size is smaller than <code>min_genome_size</code> or bigger than <code>max_genome_size</code>.</li> <li>Estimated genome coverage: A sample will fail the read screening if the estimated genome coverage is less than the <code>min_coverage</code>.</li> </ol> <p>Read screening is undertaken on both the raw and cleaned reads. The task may be skipped by setting the <code>skip_screen</code> variable to true.</p> <p>Default values vary between the PE, SE, and ONT workflows. The rationale for these default values can be found below. If two default values are shown, the first is for Illumina workflows and the second is for ONT.</p> Variable Default Value Rationale <code>skip_screen</code> false Set to true to skip the read screen from running <code>min_reads</code> 7472 or 5000 Calculated from the minimum number of base pairs required for 20x coverage of the Nasuia deltocephalinicola genome, the smallest known bacterial genome as of 2019-08-07 (112,091 bp), divided by 300 (the longest Illumina read length) or 5000 (estimate of ONT read length) <code>min_basepairs</code> 2241820 Should be greater than 20x coverage of Nasuia deltocephalinicola, the smallest known bacterial genome (112,091 bp) <code>min_genome_length</code> 100000 Based on the Nasuia deltocephalinicola genome, the smallest known bacterial genome (112,091 bp) <code>max_genome_length</code> 18040666 Based on the Minicystis rosea genome, the largest known bacterial genome (16,040,666 bp), plus an additional 2 Mbp to cater for potential extra genomic material <code>min_coverage</code> 10 or 5 A bare-minimum average per base coverage across the genome required for genome characterization. Higher coverage would be required for high-quality phylogenetics. <code>min_proportion</code> 40 Neither read1 nor read2 files should have less than 40% of the total number of reads. For paired-end data only. <p>Screen Technical Details</p> <p>There is a single WDL task for read screening. The <code>screen</code> task is run twice, once for raw reads and once for clean reads.</p> Links Task task_screen.wdl (PE sub-task)task_screen.wdl (SE sub-task) <p>These tasks clean then assemble the reads into a de novo assembly and assess the quality of the assembly.</p> <code>read_QC_trim_ont</code>: Read Quality Trimming, Quantification, and Identification <p><code>read_QC_trim_ont</code> is a sub-workflow that filters low-quality reads and trims low-quality regions of reads. It uses several tasks, described below.</p> <p>A note on estimated genome length</p> <p>By default, the estimated genome length is set to 5 Mb, which is around 0.7 Mb higher than the average bacterial genome length, according to the information of thousands of NCBI bacterial assemblies collated here. This estimate can be overwritten by the user and is used by <code>Rasusa</code>.</p> <code>Rasusa</code>: Read Subsampling <p><code>Rasusa</code> is a tool to randomly subsample sequencing reads to a specified coverage without assuming that all reads are of equal length, making it especially suitable for long-read data while still being applicable to short-read data.</p> <p>The <code>Rasusa</code> task performs subsampling on the input raw reads. By default, this task will subsample TheiaProk_ONT reads to a depth of 150X using an estimated genome length of 5 million basepairs (0.7 Mb higher than the average bacterial genome length), and TheiaEuk_ONT reads using an estimated genome length of 50 million basepairs. The estimated genome length can be changed by the user by providing a different value for the <code>genome_length</code> input parameter. The target subsampling depth can also be adjusted by modifying the <code>subsample_coverage</code> variable.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs since it performs random subsampling. To ensure reproducibility, set a a value for the <code>rasusa_seed</code> optional input variable.</p> <p>Rasusa Technical Details</p> Links Task task_rasusa.wdl Software Source Code Rasusa on GitHub Software Documentation Rasusa on GitHub Original Publication(s) Rasusa: Randomly subsample sequencing reads to a specified coverage <code>Nanoq</code>: Read Filtering <p>Reads are filtered by length and quality using <code>nanoq</code>. By default, sequences with less than 500 basepairs and quality scores lower than 10 are filtered out to improve assembly accuracy. These defaults are able to be modified by the user.</p> <p>Nanoq Technical Details</p> Links Task task_nanoq.wdl Software Source Code Nanoq on GitHub Software Documentation Nanoq Documentation Original Publication(s) Nanoq: ultra-fast quality control for nanopore reads <code>Kraken2</code>: Read Identification (optional) <p>To activate this task, set <code>call_kraken</code> to <code>true</code> and provide a value for <code>kraken_db</code>.</p> <p><code>Kraken2</code> is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>Kraken2 is run on the raw read data.</p> <p>Database-dependent</p> <p>This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz</code>.</p> <p>A database must be provided if this optional module is activated, through the kraken_db optional input. A list of suggested databases can be found on Kraken2 standalone documentation.</p> <p>Kraken2 Technical Details</p> Links Task task_kraken2.wdl Software Source Code Kraken2 on GitHub Software Documentation Kraken2 Documentation Original Publication(s) Improved metagenomic analysis with Kraken 2 <code>NanoPlot</code>: Read Quantification <p>NanoPlot is used for the determination of mean quality scores, read lengths, and number of reads. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>While this task currently is run outside of the <code>read_QC_trim_ont</code> workflow, it is being included here as it calculates statistics on the read data. This is done so that the actual assembly genome lengths can be used (if an estimated genome length is not provided by the user) to ensure the estimated coverage statistics are accurate.</p> <p>NanoPlot Technical Details</p> Links Task task_nanoplot.wdl Software Source Code NanoPlot on GitHub Software Documentation NanoPlot Documentation Original Publication(s) NanoPack2: population-scale evaluation of long-read sequencing data <p>read_QC_trim_ont Technical Details</p> Links Subworkflow wf_read_QC_trim_ont.wdl <code>Flye</code>: De novo Assembly <p><code>flye_denovo</code> is a sub-workflow that performs de novo assembly using Flye for ONT data and supports additional polishing and visualization steps.</p> <p>Ensure correct medaka model is selected if performing medaka polishing</p> <p>In order to obtain the best results, the appropriate model must be set to match the sequencer's basecaller model; this string takes the format of {pore}_{device}_{caller variant}_{caller_version}. See also https://github.com/nanoporetech/medaka?tab=readme-ov-file#models. If <code>flye</code> is being run on legacy data the medaka model will likely be <code>r941_min_hac_g507</code>. Recently generated data will likely be suited by the default model of <code>r1041_e82_400bps_sup_v5.0.0</code>.</p> <p>The detailed steps and tasks are as follows:</p> <code>Porechop</code>: Read Trimming (optional; off by default) <p>Read trimming is optional and can be enabled by setting the <code>run_porchop</code> input variable to true.</p> <p>Porechop is a tool for finding and removing adapters from ONT data. Adapters on the ends of reads are trimmed, and when a read has an adapter in the middle, the read is split into two.</p> <p>Porechop Technical Details</p> Links WDL Task task_porechop.wdl Software Source Code Porechop on GitHub Software Documentation https://github.com/rrwick/Porechop#porechop <code>Flye</code>: De novo Assembly <p>Flye is a de novo assembler for long read data using repeat graphs. Compared to de Bruijn graphs, which require exact k-mer matches, repeat graphs can use approximate matches which better tolerates the error rate of ONT data.</p> <code>flye_read_type</code> input parameter <p>This input parameter specifies the type of sequencing reads being used for assembly. This parameter significantly impacts the assembly process and should match the characteristics of your input data. Below are the available options:</p> Parameter Explanation <code>--nano-hq</code> (default) Optimized for ONT high-quality reads, such as Guppy5+ SUP or Q20 (&lt;5% error). Recommended for ONT reads processed with Guppy5 or newer <code>--nano-raw</code> For ONT regular reads, pre-Guppy5 (&lt;20% error) <code>--nano-corr</code> ONT reads corrected with other methods (&lt;3% error) <code>--pacbio-raw</code> PacBio regular CLR reads (&lt;20% error) <code>--pacbio-corr</code> PacBio reads corrected with other methods (&lt;3% error) <code>--pacbio-hifi</code> PacBio HiFi reads (&lt;1% error) <p>Refer to the Flye documentation for detailed guidance on selecting the appropriate <code>flye_read_type</code> based on your sequencing data and additional optional paramaters.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>Flye Technical Details</p> Links WDL Task task_flye.wdl Software Source Code Flye on GitHub Software Documentation Flye Documentation Original Publication(s) Assembly of long, error-prone reads using repeat graphs <code>Bandage</code>: Graph Visualization <p>Bandage creates de novo assembly graphs containing the assembled contigs and the connections between those contigs. These graphs are useful for visualizing the assembly structure, identifying potential misassemblies, and understanding the relationships between contigs.</p> <p>Bandage Technical Details</p> Links WDL Task task_bandage_plot.wdl Software Source Code Bandage on GitHub Software Documentation Bandage Documentation Original Publication(s) Bandage: interactive visualization of de novo genome assemblies <code>Polypolish</code>: Hybrid Assembly Polishing for ONT and Illumina data <p>If short reads are provided with the optional <code>illumina_read1</code> and <code>illumina_read2</code> inputs, Polypolish will use those short-reads to correct errors in the long-read assemblies. Uniquely, Polypolish uses the short-read alignments where each read is aligned to all possible locations, meaning that even repeat regions will have error correction.</p> <p>Polypolish Technical Details</p> Links Task task_polypolish.wdl Software Source Code Polypolish on GitHub Software Documentation Polypolish Documentation Original Publication(s) Polypolish: short-read polishing of long-read bacterial genome assembliesHow low can you go? Short-read polishing of Oxford Nanopore bacterial genome assemblies <code>Medaka</code>: Polishing of Flye assembly (default; optional) <p>Polishing is optional and can be skipped by setting the <code>skip_polishing</code> variable to true. If polishing is skipped, then neither Medaka or Racon will run.</p> <p>Medaka is the default assembly polisher used in TheiaProk. Racon may be used alternatively, and if so, Medaka will not run. Medaka uses the raw reads to polish the assembly and generate a consensus sequence. </p> <p>Importantly, Medaka requires knowing the model that was used to generate the read data. There are several ways to provide this information:</p> <ul> <li>Automatic Model Selection: Automatically determines the most appropriate Medaka model based on the input data, ensuring optimal polishing results without manual intervention. </li> <li>User-Specified Model Override: Allows users to specify a particular <code>Medaka model</code> if automatic selection does not yield the desired outcome or for specialized use cases.</li> <li>Default Model: If both automatic model selection fails and no user-specified model is provided, Medaka defaults to the predefined fallback model <code>r1041_e82_400bps_sup_v5.0.0</code>. </li> </ul> <p>Medaka Model Resolution Process</p> <p>Medaka's automatic model selection uses the <code>medaka tools resolve_model</code> command to identify the appropriate model for polishing. This process relies on metadata embedded in the input file, which is typically generated by the basecaller. If the automatic selection fails to identify a suitable model, Medaka gracefully falls back to the default model to maintain workflow continuity. Users should verify the chosen model and consider specifying a model override if necessary.</p> <p>Medaka Technical Details</p> Links WDL Task task_medaka.wdl Software Source Code Medaka on GitHub Software Documentation Medaka Documentation <code>Racon</code>: Polishing of Flye assembly (alternative; optional) <p>Polishing is optional and can be skipped by setting the <code>skip_polishing</code> variable to true. If polishing is skipped, then neither Medaka or Racon will run.</p> <p><code>Racon</code> is an alternative to using <code>medaka</code> for assembly polishing, and can be run by setting the <code>polisher</code> input to \"racon\".  Racon is a consensus algorithm designed for refining raw de novo DNA assemblies generated from long, uncorrected sequencing reads.</p> <p>Racon Technical Details</p> Links WDL Task task_racon.wdl Software Source Code Racon on GitHub Software Documentation Racon Documentation Original Publication(s) Fast and accurate de novo genome assembly from long uncorrected reads <code>Filter Contigs</code>: Filter contigs below a threshold length and remove homopolymer contigs <p>This task filters the created contigs based on a user-defined minimum length threshold (default of 1000) and eliminates homopolymer contigs (contigs of any length that consist of a single nucleotide).</p> <p>This ensures high-quality assemblies by retaining only contigs that meet specified criteria. Detailed metrics on contig counts and sequence lengths before and after filtering are provided in the output.</p> <p>Filter Contigs Technical Details</p> Links WDL Task task_filter_contigs.wdl <code>Dnaapler</code>: Final Assembly Orientation <p>Dnaapler reorients contigs to start at specific reference points. Dnaapler supports the following modes, which can be indicated by filling the <code>dnaapler_mode</code> input variable with the desired mode. The default is <code>all</code>, which reorients contigs to start with <code>dnaA</code>, <code>terL</code>, <code>repA</code>, or <code>COG1474</code>.</p> <ul> <li>all: Reorients contigs to start with <code>dnaA</code>, <code>terL</code>, <code>repA</code>, or <code>COG1474</code> (Default)</li> <li>chromosome: Reorients to begin with the <code>dnaA</code> chromosomal replication initiator gene, commonly used for bacterial chromosome assemblies.</li> <li>plasmid: Reorients to start with the <code>repA</code> plasmid replication initiation gene, ideal for plasmid assemblie</li> <li>phage: Reorients to start with the <code>terL</code> large terminase subunit gene, used for bacteriophage assemblies</li> <li>archaea: Reorients to start with the <code>COG1474</code> archaeal Orc1/cdc6 gene, relevant for archaeal assemblies</li> <li>custom: Reorients based on a user-specified gene in amino acid FASTA format for experimental or unique workflows</li> <li>mystery: Reorients to start with a random CDS for exploratory purposes</li> <li>largest: Reorients to start with the largest CDS in the assembly, often useful for poorly annotated genomes</li> <li>nearest: Reorients to start with the first CDS nearest to the sequence start, resolving CDS breakpoints</li> <li>bulk: Processes multiple contigs to start with the desired start gene (<code>dnaA</code>, <code>terL</code>, <code>repA</code>, or custom)</li> </ul> <p>Dnaapler Technical Details</p> Links WDL Task task_dnaapler.wdl Software Source Code Dnaapler on GitHub Software Documentation Dnaapler Documentation Original Publication(s) Dnaapler: a tool to reorient circular microbial genomes <p>Flye-Denovo Technical Details</p> Links Subworkflow wf_flye_denovo.wdl <p>Since this workflow requires FASTA files as input, no assembly or read trimming is performed, and the workflow proceeds directly to the \"post-assembly tasks\" section below.</p>"},{"location":"workflows/genomic_characterization/theiaprok/#post-assembly-tasks","title":"Post-Assembly Tasks","text":"<p>The following tasks are performed for all taxa, regardless of the input data type. They include quality control, assembly characterization, and taxonomic identification.</p>"},{"location":"workflows/genomic_characterization/theiaprok/#quality-control","title":"Quality Control","text":"<code>quast</code>: Assembly Quality Assessment <p>QUAST stands for QUality ASsessment Tool. It evaluates genome/metagenome assemblies by computing various metrics without a reference being necessary. It includes useful metrics such as number of contigs, length of the largest contig and N50.</p> <p>QUAST Technical Details</p> Links Task task_quast.wdl Software Source Code QUAST on GitHub Software Documentation QUAST Manual on SourceForge Original Publication(s) QUAST: quality assessment tool for genome assemblies <code>BUSCO</code>: Assembly Quality Assessment <p>BUSCO (Benchmarking Universal Single-Copy Orthologue) attempts to quantify the completeness and contamination of an assembly to generate quality assessment metrics. It uses taxa-specific databases containing genes that are all expected to occur in the given taxa, each in a single copy. BUSCO examines the presence or absence of these genes, whether they are fragmented, and whether they are duplicated (suggestive that additional copies came from contaminants).</p> <p>BUSCO notation </p> <p>Here is an example of BUSCO notation: <code>C:99.1%[S:98.9%,D:0.2%],F:0.0%,M:0.9%,n:440</code>. There are several abbreviations used in this output:</p> <ul> <li>Complete (C) - genes are considered \"complete\" when their lengths are within two standard deviations of the BUSCO group mean length.</li> <li>Single-copy (S) - genes that are complete and have only one copy.</li> <li>Duplicated (D) - genes that are complete and have more than one copy.</li> <li>Fragmented (F) - genes that are only partially recovered.</li> <li>Missing (M) - genes that were not recovered at all.</li> <li>Number of genes examined (n) - the number of genes examined.</li> </ul> <p>A high equity assembly will use the appropriate database for the taxa, have high complete (C) and single-copy (S) percentages, and low duplicated (D), fragmented (F) and missing (M) percentages. </p> <p>BUSCO Technical Details</p> Links Task task_busco.wdl Software Source Code BUSCO on GitLab Software Documentation https://busco.ezlab.org/ Orginal publication BUSCO: assessing genome assembly and annotation completeness with single-copy orthologs <code>qc_check</code>: Check QC Metrics Against User-Defined Thresholds (optional) <p>To activate this task, provide a <code>qc_check_table</code> as input.</p> <p>The <code>qc_check</code> task compares generated QC metrics against user-defined thresholds for each metric. This task will run if the user provides a <code>qc_check_table</code> TSV file. If all QC metrics meet the threshold, the <code>qc_check</code> output variable will read <code>QC_PASS</code>. Otherwise, the output will read <code>QC_NA</code> if the task could not proceed or <code>QC_ALERT</code> followed by a string indicating what metric failed.</p> <p>The <code>qc_check</code> task applies quality thresholds according to the sample taxa. The sample taxa is taken from the <code>gambit_predicted_taxon</code> value inferred by the GAMBIT module OR can be manually provided by the user using the <code>expected_taxon</code> workflow input.</p> Formatting the qc_check_table.tsv <ul> <li>The first column of the qc_check_table lists the <code>organism</code> that the task will assess and the header of this column must be \"taxon\".</li> <li>Any genus or species can be included as a row of the qc_check_table. However, these taxa must uniquely match the sample taxa, meaning that the file can include multiple species from the same genus (Vibrio_cholerae and Vibrio_vulnificus), but not both a genus row and species within that genus (Vibrio and Vibrio cholerae). The taxa should be formatted with the first letter capitalized and underscores in lieu of spaces.</li> <li>Each subsequent column indicates a QC metric and lists a threshold for each organism that will be checked. The column names must exactly match expected values, so we highly recommend copy and pasting the header from the template file below as a starting place.</li> </ul> Template qc_check_table.tsv files <ul> <li>TheiaProk_Illumina_PE: theiaprok_illumina_pe_qc_check_template.tsv</li> <li>TheiaProk_FASTA: theiaprok_fasta_qc_check_template.tsv</li> </ul> <p>Example Purposes Only</p> <p>The QC threshold values shown in the file above are for example purposes only and should not be presumed to be sufficient for every dataset.</p> <p>qc_check Technical Details</p> Links Task task_qc_check_phb.wdl <code>arln_stats</code>: Quality Assessment for ARLN (optional) <p>To activate this task, set <code>call_arln_stats</code> to <code>true</code>.</p> <p>The <code>arln_stats</code> task will provide the user with Antimicrobial Resistance Laboratory Network (ARLN)-compliant statistics used for PASS/FAIL assessment, such as assembly ratio, percent GC statistics, and the percent Q30 of raw and cleaned reads.</p> <p>The Q30 statistics are calculated via a Python script (q30.py) that is incorporated within this task's Docker image. The assembly ratio statistic is obtained by parsing an included NCBI Assembly Stats text file that is created by the CDC to aggregate NCBI prokaryotic assembly data. The file is sorted by taxon and has statistics for each taxon (see toggle below). This data is used to obtain and calculate the assembly ratio of samples passed through <code>arln_stats</code>, much the same as CDC's Phoenix pipeline.</p> NCBI Assembly Stats Explained <p>This aggregated data file is produced by the CDC and the columns are as follows: </p> <ul> <li>Species</li> <li>Assembly_Size_Min</li> <li>Assembly_Size_Max</li> <li>Assembly_vMedian</li> <li>Assembly_Size_Mean</li> <li>Assembly_Size_StDev</li> <li>Assembly_count</li> <li>GC_Min</li> <li>GC_Max</li> <li>GC_Median</li> <li>GC_Mean</li> <li>GC_Stdev</li> <li>GC_count</li> <li>CDS_Min</li> <li>CDS_Max</li> <li>CDS_Median</li> <li>CDS_Mean</li> <li>CDS_Stdev</li> <li>CDS_count</li> <li>Consensus_TAXID</li> </ul> <p>arln_stats Technical Details</p> Links Task task_arln_stats.wdl"},{"location":"workflows/genomic_characterization/theiaprok/#taxonomic-assignment","title":"Taxonomic Assignment","text":"<code>GAMBIT</code>: Taxon Assignment <p><code>GAMBIT</code> determines the taxon of the genome assembly using a k-mer based approach to match the assembly sequence to the closest complete genome in a database, thereby predicting its identity. Sometimes, GAMBIT can confidently designate the organism to the species level. Other times, it is more conservative and assigns it to a higher taxonomic rank.</p> <p>For additional details regarding the GAMBIT tool and a list of available GAMBIT databases for analysis, please consult the GAMBIT tool documentation.</p> <p>GAMBIT Technical Details</p> Links Task task_gambit.wdl Software Source Code GAMBIT on GitHub Software Documentation GAMBIT ReadTheDocs Original Publication(s) GAMBIT (Genomic Approximation Method for Bacterial Identification and Tracking): A methodology to rapidly leverage whole genome sequencing of bacterial isolates for clinical identification <code>KmerFinder</code>: Taxon Assignment (optional) <p>To activate this task, set <code>call_kmerfinder</code> to <code>true</code>.</p> <p>KmerFinder predicts prokaryotic species based on the number of overlapping (co-occurring)\u00a0k-mers, i.e., 16-mers, between the query genome and genomes in a reference database. These k-mers are selected with the prefix of <code>ATGAC</code> in order to focus on coding regions of genomes. A prediction is made by identifying which species in the training data has the highest number of 16-mers in common with the query. This match is made regardless of position. Ties will result in an alphabetical sorting of tied species and the return of the first species in the alphabetical list. </p> <p>This is a simpler approach than other k-mer based tools such as GAMBIT, which uses a 11-mer approach while implementing thresholds to its classification algorithm allowing it to re-assess at a higher level of classification if need be.</p> <p>KmerFinder Technical Details</p> Links Task task_kmerfinder.wdl Software Source Code KmerFinder BitBucket Software Documentation CGE KmerFinder Documentation Original Publication(s) Benchmarking of Methods for Genomic Taxonomy <code>MUMmer_ANI</code>: Taxon Assignment using Average Nucleotide Identity (optional) <p>To activate this task, set <code>call_ani</code> to <code>true</code>.</p> <p>Average Nucleotide Identity (ANI) is a useful approach for taxonomic identification. The higher the percentage ANI of a query sequence to a given reference genome, the more likely the sequence is the same taxa as the reference. </p> <p>ANI is calculated in TheiaProk using a perl script written by Lee Katz (ani-m.pl). This uses MUMmer to rapidly align entire query assemblies to one or more reference genomes. By default, TheiaProk uses a set of 43 reference genomes in RGDv2, a database containing genomes of enteric pathogens commonly sequenced by CDC EDLB &amp; PulseNet participating laboratories. The user may also provide their own reference genome. After genome alignment with MUMmer, ani-m.pl calculates the average nucleotide identity and percent bases aligned between 2 genomes (query and reference genomes)</p> <p>The default database of reference genomes used is called \"Reference Genome Database version 2\" AKA \"RGDv2\". This database is composed of 43 enteric bacteria representing 32 species and is intended for identification of enteric pathogens and common contaminants. It contains six Campylobacter spp., three Escherichia/Shigella spp., one Grimontia hollisae, six Listeria spp., one Photobacterium damselae, two Salmonella spp., and thirteen Vibrio spp. </p> <p>2 Thresholds are utilized to prevent false positive hits. The <code>ani_top_species_match</code> will only report a genus &amp; species match if both thresholds are surpassed. Both of these thresholds are set to match those used in BioNumerics for PulseNet organisms.</p> <ol> <li><code>ani_threshold</code> default value of 80.0</li> <li><code>percent_bases_aligned_threshold</code> default value of 70.0</li> </ol> <p>For more information on RGDv2 database of reference genomes, please see the publication here.</p> <p>MUMmer_ANI Technical Details</p> Links Task task_mummer_ani.wdl Software Source Code ani-m on GitHubMUMmer on GitHub Software Documentation ani-m on GitHubMUMmer on SourceForge Original Publication(s) MUMmer4: MUMmer4: A fast and versatile genome alignment systemRGDv2 database: Rapid identification of enteric bacteria from whole genome sequences using average nucleotide identity metrics"},{"location":"workflows/genomic_characterization/theiaprok/#amr-characterization","title":"AMR Characterization","text":"<code>AMRFinderPlus</code>: AMR Genotyping <p>NCBI's AMRFinderPlus is the default antimicrobial resistance (AMR) detection tool used in TheiaProk. ResFinder may be used alternatively and if so, AMRFinderPlus is not run. </p> <p>AMRFinderPlus identifies acquired antimicrobial resistance (AMR) genes, virulence genes, and stress genes.  Such AMR genes confer resistance to antibiotics, metals, biocides, heat, or acid. For some taxa (see here), AMRFinderPlus will provide taxa-specific results including filtering out genes that are almost ubiquitous in the taxa (intrinsic genes) and identifying resistance-associated point mutations.  In TheiaProk, the taxon used by AMRFinderPlus is specified based on the <code>gambit_predicted_taxon</code> or a user-provided <code>expected_taxon</code>. AMRFinderPlus also has the ability to utilize a GFF and protein FASTA file which can be enabled via <code>amrfinder_use_gff</code> allowing for more accurate calls.</p> <p>You can check if a gene or point mutation is in the AMRFinderPlus database with the Reference Gene Catalog, find the sequences of reference genes in the Bacterial Antimicrobial Resistance Reference Gene Database BioProject, and search the query Hidden Markov Models (HMMs) used by AMRFinderPlus to identify AMR genes and some stress and virulence proteins in the Reference HMM Catalog. The AMRFinderPlus database is updated frequently. You can ensure you are using the most up-to-date version by specifying the Docker image in the optional workflow input.</p> AMRFinderPlus results can be used to confirm taxonomic assignment in A. baumannii <p>The blaOXA-51-like genes, also known as oxaAB, are considered intrinsic to Acinetobacter baumannii but are not found in other Acinetobacter species. Identification of a blaOXA-51-like gene with this tool is therefore considered to confirm the species' identity as A. baumannii.</p> <p>AMRFinderPlus Technical Details</p> Links Task task_amrfinderplus.wdl Software Source Code NCBI's AMRFinderPlus on GitHub Software Documentation https://github.com/ncbi/amr/wiki Original Publication(s) AMRFinderPlus and the Reference Gene Catalog facilitate examination of the genomic links among antimicrobial resistance, stress response, and virulence <code>ResFinder</code>: AMR Genotyping and XDR Shigella Prediction (optional) <p>To activate this task, set <code>call_resfinder</code> to <code>true</code>.</p> <p>AMR Genotyping</p> <p>The <code>ResFinder</code> task is an optional task that can be used in conjunction with AMRFinderPlus for detection and identification of AMR genes and resistance-associated mutations. This task runs the Centre for Genomic Epidemiology (CGE) ResFinder tool to identify acquired antimicrobial resistance. The default thresholds for calling AMR genes are 90% identity and 50% coverage of the reference genes (expressed as a fraction in workflow inputs: 0.9 and 0.5). These are the same thresholds utilized in BioNumerics for calling AMR genes.</p> <p>This task can also run the CGE PointFinder tool if the <code>call_pointfinder</code> variable is set with to <code>true</code>. The databases underlying the task are different to those used by AMRFinderPlus.</p> PointFinder-supported organisms <p>The following organisms are currently supported by PointFinder for mutational-based predicted resistance. If GAMBIT (see above) predicted the sample to be an organism not on this list, PointFinder will be skipped.</p> <ul> <li>Campylobacter coli &amp; C. jejuni</li> <li>Enterococcus faecalis</li> <li>Enterococcus faecium</li> <li>Escherichia coli &amp; Shigella spp.</li> <li>Helicobacter pylori</li> <li>Neisseria gonorrhoeae</li> <li>Klebsiella</li> <li>Mycobacterium tuberculosis</li> <li>Salmonella spp.</li> <li>Staphylococcus aureus</li> </ul> <p>XDR Shigella prediction</p> <p>The <code>ResFinder</code> Task also has the ability to predict whether or not a sample meets the CDC's definition for extensively drug-resistant (XDR) Shigella. </p> <p>CDC defines XDR Shigella bacteria as strains that are resistant to all commonly recommended empiric and alternative antibiotics \u2014 azithromycin, ciprofloxacin, ceftriaxone, trimethoprim-sulfamethoxazole (TMP-SMX), and ampicillin. See also the Increase in Extensively Drug-Resistance Shigellosis in the United State CDC Health Network Alert where this definition can be found.</p> Criteria for XDR Shigella Prediction <p>A sample is required to meet all 7 criteria in order to be predicted as <code>XDR Shigella</code> </p> <ol> <li>The GAMBIT task in the workflow must identify the sample as <code>Shigella</code> OR the user must input the word <code>Shigella</code> somewhere within the input String variable called <code>expected_taxon</code>. This requirement serves as the identification of a sample to be of the Shigella genus.</li> <li>Resfinder or PointFinder predicted resistance to Ampicillin</li> <li>Resfinder or PointFinder predicted resistance to Azithromycin</li> <li>Resfinder or PointFinder predicted resistance to Ciprofloxacin</li> <li>Resfinder or PointFinder predicted resistance to Ceftriazone</li> <li>Resfinder or PointFinder predicted resistance to Trimethoprim</li> <li>Resfinder or PointFinder predicted resistance to Sulfamethoxazole</li> </ol> <p>There are 3 potential outputs for the <code>resfinder_predicted_xdr_shigella</code> output string:</p> <ul> <li><code>Not Shigella based on gambit_predicted_taxon or user input</code></li> <li><code>Not XDR Shigella</code>\u00a0for samples identified as Shigella by GAMBIT or user input BUT does ResFinder did not predict resistance to all 6 drugs in XDR definition</li> <li><code>XDR Shigella</code>\u00a0meaning the sample was identified as Shigella and ResFinder/PointFinder did predict resistance to ceftriazone, azithromycin, ciprofloxacin, trimethoprim, sulfamethoxazole, and ampicillin.</li> </ul> <p>ResFinder Technical Details</p> Links Task task_resfinder.wdl Software Source Code ResFinder Tool on BitBucketResFinder Database on BitBucketPointFinder Database on BitBucket Software Documentation ResFinder on BitBucket Original Publication(s) ResFinder tool: ResFinder 4.0 for predictions of phenotypes from genotypesResFinder database: Identification of acquired antimicrobial resistance genes <code>GAMMA</code>: AMR Genotyping (optional) <p>To activate this task, set <code>call_gamma</code> to <code>true</code>.</p> <p>GAMMA (Gene Allele Mutation Microbial Assessment) is a protein identity based tool that identifies gene matches in microbial genomic data. GAMMA will also translate and annotate each match providing mutational and truncation information for identified matches. This is done much like AMRFinder, however, GAMMA uses BLAT as opposed to BLAST allowing for faster calls with comparable accuracy.  </p> <p>GAMMA utilizes a multifasta database of the coding sequences of genes specified by the user. This allows for GAMMA to search for AMR, hypervirulence, plasmid markers, or any prokaryotic database. The default for <code>task_gamma.wdl</code> is the GAMMA-provided ResFinder Database. GAMMA will then return gene matches with mutation and truncation information as a <code>.gamma</code> file which can be accompanied with a GFF output utilizing the <code>--gff</code> flag.</p> <p>GAMMA also allows for the usage of only nucleotide sequences rather than translated sequences. Using GAMMA-S, enabled with the boolean <code>run_gammas</code>, will find the best matches from a multifasta database without translating sequences. </p> <p>GAMMA Technical Details</p> Links Task task_gamma.wdl Software Source Code GAMMA on GitHub Software Documentation GAMMA on GitHub Original Publication(s) GAMMA: a tool for the rapid identification, classification and annotation of translated gene matches from sequencing data <code>ABRicate</code>: AMR Genotyping (optional) <p>To activate this task, set <code>call_abricate</code> to <code>true</code>.</p> <p>The <code>abricate</code> module, if enabled, will run ABRicate with the database defined in <code>abricate_db</code> to perform mass screening of contigs for antimicrobial resistance or virulence genes. It comes bundled with multiple databases: NCBI, CARD, ARG-ANNOT, Resfinder, MEGARES, EcOH, PlasmidFinder, Ecoli_VF and VFDB. It only detects acquired resistance genes,\u00a0NOT\u00a0point mutations.</p> <p>By default, the \"vfdb\" database is used. The virulence factor database (VFDB) is a comprehensive resource for bacterial pathogen virulence factors.</p> <p>ABRicate Technical Details</p> Links Task task_abricate.wdl Software Source Code VFDB DatabaseABRicate on GitHub Software Documentation VFDB DatabaseABRicate on GitHub Original Publication(s) VFDB database: VFDB 2019: a comparative pathogenomic platform with an interactive web interface <code>amr_search</code>: Antimicrobial Resistance Profiling (optional) <p>To activate this task, set <code>run_amr_search</code> to be <code>true</code>.</p> <p>This task performs in silico antimicrobial resistance (AMR) profiling for supported species using AMRsearch, the primary tool used by Pathogenwatch to genotype and infer antimicrobial resistance (AMR) phenotypes from assembled microbial genomes.</p> <p>AMRsearch screens against Pathogenwatch's library of curated genotypes and inferred phenotypes, developed in collaboration with community experts. Resistance phenotypes are determined based on both resistance genes and mutations, and the system accounts for interactions between multiple SNPs, genes, and suppressors. Predictions follow S/I/R classification (Sensitive, Intermediate, Resistant).</p> <p>Currently, only a subset of species are supported by this task.</p> Supported Species <p>The following table shows the species name and the associated NCBI Code. If you are running AMR Search as part of TheiaProk and TheiaEuk, these codes will be automatically determined based on the GAMBIT predicted taxon, or the user-provided <code>expected_taxon</code> input.</p> Species NCBI Code Neisseria gonorrhoeae 485 Staphylococcus aureus 1280 Salmonella Typhi 90370 Streptococcus pneumoniae 1313 Klebisiella 570 Escherichia 561 Mycobacterium tuberculosis 1773 Candida auris 498019 Vibrio cholerae 666 Campylobacter 194 <p>Outputs:</p> <ul> <li>JSON Output: Contains the complete AMR profile, including detailed resistance state, detected resistance genes/mutations, and supporting BLAST results.</li> <li>CSV &amp; PDF Tables: An incorporated Python script, <code>parse_amr_json.py</code>, extracts and formats results into a CSV file and PDF summary table for easier visualization.</li> </ul> <p>amr_search Technical Details</p> Links Task task_amr_search.wdl Software Source Code AMRsearch on GitHub Software Documentation AMRsearch on GitHub Original Publication(s) PAARSNP: rapid genotypic resistance prediction for Neisseria gonorrhoeae"},{"location":"workflows/genomic_characterization/theiaprok/#sequence-type","title":"Sequence Type","text":"<code>TS_MLST</code>: MLST Profiling <p>Multilocus sequence typing (MLST) is a typing method reflecting population structure. It was developed as a portable, unambiguous method for global epidemiology using PCR, but can be applied to whole-genome sequences in silico. MLST is commonly used for pathogen surveillance, ruling out transmission, and grouping related genomes for comparative analysis.</p> <p>TheiaProk uses the MLST tool developed by Torsten Seeman to assess MLST using traditional PubMLST typing schemes. </p> <p>MLST schemes are taxa-specific. Each scheme uses fragments of typically 7 housekeeping genes (\"loci\") and has a database associating an arbitrary number with each distinct allele of each locus. Each unique combination of alleles (\"allelic profile\") is assigned a numbered sequence type (ST). Significant diversification of genomes is captured by changes to the MLST loci via mutational events creating new alleles and STs, or recombinational events replacing the allele and changing the ST. Relationships between STs are based on the number of alleles they share. Clonal complexes share a scheme-specific number of alleles (usually for five of the seven loci).</p> <p>MLST Limitations</p> <p>Some taxa have multiple MLST schemes, and some MLST schemes are insufficiently robust.</p> Interpretation of MLST results <p>Each MLST results file returns the ST and allele results for one sample. If the alleles and ST are correctly assigned, only a single integer value will be present for each. If an ST cannot be assigned, multiple integers or additional characters will be shown, representing the issues with assignment as described here.</p> Identifying novel alleles and STs <p>The MLST schemes used in TheiaProk are curated on the PubMLST website.If you identify novel alleles or allelic profiles in your data using TheiaProk's MLST task, you can get these assigned via PubMLST:</p> <ol> <li>Check that the novel allele or ST has not already been assigned a type on PubMLST. <ol> <li>Download the assembly file from Terra for your sample with the novel allele or ST</li> <li>Go to the PubMLST webpage for the organism of interest </li> <li>Navigate to the organism \"Typing\" page</li> <li>Under \"Query a sequence\" choose \"Single sequence\" (e.g., this is the page for H. influenzae), select the MLST scheme under \"Please select locus/scheme\", upload the assembly fasta file, and click submit</li> <li>Results will be returned lower on the page</li> </ol> </li> <li>If the allele or ST has not been typed previously on the PubMLST website (step 1), new allele or ST numbers can be assigned using the instructions provided by pubMLST.</li> </ol> Taxa with multiple MLST schemes <p>By default, the MLST tool automatically detects the genome's taxa to select the MLST scheme. Users may specify a desired scheme using the <code>scheme</code> variable of the <code>ts_mlst</code> task. Available schemes are listed here and the scheme name should be provided in quotation marks (\"...\").</p> <p>Some taxa have multiple MLST schemes, e.g. the Escherichia and Leptospira genera,  Acinetobacter baumannii, Clostridium difficile, and Streptococcus thermophilus. Only one scheme will be used by default. This can be changed for Escherichia and A. baumannii by setting the <code>ts_mlst run_secondary_scheme</code> variable to <code>true</code>. This will cause MLST to run the other scheme associated with those organisms and output those results in addition to the default scheme.</p> <p>For E. coli, the user may set <code>ts_mlst scheme_override</code> to be <code>true</code> to prevent running E. coli samples through the \"aeromonas\", \"cfreundii\", and \"senterica\" schemes, which can be common mischaracterizations.</p> <p>TS_MLST Technical Details</p> Links Task task_ts_mlst.wdl Software Source Code mlst on GitHub Software Documentation mlst on GitHub Original Publication(s) PubMLST database: Open-access bacterial population genomics: BIGSdb software, the PubMLST.org website and their applications"},{"location":"workflows/genomic_characterization/theiaprok/#assembly-annotation","title":"Assembly Annotation","text":"<p>By default, <code>genome_annotation</code> is set to <code>\"prokka\"</code>. To use <code>bakta</code> instead, set <code>genome_annotation</code> to <code>\"bakta\"</code>. These tools are mutually exclusive.</p> <code>Prokka</code>: Assembly Annotation (default) <p>Assembly annotation is available via <code>Prokka</code> as default.</p> <p><code>Prokka</code> is a prokaryotic genome annotation tool used to identify and describe features of interest within the genome sequence. Prokka annotates the genome by querying three core databases: ISfinder, NCBI's Bacterial Antimicrobial Resistance Reference Gene Database, and UniProtKB (SwissProt). Additional databases can be used or specified, with instructions on how to do so located in the Prokka README.</p> <p>The most versatile output from Prokka is likely the GFF3 file, as it contains all of the generated information, though other file formats are available for the instances when a reduction of the GFF3 is useful.</p> <p>Prokka Technical Details</p> Links Task task_prokka.wdl Software Source Code Prokka on GitHub Software Documentation Prokka on GitHub Original Publication(s) Prokka: rapid prokaryotic genome annotation <code>Bakta</code>: Assembly Annotation (alternative) <p>To activate this task, set <code>genome_annotation</code> to <code>\"bakta\"</code>.</p> <p><code>Bakta</code> is intended for the annotation of bacterial genomes and plasmids and is used to identify and describe regions of interest within the genome.</p> <p>In addition to the standard annotation outputs, <code>Bakta</code> also provides a plot summarizing the annotation results, which can be useful for visualizing genome features.</p> <p>Bakta Database Options</p> <p>Our implementation of <code>Bakta</code> supports three database configurations:</p> <ul> <li>Light: Optimized for faster performance and lower resource usage, with a focused set of core reference data for most bacterial genome annotations. Recommended for quick annotations or limited computational resources. Specify \"light\" for the <code>bakta_db</code> input.</li> <li>Full (default): Comprehensive with extensive reference annotations, suitable for detailed and accurate annotations. Specify \"full\" for the <code>bakta_db</code> input.</li> <li>Custom: Allows users to provide a Bakta-compatible database stored in Google Cloud Storage Bucket. This file must be a .tar.gz archive containing a properly formatted Bakta database with a valid version.json. Please see the Bakta database documentation for detailed formatting requirements. Example: <code>\"bakta_db\": \"gs://my-bucket/custom_bakta_db.tar.gz\"</code></li> </ul> <p>Bakta Technical Details</p> Links Task task_bakta.wdl Software Source Code Bakta on GitHub Software Documentation Bakta on GitHub Original Publication(s) Bakta: rapid and standardized annotation of bacterial genomes via alignment-free sequence identification"},{"location":"workflows/genomic_characterization/theiaprok/#plasmid-identification","title":"Plasmid Identification","text":"<code>PlasmidFinder</code>: Plasmid Identification (optional) <p>To activate this task, set <code>call_plasmidfinder</code> to <code>true</code>.</p> <p><code>PlasmidFinder</code>, from the Center for Genomic Epidemiology, detects plasmids in total or partially sequenced genomes and identifies the closest plasmid type in the database for typing purposes.</p> What are plasmids? <p>Plasmids are double-stranded circular or linear DNA molecules that are capable of replication independently of the chromosome and may be transferred between different species and clones. Many plasmids contain resistance or virulence genes, though some do not clearly confer an advantage to their host bacterium.</p> <p>PlasmidFinder Technical Details</p> Links Task task_plasmidfinder.wdl Software Source Code PlasmidFinder Tool on BitBucketPlasmidFinder Database on BitBucket Software Documentation PlasmidFinder on BitBucket Original Publication(s) In Silico Detection and Typing of Plasmids using PlasmidFinder and Plasmid Multilocus Sequence Typing"},{"location":"workflows/genomic_characterization/theiaprok/#taxa-specific-tasks","title":"Taxa-Specific Tasks","text":"<p>The TheiaProk workflows automatically activate taxa-specific sub-workflows after the identification of relevant taxa using <code>GAMBIT</code>. Alternatively, the user can provide the expected taxa in the <code>expected_taxon</code> workflow input to override the taxonomic assignment made by GAMBIT. Modules are launched for all TheiaProk workflows unless otherwise indicated.</p> <p>Please note that some modules require specific input data that may render it incompatible with every workflow. For example, ShigaTyper (a Shigella/EIEC serotyping tool) is not available for TheiaProk_FASTA as it requires read data as input. We have made a note next to each module to indicate which workflows are compatible with the module if there are restrictions.</p> <code>Taxon Tables</code>: Copy outputs to new data tables based on taxonomic assignment (optional) <p>This task is incompatible when running TheiaProk on the command-line as it is geared specifically for Terra. Do not activate this task if you are a command-line user.</p> <p>Activate this task by providing a value for the <code>taxon_tables</code> input variable. If provided, the user must also provide values to the <code>terra_project</code> and <code>terra_workspace</code> optional input variables.</p> <p>The <code>taxon_tables</code> module, if enabled, will copy sample data to a different data table based on the taxonomic assignment. For example, if an E. coli sample is analyzed, the module will copy the sample data to a new table for E. coli samples or add the sample data to an existing table.</p> <p>To activate the <code>taxon_tables</code> module, provide a file indicating data table names to copy samples of each taxa to in the <code>taxon_tables</code> input variable.</p> <p>Formatting the <code>taxon_tables</code> file</p> <p>The <code>taxon_tables</code>  file must be uploaded a Google storage bucket that is accessible by Terra and should be in the format below. Briefly, the bacterial genera or species should be listed in the leftmost column with the name of the data table to copy samples of that taxon to in the rightmost column.</p> taxon taxon_table Listeria_monocytogenes lmonocytogenes_specimen Salmonella salmonella_specimen Escherichia ecoli_specimen Shigella shigella_specimen Streptococcus strep_pneumo_specimen Legionella legionella_specimen Klebsiella klebsiella_specimen Mycobacterium mycobacterium_specimen Acinetobacter acinetobacter_specimen Pseudomonas pseudomonas_specimen Staphylococcus staphyloccus_specimen Neisseria neisseria_specimen <p>There are no output columns for the taxon table task. The only output of the task is that additional data tables will appear for in the Terra workspace for samples matching a taxa in the <code>taxon_tables</code> file.</p> <p><code>export_taxon_table</code> Technical Details</p> Links Task task_export_taxon_table.wdl Acinetobacter baumannii Escherichia or Shigella spp. Haemophilus influenzae Klebsiella spp. Legionella pneumophila Listeria monocytogenes Mycobacterium tuberculosis Neisseria spp. Pseudomonas aeruginosa Salmonella spp. Staphyloccocus aureus Streptococcus pneumoniae Streptococcus pyogenes Vibrio spp."},{"location":"workflows/genomic_characterization/theiaprok/#acinetobacter-baumannii","title":"Acinetobacter baumannii","text":"<code>Kaptive</code>: Capsule and Lipooligosaccharide Outer Core Typing <p>The cell-surface capsular polysaccharide (CPS) of Acinetobacter baumannii can be used as an epidemiological marker. CPS varies in its composition and structure and is a key determinant in virulence and a target for non-antibiotic therapeutics. Specificity for non-antibiotic therapeutics (e.g. phage therapy) bear particular significance given the extent of antibiotic resistance found in this ESKAPE pathogen. </p> <p>Biosynthesis and export of CPS is encoded by genes clustering at the K locus (KL). Additional genes associated with CPS biosynthesis and export are sometimes found in other chromosomal locations. The full combination of these genes is summarized as a \"K type\", described as a \"predicted serotype associated with the best match locus\". You can read more about this in the Kaptive Wiki.</p> <p>Previously, serotyping of A. baumannii focused on a major immunogenic polysaccharide which was considered the O antigen for the species. This serotyping approach appears to no longer be used and the serotyping scheme has not been updated in over 20 years. Nonetheless, the O-antigen polysaccharide is attached to lipooligosaccharide, and the outer core (OC) of this lipooligosaccharide varies. Biosynthesis of the outer core lipooligosaccharide is encoded by a cluster of genes at the outer core (OC) locus.</p> <p>Variation in the KL and OCL can be characterized with the Kaptive tool and its associated databases of numbered A. baumannii K and OC locus variants. Kaptive takes in a genome assembly file (fasta), and assigns the K and OC locus to their numbered variants, provides a K type, and a description of genes in the K or OC loci and elsewhere in the chromosome, alongside metrics for quality of locus match. A description of how Kaptive works, explanations of the full output reports, and resources for interpreting outputs are available on the Kaptive Wiki page.</p> <p>Kaptive Technical Details</p> Links Task task_kaptive.wdl Software Source Code Kaptive on GitHub Software Documentation Kaptive on GitHub Orginal Publication(s) Identification of Acinetobacter baumannii loci for capsular polysaccharide (KL) and lipooligosaccharide outer core (OCL) synthesis in genome assemblies using curated reference databases compatible with KaptiveAn update to the database for Acinetobacter baumannii capsular polysaccharide locus typing extends the extensive and diverse repertoire of genes found at and outside the K locus <code>abricate_abaum</code>: Plasmid Identification <p>Acinetobacter plasmids are not included in the PlasmidFinder database (see the above section on Plasmid Identification). Instead, the AcinetobacterPlasmidTyping database contains variants of the plasmid rep gene for A. baumannii plasmid identification. When matched with &gt;/= 95 % identity, this represents a typing scheme for Acinetobacter baumannii plasmids.</p> <p>The bioinformatics software for querying sample assemblies against the AcinetobacterPlasmidTyping database is ABRicate. By default, a 95% minimum identity threshold is set in order for successful classification.</p> <p>abricate_abaum Technical Details</p> Links Task task_abricate.wdl Software Source Code AcinetobacterPlasmidTyping Database on GitHubABRicate on GitHub Software Documentation AcinetobacterPlasmidTyping Database on GitHubABRicate on GitHub Original Publication(s) AcinetobacterPlasmidTyping database: Detection and Typing of Plasmids in\u00a0Acinetobacter baumannii\u00a0Using\u00a0rep\u00a0Genes Encoding Replication Initiation Proteins"},{"location":"workflows/genomic_characterization/theiaprok/#escherichia-or-shigella","title":"Escherichia or Shigella spp.","text":"<p>The Escherichia and Shigella genera are difficult to differentiate as they do not comply with genomic definitions of genera and species. Consequently, when either Escherichia or Shigella are identified by GAMBIT, all tools intended for these taxa are used. </p> <p><code>SerotypeFinder</code> and <code>ECTyper</code> are intended for analysis of E. coli. Both tools are used as there are occasional discrepancies between the serotypes predicted. This primarily arises due to differences in the databases used by each tool.</p> <code>SerotypeFinder</code>: Serotyping <p>SerotypeFinder, from the Centre for Genomic Epidemiology (CGE), identifies the serotype of total or partially-sequenced isolates of E. coli. By using BLAST and KMA, the SerotypeFinder database of specific O-antigen processing system genes (for O typing) and flagellin genes (for H typing) is queried and compared against the target sequence to identify the closest serotype.</p> <p>SerotypeFinder Technical Details</p> Links Task task_serotypefinder.wdl Software Source Code SerotypeFinder on BitBucketSerotypeFinder Database on BitBucket Software Documentation SerotypeFinder on BitBucket Original Publication(s) Rapid and Easy In Silico Serotyping of Escherichia coli Isolates by Use of Whole-Genome Sequencing Data <code>ECTyper</code>: Serotyping <p>ECTyper is a serotyping module for E. coli. ECTyper provides species identification and quality control for E. coli, allowing for complete reports on serotyping, Shiga toxin typing, and pathotyping. Pathotype is identified using an ECTyper internal typing database that looks at toxin and pathotype signature marker sequences. Pathotypes are distinct categories defined by specific virulence factors used to group E. coli specimens based on pathogenicity. </p> <p>ECTyper Technical Details</p> Links Task task_ectyper.wdl Software Source Code ECTyper on GitHub Software Documentation ECTyper on GitHub Orginal publication ECTyper: in silico Escherichia coli serotype and species prediction from raw and assembled whole-genome sequence data <p><code>VirulenceFinder</code> identifies virulence genes in total or partial sequenced isolates of bacteria. Currently, only E. coli is supported in TheiaProk workflows. </p> <code>VirulenceFinder</code>: Virulence Gene Identification <p>VirulenceFinder, from the Center for Genomic Epidemiology (GCE) in TheiaProk is only run on assembly files due to issues regarding discordant results when using read files on the web application versus the command-line. VirulenceFinder uses BLAST and KMA to query against a database of virulence genes in E. coli to identify any virulence factors in the sample.</p> <p>VirulenceFinder Technical Details</p> Links Task task_virulencefinder.wdl Software Source Code VirulenceFinder on BitBucketVirulenceFinder Database on BitBucket Software Documentation VirulenceFinder on BitBucketVirulenceFinder Database on BitBucket Original Publication(s) Real-time whole-genome sequencing for routine typing, surveillance, and outbreak detection of verotoxigenic Escherichia coli <p><code>ShigaTyper</code> and <code>ShigEiFinder</code> are intended for differentiation and serotype prediction for any Shigella species and Enteroinvasive Escherichia coli (EIEC). You can read about differences between these here and here. ShigEiFinder can be run using either the assembly (default) or reads. These tasks will report if the samples are neither Shigella nor EIEC.</p> <code>ShigaTyper</code>: Shigella/EIEC differentiation and serotyping for Illumina and ONT only <p>ShigaTyper predicts Shigella spp. serotypes from Illumina or ONT read data. If the genome is not Shigella or enteroinvasive E. coli (EIEC), the results from this tool will state this. In the notes it provides, it also reports on the presence of ipaB  which is suggestive of the presence of the \"virulent invasion plasmid\".</p> <p>ShigaTyper works by mapping the sample sequence to a Shigella reference sequence database using minimap2. Specifically, serotype prediction is made through the serotype-specific wzx gene as O-antigen expression is dependent on this gene. Additional criteria are applied if the serotype could not be solely predicted by this gene; please see the publication for more details.</p> <p>ShigaTyper Technical Details</p> Links Task task_shigatyper.wdl Software Source Code ShigaTyper on GitHub Software Documentation ShigaTyper on GitHub Original Publication(s) In Silico Serotyping Based on Whole-Genome Sequencing Improves the Accuracy of Shigella Identification <code>ShigEiFinder</code>: Shigella/EIEC Differentiation and Serotyping using the assembly file as input <p>ShigEiFinder differentiates\u00a0Shigella and enteroinvasive E. coli (EIEC) using cluster-specific genes, identifies some serotypes based on the presence of O-antigen and H-antigen genes (wzx and wzy), and predicts the number of virulence plasmids. It can serotype over 59 Shigella and 22 EIEC serotypes using BLAST and BWA.</p> <p>ShigEiFinder Technical Details</p> Links Task task_shigeifinder.wdl Software Source Code ShigEiFinder on GitHub Software Documentation ShigEiFinder on GitHub Original Publication(s) Cluster-specific gene markers enhance Shigella and enteroinvasive Escherichia coli in silico serotyping <code>ShigEiFinder_reads</code>: Shigella/EIEC Differentiation and Serotyping using Illumina read files as input (optional) <p>To activate the <code>shigeifinder_reads</code> task, set the <code>call_shigeifinder_reads_input</code> to be <code>true</code>. If set to <code>true</code>, <code>shigeifinder_reads</code> will run in addition to the assembly-based <code>shigeifinder</code> task.</p> <p>ShigEiFinder differentiates\u00a0Shigella and enteroinvasive E. coli (EIEC) using cluster-specific genes, identifies some serotypes based on the presence of O-antigen and H-antigen genes (wzx and wzy), and predicts the number of virulence plasmids. It can serotype over 59 Shigella and 22 EIEC serotypes using BLAST and BWA.</p> <p>ShigEiFinder Technical Details</p> Links Task task_shigeifinder.wdl Software Source Code ShigEiFinder on GitHub Software Documentation ShigEiFinder on GitHub Original Publication(s) Cluster-specific gene markers enhance Shigella and enteroinvasive Escherichia coli in silico serotyping <p><code>SonneiTyper</code> is run only when GAMBIT predicts the S. sonnei species. This is the most common Shigella species in the United States.</p> <code>SonneiTyper</code>: Shigella sonnei identification, genotyping, and resistance mutation identification for Illumina and ONT data only <p>SonneiTyper identifies Shigella sonnei, and uses single-nucleotide variants for genotyping and prediction of quinolone resistance in gyrA (S83L, D87G, D87Y) and parC (S80I). Outputs are provided in a TSV format described here.</p> <p>SonneiTyper is a wrapper script around another tool, Mykrobe, that analyses the S. sonnei genomes using the S. sonnei-specific genotyping scheme. SonneiTyper parses the Mykrobe predict results and tabulates the results.</p> <p>SonneiTyper Technical Details</p> Links Task task_sonneityping.wdl Software Source Code Mykrobe on GitHubsonneityping on GitHub Software Documentation Mykrobe Wikisonneityping on GitHub Original Publication(s) Mykrobe tool: Antibiotic resistance prediction for Mycobacterium tuberculosis from genome sequence data with MykrobeS. sonnei genotyping scheme: Global population structure and genotyping framework for genomic surveillance of the major dysentery pathogen,\u00a0Shigella sonnei <p>Shigella XDR prediction. Please see the documentation section above for ResFinder for details regarding this taxa-specific analysis. </p> <code>StxTyper</code>: Identification and Typing of Shiga toxin (Stx) Genes using the assembly file as input <p>StxTyper screens bacterial genome assemblies for shiga toxin genes and subtypes them into known subtypes and also looks for novel subtypes in cases where the detected sequences diverge from the reference sequences.</p> <p>Shiga toxin is the main virulence factor of Shiga-toxin-producing E. coli (STEC), though these genes are also found in Shigella species as well as some other genera more rarely, such as Klebsiella. Please see this review paper that describes shiga toxins in great detail.</p> <p>Running StxTyper via the TheiaProk workflows</p> <p>The TheiaProk workflow will automatically run <code>stxtyper</code> on all E. coli and Shigella spp. samples, but the user can opt-in to running the tool on any sample by setting the optional input variable <code>call_stxtyper</code> to <code>true</code> when configuring the workflow.</p> <p>Generally, <code>stxtyper</code> looks for stxA and stxB subunits that compose a complete operon. The A subunit is longer (in amino acid length) than the B subunit. Stxtyper attempts to detect these, compare them to a database of known sequences, and type them based on amino acid composition.  There typing algorithm and rules defining how to type these genes &amp; operons will be described more completely in a publication that will be available in the future.</p> <p>The <code>stxtyper_report</code> output TSV is provided in this output format.</p> <p>This tool has been incorporated into v4.0.3 of AMRFinderPlus and runs behind-the-scenes when the user (or in this case, the TheiaProk workflow) provides the <code>amrfinder --organism Escherichia --plus</code> options.</p> <p>StxTyper Technical Details</p> Links Task task_stxtyper.wdl Software Source Code ncbi/stxtyper GitHub repository Software Documentation ncbi/stxtyper GitHub repository"},{"location":"workflows/genomic_characterization/theiaprok/#haemophilus-influenzae","title":"Haemophilus influenzae","text":"<code>hicap</code>: Serotyping <p><code>hicap</code> identifies the\u00a0cap\u00a0locus serotype in\u00a0Haemophilus influenzae\u00a0assemblies. As described in the <code>hicap</code> documentation:</p> <p>The\u00a0cap\u00a0locus of\u00a0H. influenzae\u00a0is categorised into 6 different groups based on serology (a-f). There are three functionally distinct regions of the\u00a0cap\u00a0locus, designated\u00a0<code>region I</code>,\u00a0<code>region II</code>, and\u00a0<code>region III</code>. Genes within\u00a0<code>region I</code>\u00a0(<code>bexABCD</code>) and\u00a0<code>region III</code>\u00a0(<code>hcsAB</code>) are associated with transport and post-translation modification. The\u00a0<code>region II</code>\u00a0genes encode serotype-specific proteins, with each serotype (a-f) having a distinct set of genes.\u00a0cap\u00a0loci are often subject to structural changes (e.g. duplication, deletion) making the process of\u00a0in silico\u00a0typing and characterisation of loci difficult.</p> <p>hicap Technical Details</p> Links Task task_hicap.wdl Software Source Code hicap on GitHub Software Documentation hicap on GitHub Original Publication(s) hicap: In Silico Serotyping of the Haemophilus influenzae Capsule Locus"},{"location":"workflows/genomic_characterization/theiaprok/#klebsiella","title":"Klebsiella spp.","text":"<code>Kleborate</code>: Species Identification, MLST, Serotyping, AMR and Virulence Characterization <p>Kleborate is a tool to identify the Klebsiella species, MLST sequence type, serotype, virulence factors (ICE_Kp_ and plasmid associated), and AMR genes and mutations. Serotyping is based on the capsular (K antigen) and lipopolysaccharide (LPS) (O antigen) genes. The acquired resistance genes identified by Kleborate can be found in the Kleborate documentation here, along with other useful information regarding all of Kleborate's modules.</p> <p><code>Kaptive</code> can be run as well by setting the optional input variable <code>kleborate_skip_kaptive</code> to <code>false</code> in order to recieve the K antigen and O antigen locus typing via wzi alleles.</p> <p>Kleborate Technical Details</p> Links Task task_kleborate.wdl Software Source Code Kleborate on GitHub Software Documentation Kleborate Documentation on ReadTheDocs Original publication A genomic surveillance framework and genotyping tool for Klebsiella pneumoniae and its related species complexIdentification of Klebsiella capsule synthesis loci from whole genome data"},{"location":"workflows/genomic_characterization/theiaprok/#legionella-pneumophila","title":"Legionella pneumophila","text":"<code>Legsta</code>: Sequence-based typing <p>Legsta performs a sequence-based typing (SBT) of Legionella pneumophila, with the intention of being used for outbreak investigations. This tool outputs the allele number for seven genes (flaA, pilE, asd, mip, mompS, proA, and neuA), and combines the identified alleles to determine the overall SBT of the sample. Over 2,794 SBTs are able to be identified using this tool. Alleles with no in silico products are denoted with <code>-</code>s and novel alleles are listed with <code>?</code>s.</p> <p>Legsta Technical Details</p> Links Task task_legsta.wdl Software Source Code Legsta on GitHub Software Documentation Legsta on GitHub"},{"location":"workflows/genomic_characterization/theiaprok/#listeria-monocytogenes","title":"Listeria monocytogenes","text":"<code>LisSero</code>: Serogroup Prediction <p>LisSero performs serogroup prediction for Listeria monocytogenes based on the presence or absence of five genes, lmo1118, lmo0737, ORF2110, ORF2819, and Prs. LisSero does not predict somatic (O) or flagellar (H) biosynthesis.</p> <p>LisSero uses BLAST to query the sample against a built-in database to determine the most likely serogroup. </p> Serogroup Decision Tree <p>The following decision tree is used to determine the serogroup for the sample. </p><pre><code>if not Prs:\n    stop\nelif lmo0737 and not (ORF2819 or ORF2110):\n    if lmo1118:\n        Serogroup 1/2c, 3c\n    else:\n        Serogroup 1/2a, 3a\nelif ORF2819 and not (lmo0737 or lmo1118):\n    if ORF2110:\n        Serogroup 4b, 4d, 4e\n    else:\n        Serogroup 1/2b, 3b, 7\nelif lmo0737 and ORF2819 and ORF2110:\n    Serogroup 4b, 4d, 4e*\nelse:\n    Nontypable\n</code></pre><p></p> <p>LisSero Technical Details</p> Links Task task_lissero.wdl Software Source Code LisSero on GitHub Software Documentation LisSero on GitHub"},{"location":"workflows/genomic_characterization/theiaprok/#mycobacterium-tuberculosis","title":"Mycobacterium tuberculosis","text":"<code>Clockwork</code>: Read Decontamination for Illumina PE only <p>Clockwork decontaminates paired-end Mycobacterium tuberculosis data by removing all non-TB reads. At a high level, the sample is processed by aligning the reads with BWA to the H37Rv reference genome, and retaining only reads that have been mapped. This greatly improves the quality of any called variants and ensures that any variants called by TBProfiler are of suitable reliability.</p> <p>Clockwork Technical Details</p> Links Task task_clockwork.wdl Software Source Code Clockwork on GitHub Software Documentation Clockwork Wiki Original Publication(s) Clockwork tool: Minos: variant adjudication and joint genotyping of cohorts of bacterial genome <code>TBProfiler</code>: Lineage and Drug Susceptibility Prediction for Illumina and ONT only <p>TBProfiler identifies Mycobacterium tuberculosis complex species, lineages, sub-lineages and drug resistance-associated mutations.</p> <p>TBProfiler aligns the input reads to the H37Rv (NC_000962.3/AL123456.3) reference genome with <code>bwa mem</code> (or <code>minimap2</code>) and then calls variants using <code>gatk</code> (default), though other options are available (<code>bcftools</code>, <code>freebayes</code>, <code>lofreq</code>, <code>pilon</code>). After mutations are called and filtered, they are compared against TBProfiler's database (TBDB).</p> <p>A number of outputs are made available from TBProfiler, all of which can be found in the summary results JSON file. Although the JSON file contains the most information, it is not very human readable, which is why the results CSV and TXT files have been made available to the user as outputs. TBProfiler is able to detect the identified lineage and any sublineages, determine the predicted type of drug resistance, a lists the genes that are associated with resistance, along with several other useful outputs.     </p> <p>TBProfiler Technical Details</p> Links Task task_tbprofiler.wdl Software Source Code TBProfiler on GitHub Software Documentation TBProfiler Docs on GitHub Original Publication(s) Integrating informatics tools and portable sequencing technology for rapid detection of resistance to anti-tuberculous drugs <code>tbp-parser</code>: Interpretation and Parsing of TBProfiler JSON outputs (optional) <p>To activate this task, set <code>call_tbp_parser</code> to <code>true</code></p> <p>tbp-parser was developed by Theiagen in partnership with the California Department of Public Health. This tool adds useful drug resistance interpretation by applying expert rules and organizing the outputs from TBProfiler. To understand this module and its functions, please examine the documentation for this tool. </p> <p>This tool generates reports that can be automatically imported into your local LIMS system and is highly customizable with additional quality control metrics and fine-tuning. It is highly recommended to read the associated documentation to understand the full capabilities and configuration options available.</p> <p>Please note that this tool has not been tested on ONT data and although it is available, result accuracy should be considered carefully.</p> <p>tbp-parser Technical Details</p> Links Task task_tbp_parser.wdl Software Source Code tbp-parser on GitHub Software Documentation tbp-parser Documentation"},{"location":"workflows/genomic_characterization/theiaprok/#neisseria","title":"Neisseria spp.","text":"<code>ngmaster</code>: Neisseria gonorrhoeae Sequence Typing <p>NG-MAST is currently the most widely used method for epidemiological surveillance of\u00a0Neisseria gonorrhoea. This tool is targeted at clinical and research microbiology laboratories that have performed WGS of\u00a0N. gonorrhoeae isolates and wish to understand the molecular context of their data in comparison to previously published epidemiological studies. As WGS becomes more routinely performed,\u00a0NGMASTER\u00a0has been developed to completely replace PCR-based NG-MAST, reducing time and labor costs.</p> <p>NG-STAR offers a standardized method of classifying seven well-characterized genes associated antimicrobial resistance in N. gonorrhoeae (penA, mtrR, porB, ponA, gyrA, parC and 23S rRNA) to three classes of antibiotics (cephalosporins, macrolides and fluoroquinolones).</p> <p>ngmaster combines two tools: NG-MAST (in silico multi-antigen sequencing typing) and NG-STAR (sequencing typing for antimicrobial resistance) and returns the results from both tools.</p> <p>ngmaster Technical Details</p> Links Task task_ngmaster.wdl Software Source Code ngmaster on GitHub Software Documentation ngmaster on GitHub Original Publication(s) NGMASTER: in silico multi-antigen sequence typing for Neisseria gonorrhoeae <code>meningotype</code>: Neisseria meningitidis Serotyping <p>This tool performs in silico typing of N. meningitidis. It performs the following functions: serogrouping, finetyping of porA and fetA, porB sequencing typing, and Bexsero Antigen Sequencing Typing (BAST) (fHbp, NHBA, NadA, and PorA). These results are all parsed and provided to the user as outputs.</p> <p>The allele database is extracted from PubMLST's N. meningitidis database. This tool works by using BLAST to compare the sample sequence against the database entries.</p> <p>meningotype Technical Details</p> Links Task task_meningotype.wdl Software Source Code meningotype on GitHub Software Documentation meningotype on GitHub"},{"location":"workflows/genomic_characterization/theiaprok/#pseudomonas-aeruginosa","title":"Pseudomonas aeruginosa","text":"<code>pasty</code>: Serotyping <p><code>pasty</code> is a tool for in silico serogrouping of Pseudomonas aeruginosa isolates. <code>pasty</code> was developed by Robert Petit, based on the PAst tool from the Centre for Genomic Epidemiology.</p> <p><code>pasty</code> uses the <code>camlhmp</code> tool to identify the serogroup. It uses BLAST to compare an input asssembly against a set of O-antigens. The serogroup can be predicted based off of those results.</p> <p>pasty Technical Details</p> Links Task task_pasty.wdl Software Source Code pasty on GitHub Software Documentation pasty on GitHub Original Publication(s) Application of Whole-Genome Sequencing Data for O-Specific Antigen Analysis and In Silico Serotyping of Pseudomonas aeruginosa Isolates."},{"location":"workflows/genomic_characterization/theiaprok/#salmonella","title":"Salmonella spp.","text":"<p>Both SISTR and SeqSero2 are used for serotyping all Salmonella spp. Occasionally, the predicted serotypes may differ between SISTR and SeqSero2. When this occurs, differences are typically small and analogous, and are likely as a result of differing source databases. More information about Salmonella serovar nomenclature can be found here.</p> <code>SISTR</code>: Salmonella Serovar Prediction <p>SISTR performs Salmonella spp. serotype prediction using antigen gene and cgMLST gene alleles. In TheiaProk, SISTR is run on genome assemblies and uses the default database setting (which contains smaller \"centroid\" alleles or representative alleles instead of the full set of cgMLST alleles). The full set of cgMLST alleles can be activated by setting the <code>sistr_use_full_cgmlst_db</code> optional input variable to <code>true</code>. It also runs a QC module to determine the level of confidence in the serovar prediction (please see the section on QC in the SISTR documentation here).</p> <p>SISTR uses a database of Salmonella serovar determination antigens, cgMLST profiles, and MASH sketches of appropriate reference genomes. BLAST is used to compare input assemblies to this database for serotyping, and the Mash MinHash algorithm is used for serovar prediction.</p> <p>SISTR Technical Details</p> Links Task task_sistr.wdl Software Source Code SISTR on GitHub Software Documentation SISTR on GitHub Original Publication(s) The Salmonella In Silico Typing Resource (SISTR): an open web-accessible tool for rapidly typing and subtyping draft Salmonella genome assemblies. <code>SeqSero2</code>: Serotyping <p>SeqSero2 is a tool for Salmonella serotype prediction. In the TheiaProk Illumina workflows, SeqSero2 takes in raw sequencing reads and performs targeted assembly of serotype determinant alleles, which can be used to predict serotypes including contamination between serotypes. For the TheiaProk ONT and FASTA workflows, SeqSero2 uses the genome assembly as input.</p> <p>If reads are provided, SeqSero2 performs allele micro-assembly by default. This occurs through targeted assembly of serotype determinant alleles, and any assembled alleles are used to predict the sample's serotype, and can predict potential contamination. If the <code>seqsero2_mode</code> optional variable is changed to <code>\"k\"</code> (for k-mer mode), SeqSero2 will perform serotyping based on unique k-mers of serotype determinants. If the input data is an assembly FASTA, the k-mer mode must be used, and the genome assembly is used to generate the search k-mers instead of the raw reads. </p> <p>SeqSero2 Technical Details</p> Links Task task_seqsero2.wdl Software Source Code SeqSero2 Software Documentation SeqSero2 Original Publication(s) Salmonella serotype determination utilizing high-throughput genome sequencing data.SeqSero2: rapid and improved Salmonella serotype determination using whole genome sequencing data. <code>genotyphi</code>: Salmonella Typhi Characterization for Illumina and ONT only <p><code>genotyphi</code> is activated upon the identification of the \"Typhi\" serotype by SISTR or SeqSero2 (via either the <code>seqsero2_predicted_serotype</code>, or the <code>sistr_predicted_serotype</code>). <code>genotyphi</code> divides the Salmonella enterica serovar Typhi population into detailed lineages, clades, and subclades. It also detects mutations in the quinolone-resistance determining regions, acquired antimicrobial resistance genes, plasmid replicons, and subtypes of the IncHI1 plasmid which is associated with multidrug resistance.</p> <p>This task uses Mykrobe in order to perform k-mer based genotyping with a genotyping scheme specific to Salmonella Typhi, and then parses that output using the <code>genotyphi</code> tool. This scheme divides the Salmonella Typhi population into genotypes based on unique SNV markers.</p> <p>genotyphi Technical Details</p> Links Task task_genotyphi.wdl Software Source Code genotyphi on GitHub Software Documentation genotyphi on GitHub Orginal publication(s) An extended genotyping framework for Salmonella enterica serovar Typhi, the cause of human typhoidFive Years of GenoTyphi: Updates to the Global Salmonella Typhi Genotyping FrameworkTyphi Mykrobe: fast and accurate lineage identification and antimicrobial resistance genotyping directly from sequence reads for the typhoid fever agent Salmonella Typhi"},{"location":"workflows/genomic_characterization/theiaprok/#staphyloccocus-aureus","title":"Staphyloccocus aureus","text":"<code>spaTyper</code>: Sequence Typing <p>spaTyper works by identifying the number and order of repeats in the Staphylococcus protein A gene (also known as spa) of a S. aureus assembly. The repeats are assigned a numerical code that is used to assign a spa-type. The tool uses the Ridom SpaServer Database in order to assign the appropriate spa-type (please note that this link is typically considered unsafe by modern web browsers).</p> <p>Spa-types can be used for accurate and reliable typing of MRSA (methicillin-resistant Staphylococcus aureus) strains, and are often used in hospital infection control and epidemiological studies.</p> <p>spatyper Technical Details</p> Links Task task_spatyper.wdl Software Source Code spaTyper on GitHub Software Documentation spaTyper on GitHub Original Publication(s) Ridom SpaServer database: Typing of methicillin-resistant Staphylococcus aureus in a university hospital setting by using novel software for spa repeat determination and database management <code>staphopia-sccmec</code>: Sequence Typing <p>SCC_mec_ (staphylococcal cassette chromosome mec) is a mobile genetic element of Staphylococcus species. It includes a methicilin-resistant mecA gene that is shared between Staphylococcus strains via horizontal gene transfer, which leads to MRSA strains. SCC_mec_ has also been found to confer resistance to non-beta-lactam drugs as well, making it an important target for identifying antimicrobial resistance in Staphylococcus aureus.</p> <p>This tool assigns a SCC_mec_ type by using BLAST to compare the SCC_mec_ primers against the provided S. aureus assembly. <code>staphopia-sccmec</code> reports\u00a0<code>True</code> for exact primer matches and\u00a0<code>False</code> all others. The Hamming Distance is also used in TheiaProk's implementation of the tool to include the number of mismatches so that the <code>False</code> results can be examined in more detail.</p> <p>staphopia-sccmec Technical Details</p> Links Task task_staphopiasccmec.wdl Software Source Code staphopia-sccmec on GitHub Software Documentation staphopia-sccmec on GitHub Original Publication(s) Staphylococcus aureus viewed from the perspective of 40,000+ genomes <code>AgrVATE</code>: Sequence Typing <p>This tool identifies the accessory gene regulator (agr) locus type and reports possible variants in the agr operon. The agr system is a major regulator of virulence phenotypes in Staphylococcus aureus. Many S. aureus strains often have nonfunctional agr activity due to various loss-of-function mutations in the agr operon. This may be associated with increased disease severity, making its detection clinically significant.</p> <p>AgrVATE workings by using BLAST to compare a database of unique agr-group-specific k-mers against the provided assembly. The agr operon is then extracted using in-silico PCR computational methods. If an agr-group is assigned, variants are called using an Agr-group specific reference operon in order to detect possible non-functional agr. If the agr-group was untypeable, the sequence is searched for potential non-canonical agrD.</p> <p>AgrVATE Technical Details</p> Links Task task_agrvate.wdl Software Source Code AgrVATE on GitHub Software Documentation AgrVATE on GitHub Original Publication(s) Species-Wide Phylogenomics of the Staphylococcus aureus Agr Operon Revealed Convergent Evolution of Frameshift Mutations"},{"location":"workflows/genomic_characterization/theiaprok/#streptococcus-pneumoniae","title":"Streptococcus pneumoniae","text":"<code>PopPUNK</code>: Global Pneumococcal Sequence Cluster Typing <p>Global Pneumococcal Sequence Clusters (GPSC) define and name pneumococcal strains. Each GPSC is an international definition of a pneumococcal lineage and can capture all variations across the entire genome, leading to better vaccine development due to increased disease surveillance. GPSC designation is undertaken using the PopPUNK (Population Partitioning Using Nucleotide K-mers) software and the GPSC database.</p> <p>PopPUNK works by using variable-length k-mers to distinguish between sample divergences in shared genomic content. Clusters are assigned based on the resulting pairwise distance distributions. </p> <p>Interpreting GPSC results</p> <ul> <li>In the\u00a0<code>*_external_clusters.csv</code> novel clusters are assigned NA. For isolates that are assigned a novel cluster and pass QC, you can email\u00a0globalpneumoseq@gmail.com\u00a0to have these novel clusters added to the database.</li> <li>Unsampled diversity in the pneumococcal population may represent missing variation that links two GPS clusters. When this is discovered, GPSCs are merged and the merge history is indicated. For example, if GPSC23 and GPSC362 merged, the GPSC would be reported as GPSC23, with a merge history of GPSC23;362.</li> </ul> <p>PopPUNK Technical Details</p> Links Task task_poppunk_streppneumo.wdl Software Source Code PopPUNK on GitHubGlobal Pneumococcal Sequencing ProjectGPSC Database Software Documentation PopPUNK DocumentationGPS Training Documentation Original Publication(s) PopPUNK tool: Fast and flexible bacterial genomic epidemiology with PopPUNKGPSC database: International genomic definition of pneumococcal lineages, to contextualise disease, antibiotic resistance and vaccine impact <code>SeroBA</code>: Serotyping for Illumina_PE only <p>SeroBA is a k-mer based method for serotyping using the capsular polysaccharide biosynthesis (cps) locus of Streptococcus pneumoniae from paired-end sequencing data. This locus encodes the serotype and is a major virulence factor for the species. Identifying circulating serotypes is important to determine the epidemiological trends and vaccine impact.</p> <p>By adapting a database from PneumoCaT (Pneumococcal Capsular Typing), SeroBA uses KMC to generate a k-mer database and then uses a capsular type variant database and an ARIBA-compatible database that clusters all serotypes by serogroups. A k-mer analysis is performed and the serotype with the highest normalized sequence converage is selected. ARIBA then is used to build an assembly to confirm the selected serotype from the read data and aligns the cps sequence against a reference to identify variants.</p> <p>SeroBA Technical Details</p> Links Task task_seroba.wdl Software Source Code SeroBA on GitHub Software Documentation SeroBA on GitHub Original Publication(s) SeroBA: rapid high-throughput serotyping of Streptococcus pneumoniae from whole genome sequence data <code>PBPtyper</code>: Penicillin-Binding Protein Genotyping <p>The Penicillin-binding proteins (PBP) are responsible for the minimum inhibitory concentration (MIC) phenotypes for beta-lactam antibiotics, which are the drugs of choice for treating pneumococcal infections. In Streptococcus pneumoniae, these PBP genes (PBP1a, PBP2b, and PBP2x) can be identified and typed with PBPTyper to help predict beta-lactam resistance levels in S. pneumoniae, which can be invaluable in disease surveillance.</p> <p>pbptyper uses BLAST and average nucleotide identity (ANI) to identify the closest matching PBP types from a database of known PBP types and uses the PBP typing scheme described by the linked publication below.</p> <p>pbptyper Technical Details</p> Links Task task_pbptyper.wdl Software Source Code pbptyper on GitHub Software Documentation pbptyper on GitHub Original Publication(s) PBP typing method: Penicillin-Binding Protein Transpeptidase Signatures for Tracking and Predicting \u03b2-Lactam Resistance Levels in Streptococcus pneumoniae"},{"location":"workflows/genomic_characterization/theiaprok/#streptococcus-pyogenes","title":"Streptococcus pyogenes","text":"<code>emm-typing-tool</code>: Sequence Typing for Illumina_PE only <p>The Streptococcus pyogenes M protein (encoded by emm) is used for sequencing typing and disease surveillence as it is a major virulence factor. There are over 275 emm types.</p> <p><code>emm-typing-tool</code> maps the reads to a CDC-curated emm type database using bowtie2 to identify any emm genes. Alleles with 100% coverage and over 90% identity are selected, and the allele with the highest percent identity is generally reported (see the decision tree for the nuances).</p> <p>emm-typing-tool Technical Details</p> Links Task task_emmtypingtool.wdl Software Source Code emm-typing-tool on GitHub Software Documentation emm-typing-tool on GitHub Original Publication(s) emm typing scheme: A systematic and functional classification of Streptococcus pyogenes that serves as a new tool for molecular typing and vaccine development <code>emmtyper</code>: Sequence Typing <p>The Streptococcus pyogenes M protein (encoded by emm) is used for sequencing typing and disease surveillence as it is a major virulence factor. There are over 275 emm types.</p> <p><code>emmtyper</code> uses BLAST to compare the genome assembly to the CDC-curated trimmed emm type database (by default). An in silico PCR method is also available. The BLAST results are then processed to distinguish between emm and emm-like alleles to derive the isolates' M-type. The predicted emm-type is reported in addition to any possible emm-like alleles and the functional emm cluster.</p> <p>emm-typing-tool Technical Details</p> Links Task task_emmtyper.wdl Software Source Code emmtyper on GitHub Software Documentation emmtyper on GitHub Original Publication(s) emm typing scheme: A systematic and functional classification of Streptococcus pyogenes that serves as a new tool for molecular typing and vaccine development"},{"location":"workflows/genomic_characterization/theiaprok/#vibrio","title":"Vibrio spp.","text":"<code>abricate_vibrio</code>: Vibrio Characterization <p>The <code>abricate_vibrio</code> task is used to perform general characterization of Vibrio genomes using a database of target sequences that are traditionally used in PCR methods. The sequences included in the database are as follows:</p> Resistence Gene Database Sequence Name Sequence Role Purpose in Database toxR Transcriptional activator Species marker where presence identifies V. cholerae ompW Outer Membrane Protein Species marker where presence identifies V. cholerae ctxA Cholera toxin Indicates cholera toxin production tcpA_classical Toxin co-pilus A allele, associated with the Classical biotype Used to infer identity as Classical biotype tcpA_ElTor Toxin co-pilus A allele, associated with the El Tor biotype Used to infer identity as El Tor biotype wbeN O antigen encoding region Used to infer identity as O1 serogroup wbfR O antigen encoding region Used to infer identity as O139 serogroup <p>This database was developed via communication with Dr. Christine Lee, of the National Listeria, Yersinia, Vibrio and Enterobacterales Reference Laboratory within the Enteric Diseases Laboratory Branch at CDC. It is identical to the database used in the <code>srst2</code> task except it is formatted for ABRicate.</p> <p>This task works by using the ABRicate tool, which uses BLAST to compare the assembled genome to the target sequences in the database and then reporting the details of the genes that pass quality thresholds. The presence or absence of specific genes are used to verify the species, identify cholera toxin production, and designation both the biotype and serogroup of the sample. See the table above for the genes used for each of these purposes.</p> <p>abricate_vibrio Technical Details</p> Links Task task_abricate.wdl Software Source Code ABRicate on GitHub Software Documentation ABRicate on GitHub <code>SRST2</code>: Vibrio Characterization for Illumina only <p>SRST2 is used to perform general characterization of Vibrio genomes using a database of target sequences that are traditionally used in PCR methods. The sequences included in the database are as follows:</p> Resistance Gene Database Sequence Name Sequence Role Purpose in Database toxR Transcriptional activator Species marker where presence identifies V. cholerae ompW Outer Membrane Protein Species marker where presence identifies V. cholerae ctxA Cholera toxin Indicates cholera toxin production tcpA_classical Toxin co-pilus A allele, associated with the Classical biotype Used to infer identity as Classical biotype tcpA_ElTor Toxin co-pilus A allele, associated with the El Tor biotype Used to infer identity as El Tor biotype wbeN O antigen encoding region Used to infer identity as O1 serogroup wbfR O antigen encoding region Used to infer identity as O139 serogroup <p>This database was developed via communication with Dr. Christine Lee, of the National Listeria, Yersinia, Vibrio and Enterobacterales Reference Laboratory within the Enteric Diseases Laboratory Branch at CDC. It is identical to the database used in the <code>abricate_vibrio</code> task except it is formatted for SRST2.</p> <p>SRST2 works by mapping reads to the target sequences in the database and then reporting the details of all those genes that pass the quality thresholds. The presence or absence of specific genes are used to verify the species, identify cholera toxin production, and designation both the biotype and serogroup of the sample. See the table above for the genes used for each of these purposes.</p> <p>SRST2 Technical Details</p> Links Task task_srst2_vibrio.wdl Software Source Code srst2 on GitHub Software Documentation srst2 on GitHub Original Publication(s) SRST2: Rapid genomic surveillance for public health and hospital microbiology labs <code>Vibecheck</code>: O1 Vibrio  cholerae Lineage Classification for Illumina PE only <p>The <code>Vibecheck</code> task classifies O1 V. cholerae sequences into canonical lineages (T1-T17) using variant frequency demixing. The O1 designation is determined through the use of the SRST2 task.</p> <p>Vibecheck works by aligning the reads to an O1 V. cholerae reference genome, calling variants from the alignment, and estimating lineage abundances using Freyja by using a database built from canonical SNPs that define the known lineages.</p> <p>Vibecheck Technical Details</p> Links Task task_vibecheck_vibrio.wdl Software Source Code Vibecheck on GitHub Software Documentation Vibecheck on GitHub"},{"location":"workflows/genomic_characterization/theiaprok/#outputs","title":"Outputs","text":"TheiaProk_Illumina_PETheiaProk_Illumina_SETheiaProk_ONTTheiaProk_FASTA Variable Type Description abricate_abaum_database String Database of reference A. baumannii plasmid typing genes used for plasmid typing abricate_abaum_docker String Docker file used for running abricate abricate_abaum_plasmid_tsv File https://github.com/tseemann/abricate#output containing a row for each A. baumannii plasmid type gene found in the sample abricate_abaum_plasmid_type_genes String A. baumannii Plasmid typing genes found in the sample; from GENE column in https://github.com/tseemann/abricate#output abricate_abaum_version String Version of abricate used for A. baumannii plasmid typing abricate_database String Database of reference used with Abricate abricate_docker String Docker file used for running abricate abricate_genes String Genes found in the sample; from GENE column in https://github.com/tseemann/abricate#output abricate_results_tsv File https://github.com/tseemann/abricate#output containing a row for each gene found in the sample abricate_version String Version of abricate used for A. baumannii plasmid typing abricate_vibrio_biotype String Biotype classification according to tcpA gene sequence (Classical or ElTor) abricate_vibrio_ctxA String Presence or absence of the ctxA gene abricate_vibrio_database String Database to use while running abricate abricate_vibrio_detailed_tsv File Detailed ABRicate output file abricate_vibrio_docker String Docker file used for running abricate abricate_vibrio_ompW String Presence or absence of the ompW gene abricate_vibrio_serogroup String Serotype classification as O1 (wbeN gene), O139 (wbfR gene) or not detected. abricate_vibrio_toxR String Presence or absence of the toxR gene abricate_vibrio_version String The abricate version run agrvate_agr_canonical String Canonical or non-canonical agrD agrvate_agr_group String Agr group agrvate_agr_match_score String Match score for agr group agrvate_agr_multiple String If multiple agr groups were found agrvate_agr_num_frameshifts String Number of frameshifts found in CDS of extracted agr operon agrvate_docker String The docker used for AgrVATE agrvate_results File A gzipped tarball of all results agrvate_summary File The summary file produced agrvate_version String The version of AgrVATE used amr_search_csv File CSV formatted AMR profile amr_search_docker String Docker image used to run AMR_Search amr_search_results File JSON formatted AMR profile including BLAST results amr_search_results_pdf File PDF formatted AMR profile amr_search_version String Version of AMR_Search libraries used amrfinderplus_all_report File Output TSV file from AMRFinderPlus (described https://github.com/ncbi/amr/wiki/Running-AMRFinderPlus#fields) amrfinderplus_amr_betalactam_betalactam_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to beta-lactams amrfinderplus_amr_betalactam_carbapenem_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to carbapenem amrfinderplus_amr_betalactam_cephalosporin_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to cephalosporin amrfinderplus_amr_betalactam_cephalothin_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to cephalothin amrfinderplus_amr_betalactam_genes String Beta-lactam AMR genes identified by AMRFinderPlus amrfinderplus_amr_betalactam_methicillin_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to methicilin amrfinderplus_amr_classes String AMRFinderPlus predictions for classes of drugs that genes found in the reads are known to confer resistance to amrfinderplus_amr_core_genes String AMR genes identified by AMRFinderPlus where the scope is \"core\" amrfinderplus_amr_plus_genes String AMR genes identified by AMRFinderPlus where the scope is \"plus\" amrfinderplus_amr_report File TSV file detailing AMR genes only, from the amrfinderplus_all_report amrfinderplus_amr_subclasses String More specificity about the drugs that genes identified in the reads confer resistance to amrfinderplus_db_version String AMRFinderPlus database version used amrfinderplus_stress_genes String Stress genes identified by AMRFinderPlus amrfinderplus_stress_report File TSV file detailing stress genes only, from the amrfinderplus_all_report amrfinderplus_version String AMRFinderPlus version used amrfinderplus_virulence_genes String Virulence genes identified by AMRFinderPlus amrfinderplus_virulence_report File TSV file detailing virulence genes only, from the amrfinderplus_all_report ani_highest_percent Float Highest ANI between query and any given reference genome (top species match) ani_highest_percent_bases_aligned Float Percentage of bases aligned between query genome and top species match ani_mummer_docker String Docker image used to run the ANI_mummer task ani_mummer_version String Version of MUMmer used ani_output_tsv File Full output TSV from ani-m ani_top_species_match String Species of genome with highest ANI to query FASTA arln_assembly_ratio String Assembly ratio of the final assembly compared to the mean assembly length of the taxon. These stats are gathered from a statistics file created by the CDC aggregating NCBI assembly data by taxon. arln_assembly_zscore String ZScore of the samples assembly length to assess the uniformity of the assembly when compared to taxon means. arln_r1_q30_clean String Q30% of the cleaned R1 FASTQ arln_r1_q30_raw String Q30% of the raw R1 FASTQ arln_r2_q30_clean String Q30% of the cleaned R2 FASTQ arln_r2_q30_raw String Q30% of the raw R2 FASTQ arln_stats_docker_version String Docker version for task_arln_stats.wdl arln_taxon_assembly_ratio_stdev String Reported assembely length standard deviation of the given taxonomy pulled from NCBI aggregated data. arln_taxon_gc_mean String Mean GC percent of the taxon. arln_taxon_gc_percent_stdev String Reported GC percent standard deviation of the given taxonomy pulled from NCBI aggregated data. assembler String Assembler used in digger_denovo subworkflow assembler_version String Version of the assembler used in digger_denovo assembly_fasta File De novo genome assembly in FASTA format assembly_length Int Length of assembly (total contig length) as determined by QUAST bakta_gbff File Genomic GenBank format annotation file bakta_gff3 File Generic Feature Format Version 3 file bakta_plot File Bakta plot output PNG file summarizing annotated genome features such as coding sequences, RNA genes, and hypothetical proteins. bakta_summary File Bakta summary output TXT file bakta_tsv File Annotations as simple human readable TSV bakta_version String Bakta version used bbduk_docker String The Docker image for bbduk, which was used to remove the adapters from the sequences busco_database String BUSCO database used busco_docker String BUSCO docker image used busco_report File A plain text summary of the results in BUSCO notation busco_results String BUSCO results (see relevant toggle in this block) busco_version String BUSCO software version used cg_pipeline_docker String Docker file used for running CG-Pipeline on cleaned reads cg_pipeline_report_clean File TSV file of read metrics from clean reads, including average read length, number of reads, and estimated genome coverage cg_pipeline_report_raw File TSV file of read metrics from raw reads, including average read length, number of reads, and estimated genome coverage clockwork_decontaminated_read1 File Decontaminated forward reads by Clockwork clockwork_decontaminated_read2 File Decontaminated reverse reads by Clockwork combined_mean_q_clean Float Mean quality score for the combined clean reads combined_mean_q_raw Float Mean quality score for the combined raw reads combined_mean_readlength_clean Float Mean read length for the combined clean reads combined_mean_readlength_raw Float Mean read length for the combined raw reads contigs_gfa File Assembly graph output generated by SPAdes (Illumina: PE, SE) or Flye (ONT), used to visualize and evaluate genome assembly results. ectyper_database_version String Version of the ECTyper database used ectyper_pathodb_version String Version of the ECTyper pathotype database used ectyper_pathotype String Samples pathotype predicted by ECTyper ectyper_pathotype_count Int Number of pathotypes predicted by ECTyper ectyper_pathotype_genes String Pathotype genes observed by ECTyper ectyper_predicted_serotype String Serotype predicted by ECTyper ectyper_qc_result String QC pass or fail for the sample analyzed ectyper_results File TSV file of evidence for ECTyper predicted serotype (see https://github.com/phac-nml/ecoli_serotyping#report-format) ectyper_stx_subtypes String Shiga toxin subtypes predicted by ECTyper ectyper_version String Version of ECTyper used emmtyper_docker String Docker image for emmtyper emmtyper_emm_type String The emm-type of a Streptococcus pyogenes assembly emmtyper_results_tsv File TSV file with emmtyper results emmtyper_version String Version of emmtyper used emmtypingtool_docker String Docker image for emm-typing-tool emmtypingtool_emm_type String emm-type predicted emmtypingtool_results_xml File XML file with emm-typing-tool resuls emmtypingtool_version String Version of emm-typing-tool used est_coverage_clean Float Estimated coverage calculated from clean reads and genome length est_coverage_raw Float Estimated coverage calculated from raw reads and genome length fastp_html_report File The HTML report made with fastp fastp_version String The version of fastp used fastq_scan_clean1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about clean forward read quality and length fastq_scan_clean2_json File The JSON file output from <code>fastq-scan</code> containing summary stats about clean reverse read quality and length fastq_scan_num_reads_clean1 Int The number of forward reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_clean2 Int The number of reverse reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_clean_pairs String The number of read pairs after cleaning as calculated by fastq_scan fastq_scan_num_reads_raw1 Int The number of input forward reads as calculated by fastq_scan fastq_scan_num_reads_raw2 Int The number of input reserve reads as calculated by fastq_scan fastq_scan_num_reads_raw_pairs String The number of input read pairs as calculated by fastq_scan fastq_scan_raw1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about raw forward read quality and length fastq_scan_raw2_json File The JSON file output from <code>fastq-scan</code> containing summary stats about raw reverse read quality and length fastq_scan_version String The version of fastq_scan fastqc_clean1_html File An HTML file that provides a graphical visualization of clean forward read quality from fastqc to open in an internet browser fastqc_clean2_html File An HTML file that provides a graphical visualization of clean reverse read quality from fastqc to open in an internet browser fastqc_docker String The Docker container used for fastqc fastqc_num_reads_clean1 Int The number of forward reads after cleaning by fastqc fastqc_num_reads_clean2 Int The number of reverse reads after cleaning by fastqc fastqc_num_reads_clean_pairs String The number of read pairs after cleaning by fastqc fastqc_num_reads_raw1 Int The number of input forward reads by fastqc before cleaning fastqc_num_reads_raw2 Int The number of input reverse reads by fastqc before cleaning fastqc_num_reads_raw_pairs String The number of input read pairs by fastqc before cleaning fastqc_raw1_html File An HTML file that provides a graphical visualization of raw forward read quality from fastqc to open in an internet browser fastqc_raw2_html File An HTML file that provides a graphical visualization of raw reverse read quality from fastqc to open in an internet browser fastqc_version String Version of fastqc software used filtered_contigs_metrics File File containing metrics of contigs filtered gambit_closest_genomes File CSV file listing genomes in the GAMBIT database that are most similar to the query assembly gambit_db_version String Version of the GAMBIT database used gambit_docker String GAMBIT Docker used gambit_predicted_taxon String Taxon predicted by GAMBIT gambit_predicted_taxon_rank String Taxon rank of GAMBIT taxon prediction gambit_report File GAMBIT report in a machine-readable format gambit_version String Version of GAMBIT software used gamma_docker String The Docker container used gamma_fasta File The FASTA file reporting gene matches if boolean was set to true gamma_gff File The GFF file reporting gene matches if boolean was set to true gamma_results File The .gamma file reporting gene matches gamma_version String The version of GAMMA used genotyphi_final_genotype String Final genotype call from GenoTyphi genotyphi_genotype_confidence String Confidence in the final genotype call made by GenoTyphi genotyphi_mykrobe_json File JSON file of GenoTyphi output, described https://github.com/katholt/genotyphi#explanation-of-columns-in-the-output genotyphi_report_tsv File TSV file of GenoTyphi output, described https://github.com/katholt/genotyphi#explanation-of-columns-in-the-output genotyphi_species String Species call from Mykrobe, used to run GenoTyphi genotyphi_st_probes_percent_coverage Float Percentage coverage to the Typhi MLST probes genotyphi_version String Version of GenoTyphi used hicap_docker String Docker image used for hicap hicap_genes String cap genes identified. genes on different contigs delimited by;. truncation shown by trailing * hicap_results_tsv File TSV file of hicap output hicap_serotype String hicap serotype hicap_version String hicap version used kaptive_k_locus String Best matching K locus identified by Kaptive kaptive_k_type String Best matching K type identified by Kaptive kaptive_kl_confidence String Kaptive\u2019s confidence in the KL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kaptive_oc_locus String Best matching K locus identified by Kaptive kaptive_ocl_confidence String Kaptive\u2019s confidence in the OCL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kaptive_output_file_k File TSV https://github.com/katholt/Kaptive/wiki/How-to-run#output-filesfrom the K locus from Kaptive kaptive_output_file_oc File TSV https://github.com/katholt/Kaptive/wiki/How-to-run#output-filesfrom the OC locus from Kaptive kaptive_version String Version of Kaptive used kleborate_docker String Kleborate docker image used kleborate_genomic_resistance_mutations String Genomic resistance mutations identifies by Kleborate kleborate_key_resistance_genes String Key resistance genes identified by Kleborate kleborate_klocus String Best matching K locus identified by  Kleborate via Kaptive kleborate_klocus_confidence String Kaptive\u2019s confidence in the KL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kleborate_ktype String Best matching K type identified by  Kleborate via Kaptive kleborate_mlst_sequence_type String https://github.com/katholt/Kleborate/wiki/MLST#multi-locus-sequence-typing-mlst call by Kleborate kleborate_olocus String Best matching OC locus identified by  Kleborate via Kaptive kleborate_olocus_confidence String Kaptive\u2019s confidence in the KL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kleborate_otype String Best matching OC type identified by  Kleborate via Kaptive kleborate_output_file File See also https://github.com/katholt/Kleborate/wiki/Scores-and-counts kleborate_resistance_score String Resistance score as given by kleborate kleborate_version String Version of Kleborate used kleborate_virulence_score String Virulence score as given by kleborate kmerfinder_database String Database used to run KmerFinder kmerfinder_docker String Docker image used to run KmerFinder kmerfinder_query_coverage String KmerFinder\u2019s query coverage of the top hit result kmerfinder_results_tsv File Output TSV file created by KmerFinder kmerfinder_template_coverage String Percent of kmer coverage pertaining to the template, or reference selected kmerfinder_top_hit String Top hit species of KmerFinder kraken2_database String Kraken2 database used for the taxonomic assignment kraken2_report String TXT document describing taxonomic prediction of every FASTQ record. This file is usually very large and cumbersome to open and view kraken2_version String The version of kraken2 used kraken_docker String Docker image used for Kraken legsta_predicted_sbt String Sequence based type predicted by Legsta legsta_results File TSV file of legsta results (see https://github.com/tseemann/legsta#output) legsta_version String Version of legsta used lissero_results File TSV results file from LisSero (see https://github.com/MDU-PHL/LisSero#example-output) lissero_serotype String Serotype predicted by LisSero lissero_version String Version of LisSero used meningotype_BAST String BAST type meningotype_FetA String FetA type meningotype_NHBA String NHBA type meningotype_NadA String NBA type meningotype_PorA String PorA type meningotype_PorB String PorB type meningotype_fHbp String fHbp type meningotype_serogroup String Serogroup meningotype_tsv File Full result file meningotype_version String Version of meningotype used midas_docker String MIDAS docker image used midas_primary_genus String The primary genus detected by MIDAS midas_report File TSV report of full MIDAS results midas_secondary_genus String Genus of the next most abundant species after removing all species of the most abundant genus midas_secondary_genus_abundance Float Relative abundance of secondary genus midas_secondary_genus_coverage Float Absolute coverage of secondary genus n50_value Int N50 of assembly calculated by QUAST ngmaster_ngmast_porB_allele String porB allele number ngmaster_ngmast_sequence_type String NG-MAST sequence type ngmaster_ngmast_tbpB_allele String tbpB allele number ngmaster_ngstar_23S_allele String 23S rRNA allele number ngmaster_ngstar_gyrA_allele String gyrA allele number ngmaster_ngstar_mtrR_allele String mtrR allele number ngmaster_ngstar_parC_allele String parC allele number ngmaster_ngstar_penA_allele String penA allele number ngmaster_ngstar_ponA_allele String ponA allele number ngmaster_ngstar_porB_allele String porB allele number ngmaster_ngstar_sequence_type String NG-STAR sequence type ngmaster_tsv File TSV file with NG-MAST/NG-STAR typing ngmaster_version String ngmaster version number_contigs Int Total number of contigs in assembly pasty_all_serogroups File TSV file with details of each serogroup from pasty (see https://github.com/rpetit3/pasty#example-prefixdetailstsv) pasty_blast_hits File TSV file of BLAST hits from pasty (see https://github.com/rpetit3/pasty#example-prefixblastntsv) pasty_comment String pasty_docker String pasty docker image used pasty_serogroup String Serogroup predicted by pasty pasty_serogroup_coverage Float The breadth of coverage of the O-antigen by pasty pasty_serogroup_fragments Int Number of BLAST hits included in the prediction (fewer is better) pasty_summary_tsv File TSV summary file of pasty outputs (see https://github.com/rpetit3/pasty#example-prefixtsv) pasty_version String Version of pasty used pbptyper_docker String pbptyper docker image used pbptyper_pbptype_predicted_tsv File TSV file of pbptyper results (see https://github.com/rpetit3/pbptyper#example-prefixtsv) pbptyper_predicted_1A_2B_2X String PBP type predicted by pbptyper pbptyper_version String Version of pbptyper used plasmidfinder_db_version String Version of PlasmidFnder used plasmidfinder_docker String PlasmidFinder docker image used plasmidfinder_plasmids String Names of plasmids identified by PlasmidFinder plasmidfinder_results File Output file from PlasmidFinder in TSV format plasmidfinder_seqs File Hit_in_genome_seq.fsa file produced by PlasmidFinder poppunk_GPS_db_version String Version of GPSC database used poppunk_docker String PopPUNK docker image with GPSC database used poppunk_gps_cluster String GPS cluster predicted by PopPUNK poppunk_gps_external_cluster_csv File GPSC v6 scheme designations poppunk_version String Version of PopPUNK used prokka_gbk File GenBank file produced from Prokka annotation of input FASTA prokka_gff File Prokka output GFF3 file containing sequence and annotation (you can view this in IGV) prokka_sqn File A Sequin file for GenBank submission qc_check String A string that indicates whether or not the sample passes a set of pre-determined and user-provided QC thresholds qc_standard File The file used in the QC Check task containing the QC thresholds. quast_gc_percent Float The GC percent of your sample quast_report File TSV report from QUAST quast_version String The version of QUAST r1_mean_q_clean Float Mean quality score of clean forward reads r1_mean_q_raw Float Mean quality score of raw forward reads r1_mean_readlength_clean Float Mean read length of clean forward reads r1_mean_readlength_raw Float Mean read length of raw forward reads r2_mean_q_clean Float Mean quality score of clean reverse reads r2_mean_q_raw Float Mean quality score of raw reverse reads r2_mean_readlength_clean Float Mean read length of clean reverse reads r2_mean_readlength_raw Float Mean read length of raw reverse reads read1_clean File Forward read file after quality trimming and adapter removal read1_concatenated File Concatenated forward reads read2_clean File Reverse read file after quality trimming and adapter removal read2_concatenated File Concatenated reverse reads read_screen_clean String PASS or FAIL result from clean read screening; FAIL accompanied by the reason(s) for failure read_screen_clean_tsv File Clean read screening report TSV depicting read counts, total read base pairs, and estimated genome length read_screen_raw String PASS or FAIL result from raw read screening; FAIL accompanied by the reason(s) for failure read_screen_raw_tsv File Raw read screening report TSV depicting read counts, total read base pairs, and estimated genome length resfinder_db_version String Version of ResFinder database resfinder_docker String ResFinder docker image used resfinder_pheno_table File Table containing al AMR phenotypes resfinder_pheno_table_species File Table with species-specific AMR phenotypes resfinder_pointfinder_pheno_table File TSV showing presence(1)/absence(0) of predicted resistance against an antibiotic class resfinder_pointfinder_results File Predicted point mutations, grouped by the gene they occur in resfinder_predicted_pheno_resistance String Semicolon delimited list of antimicrobial drugs and associated genes and/or point mutations.\u00a0: , , ; : , ; resfinder_predicted_resistance_Amp String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Ampicillin based on resfinder phenotypic predictions resfinder_predicted_resistance_Axo String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Ceftriaxone based on resfinder phenotypic predictions resfinder_predicted_resistance_Azm String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Azithromycin based on resfinder phenotypic predictions resfinder_predicted_resistance_Cip String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Ciprofloxacin based on resfinder phenotypic predictions resfinder_predicted_resistance_Smx String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Sulfamethoxazole based on resfinder phenotypic predictions resfinder_predicted_resistance_Tmp String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Trimothoprim based on resfinder phenotypic predictions resfinder_predicted_xdr_shigella String Final prediction of XDR Shigella status based on CDC definition. Explanation can be found in the description above this table. resfinder_results File Predicted resistance genes grouped by antibiotic class resfinder_seqs File FASTA of resistance gene sequences from user\u2019s input sequence seq_platform String Description of the sequencing methodology used to generate the input read data seqsero2_note String Additional notes produced by SeqSero2 seqsero2_predicted_antigenic_profile String Antigenic profile predicted for Salmonella spp. by SeqSero2 seqsero2_predicted_contamination String Indicates whether contamination between Salmonella with different serotypes was predicted by SeqSero2 seqsero2_predicted_serotype String Serotype predicted by SeqSero2 seqsero2_report String TSV report produced by SeqSero2 seqsero2_version String Version of SeqSero2 used seroba_ariba_identity String Percentage identity between the query sequence and ARIBA-predicted serotype seroba_ariba_serotype String Serotype predicted by ARIBA, via SeroBA seroba_details File Detailed TSV file from SeroBA seroba_docker String SeroBA docker image used seroba_serotype String Serotype predicted by SeroBA seroba_version String SeroBA version used serotypefinder_docker String SerotypeFinder docker image used serotypefinder_report File TSV report produced by SerotypeFinder serotypefinder_serotype String Serotype predicted by SerotypeFinder shigatyper_docker String ShigaTyper docker image used shigatyper_hits_tsv File Detailed TSV report from ShigaTyper (see https://github.com/CFSAN-Biostatistics/shigatyper#example-prefix-hitstsv) shigatyper_ipaB_presence_absence String Presence (+) or absence (-) of ipaB identified by ShigaTyper shigatyper_notes String Any notes output from ShigaTyper shigatyper_predicted_serotype String Serotype predicted by ShigaTyper shigatyper_summary_tsv File TSV summary report from ShigaTyper (see https://github.com/CFSAN-Biostatistics/shigatyper#example-prefixtsv) shigatyper_version String Version of ShigaTyper used shigeifinder_H_antigen String H-antigen gene identified by ShigEiFinder shigeifinder_H_antigen_reads String H-antigen gene identified by ShigEiFinder using read files as inputs shigeifinder_O_antigen String O-antigen gene identified by ShigEiFinder shigeifinder_O_antigen_reads String O-antigen gene identified by ShigEiFinder using read files as inputs shigeifinder_cluster String Shigella/EIEC cluster identified by ShigEiFinder shigeifinder_cluster_reads String Shigella/EIEC cluster identified by ShigEiFinder using read files as inputs shigeifinder_docker String ShigEiFinder docker image used shigeifinder_docker_reads String ShigEiFinder docker image used using read files as inputs shigeifinder_ipaH_presence_absence String Presence (+) or absence (-) of ipaH identified by ShigEiFinder shigeifinder_ipaH_presence_absence_reads String Presence (+) or absence (-) of ipaH identified by ShigEiFinder using read files as inputs shigeifinder_notes String Any notes output from ShigEiFinder shigeifinder_notes_reads String Any notes output from ShigEiFinder using read files as inputs shigeifinder_num_virulence_plasmid_genes String Number of virulence plasmid genes identified by ShigEiFinder shigeifinder_num_virulence_plasmid_genes_reads String Number of virulence plasmid genes identified by ShigEiFinder using read files as inputs shigeifinder_report File TSV report from ShigEiFinder (see https://github.com/LanLab/ShigEiFinder#shigeifinder) shigeifinder_report_reads File TSV report from ShigEiFinder (see https://github.com/LanLab/ShigEiFinder#shigeifinder) using read files as inputs shigeifinder_serotype String Serotype predicted by ShigEiFinder shigeifinder_serotype_reads String Serotype predicted by ShigEiFinder using read files as inputs shigeifinder_version String ShigEiFinder version used shigeifinder_version_reads String ShigEiFinder version used using read files as inputs sistr_allele_fasta File FASTA file of novel cgMLST alleles from SISTR sistr_allele_json File JSON file of cgMLST allele sequences and information (see https://github.com/phac-nml/sistr_cmd#cgmlst-allele-search-results) sistr_antigenic_formula String A field that aggregates the O, H1, and H2, antigen values in a single location for convenience sistr_cgmlst File CSV file of the cgMLST allelic profile from SISTR (see https://github.com/phac-nml/sistr_cmd#cgmlst-allelic-profiles-output---cgmlst-profiles-cgmlst-profilescsv) sistr_h1_antigens String The predicted H1 antigen sistr_h2_antigens String The predicted H2 antigen sistr_o_antigens String The predicted O antigen sistr_predicted_serotype String Serotype predicted by SISTR sistr_results File TSV results file produced by SISTR (see https://github.com/phac-nml/sistr_cmd#primary-results-output--o-sistr-results) sistr_serogroup String Serogroup predicted by SISTR sistr_serotype_cgmlst String cgMLST of the serogroup prediicted by SISTR sistr_version String Version of SISTR used sonneityping_final_genotype String Final genotype call from Mykrobe, via sonneityper sonneityping_final_report_tsv File Detailed TSV report from mykrobe, via sonneityper (see https://github.com/katholt/sonneityping#example-output) sonneityping_genotype_confidence String Confidence in the final genotype call from sonneityper sonneityping_genotype_name String Human readable alias for genotype, where available provided by sonneityper sonneityping_mykrobe_docker String sonneityping docker image used sonneityping_mykrobe_report_csv File CSV report from mykrobe via sonneityper (see https://github.com/Mykrobe-tools/mykrobe/wiki/AMR-prediction-output#csv-file) sonneityping_mykrobe_report_json File JSON report from mykrobe via sonneityper (see https://github.com/Mykrobe-tools/mykrobe/wiki/AMR-prediction-output#json-file) sonneityping_mykrobe_version String Version of sonneityping used sonneityping_species String Species call from Mykrobe via sonneityping spatyper_docker String spatyper docker image used spatyper_repeats String order of identified repeats spatyper_tsv File TSV report with spatyper results spatyper_type String spa type spatyper_version String spatyper version used srst2_vibrio_biotype String Biotype classification according to tcpA gene sequence (Classical or ElTor) srst2_vibrio_ctxA String Presence or absence of the ctxA gene srst2_vibrio_database String Database used for srst2 analysis srst2_vibrio_detailed_tsv File Detailed https://github.com/katholt/srst2 output file srst2_vibrio_docker String Docker image used for srst2 analysis srst2_vibrio_ompW String Presence or absence of the ompW gene srst2_vibrio_serogroup String Serotype classification as O1 (wbeN gene), O139 (wbfR gene) or not detected. srst2_vibrio_toxR String Presence or absence of the toxR gene srst2_vibrio_version String The SRST2 version run staphopiasccmec_docker String staphopia-sccmec docker image used staphopiasccmec_hamming_distance_tsv File staphopia-sccmec version staphopiasccmec_results_tsv File sccmec types and mecA presence staphopiasccmec_types_and_mecA_presence String staphopia-sccmec Hamming distance file staphopiasccmec_version String staphopia-sccmec presence and absence TSV file stxtyper_all_hits String Comma-separated list of matches of all types. Includes complete, partial, frameshift, internal stop, and novel hits. List is de-duplicated so multiple identical hits are only listed once. For example if 5 partial stx2 hits are detected in the genome, only 1 \"stx2\" will be listed in this field. To view the potential subtype for each partial hit, the user will need to view the stxtyper_report TSV file. stxtyper_ambiguous_hits String Comma-separated list of matches that have the OPERON output of \"AMBIGUOUS\". Ambiguous bases found in the query sequence (e.g., N) stxtyper_complete_operons String Comma-separated list of all COMPLETE operons detected by StxTyper. Show multiple hits if present in results. stxtyper_docker String Name of docker image used by the stxtyper task. stxtyper_extended_operons String Comma-separated list of all EXTENDED operons detected by StxTyper if coding sequence extends beyond the reference stop codon for one or both of the reference proteins. stxtyper_novel_hits String Comma-separated list of matches that have the OPERON output of \"COMPLETE_NOVEL\". Possible outputs \"stx1\", \"stx2\", or \"stx1,stx2\" stxtyper_num_hits Int Number of \"hits\" or rows present in the <code>stxtyper_report</code> TSV file stxtyper_partial_hits String Possible outputs \"stx1\", \"stx2\", or \"stx1,stx2\". Tells the user that there was a partial hit to either the A or B subunit, but does not describe which subunit, only the possible types from the PARTIAL matches. stxtyper_report File Raw results TSV file produced by StxTyper stxtyper_stx_frameshifts_or_internal_stop_hits String Comma-separated list of matches that have the OPERON output of \"FRAMESHIFT\" or \"INTERNAL_STOP\". Possible outputs \"stx1\", \"stx2\", or \"stx1,stx2\" stxtyper_version String Version of StxTyper used taxon_table_status String Status of the taxon table upload tbp_parser_average_genome_depth Float The mean depth of coverage across all target regions included in the analysis tbp_parser_coverage_report File A file containing the breadth of coverage across each target loci tbp_parser_docker String The docker image and version tag for the tbp_parser tool tbp_parser_genome_percent_coverage Float The percent breadth of coverage across the entire genome tbp_parser_laboratorian_report_csv File An output file containing information regarding each mutation and its associated drug resistance profile in a CSV file. This file also contains two interpretation fields -- \"Looker\" and \"MDL\" which are generated using the CDC's expert rules for interpreting the severity of potential drug resistance mutations. tbp_parser_lims_report_csv File An output file formatted specifically for STAR LIMS. This CSV report summarizes the highest severity mutations for each antimicrobial and lists the relevant mutations for each gene. tbp_parser_looker_report_csv File An output file that contains condensed information suitable for generating a dashboard in Google's Looker studio. tbp_parser_version String The version number of tbp_parser tbprofiler_dr_type String The drug resistance category as determined by TBProfiler (sensitive, Pre-MDR, MDR, Pre-XDR, XDR) tbprofiler_main_lineage String The Mycobacterium tuberculosis lineage assignment as made by TBProfiler tbprofiler_median_depth Float The median depth of the H37Rv TB reference genome covered by the sample tbprofiler_output_bai File Index BAM file generated by mapping sequencing reads to reference genome by TBProfiler tbprofiler_output_bam File BAM alignment file produced by TBProfiler tbprofiler_output_file File CSV report from TBProfiler tbprofiler_output_vcf File VCF file output from TBProfiler; the concatenation of all of the different VCF files produced during TBProfiler analysis tbprofiler_pct_reads_mapped Float The percentage of reads that successfully mapped to the H37Rv genome tbprofiler_resistance_genes String The genes in which a mutation was detected that may be resistance conferring, in the format of <code>&lt;gene target&gt; &lt;variant detected&gt; (&lt;estimated fraction of reads that support the variant&gt;)</code> tbprofiler_sub_lineage String The Mycobacterium tuberculosis sub-lineage assignment as made by TBProfiler tbprofiler_version String The version of TBProfiler used for this analysis theiaprok_illumina_pe_analysis_date String Date of TheiaProk PE workflow execution theiaprok_illumina_pe_version String Version of TheiaProk PE workflow execution trimmomatic_docker String The docker image used for the trimmomatic module in this workflow trimmomatic_version String The version of Trimmomatic used ts_mlst_allelic_profile String Profile of MLST loci and allele numbers predicted by MLST ts_mlst_docker String Docker image used for MLST ts_mlst_novel_alleles File FASTA file containing nucleotide sequence of any alleles that are not in the MLST database used by TheiaProk ts_mlst_predicted_secondary_st String ST predicted by secondary MLST run ts_mlst_predicted_st String ST predicted by MLST ts_mlst_pubmlst_scheme String PubMLST scheme used byMLST ts_mlst_pubmlst_secondary_scheme String PubMLST secondary scheme used by MLST ts_mlst_results File TSV report with detailed MLST profile, including https://github.com/tseemann/mlst#missing-data ts_mlst_secondary_allelic_profile String Profile of alleles predicted by secondary MLST run ts_mlst_secondary_novel_alleles File FASTA file containing nucleotide sequence of any alleles that are not in the MLST database used by TheiaProk, from the secondary scheme run ts_mlst_version String Version of Torsten Seeman\u2019s MLST tool used vibecheck_classification_notes String Additional information provided by Vibecheck during classification vibecheck_confidence Float How confidence lineage assignment is. 0 - uncertain; 100 - Very certain vibecheck_docker String Docker image used by Vibecheck task vibecheck_lineage_report File Output CSV file created by Vibecheck vibecheck_top_lineage String Most likely lineage assigned by Vibecheck vibecheck_version String Version of Vibecheck used virulencefinder_docker String VirulenceFinder docker image used virulencefinder_hits String Virulence genes detected by VirulenceFinder virulencefinder_report_tsv File Output TSV file created by VirulenceFinder Variable Type Description abricate_abaum_database String Database of reference A. baumannii plasmid typing genes used for plasmid typing abricate_abaum_docker String Docker file used for running abricate abricate_abaum_plasmid_tsv File https://github.com/tseemann/abricate#output containing a row for each A. baumannii plasmid type gene found in the sample abricate_abaum_plasmid_type_genes String A. baumannii Plasmid typing genes found in the sample; from GENE column in https://github.com/tseemann/abricate#output abricate_abaum_version String Version of abricate used for A. baumannii plasmid typing abricate_database String Database of reference used with Abricate abricate_docker String Docker file used for running abricate abricate_genes String Genes found in the sample; from GENE column in https://github.com/tseemann/abricate#output abricate_results_tsv File https://github.com/tseemann/abricate#output containing a row for each gene found in the sample abricate_version String Version of abricate used for A. baumannii plasmid typing abricate_vibrio_biotype String Biotype classification according to tcpA gene sequence (Classical or ElTor) abricate_vibrio_ctxA String Presence or absence of the ctxA gene abricate_vibrio_database String Database to use while running abricate abricate_vibrio_detailed_tsv File Detailed ABRicate output file abricate_vibrio_docker String Docker file used for running abricate abricate_vibrio_ompW String Presence or absence of the ompW gene abricate_vibrio_serogroup String Serotype classification as O1 (wbeN gene), O139 (wbfR gene) or not detected. abricate_vibrio_toxR String Presence or absence of the toxR gene abricate_vibrio_version String The abricate version run agrvate_agr_canonical String Canonical or non-canonical agrD agrvate_agr_group String Agr group agrvate_agr_match_score String Match score for agr group agrvate_agr_multiple String If multiple agr groups were found agrvate_agr_num_frameshifts String Number of frameshifts found in CDS of extracted agr operon agrvate_docker String The docker used for AgrVATE agrvate_results File A gzipped tarball of all results agrvate_summary File The summary file produced agrvate_version String The version of AgrVATE used amr_search_csv File CSV formatted AMR profile amr_search_docker String Docker image used to run AMR_Search amr_search_results File JSON formatted AMR profile including BLAST results amr_search_results_pdf File PDF formatted AMR profile amr_search_version String Version of AMR_Search libraries used amrfinderplus_all_report File Output TSV file from AMRFinderPlus (described https://github.com/ncbi/amr/wiki/Running-AMRFinderPlus#fields) amrfinderplus_amr_betalactam_betalactam_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to beta-lactams amrfinderplus_amr_betalactam_carbapenem_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to carbapenem amrfinderplus_amr_betalactam_cephalosporin_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to cephalosporin amrfinderplus_amr_betalactam_cephalothin_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to cephalothin amrfinderplus_amr_betalactam_genes String Beta-lactam AMR genes identified by AMRFinderPlus amrfinderplus_amr_betalactam_methicillin_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to methicilin amrfinderplus_amr_classes String AMRFinderPlus predictions for classes of drugs that genes found in the reads are known to confer resistance to amrfinderplus_amr_core_genes String AMR genes identified by AMRFinderPlus where the scope is \"core\" amrfinderplus_amr_plus_genes String AMR genes identified by AMRFinderPlus where the scope is \"plus\" amrfinderplus_amr_report File TSV file detailing AMR genes only, from the amrfinderplus_all_report amrfinderplus_amr_subclasses String More specificity about the drugs that genes identified in the reads confer resistance to amrfinderplus_db_version String AMRFinderPlus database version used amrfinderplus_stress_genes String Stress genes identified by AMRFinderPlus amrfinderplus_stress_report File TSV file detailing stress genes only, from the amrfinderplus_all_report amrfinderplus_version String AMRFinderPlus version used amrfinderplus_virulence_genes String Virulence genes identified by AMRFinderPlus amrfinderplus_virulence_report File TSV file detailing virulence genes only, from the amrfinderplus_all_report ani_highest_percent Float Highest ANI between query and any given reference genome (top species match) ani_highest_percent_bases_aligned Float Percentage of bases aligned between query genome and top species match ani_mummer_docker String Docker image used to run the ANI_mummer task ani_mummer_version String Version of MUMmer used ani_output_tsv File Full output TSV from ani-m ani_top_species_match String Species of genome with highest ANI to query FASTA arln_assembly_ratio String Assembly ratio of the final assembly compared to the mean assembly length of the taxon. These stats are gathered from a statistics file created by the CDC aggregating NCBI assembly data by taxon. arln_assembly_zscore String ZScore of the samples assembly length to assess the uniformity of the assembly when compared to taxon means. arln_r1_q30_clean String Q30% of the cleaned R1 FASTQ arln_r1_q30_raw String Q30% of the raw R1 FASTQ arln_stats_docker_version String Docker version for task_arln_stats.wdl arln_taxon_assembly_ratio_stdev String Reported assembely length standard deviation of the given taxonomy pulled from NCBI aggregated data. arln_taxon_gc_mean String Mean GC percent of the taxon. arln_taxon_gc_percent_stdev String Reported GC percent standard deviation of the given taxonomy pulled from NCBI aggregated data. assembler String Assembler used in digger_denovo subworkflow assembler_version String Version of the assembler used in digger_denovo assembly_fasta File De novo genome assembly in FASTA format assembly_length Int Length of assembly (total contig length) as determined by QUAST bakta_gbff File Genomic GenBank format annotation file bakta_gff3 File Generic Feature Format Version 3 file bakta_plot File Bakta plot output PNG file summarizing annotated genome features such as coding sequences, RNA genes, and hypothetical proteins. bakta_summary File Bakta summary output TXT file bakta_tsv File Annotations as simple human readable TSV bakta_version String Bakta version used bbduk_docker String The Docker image for bbduk, which was used to remove the adapters from the sequences busco_database String BUSCO database used busco_docker String BUSCO docker image used busco_report File A plain text summary of the results in BUSCO notation busco_results String BUSCO results (see relevant toggle in this block) busco_version String BUSCO software version used cg_pipeline_docker String Docker file used for running CG-Pipeline on cleaned reads cg_pipeline_report_clean File TSV file of read metrics from clean reads, including average read length, number of reads, and estimated genome coverage cg_pipeline_report_raw File TSV file of read metrics from raw reads, including average read length, number of reads, and estimated genome coverage contigs_gfa File Assembly graph output generated by SPAdes (Illumina: PE, SE) or Flye (ONT), used to visualize and evaluate genome assembly results. ectyper_database_version String Version of the ECTyper database used ectyper_pathodb_version String Version of the ECTyper pathotype database used ectyper_pathotype String Samples pathotype predicted by ECTyper ectyper_pathotype_count Int Number of pathotypes predicted by ECTyper ectyper_pathotype_genes String Pathotype genes observed by ECTyper ectyper_predicted_serotype String Serotype predicted by ECTyper ectyper_qc_result String QC pass or fail for the sample analyzed ectyper_results File TSV file of evidence for ECTyper predicted serotype (see https://github.com/phac-nml/ecoli_serotyping#report-format) ectyper_stx_subtypes String Shiga toxin subtypes predicted by ECTyper ectyper_version String Version of ECTyper used emmtyper_docker String Docker image for emmtyper emmtyper_emm_type String The emm-type of a Streptococcus pyogenes assembly emmtyper_results_tsv File TSV file with emmtyper results emmtyper_version String Version of emmtyper used est_coverage_clean Float Estimated coverage calculated from clean reads and genome length est_coverage_raw Float Estimated coverage calculated from raw reads and genome length fastp_html_report File The HTML report made with fastp fastp_version String The version of fastp used fastq_scan_clean1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about clean forward read quality and length fastq_scan_num_reads_clean1 Int The number of forward reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_raw1 Int The number of input forward reads as calculated by fastq_scan fastq_scan_raw1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about raw forward read quality and length fastq_scan_version String The version of fastq_scan fastqc_clean1_html File An HTML file that provides a graphical visualization of clean forward read quality from fastqc to open in an internet browser fastqc_docker String The Docker container used for fastqc fastqc_num_reads_clean1 Int The number of forward reads after cleaning by fastqc fastqc_num_reads_raw1 Int The number of input forward reads by fastqc before cleaning fastqc_raw1_html File An HTML file that provides a graphical visualization of raw forward read quality from fastqc to open in an internet browser fastqc_version String Version of fastqc software used filtered_contigs_metrics File File containing metrics of contigs filtered gambit_closest_genomes File CSV file listing genomes in the GAMBIT database that are most similar to the query assembly gambit_db_version String Version of the GAMBIT database used gambit_docker String GAMBIT Docker used gambit_predicted_taxon String Taxon predicted by GAMBIT gambit_predicted_taxon_rank String Taxon rank of GAMBIT taxon prediction gambit_report File GAMBIT report in a machine-readable format gambit_version String Version of GAMBIT software used gamma_docker String The Docker container used gamma_fasta File The FASTA file reporting gene matches if boolean was set to true gamma_gff File The GFF file reporting gene matches if boolean was set to true gamma_results File The .gamma file reporting gene matches gamma_version String The version of GAMMA used genotyphi_final_genotype String Final genotype call from GenoTyphi genotyphi_genotype_confidence String Confidence in the final genotype call made by GenoTyphi genotyphi_mykrobe_json File JSON file of GenoTyphi output, described https://github.com/katholt/genotyphi#explanation-of-columns-in-the-output genotyphi_report_tsv File TSV file of GenoTyphi output, described https://github.com/katholt/genotyphi#explanation-of-columns-in-the-output genotyphi_species String Species call from Mykrobe, used to run GenoTyphi genotyphi_st_probes_percent_coverage Float Percentage coverage to the Typhi MLST probes genotyphi_version String Version of GenoTyphi used hicap_docker String Docker image used for hicap hicap_genes String cap genes identified. genes on different contigs delimited by;. truncation shown by trailing * hicap_results_tsv File TSV file of hicap output hicap_serotype String hicap serotype hicap_version String hicap version used kaptive_k_locus String Best matching K locus identified by Kaptive kaptive_k_type String Best matching K type identified by Kaptive kaptive_kl_confidence String Kaptive\u2019s confidence in the KL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kaptive_oc_locus String Best matching K locus identified by Kaptive kaptive_ocl_confidence String Kaptive\u2019s confidence in the OCL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kaptive_output_file_k File TSV https://github.com/katholt/Kaptive/wiki/How-to-run#output-filesfrom the K locus from Kaptive kaptive_output_file_oc File TSV https://github.com/katholt/Kaptive/wiki/How-to-run#output-filesfrom the OC locus from Kaptive kaptive_version String Version of Kaptive used kleborate_docker String Kleborate docker image used kleborate_genomic_resistance_mutations String Genomic resistance mutations identifies by Kleborate kleborate_key_resistance_genes String Key resistance genes identified by Kleborate kleborate_klocus String Best matching K locus identified by  Kleborate via Kaptive kleborate_klocus_confidence String Kaptive\u2019s confidence in the KL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kleborate_ktype String Best matching K type identified by  Kleborate via Kaptive kleborate_mlst_sequence_type String https://github.com/katholt/Kleborate/wiki/MLST#multi-locus-sequence-typing-mlst call by Kleborate kleborate_olocus String Best matching OC locus identified by  Kleborate via Kaptive kleborate_olocus_confidence String Kaptive\u2019s confidence in the KL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kleborate_otype String Best matching OC type identified by  Kleborate via Kaptive kleborate_output_file File See also https://github.com/katholt/Kleborate/wiki/Scores-and-counts kleborate_resistance_score String Resistance score as given by kleborate kleborate_version String Version of Kleborate used kleborate_virulence_score String Virulence score as given by kleborate kmerfinder_database String Database used to run KmerFinder kmerfinder_docker String Docker image used to run KmerFinder kmerfinder_query_coverage String KmerFinder\u2019s query coverage of the top hit result kmerfinder_results_tsv File Output TSV file created by KmerFinder kmerfinder_template_coverage String Percent of kmer coverage pertaining to the template, or reference selected kmerfinder_top_hit String Top hit species of KmerFinder kraken2_database String Kraken2 database used for the taxonomic assignment kraken2_docker String Docker image used to run kraken2 kraken2_report String TXT document describing taxonomic prediction of every FASTQ record. This file is usually very large and cumbersome to open and view kraken2_version String The version of kraken2 used legsta_predicted_sbt String Sequence based type predicted by Legsta legsta_results File TSV file of legsta results (see https://github.com/tseemann/legsta#output) legsta_version String Version of legsta used lissero_results File TSV results file from LisSero (see https://github.com/MDU-PHL/LisSero#example-output) lissero_serotype String Serotype predicted by LisSero lissero_version String Version of LisSero used meningotype_BAST String BAST type meningotype_FetA String FetA type meningotype_NHBA String NHBA type meningotype_NadA String NBA type meningotype_PorA String PorA type meningotype_PorB String PorB type meningotype_fHbp String fHbp type meningotype_serogroup String Serogroup meningotype_tsv File Full result file meningotype_version String Version of meningotype used midas_docker String MIDAS docker image used midas_primary_genus String The primary genus detected by MIDAS midas_report File TSV report of full MIDAS results midas_secondary_genus String Genus of the next most abundant species after removing all species of the most abundant genus midas_secondary_genus_abundance Float Relative abundance of secondary genus midas_secondary_genus_coverage Float Absolute coverage of secondary genus n50_value Int N50 of assembly calculated by QUAST ngmaster_ngmast_porB_allele String porB allele number ngmaster_ngmast_sequence_type String NG-MAST sequence type ngmaster_ngmast_tbpB_allele String tbpB allele number ngmaster_ngstar_23S_allele String 23S rRNA allele number ngmaster_ngstar_gyrA_allele String gyrA allele number ngmaster_ngstar_mtrR_allele String mtrR allele number ngmaster_ngstar_parC_allele String parC allele number ngmaster_ngstar_penA_allele String penA allele number ngmaster_ngstar_ponA_allele String ponA allele number ngmaster_ngstar_porB_allele String porB allele number ngmaster_ngstar_sequence_type String NG-STAR sequence type ngmaster_tsv File TSV file with NG-MAST/NG-STAR typing ngmaster_version String ngmaster version number_contigs Int Total number of contigs in assembly pasty_all_serogroups File TSV file with details of each serogroup from pasty (see https://github.com/rpetit3/pasty#example-prefixdetailstsv) pasty_blast_hits File TSV file of BLAST hits from pasty (see https://github.com/rpetit3/pasty#example-prefixblastntsv) pasty_comment String pasty_docker String pasty docker image used pasty_serogroup String Serogroup predicted by pasty pasty_serogroup_coverage Float The breadth of coverage of the O-antigen by pasty pasty_serogroup_fragments Int Number of BLAST hits included in the prediction (fewer is better) pasty_summary_tsv File TSV summary file of pasty outputs (see https://github.com/rpetit3/pasty#example-prefixtsv) pasty_version String Version of pasty used pbptyper_docker String pbptyper docker image used pbptyper_pbptype_predicted_tsv File TSV file of pbptyper results (see https://github.com/rpetit3/pbptyper#example-prefixtsv) pbptyper_predicted_1A_2B_2X String PBP type predicted by pbptyper pbptyper_version String Version of pbptyper used plasmidfinder_db_version String Version of PlasmidFnder used plasmidfinder_docker String PlasmidFinder docker image used plasmidfinder_plasmids String Names of plasmids identified by PlasmidFinder plasmidfinder_results File Output file from PlasmidFinder in TSV format plasmidfinder_seqs File Hit_in_genome_seq.fsa file produced by PlasmidFinder poppunk_GPS_db_version String Version of GPSC database used poppunk_docker String PopPUNK docker image with GPSC database used poppunk_gps_cluster String GPS cluster predicted by PopPUNK poppunk_gps_external_cluster_csv File GPSC v6 scheme designations poppunk_version String Version of PopPUNK used prokka_gbk File GenBank file produced from Prokka annotation of input FASTA prokka_gff File Prokka output GFF3 file containing sequence and annotation (you can view this in IGV) prokka_sqn File A Sequin file for GenBank submission qc_check String A string that indicates whether or not the sample passes a set of pre-determined and user-provided QC thresholds qc_standard File The file used in the QC Check task containing the QC thresholds. quast_gc_percent Float The GC percent of your sample quast_report File TSV report from QUAST quast_version String The version of QUAST r1_mean_q_clean Float Mean quality score of clean forward reads r1_mean_q_raw Float Mean quality score of raw forward reads r1_mean_readlength_clean Float Mean read length of clean forward reads r1_mean_readlength_raw Float Mean read length of raw forward reads read1_clean File Forward read file after quality trimming and adapter removal read1_concatenated File Concatenated forward reads read_screen_clean String PASS or FAIL result from clean read screening; FAIL accompanied by the reason(s) for failure read_screen_clean_tsv File Clean read screening report TSV depicting read counts, total read base pairs, and estimated genome length read_screen_raw String PASS or FAIL result from raw read screening; FAIL accompanied by the reason(s) for failure read_screen_raw_tsv File Raw read screening report TSV depicting read counts, total read base pairs, and estimated genome length resfinder_db_version String Version of ResFinder database resfinder_docker String ResFinder docker image used resfinder_pheno_table File Table containing al AMR phenotypes resfinder_pheno_table_species File Table with species-specific AMR phenotypes resfinder_pointfinder_pheno_table File TSV showing presence(1)/absence(0) of predicted resistance against an antibiotic class resfinder_pointfinder_results File Predicted point mutations, grouped by the gene they occur in resfinder_predicted_pheno_resistance String Semicolon delimited list of antimicrobial drugs and associated genes and/or point mutations.\u00a0: , , ; : , ; resfinder_predicted_resistance_Amp String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Ampicillin based on resfinder phenotypic predictions resfinder_predicted_resistance_Axo String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Ceftriaxone based on resfinder phenotypic predictions resfinder_predicted_resistance_Azm String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Azithromycin based on resfinder phenotypic predictions resfinder_predicted_resistance_Cip String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Ciprofloxacin based on resfinder phenotypic predictions resfinder_predicted_resistance_Smx String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Sulfamethoxazole based on resfinder phenotypic predictions resfinder_predicted_resistance_Tmp String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Trimothoprim based on resfinder phenotypic predictions resfinder_predicted_xdr_shigella String Final prediction of XDR Shigella status based on CDC definition. Explanation can be found in the description above this table. resfinder_results File Predicted resistance genes grouped by antibiotic class resfinder_seqs File FASTA of resistance gene sequences from user\u2019s input sequence seq_platform String Description of the sequencing methodology used to generate the input read data seqsero2_note String Additional notes produced by SeqSero2 seqsero2_predicted_antigenic_profile String Antigenic profile predicted for Salmonella spp. by SeqSero2 seqsero2_predicted_contamination String Indicates whether contamination between Salmonella with different serotypes was predicted by SeqSero2 seqsero2_predicted_serotype String Serotype predicted by SeqSero2 seqsero2_report String TSV report produced by SeqSero2 seqsero2_version String Version of SeqSero2 used serotypefinder_docker String SerotypeFinder docker image used serotypefinder_report File TSV report produced by SerotypeFinder serotypefinder_serotype String Serotype predicted by SerotypeFinder shigatyper_docker String ShigaTyper docker image used shigatyper_hits_tsv File Detailed TSV report from ShigaTyper (see https://github.com/CFSAN-Biostatistics/shigatyper#example-prefix-hitstsv) shigatyper_ipaB_presence_absence String Presence (+) or absence (-) of ipaB identified by ShigaTyper shigatyper_notes String Any notes output from ShigaTyper shigatyper_predicted_serotype String Serotype predicted by ShigaTyper shigatyper_summary_tsv File TSV summary report from ShigaTyper (see https://github.com/CFSAN-Biostatistics/shigatyper#example-prefixtsv) shigatyper_version String Version of ShigaTyper used shigeifinder_H_antigen String H-antigen gene identified by ShigEiFinder shigeifinder_H_antigen_reads String H-antigen gene identified by ShigEiFinder using read files as inputs shigeifinder_O_antigen String O-antigen gene identified by ShigEiFinder shigeifinder_O_antigen_reads String O-antigen gene identified by ShigEiFinder using read files as inputs shigeifinder_cluster String Shigella/EIEC cluster identified by ShigEiFinder shigeifinder_cluster_reads String Shigella/EIEC cluster identified by ShigEiFinder using read files as inputs shigeifinder_docker String ShigEiFinder docker image used shigeifinder_docker_reads String ShigEiFinder docker image used using read files as inputs shigeifinder_ipaH_presence_absence String Presence (+) or absence (-) of ipaH identified by ShigEiFinder shigeifinder_ipaH_presence_absence_reads String Presence (+) or absence (-) of ipaH identified by ShigEiFinder using read files as inputs shigeifinder_notes String Any notes output from ShigEiFinder shigeifinder_notes_reads String Any notes output from ShigEiFinder using read files as inputs shigeifinder_num_virulence_plasmid_genes String Number of virulence plasmid genes identified by ShigEiFinder shigeifinder_num_virulence_plasmid_genes_reads String Number of virulence plasmid genes identified by ShigEiFinder using read files as inputs shigeifinder_report File TSV report from ShigEiFinder (see https://github.com/LanLab/ShigEiFinder#shigeifinder) shigeifinder_report_reads File TSV report from ShigEiFinder (see https://github.com/LanLab/ShigEiFinder#shigeifinder) using read files as inputs shigeifinder_serotype String Serotype predicted by ShigEiFinder shigeifinder_serotype_reads String Serotype predicted by ShigEiFinder using read files as inputs shigeifinder_version String ShigEiFinder version used shigeifinder_version_reads String ShigEiFinder version used using read files as inputs sistr_allele_fasta File FASTA file of novel cgMLST alleles from SISTR sistr_allele_json File JSON file of cgMLST allele sequences and information (see https://github.com/phac-nml/sistr_cmd#cgmlst-allele-search-results) sistr_antigenic_formula String A field that aggregates the O, H1, and H2, antigen values in a single location for convenience sistr_cgmlst File CSV file of the cgMLST allelic profile from SISTR (see https://github.com/phac-nml/sistr_cmd#cgmlst-allelic-profiles-output---cgmlst-profiles-cgmlst-profilescsv) sistr_h1_antigens String The predicted H1 antigen sistr_h2_antigens String The predicted H2 antigen sistr_o_antigens String The predicted O antigen sistr_predicted_serotype String Serotype predicted by SISTR sistr_results File TSV results file produced by SISTR (see https://github.com/phac-nml/sistr_cmd#primary-results-output--o-sistr-results) sistr_serogroup String Serogroup predicted by SISTR sistr_serotype_cgmlst String cgMLST of the serogroup prediicted by SISTR sistr_version String Version of SISTR used sonneityping_final_genotype String Final genotype call from Mykrobe, via sonneityper sonneityping_final_report_tsv File Detailed TSV report from mykrobe, via sonneityper (see https://github.com/katholt/sonneityping#example-output) sonneityping_genotype_confidence String Confidence in the final genotype call from sonneityper sonneityping_genotype_name String Human readable alias for genotype, where available provided by sonneityper sonneityping_mykrobe_docker String sonneityping docker image used sonneityping_mykrobe_report_csv File CSV report from mykrobe via sonneityper (see https://github.com/Mykrobe-tools/mykrobe/wiki/AMR-prediction-output#csv-file) sonneityping_mykrobe_report_json File JSON report from mykrobe via sonneityper (see https://github.com/Mykrobe-tools/mykrobe/wiki/AMR-prediction-output#json-file) sonneityping_mykrobe_version String Version of sonneityping used sonneityping_species String Species call from Mykrobe via sonneityping spatyper_docker String spatyper docker image used spatyper_repeats String order of identified repeats spatyper_tsv File TSV report with spatyper results spatyper_type String spa type spatyper_version String spatyper version used srst2_vibrio_biotype String Biotype classification according to tcpA gene sequence (Classical or ElTor) srst2_vibrio_ctxA String Presence or absence of the ctxA gene srst2_vibrio_database String Database used for srst2 analysis srst2_vibrio_detailed_tsv File Detailed https://github.com/katholt/srst2 output file srst2_vibrio_docker String Docker image used for srst2 analysis srst2_vibrio_ompW String Presence or absence of the ompW gene srst2_vibrio_serogroup String Serotype classification as O1 (wbeN gene), O139 (wbfR gene) or not detected. srst2_vibrio_toxR String Presence or absence of the toxR gene srst2_vibrio_version String The SRST2 version run staphopiasccmec_docker String staphopia-sccmec docker image used staphopiasccmec_hamming_distance_tsv File staphopia-sccmec version staphopiasccmec_results_tsv File sccmec types and mecA presence staphopiasccmec_types_and_mecA_presence String staphopia-sccmec Hamming distance file staphopiasccmec_version String staphopia-sccmec presence and absence TSV file stxtyper_all_hits String Comma-separated list of matches of all types. Includes complete, partial, frameshift, internal stop, and novel hits. List is de-duplicated so multiple identical hits are only listed once. For example if 5 partial stx2 hits are detected in the genome, only 1 \"stx2\" will be listed in this field. To view the potential subtype for each partial hit, the user will need to view the stxtyper_report TSV file. stxtyper_ambiguous_hits String Comma-separated list of matches that have the OPERON output of \"AMBIGUOUS\". Ambiguous bases found in the query sequence (e.g., N) stxtyper_complete_operons String Comma-separated list of all COMPLETE operons detected by StxTyper. Show multiple hits if present in results. stxtyper_docker String Name of docker image used by the stxtyper task. stxtyper_extended_operons String Comma-separated list of all EXTENDED operons detected by StxTyper if coding sequence extends beyond the reference stop codon for one or both of the reference proteins. stxtyper_novel_hits String Comma-separated list of matches that have the OPERON output of \"COMPLETE_NOVEL\". Possible outputs \"stx1\", \"stx2\", or \"stx1,stx2\" stxtyper_num_hits Int Number of \"hits\" or rows present in the <code>stxtyper_report</code> TSV file stxtyper_partial_hits String Possible outputs \"stx1\", \"stx2\", or \"stx1,stx2\". Tells the user that there was a partial hit to either the A or B subunit, but does not describe which subunit, only the possible types from the PARTIAL matches. stxtyper_report File Raw results TSV file produced by StxTyper stxtyper_stx_frameshifts_or_internal_stop_hits String Comma-separated list of matches that have the OPERON output of \"FRAMESHIFT\" or \"INTERNAL_STOP\". Possible outputs \"stx1\", \"stx2\", or \"stx1,stx2\" stxtyper_version String Version of StxTyper used taxon_table_status String Status of the taxon table upload tbp_parser_average_genome_depth Float The mean depth of coverage across all target regions included in the analysis tbp_parser_coverage_report File A file containing the breadth of coverage across each target loci tbp_parser_genome_percent_coverage Float The percent breadth of coverage across the entire genome tbp_parser_laboratorian_report_csv File An output file containing information regarding each mutation and its associated drug resistance profile in a CSV file. This file also contains two interpretation fields -- \"Looker\" and \"MDL\" which are generated using the CDC's expert rules for interpreting the severity of potential drug resistance mutations. tbp_parser_lims_report_csv File An output file formatted specifically for STAR LIMS. This CSV report summarizes the highest severity mutations for each antimicrobial and lists the relevant mutations for each gene. tbp_parser_looker_report_csv File An output file that contains condensed information suitable for generating a dashboard in Google's Looker studio. tbprofiler_dr_type String The drug resistance category as determined by TBProfiler (sensitive, Pre-MDR, MDR, Pre-XDR, XDR) tbprofiler_main_lineage String The Mycobacterium tuberculosis lineage assignment as made by TBProfiler tbprofiler_output_bai File Index BAM file generated by mapping sequencing reads to reference genome by TBProfiler tbprofiler_output_bam File BAM alignment file produced by TBProfiler tbprofiler_output_file File CSV report from TBProfiler tbprofiler_output_vcf File VCF file output from TBProfiler; the concatenation of all of the different VCF files produced during TBProfiler analysis tbprofiler_resistance_genes String The genes in which a mutation was detected that may be resistance conferring, in the format of <code>&lt;gene target&gt; &lt;variant detected&gt; (&lt;estimated fraction of reads that support the variant&gt;)</code> tbprofiler_sub_lineage String The Mycobacterium tuberculosis sub-lineage assignment as made by TBProfiler tbprofiler_version String The version of TBProfiler used for this analysis theiaprok_illumina_se_analysis_date String Date of TheiaProk SE workflow execution theiaprok_illumina_se_version String Version of TheiaProk SE workflow execution trimmomatic_docker String The docker image used for the trimmomatic module in this workflow trimmomatic_version String The version of Trimmomatic used ts_mlst_allelic_profile String Profile of MLST loci and allele numbers predicted by MLST ts_mlst_docker String Docker image used for MLST ts_mlst_novel_alleles File FASTA file containing nucleotide sequence of any alleles that are not in the MLST database used by TheiaProk ts_mlst_predicted_secondary_st String ST predicted by secondary MLST run ts_mlst_predicted_st String ST predicted by MLST ts_mlst_pubmlst_scheme String PubMLST scheme used byMLST ts_mlst_pubmlst_secondary_scheme String PubMLST secondary scheme used by MLST ts_mlst_results File TSV report with detailed MLST profile, including https://github.com/tseemann/mlst#missing-data ts_mlst_secondary_allelic_profile String Profile of alleles predicted by secondary MLST run ts_mlst_secondary_novel_alleles File FASTA file containing nucleotide sequence of any alleles that are not in the MLST database used by TheiaProk, from the secondary scheme run ts_mlst_version String Version of Torsten Seeman\u2019s MLST tool used virulencefinder_docker String VirulenceFinder docker image used virulencefinder_hits String Virulence genes detected by VirulenceFinder virulencefinder_report_tsv File Output TSV file created by VirulenceFinder Variable Type Description abricate_abaum_database String Database of reference A. baumannii plasmid typing genes used for plasmid typing abricate_abaum_docker String Docker file used for running abricate abricate_abaum_plasmid_tsv File https://github.com/tseemann/abricate#output containing a row for each A. baumannii plasmid type gene found in the sample abricate_abaum_plasmid_type_genes String A. baumannii Plasmid typing genes found in the sample; from GENE column in https://github.com/tseemann/abricate#output abricate_abaum_version String Version of abricate used for A. baumannii plasmid typing abricate_database String Database of reference used with Abricate abricate_docker String Docker file used for running abricate abricate_genes String Genes found in the sample; from GENE column in https://github.com/tseemann/abricate#output abricate_results_tsv File https://github.com/tseemann/abricate#output containing a row for each gene found in the sample abricate_version String Version of abricate used for A. baumannii plasmid typing abricate_vibrio_biotype String Biotype classification according to tcpA gene sequence (Classical or ElTor) abricate_vibrio_ctxA String Presence or absence of the ctxA gene abricate_vibrio_database String Database to use while running abricate abricate_vibrio_detailed_tsv File Detailed ABRicate output file abricate_vibrio_docker String Docker file used for running abricate abricate_vibrio_ompW String Presence or absence of the ompW gene abricate_vibrio_serogroup String Serotype classification as O1 (wbeN gene), O139 (wbfR gene) or not detected. abricate_vibrio_toxR String Presence or absence of the toxR gene abricate_vibrio_version String The abricate version run agrvate_agr_canonical String Canonical or non-canonical agrD agrvate_agr_group String Agr group agrvate_agr_match_score String Match score for agr group agrvate_agr_multiple String If multiple agr groups were found agrvate_agr_num_frameshifts String Number of frameshifts found in CDS of extracted agr operon agrvate_docker String The docker used for AgrVATE agrvate_results File A gzipped tarball of all results agrvate_summary File The summary file produced agrvate_version String The version of AgrVATE used amr_search_csv File CSV formatted AMR profile amr_search_docker String Docker image used to run AMR_Search amr_search_results File JSON formatted AMR profile including BLAST results amr_search_results_pdf File PDF formatted AMR profile amr_search_version String Version of AMR_Search libraries used amrfinderplus_all_report File Output TSV file from AMRFinderPlus (described https://github.com/ncbi/amr/wiki/Running-AMRFinderPlus#fields) amrfinderplus_amr_betalactam_betalactam_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to beta-lactams amrfinderplus_amr_betalactam_carbapenem_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to carbapenem amrfinderplus_amr_betalactam_cephalosporin_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to cephalosporin amrfinderplus_amr_betalactam_cephalothin_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to cephalothin amrfinderplus_amr_betalactam_genes String Beta-lactam AMR genes identified by AMRFinderPlus amrfinderplus_amr_betalactam_methicillin_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to methicilin amrfinderplus_amr_classes String AMRFinderPlus predictions for classes of drugs that genes found in the reads are known to confer resistance to amrfinderplus_amr_core_genes String AMR genes identified by AMRFinderPlus where the scope is \"core\" amrfinderplus_amr_plus_genes String AMR genes identified by AMRFinderPlus where the scope is \"plus\" amrfinderplus_amr_report File TSV file detailing AMR genes only, from the amrfinderplus_all_report amrfinderplus_amr_subclasses String More specificity about the drugs that genes identified in the reads confer resistance to amrfinderplus_db_version String AMRFinderPlus database version used amrfinderplus_stress_genes String Stress genes identified by AMRFinderPlus amrfinderplus_stress_report File TSV file detailing stress genes only, from the amrfinderplus_all_report amrfinderplus_version String AMRFinderPlus version used amrfinderplus_virulence_genes String Virulence genes identified by AMRFinderPlus amrfinderplus_virulence_report File TSV file detailing virulence genes only, from the amrfinderplus_all_report ani_highest_percent Float Highest ANI between query and any given reference genome (top species match) ani_highest_percent_bases_aligned Float Percentage of bases aligned between query genome and top species match ani_mummer_docker String Docker image used to run the ANI_mummer task ani_mummer_version String Version of MUMmer used ani_output_tsv File Full output TSV from ani-m ani_top_species_match String Species of genome with highest ANI to query FASTA arln_assembly_ratio String Assembly ratio of the final assembly compared to the mean assembly length of the taxon. These stats are gathered from a statistics file created by the CDC aggregating NCBI assembly data by taxon. arln_assembly_zscore String ZScore of the samples assembly length to assess the uniformity of the assembly when compared to taxon means. arln_stats_docker_version String Docker version for task_arln_stats.wdl arln_taxon_assembly_ratio_stdev String Reported assembely length standard deviation of the given taxonomy pulled from NCBI aggregated data. arln_taxon_gc_mean String Mean GC percent of the taxon. arln_taxon_gc_percent_stdev String Reported GC percent standard deviation of the given taxonomy pulled from NCBI aggregated data. assembly_length Int Length of assembly (total contig length) as determined by QUAST bakta_gbff File Genomic GenBank format annotation file bakta_gff3 File Generic Feature Format Version 3 file bakta_plot File Bakta plot output PNG file summarizing annotated genome features such as coding sequences, RNA genes, and hypothetical proteins. bakta_summary File Bakta summary output TXT file bakta_tsv File Annotations as simple human readable TSV bakta_version String Bakta version used busco_database String BUSCO database used busco_docker String BUSCO docker image used busco_report File A plain text summary of the results in BUSCO notation busco_results String BUSCO results (see relevant toggle in this block) busco_version String BUSCO software version used ectyper_database_version String Version of the ECTyper database used ectyper_pathodb_version String Version of the ECTyper pathotype database used ectyper_pathotype String Samples pathotype predicted by ECTyper ectyper_pathotype_count Int Number of pathotypes predicted by ECTyper ectyper_pathotype_genes String Pathotype genes observed by ECTyper ectyper_predicted_serotype String Serotype predicted by ECTyper ectyper_qc_result String QC pass or fail for the sample analyzed ectyper_results File TSV file of evidence for ECTyper predicted serotype (see https://github.com/phac-nml/ecoli_serotyping#report-format) ectyper_stx_subtypes String Shiga toxin subtypes predicted by ECTyper ectyper_version String Version of ECTyper used emmtyper_docker String Docker image for emmtyper emmtyper_emm_type String The emm-type of a Streptococcus pyogenes assembly emmtyper_results_tsv File TSV file with emmtyper results emmtyper_version String Version of emmtyper used gambit_closest_genomes File CSV file listing genomes in the GAMBIT database that are most similar to the query assembly gambit_db_version String Version of the GAMBIT database used gambit_docker String GAMBIT Docker used gambit_predicted_taxon String Taxon predicted by GAMBIT gambit_predicted_taxon_rank String Taxon rank of GAMBIT taxon prediction gambit_report File GAMBIT report in a machine-readable format gambit_version String Version of GAMBIT software used gamma_docker String The Docker container used gamma_fasta File The FASTA file reporting gene matches if boolean was set to true gamma_gff File The GFF file reporting gene matches if boolean was set to true gamma_results File The .gamma file reporting gene matches gamma_version String The version of GAMMA used hicap_docker String Docker image used for hicap hicap_genes String cap genes identified. genes on different contigs delimited by;. truncation shown by trailing * hicap_results_tsv File TSV file of hicap output hicap_serotype String hicap serotype hicap_version String hicap version used kaptive_k_locus String Best matching K locus identified by Kaptive kaptive_k_type String Best matching K type identified by Kaptive kaptive_kl_confidence String Kaptive\u2019s confidence in the KL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kaptive_oc_locus String Best matching K locus identified by Kaptive kaptive_ocl_confidence String Kaptive\u2019s confidence in the OCL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kaptive_output_file_k File TSV https://github.com/katholt/Kaptive/wiki/How-to-run#output-filesfrom the K locus from Kaptive kaptive_output_file_oc File TSV https://github.com/katholt/Kaptive/wiki/How-to-run#output-filesfrom the OC locus from Kaptive kaptive_version String Version of Kaptive used kleborate_docker String Kleborate docker image used kleborate_genomic_resistance_mutations String Genomic resistance mutations identifies by Kleborate kleborate_key_resistance_genes String Key resistance genes identified by Kleborate kleborate_klocus String Best matching K locus identified by  Kleborate via Kaptive kleborate_klocus_confidence String Kaptive\u2019s confidence in the KL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kleborate_ktype String Best matching K type identified by  Kleborate via Kaptive kleborate_mlst_sequence_type String https://github.com/katholt/Kleborate/wiki/MLST#multi-locus-sequence-typing-mlst call by Kleborate kleborate_olocus String Best matching OC locus identified by  Kleborate via Kaptive kleborate_olocus_confidence String Kaptive\u2019s confidence in the KL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kleborate_otype String Best matching OC type identified by  Kleborate via Kaptive kleborate_output_file File See also https://github.com/katholt/Kleborate/wiki/Scores-and-counts kleborate_resistance_score String Resistance score as given by kleborate kleborate_version String Version of Kleborate used kleborate_virulence_score String Virulence score as given by kleborate kmerfinder_database String Database used to run KmerFinder kmerfinder_docker String Docker image used to run KmerFinder kmerfinder_query_coverage String KmerFinder\u2019s query coverage of the top hit result kmerfinder_results_tsv File Output TSV file created by KmerFinder kmerfinder_template_coverage String Percent of kmer coverage pertaining to the template, or reference selected kmerfinder_top_hit String Top hit species of KmerFinder legsta_predicted_sbt String Sequence based type predicted by Legsta legsta_results File TSV file of legsta results (see https://github.com/tseemann/legsta#output) legsta_version String Version of legsta used lissero_results File TSV results file from LisSero (see https://github.com/MDU-PHL/LisSero#example-output) lissero_serotype String Serotype predicted by LisSero lissero_version String Version of LisSero used meningotype_BAST String BAST type meningotype_FetA String FetA type meningotype_NHBA String NHBA type meningotype_NadA String NBA type meningotype_PorA String PorA type meningotype_PorB String PorB type meningotype_fHbp String fHbp type meningotype_serogroup String Serogroup meningotype_tsv File Full result file meningotype_version String Version of meningotype used n50_value Int N50 of assembly calculated by QUAST ngmaster_ngmast_porB_allele String porB allele number ngmaster_ngmast_sequence_type String NG-MAST sequence type ngmaster_ngmast_tbpB_allele String tbpB allele number ngmaster_ngstar_23S_allele String 23S rRNA allele number ngmaster_ngstar_gyrA_allele String gyrA allele number ngmaster_ngstar_mtrR_allele String mtrR allele number ngmaster_ngstar_parC_allele String parC allele number ngmaster_ngstar_penA_allele String penA allele number ngmaster_ngstar_ponA_allele String ponA allele number ngmaster_ngstar_porB_allele String porB allele number ngmaster_ngstar_sequence_type String NG-STAR sequence type ngmaster_tsv File TSV file with NG-MAST/NG-STAR typing ngmaster_version String ngmaster version number_contigs Int Total number of contigs in assembly pasty_all_serogroups File TSV file with details of each serogroup from pasty (see https://github.com/rpetit3/pasty#example-prefixdetailstsv) pasty_blast_hits File TSV file of BLAST hits from pasty (see https://github.com/rpetit3/pasty#example-prefixblastntsv) pasty_comment String pasty_docker String pasty docker image used pasty_serogroup String Serogroup predicted by pasty pasty_serogroup_coverage Float The breadth of coverage of the O-antigen by pasty pasty_serogroup_fragments Int Number of BLAST hits included in the prediction (fewer is better) pasty_summary_tsv File TSV summary file of pasty outputs (see https://github.com/rpetit3/pasty#example-prefixtsv) pasty_version String Version of pasty used pbptyper_docker String pbptyper docker image used pbptyper_pbptype_predicted_tsv File TSV file of pbptyper results (see https://github.com/rpetit3/pbptyper#example-prefixtsv) pbptyper_predicted_1A_2B_2X String PBP type predicted by pbptyper pbptyper_version String Version of pbptyper used plasmidfinder_db_version String Version of PlasmidFnder used plasmidfinder_docker String PlasmidFinder docker image used plasmidfinder_plasmids String Names of plasmids identified by PlasmidFinder plasmidfinder_results File Output file from PlasmidFinder in TSV format plasmidfinder_seqs File Hit_in_genome_seq.fsa file produced by PlasmidFinder poppunk_GPS_db_version String Version of GPSC database used poppunk_docker String PopPUNK docker image with GPSC database used poppunk_gps_cluster String GPS cluster predicted by PopPUNK poppunk_gps_external_cluster_csv File GPSC v6 scheme designations poppunk_version String Version of PopPUNK used prokka_gbk File GenBank file produced from Prokka annotation of input FASTA prokka_gff File Prokka output GFF3 file containing sequence and annotation (you can view this in IGV) prokka_sqn File A Sequin file for GenBank submission qc_check String A string that indicates whether or not the sample passes a set of pre-determined and user-provided QC thresholds qc_standard File The file used in the QC Check task containing the QC thresholds. quast_gc_percent Float The GC percent of your sample quast_report File TSV report from QUAST quast_version String The version of QUAST resfinder_db_version String Version of ResFinder database resfinder_docker String ResFinder docker image used resfinder_pheno_table File Table containing al AMR phenotypes resfinder_pheno_table_species File Table with species-specific AMR phenotypes resfinder_pointfinder_pheno_table File TSV showing presence(1)/absence(0) of predicted resistance against an antibiotic class resfinder_pointfinder_results File Predicted point mutations, grouped by the gene they occur in resfinder_predicted_pheno_resistance String Semicolon delimited list of antimicrobial drugs and associated genes and/or point mutations.\u00a0: , , ; : , ; resfinder_predicted_resistance_Amp String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Ampicillin based on resfinder phenotypic predictions resfinder_predicted_resistance_Axo String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Ceftriaxone based on resfinder phenotypic predictions resfinder_predicted_resistance_Azm String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Azithromycin based on resfinder phenotypic predictions resfinder_predicted_resistance_Cip String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Ciprofloxacin based on resfinder phenotypic predictions resfinder_predicted_resistance_Smx String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Sulfamethoxazole based on resfinder phenotypic predictions resfinder_predicted_resistance_Tmp String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Trimothoprim based on resfinder phenotypic predictions resfinder_predicted_xdr_shigella String Final prediction of XDR Shigella status based on CDC definition. Explanation can be found in the description above this table. resfinder_results File Predicted resistance genes grouped by antibiotic class resfinder_seqs File FASTA of resistance gene sequences from user\u2019s input sequence seq_platform String Description of the sequencing methodology used to generate the input read data seqsero2_note String Additional notes produced by SeqSero2 seqsero2_predicted_antigenic_profile String Antigenic profile predicted for Salmonella spp. by SeqSero2 seqsero2_predicted_serotype String Serotype predicted by SeqSero2 seqsero2_report String TSV report produced by SeqSero2 seqsero2_version String Version of SeqSero2 used serotypefinder_docker String SerotypeFinder docker image used serotypefinder_report File TSV report produced by SerotypeFinder serotypefinder_serotype String Serotype predicted by SerotypeFinder shigeifinder_H_antigen String H-antigen gene identified by ShigEiFinder shigeifinder_O_antigen String O-antigen gene identified by ShigEiFinder shigeifinder_cluster String Shigella/EIEC cluster identified by ShigEiFinder shigeifinder_docker String ShigEiFinder docker image used shigeifinder_ipaH_presence_absence String Presence (+) or absence (-) of ipaH identified by ShigEiFinder shigeifinder_notes String Any notes output from ShigEiFinder shigeifinder_num_virulence_plasmid_genes String Number of virulence plasmid genes identified by ShigEiFinder shigeifinder_report File TSV report from ShigEiFinder (see https://github.com/LanLab/ShigEiFinder#shigeifinder) shigeifinder_serotype String Serotype predicted by ShigEiFinder shigeifinder_version String ShigEiFinder version used sistr_allele_fasta File FASTA file of novel cgMLST alleles from SISTR sistr_allele_json File JSON file of cgMLST allele sequences and information (see https://github.com/phac-nml/sistr_cmd#cgmlst-allele-search-results) sistr_antigenic_formula String A field that aggregates the O, H1, and H2, antigen values in a single location for convenience sistr_cgmlst File CSV file of the cgMLST allelic profile from SISTR (see https://github.com/phac-nml/sistr_cmd#cgmlst-allelic-profiles-output---cgmlst-profiles-cgmlst-profilescsv) sistr_h1_antigens String The predicted H1 antigen sistr_h2_antigens String The predicted H2 antigen sistr_o_antigens String The predicted O antigen sistr_predicted_serotype String Serotype predicted by SISTR sistr_results File TSV results file produced by SISTR (see https://github.com/phac-nml/sistr_cmd#primary-results-output--o-sistr-results) sistr_serogroup String Serogroup predicted by SISTR sistr_serotype_cgmlst String cgMLST of the serogroup prediicted by SISTR sistr_version String Version of SISTR used spatyper_docker String spatyper docker image used spatyper_repeats String order of identified repeats spatyper_tsv File TSV report with spatyper results spatyper_type String spa type spatyper_version String spatyper version used staphopiasccmec_docker String staphopia-sccmec docker image used staphopiasccmec_hamming_distance_tsv File staphopia-sccmec version staphopiasccmec_results_tsv File sccmec types and mecA presence staphopiasccmec_types_and_mecA_presence String staphopia-sccmec Hamming distance file staphopiasccmec_version String staphopia-sccmec presence and absence TSV file stxtyper_all_hits String Comma-separated list of matches of all types. Includes complete, partial, frameshift, internal stop, and novel hits. List is de-duplicated so multiple identical hits are only listed once. For example if 5 partial stx2 hits are detected in the genome, only 1 \"stx2\" will be listed in this field. To view the potential subtype for each partial hit, the user will need to view the stxtyper_report TSV file. stxtyper_ambiguous_hits String Comma-separated list of matches that have the OPERON output of \"AMBIGUOUS\". Ambiguous bases found in the query sequence (e.g., N) stxtyper_complete_operons String Comma-separated list of all COMPLETE operons detected by StxTyper. Show multiple hits if present in results. stxtyper_docker String Name of docker image used by the stxtyper task. stxtyper_extended_operons String Comma-separated list of all EXTENDED operons detected by StxTyper if coding sequence extends beyond the reference stop codon for one or both of the reference proteins. stxtyper_novel_hits String Comma-separated list of matches that have the OPERON output of \"COMPLETE_NOVEL\". Possible outputs \"stx1\", \"stx2\", or \"stx1,stx2\" stxtyper_num_hits Int Number of \"hits\" or rows present in the <code>stxtyper_report</code> TSV file stxtyper_partial_hits String Possible outputs \"stx1\", \"stx2\", or \"stx1,stx2\". Tells the user that there was a partial hit to either the A or B subunit, but does not describe which subunit, only the possible types from the PARTIAL matches. stxtyper_report File Raw results TSV file produced by StxTyper stxtyper_stx_frameshifts_or_internal_stop_hits String Comma-separated list of matches that have the OPERON output of \"FRAMESHIFT\" or \"INTERNAL_STOP\". Possible outputs \"stx1\", \"stx2\", or \"stx1,stx2\" stxtyper_version String Version of StxTyper used taxon_table_status String Status of the taxon table upload theiaprok_fasta_analysis_date String Date of TheiaProk FASTA workflow execution theiaprok_fasta_version String Version of TheiaProk FASTA workflow execution ts_mlst_allelic_profile String Profile of MLST loci and allele numbers predicted by MLST ts_mlst_docker String Docker image used for MLST ts_mlst_novel_alleles File FASTA file containing nucleotide sequence of any alleles that are not in the MLST database used by TheiaProk ts_mlst_predicted_secondary_st String ST predicted by secondary MLST run ts_mlst_predicted_st String ST predicted by MLST ts_mlst_pubmlst_scheme String PubMLST scheme used byMLST ts_mlst_pubmlst_secondary_scheme String PubMLST secondary scheme used by MLST ts_mlst_results File TSV report with detailed MLST profile, including https://github.com/tseemann/mlst#missing-data ts_mlst_secondary_allelic_profile String Profile of alleles predicted by secondary MLST run ts_mlst_secondary_novel_alleles File FASTA file containing nucleotide sequence of any alleles that are not in the MLST database used by TheiaProk, from the secondary scheme run ts_mlst_version String Version of Torsten Seeman\u2019s MLST tool used virulencefinder_docker String VirulenceFinder docker image used virulencefinder_hits String Virulence genes detected by VirulenceFinder virulencefinder_report_tsv File Output TSV file created by VirulenceFinder Variable Type Description abricate_abaum_database String Database of reference A. baumannii plasmid typing genes used for plasmid typing abricate_abaum_docker String Docker file used for running abricate abricate_abaum_plasmid_tsv File https://github.com/tseemann/abricate#output containing a row for each A. baumannii plasmid type gene found in the sample abricate_abaum_plasmid_type_genes String A. baumannii Plasmid typing genes found in the sample; from GENE column in https://github.com/tseemann/abricate#output abricate_abaum_version String Version of abricate used for A. baumannii plasmid typing abricate_database String Database of reference used with Abricate abricate_docker String Docker file used for running abricate abricate_genes String Genes found in the sample; from GENE column in https://github.com/tseemann/abricate#output abricate_results_tsv File https://github.com/tseemann/abricate#output containing a row for each gene found in the sample abricate_version String Version of abricate used for A. baumannii plasmid typing abricate_vibrio_biotype String Biotype classification according to tcpA gene sequence (Classical or ElTor) abricate_vibrio_ctxA String Presence or absence of the ctxA gene abricate_vibrio_database String Database to use while running abricate abricate_vibrio_detailed_tsv File Detailed ABRicate output file abricate_vibrio_docker String Docker file used for running abricate abricate_vibrio_ompW String Presence or absence of the ompW gene abricate_vibrio_serogroup String Serotype classification as O1 (wbeN gene), O139 (wbfR gene) or not detected. abricate_vibrio_toxR String Presence or absence of the toxR gene abricate_vibrio_version String The abricate version run agrvate_agr_canonical String Canonical or non-canonical agrD agrvate_agr_group String Agr group agrvate_agr_match_score String Match score for agr group agrvate_agr_multiple String If multiple agr groups were found agrvate_agr_num_frameshifts String Number of frameshifts found in CDS of extracted agr operon agrvate_docker String The docker used for AgrVATE agrvate_results File A gzipped tarball of all results agrvate_summary File The summary file produced agrvate_version String The version of AgrVATE used amr_search_csv File CSV formatted AMR profile amr_search_docker String Docker image used to run AMR_Search amr_search_results File JSON formatted AMR profile including BLAST results amr_search_results_pdf File PDF formatted AMR profile amr_search_version String Version of AMR_Search libraries used amrfinderplus_all_report File Output TSV file from AMRFinderPlus (described https://github.com/ncbi/amr/wiki/Running-AMRFinderPlus#fields) amrfinderplus_amr_betalactam_betalactam_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to beta-lactams amrfinderplus_amr_betalactam_carbapenem_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to carbapenem amrfinderplus_amr_betalactam_cephalosporin_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to cephalosporin amrfinderplus_amr_betalactam_cephalothin_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to cephalothin amrfinderplus_amr_betalactam_genes String Beta-lactam AMR genes identified by AMRFinderPlus amrfinderplus_amr_betalactam_methicillin_genes String Beta-lactam AMR genes identified by AMRFinderPlus that are known to confer resistance to methicilin amrfinderplus_amr_classes String AMRFinderPlus predictions for classes of drugs that genes found in the reads are known to confer resistance to amrfinderplus_amr_core_genes String AMR genes identified by AMRFinderPlus where the scope is \"core\" amrfinderplus_amr_plus_genes String AMR genes identified by AMRFinderPlus where the scope is \"plus\" amrfinderplus_amr_report File TSV file detailing AMR genes only, from the amrfinderplus_all_report amrfinderplus_amr_subclasses String More specificity about the drugs that genes identified in the reads confer resistance to amrfinderplus_db_version String AMRFinderPlus database version used amrfinderplus_stress_genes String Stress genes identified by AMRFinderPlus amrfinderplus_stress_report File TSV file detailing stress genes only, from the amrfinderplus_all_report amrfinderplus_version String AMRFinderPlus version used amrfinderplus_virulence_genes String Virulence genes identified by AMRFinderPlus amrfinderplus_virulence_report File TSV file detailing virulence genes only, from the amrfinderplus_all_report ani_highest_percent Float Highest ANI between query and any given reference genome (top species match) ani_highest_percent_bases_aligned Float Percentage of bases aligned between query genome and top species match ani_mummer_docker String Docker image used to run the ANI_mummer task ani_mummer_version String Version of MUMmer used ani_output_tsv File Full output TSV from ani-m ani_top_species_match String Species of genome with highest ANI to query FASTA arln_assembly_ratio String Assembly ratio of the final assembly compared to the mean assembly length of the taxon. These stats are gathered from a statistics file created by the CDC aggregating NCBI assembly data by taxon. arln_assembly_zscore String ZScore of the samples assembly length to assess the uniformity of the assembly when compared to taxon means. arln_stats_docker_version String Docker version for task_arln_stats.wdl arln_taxon_assembly_ratio_stdev String Reported assembely length standard deviation of the given taxonomy pulled from NCBI aggregated data. arln_taxon_gc_mean String Mean GC percent of the taxon. arln_taxon_gc_percent_stdev String Reported GC percent standard deviation of the given taxonomy pulled from NCBI aggregated data. assembly_length Int Length of assembly (total contig length) as determined by QUAST bakta_gbff File Genomic GenBank format annotation file bakta_gff3 File Generic Feature Format Version 3 file bakta_plot File Bakta plot output PNG file summarizing annotated genome features such as coding sequences, RNA genes, and hypothetical proteins. bakta_summary File Bakta summary output TXT file bakta_tsv File Annotations as simple human readable TSV bakta_version String Bakta version used busco_database String BUSCO database used busco_docker String BUSCO docker image used busco_report File A plain text summary of the results in BUSCO notation busco_results String BUSCO results (see relevant toggle in this block) busco_version String BUSCO software version used ectyper_database_version String Version of the ECTyper database used ectyper_pathodb_version String Version of the ECTyper pathotype database used ectyper_pathotype String Samples pathotype predicted by ECTyper ectyper_pathotype_count Int Number of pathotypes predicted by ECTyper ectyper_pathotype_genes String Pathotype genes observed by ECTyper ectyper_predicted_serotype String Serotype predicted by ECTyper ectyper_qc_result String QC pass or fail for the sample analyzed ectyper_results File TSV file of evidence for ECTyper predicted serotype (see https://github.com/phac-nml/ecoli_serotyping#report-format) ectyper_stx_subtypes String Shiga toxin subtypes predicted by ECTyper ectyper_version String Version of ECTyper used emmtyper_docker String Docker image for emmtyper emmtyper_emm_type String The emm-type of a Streptococcus pyogenes assembly emmtyper_results_tsv File TSV file with emmtyper results emmtyper_version String Version of emmtyper used gambit_closest_genomes File CSV file listing genomes in the GAMBIT database that are most similar to the query assembly gambit_db_version String Version of the GAMBIT database used gambit_docker String GAMBIT Docker used gambit_predicted_taxon String Taxon predicted by GAMBIT gambit_predicted_taxon_rank String Taxon rank of GAMBIT taxon prediction gambit_report File GAMBIT report in a machine-readable format gambit_version String Version of GAMBIT software used gamma_docker String The Docker container used gamma_fasta File The FASTA file reporting gene matches if boolean was set to true gamma_gff File The GFF file reporting gene matches if boolean was set to true gamma_results File The .gamma file reporting gene matches gamma_version String The version of GAMMA used hicap_docker String Docker image used for hicap hicap_genes String cap genes identified. genes on different contigs delimited by;. truncation shown by trailing * hicap_results_tsv File TSV file of hicap output hicap_serotype String hicap serotype hicap_version String hicap version used kaptive_k_locus String Best matching K locus identified by Kaptive kaptive_k_type String Best matching K type identified by Kaptive kaptive_kl_confidence String Kaptive\u2019s confidence in the KL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kaptive_oc_locus String Best matching K locus identified by Kaptive kaptive_ocl_confidence String Kaptive\u2019s confidence in the OCL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kaptive_output_file_k File TSV https://github.com/katholt/Kaptive/wiki/How-to-run#output-filesfrom the K locus from Kaptive kaptive_output_file_oc File TSV https://github.com/katholt/Kaptive/wiki/How-to-run#output-filesfrom the OC locus from Kaptive kaptive_version String Version of Kaptive used kleborate_docker String Kleborate docker image used kleborate_genomic_resistance_mutations String Genomic resistance mutations identifies by Kleborate kleborate_key_resistance_genes String Key resistance genes identified by Kleborate kleborate_klocus String Best matching K locus identified by  Kleborate via Kaptive kleborate_klocus_confidence String Kaptive\u2019s confidence in the KL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kleborate_ktype String Best matching K type identified by  Kleborate via Kaptive kleborate_mlst_sequence_type String https://github.com/katholt/Kleborate/wiki/MLST#multi-locus-sequence-typing-mlst call by Kleborate kleborate_olocus String Best matching OC locus identified by  Kleborate via Kaptive kleborate_olocus_confidence String Kaptive\u2019s confidence in the KL match (see https://github.com/katholt/Kaptive/wiki/Interpreting-the-results) kleborate_otype String Best matching OC type identified by  Kleborate via Kaptive kleborate_output_file File See also https://github.com/katholt/Kleborate/wiki/Scores-and-counts kleborate_resistance_score String Resistance score as given by kleborate kleborate_version String Version of Kleborate used kleborate_virulence_score String Virulence score as given by kleborate kmerfinder_database String Database used to run KmerFinder kmerfinder_docker String Docker image used to run KmerFinder kmerfinder_query_coverage String KmerFinder\u2019s query coverage of the top hit result kmerfinder_results_tsv File Output TSV file created by KmerFinder kmerfinder_template_coverage String Percent of kmer coverage pertaining to the template, or reference selected kmerfinder_top_hit String Top hit species of KmerFinder legsta_predicted_sbt String Sequence based type predicted by Legsta legsta_results File TSV file of legsta results (see https://github.com/tseemann/legsta#output) legsta_version String Version of legsta used lissero_results File TSV results file from LisSero (see https://github.com/MDU-PHL/LisSero#example-output) lissero_serotype String Serotype predicted by LisSero lissero_version String Version of LisSero used meningotype_BAST String BAST type meningotype_FetA String FetA type meningotype_NHBA String NHBA type meningotype_NadA String NBA type meningotype_PorA String PorA type meningotype_PorB String PorB type meningotype_fHbp String fHbp type meningotype_serogroup String Serogroup meningotype_tsv File Full result file meningotype_version String Version of meningotype used n50_value Int N50 of assembly calculated by QUAST ngmaster_ngmast_porB_allele String porB allele number ngmaster_ngmast_sequence_type String NG-MAST sequence type ngmaster_ngmast_tbpB_allele String tbpB allele number ngmaster_ngstar_23S_allele String 23S rRNA allele number ngmaster_ngstar_gyrA_allele String gyrA allele number ngmaster_ngstar_mtrR_allele String mtrR allele number ngmaster_ngstar_parC_allele String parC allele number ngmaster_ngstar_penA_allele String penA allele number ngmaster_ngstar_ponA_allele String ponA allele number ngmaster_ngstar_porB_allele String porB allele number ngmaster_ngstar_sequence_type String NG-STAR sequence type ngmaster_tsv File TSV file with NG-MAST/NG-STAR typing ngmaster_version String ngmaster version number_contigs Int Total number of contigs in assembly pasty_all_serogroups File TSV file with details of each serogroup from pasty (see https://github.com/rpetit3/pasty#example-prefixdetailstsv) pasty_blast_hits File TSV file of BLAST hits from pasty (see https://github.com/rpetit3/pasty#example-prefixblastntsv) pasty_comment String pasty_docker String pasty docker image used pasty_serogroup String Serogroup predicted by pasty pasty_serogroup_coverage Float The breadth of coverage of the O-antigen by pasty pasty_serogroup_fragments Int Number of BLAST hits included in the prediction (fewer is better) pasty_summary_tsv File TSV summary file of pasty outputs (see https://github.com/rpetit3/pasty#example-prefixtsv) pasty_version String Version of pasty used pbptyper_docker String pbptyper docker image used pbptyper_pbptype_predicted_tsv File TSV file of pbptyper results (see https://github.com/rpetit3/pbptyper#example-prefixtsv) pbptyper_predicted_1A_2B_2X String PBP type predicted by pbptyper pbptyper_version String Version of pbptyper used plasmidfinder_db_version String Version of PlasmidFnder used plasmidfinder_docker String PlasmidFinder docker image used plasmidfinder_plasmids String Names of plasmids identified by PlasmidFinder plasmidfinder_results File Output file from PlasmidFinder in TSV format plasmidfinder_seqs File Hit_in_genome_seq.fsa file produced by PlasmidFinder poppunk_GPS_db_version String Version of GPSC database used poppunk_docker String PopPUNK docker image with GPSC database used poppunk_gps_cluster String GPS cluster predicted by PopPUNK poppunk_gps_external_cluster_csv File GPSC v6 scheme designations poppunk_version String Version of PopPUNK used prokka_gbk File GenBank file produced from Prokka annotation of input FASTA prokka_gff File Prokka output GFF3 file containing sequence and annotation (you can view this in IGV) prokka_sqn File A Sequin file for GenBank submission qc_check String A string that indicates whether or not the sample passes a set of pre-determined and user-provided QC thresholds qc_standard File The file used in the QC Check task containing the QC thresholds. quast_gc_percent Float The GC percent of your sample quast_report File TSV report from QUAST quast_version String The version of QUAST resfinder_db_version String Version of ResFinder database resfinder_docker String ResFinder docker image used resfinder_pheno_table File Table containing al AMR phenotypes resfinder_pheno_table_species File Table with species-specific AMR phenotypes resfinder_pointfinder_pheno_table File TSV showing presence(1)/absence(0) of predicted resistance against an antibiotic class resfinder_pointfinder_results File Predicted point mutations, grouped by the gene they occur in resfinder_predicted_pheno_resistance String Semicolon delimited list of antimicrobial drugs and associated genes and/or point mutations.\u00a0: , , ; : , ; resfinder_predicted_resistance_Amp String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Ampicillin based on resfinder phenotypic predictions resfinder_predicted_resistance_Axo String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Ceftriaxone based on resfinder phenotypic predictions resfinder_predicted_resistance_Azm String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Azithromycin based on resfinder phenotypic predictions resfinder_predicted_resistance_Cip String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Ciprofloxacin based on resfinder phenotypic predictions resfinder_predicted_resistance_Smx String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Sulfamethoxazole based on resfinder phenotypic predictions resfinder_predicted_resistance_Tmp String States either\u00a0Resistance\u00a0or\u00a0No Resistance predicted\u00a0to Trimothoprim based on resfinder phenotypic predictions resfinder_predicted_xdr_shigella String Final prediction of XDR Shigella status based on CDC definition. Explanation can be found in the description above this table. resfinder_results File Predicted resistance genes grouped by antibiotic class resfinder_seqs File FASTA of resistance gene sequences from user\u2019s input sequence seq_platform String Description of the sequencing methodology used to generate the input read data seqsero2_note String Additional notes produced by SeqSero2 seqsero2_predicted_antigenic_profile String Antigenic profile predicted for Salmonella spp. by SeqSero2 seqsero2_predicted_serotype String Serotype predicted by SeqSero2 seqsero2_report String TSV report produced by SeqSero2 seqsero2_version String Version of SeqSero2 used serotypefinder_docker String SerotypeFinder docker image used serotypefinder_report File TSV report produced by SerotypeFinder serotypefinder_serotype String Serotype predicted by SerotypeFinder shigeifinder_H_antigen String H-antigen gene identified by ShigEiFinder shigeifinder_O_antigen String O-antigen gene identified by ShigEiFinder shigeifinder_cluster String Shigella/EIEC cluster identified by ShigEiFinder shigeifinder_docker String ShigEiFinder docker image used shigeifinder_ipaH_presence_absence String Presence (+) or absence (-) of ipaH identified by ShigEiFinder shigeifinder_notes String Any notes output from ShigEiFinder shigeifinder_num_virulence_plasmid_genes String Number of virulence plasmid genes identified by ShigEiFinder shigeifinder_report File TSV report from ShigEiFinder (see https://github.com/LanLab/ShigEiFinder#shigeifinder) shigeifinder_serotype String Serotype predicted by ShigEiFinder shigeifinder_version String ShigEiFinder version used sistr_allele_fasta File FASTA file of novel cgMLST alleles from SISTR sistr_allele_json File JSON file of cgMLST allele sequences and information (see https://github.com/phac-nml/sistr_cmd#cgmlst-allele-search-results) sistr_antigenic_formula String A field that aggregates the O, H1, and H2, antigen values in a single location for convenience sistr_cgmlst File CSV file of the cgMLST allelic profile from SISTR (see https://github.com/phac-nml/sistr_cmd#cgmlst-allelic-profiles-output---cgmlst-profiles-cgmlst-profilescsv) sistr_h1_antigens String The predicted H1 antigen sistr_h2_antigens String The predicted H2 antigen sistr_o_antigens String The predicted O antigen sistr_predicted_serotype String Serotype predicted by SISTR sistr_results File TSV results file produced by SISTR (see https://github.com/phac-nml/sistr_cmd#primary-results-output--o-sistr-results) sistr_serogroup String Serogroup predicted by SISTR sistr_serotype_cgmlst String cgMLST of the serogroup prediicted by SISTR sistr_version String Version of SISTR used spatyper_docker String spatyper docker image used spatyper_repeats String order of identified repeats spatyper_tsv File TSV report with spatyper results spatyper_type String spa type spatyper_version String spatyper version used staphopiasccmec_docker String staphopia-sccmec docker image used staphopiasccmec_hamming_distance_tsv File staphopia-sccmec version staphopiasccmec_results_tsv File sccmec types and mecA presence staphopiasccmec_types_and_mecA_presence String staphopia-sccmec Hamming distance file staphopiasccmec_version String staphopia-sccmec presence and absence TSV file stxtyper_all_hits String Comma-separated list of matches of all types. Includes complete, partial, frameshift, internal stop, and novel hits. List is de-duplicated so multiple identical hits are only listed once. For example if 5 partial stx2 hits are detected in the genome, only 1 \"stx2\" will be listed in this field. To view the potential subtype for each partial hit, the user will need to view the stxtyper_report TSV file. stxtyper_ambiguous_hits String Comma-separated list of matches that have the OPERON output of \"AMBIGUOUS\". Ambiguous bases found in the query sequence (e.g., N) stxtyper_complete_operons String Comma-separated list of all COMPLETE operons detected by StxTyper. Show multiple hits if present in results. stxtyper_docker String Name of docker image used by the stxtyper task. stxtyper_extended_operons String Comma-separated list of all EXTENDED operons detected by StxTyper if coding sequence extends beyond the reference stop codon for one or both of the reference proteins. stxtyper_novel_hits String Comma-separated list of matches that have the OPERON output of \"COMPLETE_NOVEL\". Possible outputs \"stx1\", \"stx2\", or \"stx1,stx2\" stxtyper_num_hits Int Number of \"hits\" or rows present in the <code>stxtyper_report</code> TSV file stxtyper_partial_hits String Possible outputs \"stx1\", \"stx2\", or \"stx1,stx2\". Tells the user that there was a partial hit to either the A or B subunit, but does not describe which subunit, only the possible types from the PARTIAL matches. stxtyper_report File Raw results TSV file produced by StxTyper stxtyper_stx_frameshifts_or_internal_stop_hits String Comma-separated list of matches that have the OPERON output of \"FRAMESHIFT\" or \"INTERNAL_STOP\". Possible outputs \"stx1\", \"stx2\", or \"stx1,stx2\" stxtyper_version String Version of StxTyper used taxon_table_status String Status of the taxon table upload theiaprok_fasta_analysis_date String Date of TheiaProk FASTA workflow execution theiaprok_fasta_version String Version of TheiaProk FASTA workflow execution ts_mlst_allelic_profile String Profile of MLST loci and allele numbers predicted by MLST ts_mlst_docker String Docker image used for MLST ts_mlst_novel_alleles File FASTA file containing nucleotide sequence of any alleles that are not in the MLST database used by TheiaProk ts_mlst_predicted_secondary_st String ST predicted by secondary MLST run ts_mlst_predicted_st String ST predicted by MLST ts_mlst_pubmlst_scheme String PubMLST scheme used byMLST ts_mlst_pubmlst_secondary_scheme String PubMLST secondary scheme used by MLST ts_mlst_results File TSV report with detailed MLST profile, including https://github.com/tseemann/mlst#missing-data ts_mlst_secondary_allelic_profile String Profile of alleles predicted by secondary MLST run ts_mlst_secondary_novel_alleles File FASTA file containing nucleotide sequence of any alleles that are not in the MLST database used by TheiaProk, from the secondary scheme run ts_mlst_version String Version of Torsten Seeman\u2019s MLST tool used virulencefinder_docker String VirulenceFinder docker image used virulencefinder_hits String Virulence genes detected by VirulenceFinder virulencefinder_report_tsv File Output TSV file created by VirulenceFinder"},{"location":"workflows/genomic_characterization/theiaviral/","title":"TheiaViral Workflow Series","text":""},{"location":"workflows/genomic_characterization/theiaviral/#theiaviral-workflow-series","title":"TheiaViral Workflow Series","text":""},{"location":"workflows/genomic_characterization/theiaviral/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Genomic Characterization Viral vX.X.X Yes Sample-level TheiaViral_Illumina_PE_PHB, TheiaViral_ONT_PHB"},{"location":"workflows/genomic_characterization/theiaviral/#theiaviral-workflows","title":"TheiaViral Workflows","text":"<p>TheiaViral workflows assemble, quality assess, and characterize viral genomes from diverse data sources, including metagenomic samples. TheiaViral workflows can generate consensus assemblies of recalcitrant viruses, including diverse or recombinant lineages, such as rabies virus and norovirus, through a three-step approach: 1) generating an intermediate de novo assembly from taxonomy-filtered reads, 2) selecting the best reference from a database of ~200,000 viral genomes using average nucleotide identity, and 3) producing a final consensus assembly through reference-based read mapping and variant calling. Reference genomes can be directly provided to TheiaViral to bypass de novo assembly, which enables compatibility with tiled amplicon sequencing data. Targeted viral characterization is functional for lineages listed below.</p> What are the main differences between the TheiaViral and TheiaCov workflows? <ul> <li> <p> TheiaCov Workflows</p> <ul> <li>For amplicon-derived viral sequencing methods</li> <li>Supports a limited number of pathogens</li> <li>Uses manually curated, static reference genomes</li> </ul> </li> <li> <p> TheiaViral Workflows</p> <ul> <li>Designed for a variety of sequencing methods</li> <li>Supports relatively diverse and recombinant pathogens</li> <li>Dynamically identifies the most similar reference genome for consensus assembly via an intermediate de novo assembly</li> </ul> </li> </ul> Segmented viruses <p>Segmented viruses are accounted for in TheiaViral. The reference genome database excludes segmented viral nucleotide accessions, while including RefSeq assembly accessions that include all viral segments. Consensus assembly modules are constructed to handle multi-segment references.</p>"},{"location":"workflows/genomic_characterization/theiaviral/#workflow-diagram","title":"Workflow Diagram","text":"TheiaViral_Illumina_PETheiaViral_ONT <p>TheiaViral_Illumina_PE Workflow Diagram</p> <p></p> <p>TheiaViral_ONT Workflow Diagram</p> <p></p>"},{"location":"workflows/genomic_characterization/theiaviral/#theiaviral-workflows-for-different-input-types","title":"TheiaViral Workflows for Different Input Types","text":"<ul> <li> TheiaViral_Illumina_PE <p>Illumina_PE Input Read Data</p> <p>The TheiaViral_Illumina_PE workflow inputs Illumina paired-end read data. Read file extensions should be <code>.fastq</code> or <code>.fq</code>, and can optionally include the <code>.gz</code> compression extension. Theiagen recommends compressing files with gzip before Terra uploads to minimize data upload time and storage costs.</p> <p>Modifications to the optional parameter for <code>trim_minlen</code> may be required to appropriately trim reads shorter than 2 x 150 bp (i.e. generated using a 300-cycle sequencing kit), such as the 2 x 75bp reads generated using a 150-cycle sequencing kit.</p> </li> <li> <p></p> TheiaViral_ONT <p></p> <p>ONT Input Read Data</p> <p>The TheiaViral_ONT workflow inputs base-called Oxford Nanopore Technology (ONT) read data. Read file extensions should be <code>.fastq</code> or <code>.fq</code>, and can optionally include the <code>.gz</code> compression extension. Theiagen recommends compressing files with gzip before Terra uploads to minimize data upload time and storage costs.</p> <p>It is recommended to trim adapter sequencings via <code>dorado</code> basecalling prior to running TheiaViral_ONT, though <code>porechop</code> can optionally be called to trim adapters within the workflow.</p> <p>The ONT sequencing kit and base-calling approach can produce substantial variability in the amount and quality of read data. Genome assemblies produced by the TheiaViral_ONT workflow must be quality assessed before reporting results. We recommend using the Dorado_Basecalling_PHB workflow if applicable.</p> </li> </ul>"},{"location":"workflows/genomic_characterization/theiaviral/#inputs","title":"Inputs","text":"<code>taxon</code> required input parameter <p><code>taxon</code> is the standardized taxonomic name (e.g. \"Lyssavirus rabies\") or NCBI taxon ID (e.g. \"11292\") of the desired virus to analyze. Inputs must be represented in the NCBI taxonomy database and do not have to be species-level (see <code>read_extraction_rank</code> below).</p> <code>host</code> optional input parameter <p>The <code>host</code> input triggers the Host Decontaminate workflow, which removes reads that map to a reference host genome. This input needs to be an NCBI Taxonomy-compatible taxon or an NCBI assembly accession. If using a taxon, the first retrieved genome corresponding to that taxon is retrieved. If using an accession, it must be coupled with the Host Decontaminate task <code>is_accession</code> (ONT) or Read QC Trim PE <code>host_is_accession</code> (Illumina) boolean populated as \"true\".</p> <code>extract_unclassified</code> optional input parameter <p>By default, the <code>extract_unclassified</code> parameter is set to \"true\", which indicates that reads that are not classified by Kraken2 (Illumina) or Metabuli (ONT) will be included with reads classified as the input <code>taxon</code>. These classification software most often do not comprehensively classify reads using the default RefSeq databases, so extracting unclassified reads is desirable when host and contaminant reads have been sufficiently decontaminated. Host decontamination occurs in TheiaViral using NCBI <code>sra-human-scrubber</code>, read classification to the human genome, and/or via mapping reads to the inputted <code>host</code>. Contaminant viral reads are mostly excluded because they will be often be classified against the default RefSeq classification databases. Consider setting <code>extract_unclassified</code> to false if de novo assembly or Skani reference selection is failing.</p> <code>min_allele_freq</code>, <code>min_depth</code>, and <code>min_map_quality</code> optional input parameters <p>These parameters have a direct effect on the variants that will ultimately be reported in the consensus assembly. <code>min_allele_freq</code> determines the minimum proportion of an allelic variant to be reported in the consensus assembly. <code>min_depth</code> and <code>min_map_quality</code> affect how \"N\" is reported in the consensus, i.e. depth below <code>min_depth</code> is reported as \"N\" and reads with mapping quality below <code>min_map_quality</code> are not included in depth calculations.</p> <code>read_extraction_rank</code> optional input parameter <p>By default, the <code>read_extraction_rank</code> parameter is set to \"family\", which indicates that reads will be extracted if they are classified as the taxonomic family of the input <code>taxon</code>, including all descendant taxa of the family. Read classification may not resolve to the rank of the input <code>taxon</code>, so these reads may be classified at higher ranks. For example, some Lyssavirus rabies (species) reads may only be resolved to Lyssavirus (genus), so they would not be extracted if the <code>read_extraction_rank</code> is set to \"species\". Setting the <code>read_extraction_rank</code> above the inputted <code>taxon</code>'s rank can therefore dramatically increase the number of reads recovered, at the potential cost of including other viruses. This likely is not a problem for scarcely represented lineages, e.g. a sample that is expected to include Lyssavirus rabies is unlikely to contain other viruses of the corresponding family, Rhabdoviridae, within the same sample. However, setting a <code>read_extraction_rank</code> far beyond the input <code>taxon</code> rank can be problematic when multiple representatives of the same viral family are included in similar abundance within the same sample. To further refine the desired <code>read_extraction_rank</code>, please review the corresponding classification reports of the respective classification software (kraken2 for Illumina and Metabuli for ONT)</p> TheiaViral_Illumina_PETheiaViral_ONT Terra Task Name Variable Type Description Default Value Terra Status theiaviral_illumina_pe read1 File llumina forward read file in FASTQ file format (compression optional) Required theiaviral_illumina_pe read2 File llumina reverse read file in FASTQ file format (compression optional) Required theiaviral_illumina_pe samplename String Nme of the sample being analyzed Required theiaviral_illumina_pe taxon String Taxon ID or organism name of interest Required bwa cpu Int Number of CPUs to allocate to the task 6 Optional bwa disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional bwa docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional bwa memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional checkv_consensus checkv_db File CheckV database file gs://theiagen-public-resources-rp/reference_data/databases/checkv/checkv-db-v1.5.tar.gz Optional checkv_consensus cpu Int Number of CPUs to allocate to the task 2 Optional checkv_consensus disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional checkv_consensus docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/checkv:1.0.3 Optional checkv_consensus memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional checkv_denovo checkv_db File CheckV database file gs://theiagen-public-resources-rp/reference_data/databases/checkv/checkv-db-v1.5.tar.gz Optional checkv_denovo cpu Int Number of CPUs to allocate to the task 2 Optional checkv_denovo disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional checkv_denovo docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/checkv:1.0.3 Optional checkv_denovo memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional clean_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional clean_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional clean_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional clean_check_reads max_genome_length Int Maximum genome length able to pass read screening 2673870 Optional clean_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional clean_check_reads min_basepairs Int Minimum base pairs to pass read screening 15000 Optional clean_check_reads min_coverage Int Minimum coverage to pass read screening 10 Optional clean_check_reads min_genome_length Int Minimum genome length to pass read screening 1500 Optional clean_check_reads min_proportion Int Minimum read proportion to pass read screening 40 Optional clean_check_reads min_reads Int Minimum reads to pass read screening 50 Optional consensus char_unknown String Character used to represent unknown bases in the consensus sequence N Optional consensus count_orphans Boolean True/False that determines if anomalous read pairs are NOT skipped in variant calling. Anomalous read pairs are those marked in the FLAG field as paired in sequencing but without the properly-paired flag set. TRUE Optional consensus cpu Int Number of CPUs to allocate to the task 8 Optional consensus cpu Int Number of CPUs to allocate to the task 2 Optional consensus disable_baq Boolean True/False that determines if base alignment quality (BAQ) computation should be disabled during samtools mpileup before consensus generation TRUE Optional consensus disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional consensus docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional consensus max_depth Int For a given position, read at maximum INT number of reads per input file during samtools mpileup before consensus generation 600000 Optional consensus memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional consensus memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional consensus min_bq Int Minimum base quality required for a base to be considered during samtools mpileup before consensus generation 0 Optional consensus skip_N Boolean True/False that determines if \"N\" bases should be skipped in the consensus sequence FALSE Optional consensus_qc cpu Int Number of CPUs to allocate to the task 1 Optional consensus_qc disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional consensus_qc docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional consensus_qc memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional ivar_variants cpu Int Number of CPUs to allocate to the task 2 Optional ivar_variants disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ivar_variants docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ivar:1.3.1-titan Optional ivar_variants memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional ivar_variants reference_gff File A GFF file in the GFF3 format can be supplied to specify coordinates of open reading frames (ORFs) so iVar can identify codons and translate variants into amino acids Optional megahit cpu Int Number of CPUs to allocate to the task 4 Optional megahit disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional megahit docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/megahit:1.2.9 Optional megahit kmers String Comma-separated list of kmer sizes to use for assembly. All must be odd, in the range 15-255, increment &lt;= 28 21,29,39,59,79,99,119,141 Optional megahit megahit_opts String Additional parameters for MEGAHIT assembler Optional megahit memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional megahit min_contig_length Int Minimum contig length for MEGAHIT assembler 1 Optional morgana_magic abricate_flu_cpu Int Number of CPUs to allocate to the task 2 Optional morgana_magic abricate_flu_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional morgana_magic abricate_flu_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-insaflu-220727 Optional morgana_magic abricate_flu_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional morgana_magic abricate_flu_min_percent_coverage Int Minimum DNA percent coverage 60 Optional morgana_magic abricate_flu_min_percent_identity Int Minimum DNA percent identity 70 Optional morgana_magic assembly_metrics_cpu Int Number of CPUs to allocate to the task 2 Optional morgana_magic assembly_metrics_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional morgana_magic assembly_metrics_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional morgana_magic assembly_metrics_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional morgana_magic genoflu_cpu Int Number of CPUs to allocate to the task 1 Optional morgana_magic genoflu_cross_reference File An Excel file to cross-reference BLAST findings; probably useful if novel genotypes are not in the default file used by genoflu.py Optional morgana_magic genoflu_disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional morgana_magic genoflu_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/genoflu:1.06 Optional morgana_magic genoflu_memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional morgana_magic irma_cpu Int Number of CPUs to allocate to the task 4 Optional morgana_magic irma_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional morgana_magic irma_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/irma:1.2.0 Optional morgana_magic irma_keep_ref_deletions Boolean True/False variable that determines if sites missed (i.e. 0 reads for a site in the reference genome) during read gathering should be deleted by ambiguation by inserting N's or deleting the sequence entirely. False sets this IRMA paramater to \"DEL\" and true sets it to \"NNN\" TRUE Optional morgana_magic irma_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional morgana_magic nextclade_cpu Int Number of CPUs to allocate to the task 2 Optional morgana_magic nextclade_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional morgana_magic nextclade_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.10.2 Optional morgana_magic nextclade_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional morgana_magic nextclade_output_parser_cpu Int Number of CPUs to allocate to the task 2 Optional morgana_magic nextclade_output_parser_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional morgana_magic nextclade_output_parser_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/python/python:3.8.18-slim Optional morgana_magic nextclade_output_parser_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional morgana_magic pangolin_cpu Int Number of CPUs to allocate to the task 2 Optional morgana_magic pangolin_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional morgana_magic pangolin_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.10.2 Optional morgana_magic pangolin_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional ncbi_datasets cpu Int Number of CPUs to allocate to the task 1 Optional ncbi_datasets disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional ncbi_datasets docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ncbi-datasets:16.38.1 Optional ncbi_datasets include_gbff Boolean True/False to include gbff files in the output FALSE Optional ncbi_datasets include_gff3 Boolean True/False to include gff3 files in the output FALSE Optional ncbi_datasets memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional ncbi_identify complete Boolean Only query genomes labeled complete TRUE Optional ncbi_identify cpu Int Number of CPUs to allocate to the task 1 Optional ncbi_identify disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional ncbi_identify docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ncbi-datasets:16.38.1 Optional ncbi_identify memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional ncbi_identify refseq Boolean Only query RefSeq genomes TRUE Optional ncbi_identify summary_limit Int Maximum number of genomes to return in the summary 100 Optional ncbi_identify use_ncbi_virus Boolean Set to true to download from NCBI Virus Datasets FALSE Optional quast_denovo cpu Int Number of CPUs to allocate to the task 2 Optional quast_denovo disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional quast_denovo docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/quast:5.0.2 Optional quast_denovo memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional rasusa bases String Explicitly set the number of bases required e.g., 4.3kb, 7Tb, 9000, 4.1MB. If this option is given, --coverage and --genome-size are ignored Optional rasusa coverage Float The desired coverage to sub-sample the reads to. If --bases is not provided, this option and --genome-size are required 250 Optional rasusa cpu Int Number of CPUs to allocate to the task 4 Optional rasusa disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional rasusa docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/rasusa:2.1.0 Optional rasusa frac Float Subsample to a fraction of the reads - e.g., 0.5 samples half the reads Optional rasusa memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional rasusa num Int Subsample to a specific number of reads Optional rasusa seed Int Random seed for reproducibility Optional read_QC_trim adapters File File with adapter sequences to be removed Optional read_QC_trim bbduk_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional read_QC_trim call_kraken Boolean Internal component, do not modify FALSE Optional read_QC_trim call_midas Boolean Internal component, do not modify FALSE Optional read_QC_trim fastp_args String Additional arguments to use with fastp --detect_adapter_for_pe -g -5 20 -3 20 Optional read_QC_trim host_complete_only Boolean Only download host reference genome labeled \"complete\" FALSE Optional read_QC_trim host_decontaminate_mem Int Memory allocated for minimap2 (in GB) 32 Optional read_QC_trim host_is_accession Boolean Inputted \"host\" is an accession FALSE Optional read_QC_trim host_refseq Boolean Internal component, do not modify TRUE Optional read_QC_trim kraken_cpu Int Number of CPUs to allocate to the task 4 Optional read_QC_trim kraken_disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional read_QC_trim kraken_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional read_QC_trim midas_db File Internal component, do not modify gs://theiagen-public-files-rp/terra/theiaprok-files/midas/midas_db_v1.2.tar.gz Optional read_QC_trim phix File A file containing the phix used during Illumina sequencing; used in the BBDuk task Optional read_QC_trim read_processing String The name of the tool to perform basic read processing; options: \"trimmomatic\" or \"fastp\" trimmomatic Optional read_QC_trim read_qc String The tool used for quality control (QC) of reads. Options are \"fastq_scan\" (default) and \"fastqc\" fastq_scan Optional read_QC_trim target_organism String Internal component, do not modify Optional read_QC_trim trim_min_length Int Specifies minimum length of each read after trimming to be kept 75 Optional read_QC_trim trim_quality_min_score Int Specifies the average quality of bases in a sliding window to be kept 30 Optional read_QC_trim trim_window_size Int Specifies window size for trimming (the number of bases to average the quality across) 4 Optional read_QC_trim trimmomatic_args String Additional arguments to pass to trimmomatic. \"-phred33\" specifies the Phred Q score encoding which is almost always phred33 with modern sequence data. -phred33 Optional read_mapping_stats cpu Int Number of CPUs to allocate to the task 2 Optional read_mapping_stats disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_mapping_stats docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional read_mapping_stats memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional skani cpu Int Number of CPUs to allocate to the task 2 Optional skani disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional skani docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/skani:0.2.2 Optional skani memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional skani skani_db File Skani database file gs://theiagen-public-resources-rp/reference_data/databases/skani/skani_db_20250613.tar Optional spades cpu Int Number of CPUs to allocate to the task 4 Optional spades disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional spades docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/spades:4.1.0 Optional spades kmers String list of k-mer sizes (must be odd and less than 128) auto Optional spades memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional spades phred_offset Int PHRED quality offset in the input reads (33 or 64) 33 Optional spades spades_opts String Additional parameters for Spades assembler Optional theiaviral_illumina_pe call_metaviralspades Boolean True/False to call assembly with MetaviralSPAdes and use Megahit as fallback TRUE Optional theiaviral_illumina_pe extract_unclassified Boolean True/False that determines if unclassified reads should be extracted and combined with the taxon specific extracted reads TRUE Optional theiaviral_illumina_pe genome_length Int Expected genome length of taxon of interest Optional theiaviral_illumina_pe host String Host taxon/accession to dehost reads, if provided Optional theiaviral_illumina_pe kraken_db File Kraken2 database file gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz Optional theiaviral_illumina_pe min_allele_freq Float Minimum allele frequency required for a variant to populate the consensus sequence 0.6 Optional theiaviral_illumina_pe min_depth Int Minimum read depth required for a variant to populate the consensus sequence 10 Optional theiaviral_illumina_pe min_map_quality Int Minimum mapping quality required for read alignments 20 Optional theiaviral_illumina_pe read_extraction_rank String Taxonomic rank to use for read extraction - limits taxons to only those within the specified ranks. family Optional theiaviral_illumina_pe reference_fasta File Reference genome in FASTA format Optional theiaviral_illumina_pe skip_rasusa Boolean True/False to skip read subsampling with Rasusa TRUE Optional theiaviral_illumina_pe skip_screen Boolean True/False to skip read screening check prior to analysis FALSE Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status theiaviral_ont read1 File Base-called ONT read file in FASTQ file format (compression optional) Required theiaviral_ont samplename String Name of the sample being analyzed Required theiaviral_ont taxon String Taxon ID or organism name of interest Required bcftools_consensus cpu Int Number of CPUs to allocate to the task 2 Optional bcftools_consensus disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional bcftools_consensus docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/bcftools:1.20 Optional bcftools_consensus memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional checkv_consensus checkv_db File CheckV database file gs://theiagen-public-resources-rp/reference_data/databases/checkv/checkv-db-v1.5.tar.gz Optional checkv_consensus cpu Int Number of CPUs to allocate to the task 2 Optional checkv_consensus disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional checkv_consensus docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/checkv:1.0.3 Optional checkv_consensus memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional checkv_denovo checkv_db File CheckV database file gs://theiagen-public-resources-rp/reference_data/databases/checkv/checkv-db-v1.5.tar.gz Optional checkv_denovo cpu Int Number of CPUs to allocate to the task 2 Optional checkv_denovo disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional checkv_denovo docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/checkv:1.0.3 Optional checkv_denovo memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional clair3 clair3_model String Model to be used by Clair3 r1041_e82_400bps_sup_v500 Optional clair3 cpu Int Number of CPUs to allocate to the task 4 Optional clair3 disable_phasing Boolean True/False that determines if variants should be called without whatshap phasing in full alignment calling TRUE Optional clair3 disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional clair3 docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/clair3-extra-models:1.0.10 Optional clair3 enable_gvcf Boolean True/False that determines if an additional GVCF output should generated FALSE Optional clair3 enable_haploid_precise Boolean True/False that determines haploid calling mode where only 1/1 is considered as a variant TRUE Optional clair3 include_all_contigs Boolean True/False that determines if all contigs should be included in the output TRUE Optional clair3 indel_min_af Float Minimum Indel AF required for a candidate variant 0.08 Optional clair3 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional clair3 snp_min_af Float Minimum SNP allele frequency required for a candidate variant. Lowering the value might increase a bit of sensitivity in trade of speed and accuracy 0.08 Optional clair3 variant_quality Int If set, variants with &gt;$qual will be marked PASS, or LowQual otherwise 2 Optional clean_check_reads cpu Int Number of CPUs to allocate to the task 1 Optional clean_check_reads disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional clean_check_reads docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/bactopia/gather_samples:2.0.2 Optional clean_check_reads max_genome_length Int Maximum genome length able to pass read screening 2673870 Optional clean_check_reads memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional clean_check_reads min_basepairs Int Minimum base pairs to pass read screening 15000 Optional clean_check_reads min_coverage Int Minimum coverage to pass read screening 10 Optional clean_check_reads min_genome_length Int Minimum genome length to pass read screening 1500 Optional clean_check_reads min_reads Int Minimum reads to pass read screening 50 Optional consensus_qc cpu Int Number of CPUs to allocate to the task 1 Optional consensus_qc disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional consensus_qc docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional consensus_qc memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional fasta_utilities cpu Int Number of CPUs to allocate to the task 1 Optional fasta_utilities disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional fasta_utilities docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Optional fasta_utilities memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional flye additional_parameters String Additional parameters for Flye assembler Optional flye asm_coverage Int Reduced coverage for initial disjointig assembly Optional flye cpu Int Number of CPUs to allocate to the task 4 Optional flye disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional flye docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/flye:2.9.4 Optional flye flye_polishing_iterations Int Number of polishing iterations 1 Optional flye genome_length Int Expected genome length for assembly - requires asm_coverage Optional flye keep_haplotypes Boolean True/False to prevent collapsing alternative haplotypes FALSE Optional flye memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional flye minimum_overlap Int Minimum overlap between reads Optional flye no_alt_contigs Boolean True/False to disable alternative contig generation FALSE Optional flye read_error_rate Float Expected error rate in reads Optional flye read_type String Type of read data for Flye --nano-hq Optional flye scaffold Boolean True/False to enable scaffolding using graph FALSE Optional host_decontaminate complete_only Boolean Only download genomes labeled \"complete\" FALSE Optional host_decontaminate is_accession Boolean Inputted \"host\" is an accession FALSE Optional host_decontaminate minimap2_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional host_decontaminate read2 File Internal component, do not modify Optional host_decontaminate refseq Boolean Only download RefSeq genomes TRUE Optional mask_low_coverage cpu Int Number of CPUs to allocate to the task 2 Optional mask_low_coverage disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional mask_low_coverage docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/bedtools:2.31.0 Optional mask_low_coverage memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional metabuli cpu Int Number of CPUs to allocate to the task 4 Optional metabuli disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional metabuli docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/metabuli:1.1.0 Optional metabuli memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional metabuli metabuli_db File Metabuli database file gs://theiagen-public-resources-rp/reference_data/databases/metabuli/refseq_virus-v223.tar.gz Optional metabuli min_percent_coverage Float Minimum query coverage threshold (0.0 - 1.0) 0 Optional metabuli min_score Float Minimum sequenece similarity score (0.0 - 1.0) 0 Optional metabuli min_sp_score Float Minimum score for species- or lower-level classification 0 Optional metabuli taxonomy_path File Path to taxonomy file gs://theiagen-public-resources-rp/reference_data/databases/metabuli/new_taxdump.tar.gz Optional minimap2 cpu Int Number of CPUs to allocate to the task 2 Optional minimap2 disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional minimap2 docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/minimap2:2.22 Optional minimap2 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional minimap2 query2 File Internal component, do not modify Optional morgana_magic abricate_flu_cpu Int Number of CPUs to allocate to the task 2 Optional morgana_magic abricate_flu_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional morgana_magic abricate_flu_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/abricate:1.0.1-insaflu-220727 Optional morgana_magic abricate_flu_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional morgana_magic abricate_flu_min_percent_coverage Int Minimum DNA percent coverage 60 Optional morgana_magic abricate_flu_min_percent_identity Int Minimum DNA percent identity 70 Optional morgana_magic assembly_metrics_cpu Int Number of CPUs to allocate to the task 2 Optional morgana_magic assembly_metrics_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional morgana_magic assembly_metrics_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional morgana_magic assembly_metrics_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional morgana_magic genoflu_cpu Int Number of CPUs to allocate to the task 1 Optional morgana_magic genoflu_cross_reference File An Excel file to cross-reference BLAST findings; probably useful if novel genotypes are not in the default file used by genoflu.py Optional morgana_magic genoflu_disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional morgana_magic genoflu_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/genoflu:1.06 Optional morgana_magic genoflu_memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional morgana_magic irma_cpu Int Number of CPUs to allocate to the task 4 Optional morgana_magic irma_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional morgana_magic irma_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/irma:1.2.0 Optional morgana_magic irma_keep_ref_deletions Boolean True/False variable that determines if sites missed (i.e. 0 reads for a site in the reference genome) during read gathering should be deleted by ambiguation by inserting N's or deleting the sequence entirely. False sets this IRMA paramater to \"DEL\" and true sets it to \"NNN\" TRUE Optional morgana_magic irma_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional morgana_magic nextclade_cpu Int Number of CPUs to allocate to the task 2 Optional morgana_magic nextclade_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional morgana_magic nextclade_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.10.2 Optional morgana_magic nextclade_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional morgana_magic nextclade_output_parser_cpu Int Number of CPUs to allocate to the task 2 Optional morgana_magic nextclade_output_parser_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional morgana_magic nextclade_output_parser_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/python/python:3.8.18-slim Optional morgana_magic nextclade_output_parser_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional morgana_magic pangolin_cpu Int Number of CPUs to allocate to the task 2 Optional morgana_magic pangolin_disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional morgana_magic pangolin_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.10.2 Optional morgana_magic pangolin_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional morgana_magic read2 File Internal component, do not modify Optional nanoplot_clean cpu Int Number of CPUs to allocate to the task 4 Optional nanoplot_clean disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoplot_clean docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Optional nanoplot_clean max_length Int The maximum length of clean reads, for which reads longer than the length specified will be hidden. 100000 Optional nanoplot_clean memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional nanoplot_raw cpu Int Number of CPUs to allocate to the task 4 Optional nanoplot_raw disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoplot_raw docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/nanoplot:1.40.0 Optional nanoplot_raw max_length Int The maximum length of clean reads, for which reads longer than the length specified will be hidden. 100000 Optional nanoplot_raw memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional nanoq cpu Int Number of CPUs to allocate to the task 2 Optional nanoq disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nanoq docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/nanoq:0.9.0--hec16e2b_1 Optional nanoq max_read_length Int Maximum read length to keep 100000 Optional nanoq max_read_qual Int Maximum read quality to keep 100 Optional nanoq memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional nanoq min_read_length Int Minimum read length to keep 500 Optional nanoq min_read_qual Int Minimum read quality to keep 10 Optional ncbi_datasets cpu Int Number of CPUs to allocate to the task 1 Optional ncbi_datasets disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional ncbi_datasets docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ncbi-datasets:16.38.1 Optional ncbi_datasets include_gbff Boolean True/False to include gbff files in the output FALSE Optional ncbi_datasets include_gff3 Boolean True/False to include gff3 files in the output FALSE Optional ncbi_datasets memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional ncbi_identify complete Boolean Only query genomes labeled complete TRUE Optional ncbi_identify cpu Int Number of CPUs to allocate to the task 1 Optional ncbi_identify disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional ncbi_identify docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ncbi-datasets:16.38.1 Optional ncbi_identify memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional ncbi_identify refseq Boolean Only query RefSeq genomes TRUE Optional ncbi_identify summary_limit Int Maximum number of genomes to return in the summary 100 Optional ncbi_identify use_ncbi_virus Boolean Set to true to download from NCBI Virus Datasets FALSE Optional ncbi_scrub_se cpu Int Number of CPUs to allocate to the task 4 Optional ncbi_scrub_se disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ncbi_scrub_se docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ncbi/sra-human-scrubber:2.2.1 Optional ncbi_scrub_se memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional parse_mapping cpu Int Number of CPUs to allocate to the task 2 Optional parse_mapping disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional parse_mapping docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Optional parse_mapping memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional porechop cpu Int Number of CPUs to allocate to the task 4 Optional porechop disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional porechop docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/porechop:0.2.4 Optional porechop memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional porechop trimopts String Additional trimming options for Porechop Optional quast_denovo cpu Int Number of CPUs to allocate to the task 2 Optional quast_denovo disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional quast_denovo docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/quast:5.0.2 Optional quast_denovo memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional quast_denovo min_contig_length Int Minimum length of contig for QUAST 500 Optional rasusa bases String Explicitly set the number of bases required e.g., 4.3kb, 7Tb, 9000, 4.1MB. If this option is given, --coverage and --genome-size are ignored Optional rasusa coverage Float The desired coverage to sub-sample the reads to. If --bases is not provided, this option and --genome-size are required 250 Optional rasusa cpu Int Number of CPUs to allocate to the task 4 Optional rasusa disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional rasusa docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/rasusa:2.1.0 Optional rasusa frac Float Subsample to a fraction of the reads - e.g., 0.5 samples half the reads Optional rasusa memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional rasusa num Int Subsample to a specific number of reads Optional rasusa read2 File Internal component, do not modify Optional rasusa seed Int Random seed for reproducibility Optional raven cpu Int Number of CPUs to allocate to the task 4 Optional raven disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional raven docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/raven:1.8.3 Optional raven memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional raven raven_identity Float Threshold for overlap between two reads in order to construct an edge between them 0 Optional raven raven_opts String Additional parameters for Raven assembler Optional raven raven_polishing_iterations Int Number of polishing iterations 2 Optional read_mapping_stats cpu Int Number of CPUs to allocate to the task 2 Optional read_mapping_stats disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional read_mapping_stats docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.15 Optional read_mapping_stats memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional skani cpu Int Number of CPUs to allocate to the task 2 Optional skani disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional skani docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/skani:0.2.2 Optional skani memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional skani skani_db File Skani database file gs://theiagen-public-resources-rp/reference_data/databases/skani/skani_db_20250613.tar Optional theiaviral_ont call_porechop Boolean True/False to trim adapters with porechop FALSE Optional theiaviral_ont call_raven Boolean True/False to call assembly with Raven and use Flye as fallback TRUE Optional theiaviral_ont extract_unclassified Boolean True/False that determines if unclassified reads should be extracted and combined with the taxon specific extracted reads TRUE Optional theiaviral_ont genome_length Int Expected genome length of taxon of interest Optional theiaviral_ont host String Host taxon/accession to dehost reads, if provided Optional theiaviral_ont min_allele_freq Float Minimum allele frequency required for a variant to populate the consensus sequence 0.6 Optional theiaviral_ont min_depth Int Minimum read depth required for a variant to populate the consensus sequence 10 Optional theiaviral_ont min_map_quality Int Minimum mapping quality required for read alignments 20 Optional theiaviral_ont read_extraction_rank String Taxonomic rank to use for read extraction - limits taxons to only those within the specified ranks. family Optional theiaviral_ont reference_fasta File Reference genome in FASTA format Optional theiaviral_ont skip_rasusa Boolean True/False to skip read subsampling with Rasusa TRUE Optional theiaviral_ont skip_screen Boolean True/False to skip read screening check prior to analysis FALSE Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/genomic_characterization/theiaviral/#workflow-tasks","title":"Workflow Tasks","text":"TheiaViral_Illumina_PETheiaViral_ONT Versioning <code>versioning</code>: Version Capture <p>The <code>versioning</code> task captures the workflow version from the GitHub (code repository) version.</p> <p>Version Capture Technical details</p> Links Task task_versioning.wdl Taxonomic Identification <code>ncbi_identify</code> <p>The <code>ncbi_identify</code> task uses <code>NCBI Datasets</code> to search the NCBI Viral Genome Database and acquire taxonomic metadata from a user's inputted taxonomy and desired taxonomic rank. This task will always return a taxon ID, name, and rank, and it facilitates multiple downstream functions, including read classification and targeted read extraction. This task also generates a comprehensive summary file of all successful hits to the input <code>taxon</code>, which includes each taxon's accession number, completeness status, genome length, source, and other relevant metadata. Based on this summary, the task also calculates the average expected genome size for the input <code>taxon</code>.</p> <code>taxon</code> input parameter <p>This parameter accepts either a NCBI taxon ID (e.g. <code>11292</code>) or an organism name (e.g. <code>Lyssavirus rabies</code>).</p> <code>rank</code> a.k.a <code>read_extraction_rank</code> input parameter <p>Valid options include: <code>\"species\"</code>, <code>\"genus\"</code>, <code>\"family\"</code>, <code>\"order\"</code>, <code>\"class\"</code>, <code>\"phylum\"</code>, <code>\"kingdom\"</code>, or <code>\"domain\"</code>. By default it is set to <code>\"family\"</code>. This parameter filters metadata to report information only at the taxonomic <code>rank</code> specified by the user, regardless of the taxonomic rank implied by the original input <code>taxon</code>.</p> Important <ul> <li>The <code>rank</code> parameter must specify a taxonomic rank that is equal to or above the input taxon's taxonomic rank.</li> </ul> <p>Examples:</p> <ul> <li>If your input <code>taxon</code> is <code>Lyssavirus rabies</code> (species level) with <code>rank</code> set to <code>family</code>, the task will return information for the family of <code>Lyssavirus rabies</code>: taxon ID for Rhabdoviridae (11270), name \"Rhabdoviridae\", and rank \"family\".</li> <li>If your input <code>taxon</code> is <code>Lyssavirus</code> (genus level) with <code>rank</code> set to <code>species</code>, the task will fail because it cannot determine species information from an inputted genus.</li> </ul> <p>NCBI Datasets Technical Details</p> Links Task task_identify_taxon_id.wdl Software Source Code NCBI Datasets on GitHub Software Documentation NCBI Datasets Documentation on NCBI Original Publication(s) Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets Read Quality Control, Trimming, Filtering, Identification and Extraction <code>read_QC_trim</code> <p><code>read_QC_trim</code> is a sub-workflow that removes low-quality reads, low-quality regions of reads, and sequencing adapters to improve data quality. It uses a number of tasks, described below. The differences between the PE and SE versions of the <code>read_QC_trim</code> sub-workflow lie in the default parameters, the use of two or one input read file(s), and the different output files.</p> <code>HRRT</code>: Human Host Sequence Removal <p>All reads of human origin are removed, including their mates, by using NCBI's human read removal tool (HRRT). </p> <p>HRRT is based on the SRA Taxonomy Analysis Tool and employs a k-mer database constructed of k-mers from Eukaryota derived from all human RefSeq records with any k-mers found in non-Eukaryota RefSeq records subtracted from the database.</p> <p>NCBI-Scrub Technical Details</p> Links Task task_ncbi_scrub.wdl Software Source Code HRRT on GitHub Software Documentation HRRT on NCBI <p>By default, <code>read_processing</code> is set to <code>\"trimmomatic\"</code>. To use <code>fastp</code> instead, set <code>read_processing</code> to <code>\"fastp\"</code>. These tasks are mutually exclusive.</p> <code>Trimmomatic</code>: Read Trimming (default) <p>Read proccessing is available via <code>Trimmomatic</code> by default.</p> <p>Trimmomatic trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>Trimmomatic</code> Technical Details</p> Links Task task_trimmomatic.wdl Software Source Code Trimmomatic on GitHub Software Documentation Trimmomatic Website Original Publication(s) Trimmomatic: a flexible trimmer for Illumina sequence data <code>fastp</code>: Read Trimming (alternative) <p>To activate this task, set <code>read_processing</code> to <code>\"fastp\"</code>.</p> <p><code>fastp</code> trims low-quality regions of Illumina paired-end or single-end reads with a sliding window (with a default window size of 4, specified with <code>trim_window_size</code>), cutting once the average quality within the window falls below the <code>trim_quality_trim_score</code> (default of 20 for paired-end, 30 for single-end). The read is discarded if it is trimmed below <code>trim_minlen</code> (default of 75 for paired-end, 25 for single-end).</p> <p><code>fastp</code> also has additional default parameters and features that are not a part of <code>trimmomatic</code>'s default configuration.</p> <code>fastp</code> default read-trimming parameters Parameter Explanation -g enables polyG tail trimming -5 20 enables read end-trimming -3 20 enables read end-trimming --detect_adapter_for_pe enables adapter-trimming only for paired-end reads <p>Additional arguments can be passed using the <code>fastp_args</code> optional parameter.</p> <p>Trimmomatic and fastp Technical Details</p> Links Task task_fastp.wdl Software Source Code fastp on GitHub Software Documentation fastp on GitHub Original Publication(s) fastp: an ultra-fast all-in-one FASTQ preprocessor <code>BBDuk</code>: Adapter Trimming and PhiX Removal <p>Adapters are manufactured oligonucleotide sequences attached to DNA fragments during the library preparation process. In Illumina sequencing, these adapter sequences are required for attaching reads to flow cells. You can read more about Illumina adapters here. For genome analysis, it's important to remove these sequences since they're not actually from your sample. If you don't remove them, the downstream analysis may be affected.</p> <p>The <code>bbduk</code> task removes adapters from sequence reads. To do this:</p> <ul> <li>Repair from the BBTools package reorders reads in paired fastq files to ensure the forward and reverse reads of a pair are in the same position in the two fastq files (it re-pairs).</li> <li>BBDuk  (\"Bestus Bioinformaticus\" Decontamination Using Kmers) is then used to trim the adapters and filter out all reads that have a 31-mer match to PhiX, which is commonly added to Illumina sequencing runs to monitor and/or improve overall run quality.</li> </ul> <p>BBDuk Technical Details</p> Links Task task_bbduk.wdl Software Source Code BBMap on SourceForge Software Documentation BBDuk Guide (archived) <p>By default, <code>read_qc</code> is set to <code>\"fastq_scan\"</code>. To use <code>fastqc</code> instead, set <code>read_qc</code> to <code>\"fastqc\"</code>. These tasks are mutually exclusive.</p> <code>fastq-scan</code>: Read Quantification (default) <p>Read quantification is available via <code>fastq-scan</code> by default.</p> <p><code>fastq-scan</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p><code>fastq-scan</code> Technical Details</p> Links Task task_fastq_scan.wdl Software Source Code fastq-scan on GitHub Software Documentation fastq-scan on GitHub <code>FastQC</code>: Read Quantification (alternative) <p>To activate this task, set <code>read_qc</code> to <code>\"fastqc\"</code>.</p> <p><code>FastQC</code> quantifies the forward and reverse reads in FASTQ files. For paired-end data, it also provide the total number of read pairs. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>This tool also provides a graphical visualization of the read quality.</p> <p><code>FastQC</code> Technical Details</p> Links Task task_fastqc.wdl Software Source Code FastQC on Github Software Documentation FastQC Website <code>host_decontaminate</code>: Host Read Decontamination <p>Host genetic data is frequently incidentally sequenced alongside pathogens, which can negatively affect the quality of downstream analysis. Host Decontaminate attempts to remove host reads by aligning to a reference host genome acquired on-the-fly. The reference host genome can be acquired via NCBI Taxonomy-compatible taxon input or assembly accession. Host Decontaminate maps inputted reads to the host genome using <code>minimap2</code>, reports mapping statistics to this host genome, and outputs the unaligned dehosted reads. </p> <p>The detailed steps and tasks are as follows:</p> Taxonomic Identification <p>The <code>ncbi_identify</code> task uses <code>NCBI Datasets</code> to search the NCBI Viral Genome Database and acquire taxonomic metadata from a user's inputted taxonomy and desired taxonomic rank. This task will always return a taxon ID, name, and rank, and it facilitates multiple downstream functions, including read classification and targeted read extraction. This task also generates a comprehensive summary file of all successful hits to the input <code>taxon</code>, which includes each taxon's accession number, completeness status, genome length, source, and other relevant metadata. Based on this summary, the task also calculates the average expected genome size for the input <code>taxon</code>.</p> <code>taxon</code> input parameter <p>This parameter accepts either a NCBI taxon ID (e.g. <code>11292</code>) or an organism name (e.g. <code>Lyssavirus rabies</code>).</p> <code>rank</code> a.k.a <code>read_extraction_rank</code> input parameter <p>Valid options include: <code>\"species\"</code>, <code>\"genus\"</code>, <code>\"family\"</code>, <code>\"order\"</code>, <code>\"class\"</code>, <code>\"phylum\"</code>, <code>\"kingdom\"</code>, or <code>\"domain\"</code>. By default it is set to <code>\"family\"</code>. This parameter filters metadata to report information only at the taxonomic <code>rank</code> specified by the user, regardless of the taxonomic rank implied by the original input <code>taxon</code>.</p> Important <ul> <li>The <code>rank</code> parameter must specify a taxonomic rank that is equal to or above the input taxon's taxonomic rank.</li> </ul> <p>Examples:</p> <ul> <li>If your input <code>taxon</code> is <code>Lyssavirus rabies</code> (species level) with <code>rank</code> set to <code>family</code>, the task will return information for the family of <code>Lyssavirus rabies</code>: taxon ID for Rhabdoviridae (11270), name \"Rhabdoviridae\", and rank \"family\".</li> <li>If your input <code>taxon</code> is <code>Lyssavirus</code> (genus level) with <code>rank</code> set to <code>species</code>, the task will fail because it cannot determine species information from an inputted genus.</li> </ul> <p>NCBI Datasets Technical Details</p> Links Task task_identify_taxon_id.wdl Software Source Code NCBI Datasets on GitHub Software Documentation NCBI Datasets Documentation on NCBI Original Publication(s) Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets Download Accession <p>The <code>NCBI Datasets</code> task downloads specified assemblies from NCBI using either the virus or genome (for all other genome types) package as appropriate.</p> <p>This task uses the accession ID output from the <code>skani</code> task to download the the most closely related reference genome to the input assembly. The downloaded reference is then used for downstream analysis, including variant calling and consensus generation.</p> <p>NCBI Datasets Technical Details</p> Links Task task_ncbi_datasets.wdl Software Source Code NCBI Datasets on GitHub Software Documentation NCBI Datasets Documentation on NCBI Original Publication(s) Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets Map Reads to Host <p><code>minimap2</code> is a popular aligner that is used to align reads (or assemblies) to an assembly file. In minimap2, \"modes\" are a group of preset options.</p> <p>The mode used in this task is <code>map-ont</code> which is the default mode for long reads and indicates that long reads of ~10% error rates should be aligned to the reference genome. The output file is in SAM format.</p> <p>For more information regarding modes and the available options for <code>minimap2</code>, please see the minimap2 manpage</p> <p>minimap2 Technical Details</p> Links Task task_minimap2.wdl Software Source Code minimap2 on GitHub Software Documentation minimap2 Original Publication(s) Minimap2: pairwise alignment for nucleotide sequences Extract Unaligned Reads <p>The <code>bam_to_unaligned_fastq</code> task will extract a FASTQ file of reads that failed to align, while removing unpaired reads. </p> <p><code>parse_mapping</code> Technical Details</p> Links Task task_parse_mapping.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <code>assembly_metrics</code>: Mapping Statistics <p>The <code>assembly_metrics</code> task generates mapping statistics from a BAM file. It uses samtools to generate a summary of the mapping statistics, which includes coverage, depth, average base quality, average mapping quality, and other relevant metrics.</p> <p><code>assembly_metrics</code> Technical Details</p> Links Task task_assembly_metrics.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <p>Host Decontaminate Technical Details</p> Links Subworkflow wf_host_decontaminate.wdl <code>Kraken2</code>: Read Identification <p><code>Kraken2</code> is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>This task runs on cleaned reads passed from the <code>read_QC_trim</code> subworkflow and outputs a Kraken2 report detailing taxonomic classifications. It also separates classified reads from unclassified ones.</p> <p>Database-dependent</p> <p>This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz</code>.</p> <p>Kraken2 Technical Details</p> Links Task task_kraken2.wdl Software Source Code Kraken2 on GitHub Software Documentation Kraken2 Documentation Original Publication(s) Improved metagenomic analysis with Kraken 2 <code>krakentools</code>: Read Extraction <p>The <code>task_krakentools.wdl</code> task extracts reads from the Kraken2 output file. It uses the KrakenTools package to extract reads classified at any user-specified taxon ID.</p> <code>extract_unclassified</code> input parameter <p>This parameter determines whether unclassified reads should also be extracted and combined with the <code>taxon</code>-specific extracted reads. By default, this is set to <code>false</code>, meaning that only reads classified to the specified input <code>taxon</code> will be extracted.</p> Important <p>This task will extract reads classified to the input <code>taxon</code> and all of its descendant taxa. The <code>rank</code> input parameter controls the extraction of reads classified at the specified <code>rank</code> and all suboridante taxonomic levels. See task <code>ncbi_identify</code> under the Taxonomic Identification section for more details on the <code>rank</code> input parameter.</p> <p>KrakenTools Technical Details</p> Links Task task_krakentools.wdl Software Source Code KrakenTools on GitHub Software Documentation KrakenTools Original Publication(s) Metagenome analysis using the Kraken software suite <p>read_QC_trim Technical Details</p> Links Subworkflow wf_read_QC_trim_pe.wdlwf_read_QC_trim_se.wdl <code>rasusa</code> <p><code>Rasusa</code> is a tool to randomly subsample sequencing reads to a specified coverage without assuming that all reads are of equal length, making it especially suitable for long-read data while still being applicable to short-read data.</p> <p>The <code>Rasusa</code> task performs subsampling on the input raw reads. By default, it subsamples reads to a target depth of 250X, using the estimated genome length either generated by the <code>ncbi_identify</code> task or provided directly by the user. Disabled by default, users can enable it by setting the <code>skip_rasusa</code> variable to <code>false</code>. The target subsampling depth can also be adjusted by modifying the <code>coverage</code> variable.</p> <code>coverage</code> input parameter <p>This parameter specifies the target coverage for subsampling. The default value is <code>250</code>, but users can adjust it as needed.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs since it performs random subsampling. To ensure reproducibility, set a a value for the <code>rasusa_seed</code> optional input variable.</p> <p>Rasusa Technical Details</p> Links Task task_rasusa.wdl Software Source Code Rasusa on GitHub Software Documentation Rasusa on GitHub Original Publication(s) Rasusa: Randomly subsample sequencing reads to a specified coverage <code>clean_check_reads</code> <p>The <code>screen</code> task ensures the quantity of sequence data is sufficient to undertake genomic analysis. It uses <code>fastq-scan</code> and bash commands for quantification of reads and base pairs, and mash sketching to estimate the genome size and its coverage. At each step, the results are assessed relative to pass/fail criteria and thresholds that may be defined by optional user inputs. Samples are run through all threshold checks, regardless of failures, and the workflow will terminate after the <code>screen</code> task if any thresholds are not met:</p> <ol> <li>Total number of reads: A sample will fail the read screening task if its total number of reads is less than or equal to <code>min_reads</code>.</li> <li>The proportion of basepairs reads in the forward and reverse read files: A sample will fail the read screening if fewer than <code>min_proportion</code> basepairs are in either the reads1 or read2 files.</li> <li>Number of basepairs: A sample will fail the read screening if there are fewer than <code>min_basepairs</code> basepairs</li> <li>Estimated genome size:  A sample will fail the read screening if the estimated genome size is smaller than <code>min_genome_size</code> or bigger than <code>max_genome_size</code>.</li> <li>Estimated genome coverage: A sample will fail the read screening if the estimated genome coverage is less than the <code>min_coverage</code>.</li> </ol> <p>Read screening is performed only on the cleaned reads. The task may be skipped by setting the <code>skip_screen</code> variable to <code>true</code>. Default values vary between the ONT and PE workflow. The rationale for these default values can be found below:</p> Default Thresholds and Rationales Variable Description Default Value Rationale <code>min_reads</code> A sample will fail the read screening task if its total number of reads is less than or equal to <code>min_reads</code> 50 Minimum number of base pairs for 10x coverage of the Hepatitis delta (of the Deltavirus genus) virus divided by 300 (longest Illumina read length) <code>min_basepairs</code> A sample will fail the read screening if there are fewer than <code>min_basepairs</code> basepairs 15000 Greater than 10x coverage of the Hepatitis delta (of the Deltavirus genus) virus <code>min_genome_size</code> A sample will fail the read screening if the estimated genome size is smaller than <code>min_genome_size</code> 1500 Based on the Hepatitis delta (of the Deltavirus genus) genome- the smallest viral genome as of 2024-04-11 (1,700 bp) <code>max_genome_size</code> A sample will fail the read screening if the estimated genome size is smaller than <code>max_genome_size</code> 2673870 Based on the Pandoravirus salinus genome, the biggest viral genome, (2,673,870 bp) with 2 Mbp added <code>min_coverage</code> A sample will fail the read screening if the estimated genome coverage is less than the <code>min_coverage</code> 10 A bare-minimum coverage for genome characterization. Higher coverage would be required for high-quality phylogenetics. <code>min_proportion</code> A sample will fail the read screening if fewer than <code>min_proportion</code> basepairs are in either the reads1 or read2 files 40 Greater than 50% reads are in the read1 file; others are in the read2 file. (PE workflow only) <p>Screen Technical Details</p> Links Task task_screen.wdl (PE sub-task)task_screen.wdl (SE sub-task) De novo Assembly and Reference Selection These tasks are only performed if no reference genome is provided <p>In this workflow, de novo assembly is primarily used to facilitate the selection of a closely related reference genome, though high quality de novo assemblies can be used for downstream analysis. If the user provides an input <code>reference_fasta</code>, the following assembly generation, assembly evaluation, and reference selections tasks will be skipped:</p> <ul> <li><code>spades</code></li> <li><code>megahit</code></li> <li><code>checkv_denovo</code></li> <li><code>quast_denovo</code></li> <li><code>skani</code></li> <li><code>ncbi_datasets</code></li> </ul> <code>spades</code> <p><code>SPAdes</code> (St. Petersburg genome assembler) is a de novo assembly tool that uses de Bruijn graphs to assemble genomes from Illumina short reads.</p> <p>It is run with the <code>--metaviral</code> option, which is recommended for viral genomes. MetaviralSPAdes pipeline consists of three independent steps, <code>ViralAssembly</code> for finding putative viral subgraphs in a metagenomic assembly graph and generating contigs in these graphs, <code>ViralVerify</code> for checking whether the resulting contigs have viral origin and <code>ViralComplete</code> for checking whether these contigs represent complete viral genomes. For more details, please see the original publication.</p> <p>MetaviralSPAdes was selected as the default assembler because it produces the most complete viral genomes within TheiaViral, determined by CheckV quality assessment (see task <code>checkv</code> for technical details).</p> <code>call_metaviralspades</code> input parameter <p>This parameter controls whether or not the <code>spades</code> task is called by the workflow. By default, <code>call_metaviralspades</code> is set to <code>true</code> because MetaviralSPAdes is used as the primary assembler. MetaviralSPAdes is generally recommended for most users, but it might not perform optimally on all datasets. If users encounter issues with MetaviralSPAdes, they can set the <code>call_metaviralspades</code> variable to <code>false</code> to bypass the <code>spades</code> task and instead de novo assemble using MEGAHIT (see task <code>megahit</code> for details). Additionally, if the <code>spades</code> task fails during execution, the workflow will automatically fall back to using MEGAHIT for de novo assembly.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>MetaviralSPAdes Technical Details</p> Links Task task_spades.wdl Software Source Code SPAdes on GitHub Software Documentation SPAdes Manual Original Publication(s) TheiaProk: SPAdes: A New Genome Assembly Algorithm and Its Applications to Single-Cell SequencingTheiaViral: MetaviralSPAdes: assembly of viruses from metagenomic data <code>megahit</code> <p>The MEGAHIT assembler is a fast and memory-efficient de novo assembler that can handle large datasets. While optimized for metagenomics, MEGAHIT also performs well on single-genome assemblies, making it a versatile choice for various assembly tasks.</p> <p>MEGAHIT uses a multiple k-mer strategy that can be beneficial for assembling genomes with varying coverage levels, which is common in metagenomic samples. It constructs succinct de Bruijn graphs to efficiently represent the assembly process, allowing it to handle large and complex datasets with reduced memory usage.</p> <p>This task is optional, turned off by default, and will only be called if MetaviralSPAdes fails. It can be enabled by setting the <code>skip_metaviralspades</code> parameter to <code>true</code>. The <code>megahit</code> task is used as a fallback option if the <code>spades</code> task fails during execution (see task <code>spades</code> for more details).</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>MEGAHIT Technical Details</p> Links Task task_megahit.wdl Software Source Code MEGAHIT on GitHub Software Documentation MEGAHIT on GitHub Original Publication(s) MEGAHIT: an ultra-fast single-node solution for large and complex metagenomics assembly via succinct de Bruijn graph <code>skani</code> <p>The <code>skani</code> task is used to identify and select the most closely related reference genome to the de novo assembly. Skani uses an approximate mapping method without base-level alignment to calculate average nucleotide identity (ANI). It is magnitudes faster than BLAST-based methods and almost as accurate.</p> <p>By default, the reference genome is selected from a database of approximately 200,000 viral genomes. This database was constructed with the following methodology:</p> <ol> <li> <p>Extracting all complete NCBI viral genomes, excluding RefSeq accessions (redundancy), SARS-CoV-2 accessions, and segmented families (Orthomyxoviridae, Hantaviridae, Arenaviridae, and Phenuiviridae). Some complete gene accessions, and not complete genomes, are included because NCBI <code>datasets</code> completeness parameters are susceptible to metadata errors.</p> </li> <li> <p>Adding complete RefSeq segmented viral assembly accessions, which represent segments as individual contigs within the FASTA</p> </li> <li> <p>Adding one SARS-CoV-2 genome for each major pangolin lineage</p> </li> </ol> <p>Skani Technical Details</p> Links Task task_skani.wdl Software Source Code Skani on GitHub Software Documentation Skani Documentation Original Publication(s) Fast and robust metagenomic sequence comparison through sparse chaining with skani <code>ncbi_datasets</code> <p>The <code>NCBI Datasets</code> task downloads specified assemblies from NCBI using either the virus or genome (for all other genome types) package as appropriate.</p> <p>This task uses the accession ID output from the <code>skani</code> task to download the the most closely related reference genome to the input assembly. The downloaded reference is then used for downstream analysis, including variant calling and consensus generation.</p> <p>NCBI Datasets Technical Details</p> Links Task task_ncbi_datasets.wdl Software Source Code NCBI Datasets on GitHub Software Documentation NCBI Datasets Documentation on NCBI Original Publication(s) Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets Reference Mapping <code>bwa</code> <p>The <code>bwa</code> task is a wrapper for the BWA alignment tool. It utilizes the BWA-MEM algorithm to map cleaned reads to the reference genome, either selected by the <code>skani</code> task or provided by the user input <code>reference_fasta</code>. This creates a BAM file which is then sorted using the command <code>samtools sort</code>.</p> <p>BWA Technical Details</p> Links Task task_bwa.wdl Software Source Code BWA on GitHub Software Documentation BWA Documentation Original Publication(s) Fast and accurate short read alignment with Burrows-Wheeler transform <code>read_mapping_stats</code>: Mapping Statistics <p>The <code>read_mapping_stats</code> task generates mapping statistics from a BAM file. It uses samtools to generate a summary of the mapping statistics, which includes coverage, depth, average base quality, average mapping quality, and other relevant metrics.</p> <p><code>read_mapping_stats</code> Technical Details</p> Links Task task_assembly_metrics.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools Variant Calling and Consensus Generation <code>ivar_variants</code>: Variant Calling <p>iVar uses the outputs of <code>samtools mpileup</code> to call single nucleotide variants (SNVs) and insertions/deletions (indels). Several key parameters can be set to determine the stringency of variant calling, including minimum quality, minimum allele frequency, and minimum depth.</p> <p>This task returns a VCF file containing all called variants, the number of detected variants, and the proportion of those variants with allele frequencies between 0.6 and 0.9 (also known as intermediate variants).</p> <code>min_depth</code> input parameter <p>This parameter accepts an integer value to set the minimum read depth for variant calling and subsequent consensus sequence generation. The default value is <code>10</code>.</p> <code>min_map_quality</code> input parameter <p>This parameter accepts an integer value to set the minimum mapping quality for variant calling and subsequent consensus sequence generation. The default value is <code>20</code>.</p> <code>min_allele_freq</code> input parameter <p>This parameter accepts a float value to set the minimum allele frequency for variant calling and subsequent consensus sequence generation. The default value is <code>0.6</code>.</p> <p>iVar Technical Details</p> Links Task task_ivar_variant_call.wdl Software Source Code Ivar on GitHub Software Documentation Ivar Documentation Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar <code>ivar_consensus</code>: Consensus Assembly <p>iVar's <code>consensus</code> tool generates a reference-based consensus assembly. Several parameters can be set that determine the stringency of the consensus assembly, including minimum quality, minimum allele frequency, and minimum depth.</p> <p>This task is functional for segmented viruses by iteratively executing iVar on a contig-by-contig basis and concantenating resulting consensus contigs.</p> <code>min_depth</code> input parameter <p>This parameter accepts an integer value to set the minimum read depth for variant calling and subsequent consensus sequence generation. The default value is <code>10</code>.</p> <code>min_map_quality</code> input parameter <p>This parameter accepts an integer value to set the minimum mapping quality for variant calling and subsequent consensus sequence generation. The default value is <code>20</code>.</p> <code>min_allele_freq</code> input parameter <p>This parameter accepts a float value to set the minimum allele frequency for variant calling and subsequent consensus sequence generation. The default value is <code>0.6</code>.</p> <p>iVar Technical Details</p> Links Task task_ivar_consensus.wdl Software Source Code Ivar on GitHub Software Documentation Ivar Documentation Original Publication(s) An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar Assembly Evaluation and Consensus Quality Control <code>quast_denovo</code> <p>QUAST stands for QUality ASsessment Tool. It evaluates genome/metagenome assemblies by computing various metrics without a reference being necessary. It includes useful metrics such as number of contigs, length of the largest contig and N50.</p> <p>QUAST Technical Details</p> Links Task task_quast.wdl Software Source Code QUAST on GitHub Software Documentation QUAST Manual on SourceForge Original Publication(s) QUAST: quality assessment tool for genome assemblies <code>checkv_denovo</code> &amp; <code>checkv_consensus</code> <p>CheckV is a fully automated command-line pipeline for assessing the quality of viral genomes, including identification of host contamination for integrated proviruses, estimating completeness for genome fragments, and identification of closed genomes.</p> <p>By default, CheckV reports results on a contig-by-contig basis. The <code>checkv</code> task additionally reports both \"weighted_contamination\" and \"weighted_completeness\", which are average percents calculated across the total assembly that are weighted by contig length.</p> <p>CheckV Technical Details</p> Links Task task_checkv.wdl Software Source Code CheckV on Bitbucket Software Documentation CheckV Documentation Original Publication(s) CheckV assesses the quality and completeness of metagenome-assembled viral genomes <code>consensus_qc</code>: Assembly Statistics <p>The consensus_qc task generates a summary of genomic statistics from a consensus genome. This includes the total number of bases, \"N\" bases, degenerate bases, and an estimate of the percent coverage to the reference genome.</p> <p><code>consensus_qc</code> Technical Details</p> Links Task task_consensus_qc.wdl Versioning <code>versioning</code>: Version Capture <p>The <code>versioning</code> task captures the workflow version from the GitHub (code repository) version.</p> <p>Version Capture Technical details</p> Links Task task_versioning.wdl Taxonomic Identification <code>ncbi_identify</code> <p>The <code>ncbi_identify</code> task uses <code>NCBI Datasets</code> to search the NCBI Viral Genome Database and acquire taxonomic metadata from a user's inputted taxonomy and desired taxonomic rank. This task will always return a taxon ID, name, and rank, and it facilitates multiple downstream functions, including read classification and targeted read extraction. This task also generates a comprehensive summary file of all successful hits to the input <code>taxon</code>, which includes each taxon's accession number, completeness status, genome length, source, and other relevant metadata. Based on this summary, the task also calculates the average expected genome size for the input <code>taxon</code>.</p> <code>taxon</code> input parameter <p>This parameter accepts either a NCBI taxon ID (e.g. <code>11292</code>) or an organism name (e.g. <code>Lyssavirus rabies</code>).</p> <code>rank</code> a.k.a <code>read_extraction_rank</code> input parameter <p>Valid options include: <code>\"species\"</code>, <code>\"genus\"</code>, <code>\"family\"</code>, <code>\"order\"</code>, <code>\"class\"</code>, <code>\"phylum\"</code>, <code>\"kingdom\"</code>, or <code>\"domain\"</code>. By default it is set to <code>\"family\"</code>. This parameter filters metadata to report information only at the taxonomic <code>rank</code> specified by the user, regardless of the taxonomic rank implied by the original input <code>taxon</code>.</p> Important <ul> <li>The <code>rank</code> parameter must specify a taxonomic rank that is equal to or above the input taxon's taxonomic rank.</li> </ul> <p>Examples:</p> <ul> <li>If your input <code>taxon</code> is <code>Lyssavirus rabies</code> (species level) with <code>rank</code> set to <code>family</code>, the task will return information for the family of <code>Lyssavirus rabies</code>: taxon ID for Rhabdoviridae (11270), name \"Rhabdoviridae\", and rank \"family\".</li> <li>If your input <code>taxon</code> is <code>Lyssavirus</code> (genus level) with <code>rank</code> set to <code>species</code>, the task will fail because it cannot determine species information from an inputted genus.</li> </ul> <p>NCBI Datasets Technical Details</p> Links Task task_identify_taxon_id.wdl Software Source Code NCBI Datasets on GitHub Software Documentation NCBI Datasets Documentation on NCBI Original Publication(s) Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets Read Quality Control, Trimming, and Filtering <code>NanoPlot</code>: Read Quantification <p>NanoPlot is used for the determination of mean quality scores, read lengths, and number of reads. This task is run once with raw reads as input and once with clean reads as input. If QC has been performed correctly, you should expect fewer clean reads than raw reads.</p> <p>NanoPlot Technical Details</p> Links Task task_nanoplot.wdl Software Source Code NanoPlot on GitHub Software Documentation NanoPlot Documentation Original Publication(s) NanoPack2: population-scale evaluation of long-read sequencing data <code>porechop</code> <p>Porechop is a tool for finding and removing adapters from ONT data. Adapters on the ends of reads are trimmed, and when a read has an adapter in the middle, the read is split into two.</p> <p>The <code>porechop</code> task is optional and is turned off by default. It can be enabled by setting the <code>call_porechop</code> parameter to <code>true</code>.</p> <p>Porechop Technical Details</p> Links WDL Task task_porechop.wdl Software Source Code Porechop on GitHub Software Documentation https://github.com/rrwick/Porechop#porechop <code>Nanoq</code>: Read Filtering <p>Reads are filtered by length and quality using <code>nanoq</code>. By default, sequences with less than 500 basepairs and quality scores lower than 10 are filtered out to improve assembly accuracy. These defaults are able to be modified by the user.</p> <p>Nanoq Technical Details</p> Links Task task_nanoq.wdl Software Source Code Nanoq on GitHub Software Documentation Nanoq Documentation Original Publication(s) Nanoq: ultra-fast quality control for nanopore reads <code>ncbi_scrub_se</code> <p>All reads of human origin are removed, including their mates, by using NCBI's human read removal tool (HRRT). </p> <p>HRRT is based on the SRA Taxonomy Analysis Tool and employs a k-mer database constructed of k-mers from Eukaryota derived from all human RefSeq records with any k-mers found in non-Eukaryota RefSeq records subtracted from the database.</p> <p>NCBI-Scrub Technical Details</p> Links Task task_ncbi_scrub.wdl Software Source Code HRRT on GitHub Software Documentation HRRT on NCBI <code>host_decontaminate</code>: Host Read Decontamination <p>Host genetic data is frequently incidentally sequenced alongside pathogens, which can negatively affect the quality of downstream analysis. Host Decontaminate attempts to remove host reads by aligning to a reference host genome acquired on-the-fly. The reference host genome can be acquired via NCBI Taxonomy-compatible taxon input or assembly accession. Host Decontaminate maps inputted reads to the host genome using <code>minimap2</code>, reports mapping statistics to this host genome, and outputs the unaligned dehosted reads. </p> <p>The detailed steps and tasks are as follows:</p> Taxonomic Identification <p>The <code>ncbi_identify</code> task uses <code>NCBI Datasets</code> to search the NCBI Viral Genome Database and acquire taxonomic metadata from a user's inputted taxonomy and desired taxonomic rank. This task will always return a taxon ID, name, and rank, and it facilitates multiple downstream functions, including read classification and targeted read extraction. This task also generates a comprehensive summary file of all successful hits to the input <code>taxon</code>, which includes each taxon's accession number, completeness status, genome length, source, and other relevant metadata. Based on this summary, the task also calculates the average expected genome size for the input <code>taxon</code>.</p> <code>taxon</code> input parameter <p>This parameter accepts either a NCBI taxon ID (e.g. <code>11292</code>) or an organism name (e.g. <code>Lyssavirus rabies</code>).</p> <code>rank</code> a.k.a <code>read_extraction_rank</code> input parameter <p>Valid options include: <code>\"species\"</code>, <code>\"genus\"</code>, <code>\"family\"</code>, <code>\"order\"</code>, <code>\"class\"</code>, <code>\"phylum\"</code>, <code>\"kingdom\"</code>, or <code>\"domain\"</code>. By default it is set to <code>\"family\"</code>. This parameter filters metadata to report information only at the taxonomic <code>rank</code> specified by the user, regardless of the taxonomic rank implied by the original input <code>taxon</code>.</p> Important <ul> <li>The <code>rank</code> parameter must specify a taxonomic rank that is equal to or above the input taxon's taxonomic rank.</li> </ul> <p>Examples:</p> <ul> <li>If your input <code>taxon</code> is <code>Lyssavirus rabies</code> (species level) with <code>rank</code> set to <code>family</code>, the task will return information for the family of <code>Lyssavirus rabies</code>: taxon ID for Rhabdoviridae (11270), name \"Rhabdoviridae\", and rank \"family\".</li> <li>If your input <code>taxon</code> is <code>Lyssavirus</code> (genus level) with <code>rank</code> set to <code>species</code>, the task will fail because it cannot determine species information from an inputted genus.</li> </ul> <p>NCBI Datasets Technical Details</p> Links Task task_identify_taxon_id.wdl Software Source Code NCBI Datasets on GitHub Software Documentation NCBI Datasets Documentation on NCBI Original Publication(s) Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets Download Accession <p>The <code>NCBI Datasets</code> task downloads specified assemblies from NCBI using either the virus or genome (for all other genome types) package as appropriate.</p> <p>This task uses the accession ID output from the <code>skani</code> task to download the the most closely related reference genome to the input assembly. The downloaded reference is then used for downstream analysis, including variant calling and consensus generation.</p> <p>NCBI Datasets Technical Details</p> Links Task task_ncbi_datasets.wdl Software Source Code NCBI Datasets on GitHub Software Documentation NCBI Datasets Documentation on NCBI Original Publication(s) Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets Map Reads to Host <p><code>minimap2</code> is a popular aligner that is used to align reads (or assemblies) to an assembly file. In minimap2, \"modes\" are a group of preset options.</p> <p>The mode used in this task is <code>map-ont</code> which is the default mode for long reads and indicates that long reads of ~10% error rates should be aligned to the reference genome. The output file is in SAM format.</p> <p>For more information regarding modes and the available options for <code>minimap2</code>, please see the minimap2 manpage</p> <p>minimap2 Technical Details</p> Links Task task_minimap2.wdl Software Source Code minimap2 on GitHub Software Documentation minimap2 Original Publication(s) Minimap2: pairwise alignment for nucleotide sequences Extract Unaligned Reads <p>The <code>bam_to_unaligned_fastq</code> task will extract a FASTQ file of reads that failed to align, while removing unpaired reads. </p> <p><code>parse_mapping</code> Technical Details</p> Links Task task_parse_mapping.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <code>assembly_metrics</code>: Mapping Statistics <p>The <code>assembly_metrics</code> task generates mapping statistics from a BAM file. It uses samtools to generate a summary of the mapping statistics, which includes coverage, depth, average base quality, average mapping quality, and other relevant metrics.</p> <p><code>assembly_metrics</code> Technical Details</p> Links Task task_assembly_metrics.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <p>Host Decontaminate Technical Details</p> Links Subworkflow wf_host_decontaminate.wdl <code>rasusa</code> <p><code>Rasusa</code> is a tool to randomly subsample sequencing reads to a specified coverage without assuming that all reads are of equal length, making it especially suitable for long-read data while still being applicable to short-read data.</p> <p>The <code>Rasusa</code> task performs subsampling on the input raw reads. By default, it subsamples reads to a target depth of 250X, using the estimated genome length either generated by the <code>ncbi_identify</code> task or provided directly by the user. Disabled by default, users can enable it by setting the <code>skip_rasusa</code> variable to <code>false</code>. The target subsampling depth can also be adjusted by modifying the <code>coverage</code> variable.</p> <code>coverage</code> input parameter <p>This parameter specifies the target coverage for subsampling. The default value is <code>250</code>, but users can adjust it as needed.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs since it performs random subsampling. To ensure reproducibility, set a a value for the <code>rasusa_seed</code> optional input variable.</p> <p>Rasusa Technical Details</p> Links Task task_rasusa.wdl Software Source Code Rasusa on GitHub Software Documentation Rasusa on GitHub Original Publication(s) Rasusa: Randomly subsample sequencing reads to a specified coverage <code>clean_check_reads</code> <p>The <code>screen</code> task ensures the quantity of sequence data is sufficient to undertake genomic analysis. It uses <code>fastq-scan</code> and bash commands for quantification of reads and base pairs, and mash sketching to estimate the genome size and its coverage. At each step, the results are assessed relative to pass/fail criteria and thresholds that may be defined by optional user inputs. Samples are run through all threshold checks, regardless of failures, and the workflow will terminate after the <code>screen</code> task if any thresholds are not met:</p> <ol> <li>Total number of reads: A sample will fail the read screening task if its total number of reads is less than or equal to <code>min_reads</code>.</li> <li>The proportion of basepairs reads in the forward and reverse read files: A sample will fail the read screening if fewer than <code>min_proportion</code> basepairs are in either the reads1 or read2 files.</li> <li>Number of basepairs: A sample will fail the read screening if there are fewer than <code>min_basepairs</code> basepairs</li> <li>Estimated genome size:  A sample will fail the read screening if the estimated genome size is smaller than <code>min_genome_size</code> or bigger than <code>max_genome_size</code>.</li> <li>Estimated genome coverage: A sample will fail the read screening if the estimated genome coverage is less than the <code>min_coverage</code>.</li> </ol> <p>Read screening is performed only on the cleaned reads. The task may be skipped by setting the <code>skip_screen</code> variable to <code>true</code>. Default values vary between the ONT and PE workflow. The rationale for these default values can be found below:</p> Default Thresholds and Rationales Variable Description Default Value Rationale <code>min_reads</code> A sample will fail the read screening task if its total number of reads is less than or equal to <code>min_reads</code> 50 Minimum number of base pairs for 10x coverage of the Hepatitis delta (of the Deltavirus genus) virus divided by 300 (longest Illumina read length) <code>min_basepairs</code> A sample will fail the read screening if there are fewer than <code>min_basepairs</code> basepairs 15000 Greater than 10x coverage of the Hepatitis delta (of the Deltavirus genus) virus <code>min_genome_size</code> A sample will fail the read screening if the estimated genome size is smaller than <code>min_genome_size</code> 1500 Based on the Hepatitis delta (of the Deltavirus genus) genome- the smallest viral genome as of 2024-04-11 (1,700 bp) <code>max_genome_size</code> A sample will fail the read screening if the estimated genome size is smaller than <code>max_genome_size</code> 2673870 Based on the Pandoravirus salinus genome, the biggest viral genome, (2,673,870 bp) with 2 Mbp added <code>min_coverage</code> A sample will fail the read screening if the estimated genome coverage is less than the <code>min_coverage</code> 10 A bare-minimum coverage for genome characterization. Higher coverage would be required for high-quality phylogenetics. <code>min_proportion</code> A sample will fail the read screening if fewer than <code>min_proportion</code> basepairs are in either the reads1 or read2 files 40 Greater than 50% reads are in the read1 file; others are in the read2 file. (PE workflow only) <p>Screen Technical Details</p> Links Task task_screen.wdl (PE sub-task)task_screen.wdl (SE sub-task) Read Classification and Extraction <code>metabuli</code> <p>The <code>metabuli</code> task is used to classify and extract reads against a reference database. Metabuli uses a novel k-mer structure, called metamer, to analyze both amino acid (AA) and DNA sequences. It leverages AA conservation for sensitive homology detection and DNA mutations for specific differentiation between closely related taxa.</p> <code>cpu</code> / <code>memory</code> input parameters <p>Increasing the memory and cpus allocated to Metabuli can substantially increase throughput.</p> <code>extract_unclassified</code> input parameter <p>This parameter determines whether unclassified reads should also be extracted and combined with the <code>taxon</code>-specific extracted reads. By default, this is set to <code>false</code>, meaning that only reads classified to the specified input <code>taxon</code> will be extracted.</p> Descendant taxa reads are extracted <p>This task will extract reads classified to the input <code>taxon</code> and all of its descendant taxa. The <code>rank</code> input parameter controls the extraction of reads classified at the specified <code>rank</code> and all subordiante taxonomic levels. See task <code>ncbi_identify</code> under the Taxonomic Identification section above for more details on the <code>rank</code> input parameter.</p> <p>Metabuli Technical Details</p> Links Task task_metabuli.wdl Software Source Code Metabuli on GitHub Software Documentation Metabuli Documentation Original Publication(s) Metabuli: sensitive and specific metagenomic classification via joint analysis of amino acid and DNA De novo Assembly and Reference Selection These tasks are only performed if no reference genome is provided <p>In this workflow, de novo assembly is used solely to facilitate the selection of a closely related reference genome. If the user provides an input <code>reference_fasta</code>, the following assembly generation, assembly evaluation, and reference selections tasks will be skipped:</p> <ul> <li><code>raven</code></li> <li><code>flye</code></li> <li><code>checkv_denovo</code></li> <li><code>quast_denovo</code></li> <li><code>skani</code></li> <li><code>ncbi_datasets</code></li> </ul> <code>raven</code> <p>The <code>raven</code> task is used to create a de novo assembly from cleaned reads. Raven is an overlap-layout-consensus based assembler that accelerates the overlap step, constructs an assembly graph from reads pre-processed with pile-o-grams, applies a novel and robust graph simplification method based on graph drawings, and polishes unambiguous graph paths using Racon. </p> <p>Based on internal benchmarking against Flye and results reported by Cook et al. (2024), Raven is faster, produces more contiguous assemblies, and yields more complete genomes within TheiaViral according to CheckV quality assessment (see task <code>checkv</code> for technical details).</p> <code>call_raven</code> input parameter <p>This parameter controls whether or not the <code>raven</code> task is called by the workflow. By default, <code>call_raven</code> is set to <code>true</code> because Raven is used as the primary assembler. Raven is generally recommended for most users, but it might not perform optimally on all datasets. If users encounter issues with Raven, they can set the <code>call_raven</code> variable to <code>false</code> to bypass the <code>raven</code> task and instead de novo assemble using Flye (see task <code>flye</code> for details). Additionally, if the Raven task fails during execution, the workflow will automatically fall back to using Flye for de novo assembly.</p> Error traceback <p>Raven may fail with cryptic \"segmentation fault\" (segfault) errors or by failing to output an output file. It is difficult to traceback the source of these issues, though increasing the <code>memory</code> parameter may resolve some errors.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>Raven Technical Details</p> Links Task task_raven.wdl Software Source Code Raven on GitHub Software Documentation Raven Documentation Original Publication(s) Time- and memory-efficient genome assembly with Raven <code>flye</code> <p>Flye is a de novo assembler for long read data using repeat graphs. Compared to de Bruijn graphs, which require exact k-mer matches, repeat graphs can use approximate matches which better tolerates the error rate of ONT data.</p> <p>It can be enabled by setting the <code>call_raven</code> parameter to <code>false</code>. The <code>flye</code> task is used as a fallback option if the <code>raven</code> task fails during execution (see task <code>raven</code> for more details).</p> <code>read_type</code> input parameter <p>This input parameter specifies the type of sequencing reads being used for assembly. This parameter significantly impacts the assembly process and should match the characteristics of your input data. Below are the available options:</p> Parameter Explanation <code>--nano-hq</code> (default) Optimized for ONT high-quality reads, such as Guppy5+ SUP or Q20 (&lt;5% error). Recommended for ONT reads processed with Guppy5 or newer <code>--nano-raw</code> For ONT regular reads, pre-Guppy5 (&lt;20% error) <code>--nano-corr</code> ONT reads corrected with other methods (&lt;3% error) <code>--pacbio-raw</code> PacBio regular CLR reads (&lt;20% error) <code>--pacbio-corr</code> PacBio reads corrected with other methods (&lt;3% error) <code>--pacbio-hifi</code> PacBio HiFi reads (&lt;1% error) <p>Refer to the Flye documentation for detailed guidance on selecting the appropriate <code>read_type</code> based on your sequencing data and additional optional paramaters.</p> Non-deterministic output(s) <p>This task may yield non-deterministic outputs.</p> <p>Flye Technical Details</p> Links WDL Task task_flye.wdl Software Source Code Flye on GitHub Software Documentation Flye Documentation Original Publication(s) Assembly of long, error-prone reads using repeat graphs <code>skani</code> <p>The <code>skani</code> task is used to identify and select the most closely related reference genome to the de novo assembly. Skani uses an approximate mapping method without base-level alignment to calculate average nucleotide identity (ANI). It is magnitudes faster than BLAST-based methods and almost as accurate.</p> <p>By default, the reference genome is selected from a database of approximately 200,000 viral genomes. This database was constructed with the following methodology:</p> <ol> <li> <p>Extracting all complete NCBI viral genomes, excluding RefSeq accessions (redundancy), SARS-CoV-2 accessions, and segmented families (Orthomyxoviridae, Hantaviridae, Arenaviridae, and Phenuiviridae). Some complete gene accessions, and not complete genomes, are included because NCBI <code>datasets</code> completeness parameters are susceptible to metadata errors.</p> </li> <li> <p>Adding complete RefSeq segmented viral assembly accessions, which represent segments as individual contigs within the FASTA</p> </li> <li> <p>Adding one SARS-CoV-2 genome for each major pangolin lineage</p> </li> </ol> <p>Skani Technical Details</p> Links Task task_skani.wdl Software Source Code Skani on GitHub Software Documentation Skani Documentation Original Publication(s) Fast and robust metagenomic sequence comparison through sparse chaining with skani <code>ncbi_datasets</code> <p>The <code>NCBI Datasets</code> task downloads specified assemblies from NCBI using either the virus or genome (for all other genome types) package as appropriate.</p> <p>This task uses the accession ID output from the <code>skani</code> task to download the the most closely related reference genome to the input assembly. The downloaded reference is then used for downstream analysis, including variant calling and consensus generation.</p> <p>NCBI Datasets Technical Details</p> Links Task task_ncbi_datasets.wdl Software Source Code NCBI Datasets on GitHub Software Documentation NCBI Datasets Documentation on NCBI Original Publication(s) Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets Reference Mapping <code>minimap2</code> <p><code>minimap2</code> is a popular aligner that is used to align reads (or assemblies) to an assembly file. In minimap2, \"modes\" are a group of preset options.</p> <p>The mode used in this task is <code>map-ont</code> with additional long-read-specific parameters (the <code>-L --cs --MD</code> flags) to align ONT reads to the reference genome. These specialized parameters are essential for proper handling of long read error profiles, generation of detailed alignment information, and improved mapping accuracy for long reads.</p> <p><code>map-ont</code> is the default mode for long reads and it indicates that long reads of ~10% error rates should be aligned to the reference genome. The output file is in SAM format.</p> <p>For more information regarding modes and the available options for <code>minimap2</code>, please see the minimap2 manpage</p> <p>minimap2 Technical Details</p> Links Task task_minimap2.wdl Software Source Code minimap2 on GitHub Software Documentation minimap2 Original Publication(s) Minimap2: pairwise alignment for nucleotide sequences <code>parse_mapping</code> <p>The <code>sam_to_sorted_bam</code> sub-task converts the output SAM file from the <code>minimap2</code> task and converts it to a BAM file. It then sorts the BAM file by coordinate, and creates a BAM index file.</p> <code>min_map_quality</code> input parameter <p>This parameter accepts an integer value to set the minimum mapping quality for variant calling and subsequent consensus sequence generation. The default value is <code>20</code>.</p> <p><code>parse_mapping</code> Technical Details</p> Links Task task_parse_mapping.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <code>read_mapping_stats</code>: Mapping Statistics <p>The <code>read_mapping_stats</code> task generates mapping statistics from a BAM file. It uses samtools to generate a summary of the mapping statistics, which includes coverage, depth, average base quality, average mapping quality, and other relevant metrics.</p> <p><code>read_mapping_stats</code> Technical Details</p> Links Task task_assembly_metrics.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <code>fasta_utilities</code> <p>The <code>fasta_utilities</code> task utilizes samtools to index a reference fasta file. This reference is selected by the <code>skani</code> task or provided by the user input <code>reference_fasta</code>. This indexed reference genome is used for downstream variant calling and consensus generation tasks.</p> <p><code>fasta_utilities</code> Technical Details</p> Links Task task_fasta_utilities.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools Variant Calling and Consensus Generation <code>clair3</code> <p><code>Clair3</code> performs deep learning-based variant detection using a multi-stage approach. The process begins with pileup-based calling for initial variant identification, followed by full-alignment analysis for comprehensive variant detection. Results are merged into a final high-confidence call set.</p> <p>The variant calling pipeline employs specialized neural networks trained on ONT data to accurately identify: - Single nucleotide variants (SNVs) - Small insertions and deletions (indels) - Structural variants</p> <code>clair3_model</code> input parameter <p>This parameter specifies the clair3 model to use for variant calling. The default is set to <code>\"r1041_e82_400bps_sup_v500\"</code>, but users may select from other available models that <code>clair3</code> was trained on, which may yield better results depending on the basecaller and data type. The following models are available:</p> <ul> <li><code>\"ont\"</code></li> <li><code>\"ont_guppy2\"</code></li> <li><code>\"ont_guppy5\"</code></li> <li><code>\"r941_prom_sup_g5014\"</code></li> <li><code>\"r941_prom_hac_g360+g422\"</code></li> <li><code>\"r941_prom_hac_g238\"</code></li> <li><code>\"r1041_e82_400bps_sup_v500\"</code></li> <li><code>\"r1041_e82_400bps_hac_v500\"</code></li> <li><code>\"r1041_e82_400bps_sup_v410\"</code></li> <li><code>\"r1041_e82_400bps_hac_v410\"</code></li> </ul> Default Parameters and Filtering <p>In this workflow, <code>clair3</code> is run with nearly all default parameters. Note that the VCF file produced by the <code>clair3</code> task is unfiltered and does not represent the final set of variants that will be included in the final consensus genome. A filtered vcf file is generated by the <code>bcftools_consensus</code> task. The filtering parameters are as follows:</p> <ul> <li>The <code>min_map_quality</code> parameter is applied before calling variants.</li> <li>The <code>min_depth</code> and <code>min_allele_freq</code> parameters are applied after variant calling during consensus genome construction.</li> </ul> <p>Clair3 Technical Details</p> Links Task task_clair3.wdl Software Source Code Clair3 on GitHub Software Documentation Clair3 Documentation Original Publication(s) Symphonizing pileup and full-alignment for deep learning-based long-read variant calling <code>parse_mapping</code> <p>The <code>mask_low_coverage</code> sub-task is used to mask low coverage regions in the <code>reference_fasta</code> file to improve the accuracy of the final consensus genome. Coverage thresholds are defined by the <code>min_depth</code> parameter, which specifies the minimum read depth required for a base to be retained. Bases falling below this threshold are replaced with \"N\"s to clearly mark low confidence regions. The masked reference is then combined with variants from the <code>clair3</code> task to produce the final consensus genome.</p> <code>min_depth</code> input parameter <p>This parameter accepts an integer value to set the minimum read depth for variant calling and subsequent consensus sequence generation. The default value is <code>10</code>.</p> <p><code>parse_mapping</code> Technical Details</p> Links Task task_parse_mapping.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <code>bcftools_consensus</code> <p>The <code>bcftools_consensus</code> task generates a consensus genome assembly by applying variants from the <code>clair3</code> task to a masked reference genome. It uses bcftools to filter variants based on the <code>min_depth</code> and <code>min_allele_freq</code> input parameter, left aligns and normalizes indels, indexes the VCF file, and generates a consensus genome in FASTA format. Reference bases are substituted with filtered variants where applicable, preserved in regions without variant calls, and replaced with \"N\"s in areas masked by the <code>mask_low_coverage</code> task.</p> <code>min_depth</code> input parameter <p>This parameter accepts an integer value to set the minimum read depth for variant calling and subsequent consensus sequence generation. The default value is <code>10</code>.</p> <code>min_allele_freq</code> input parameter <p>This parameter accepts a float value to set the minimum allele frequency for variant calling and subsequent consensus sequence generation. The default value is <code>0.6</code>.</p> <p><code>bcftools_consensus</code> Technical Details</p> Links Task task_bcftools_consensus.wdl Software Source Code bcftools on GitHub Software Documentation bcftools Manual Page Original Publication(s) Twelve Years of SAMtools and BCFtools Assembly Evaluation and Consensus Quality Control <code>quast_denovo</code> <p>QUAST stands for QUality ASsessment Tool. It evaluates genome/metagenome assemblies by computing various metrics without a reference being necessary. It includes useful metrics such as number of contigs, length of the largest contig and N50.</p> <p>QUAST Technical Details</p> Links Task task_quast.wdl Software Source Code QUAST on GitHub Software Documentation QUAST Manual on SourceForge Original Publication(s) QUAST: quality assessment tool for genome assemblies <code>checkv_denovo</code> &amp; <code>checkv_consensus</code> <p>CheckV is a fully automated command-line pipeline for assessing the quality of viral genomes, including identification of host contamination for integrated proviruses, estimating completeness for genome fragments, and identification of closed genomes.</p> <p>By default, CheckV reports results on a contig-by-contig basis. The <code>checkv</code> task additionally reports both \"weighted_contamination\" and \"weighted_completeness\", which are average percents calculated across the total assembly that are weighted by contig length.</p> <p>CheckV Technical Details</p> Links Task task_checkv.wdl Software Source Code CheckV on Bitbucket Software Documentation CheckV Documentation Original Publication(s) CheckV assesses the quality and completeness of metagenome-assembled viral genomes <code>consensus_qc</code>: Assembly Statistics <p>The consensus_qc task generates a summary of genomic statistics from a consensus genome. This includes the total number of bases, \"N\" bases, degenerate bases, and an estimate of the percent coverage to the reference genome.</p> <p><code>consensus_qc</code> Technical Details</p> Links Task task_consensus_qc.wdl"},{"location":"workflows/genomic_characterization/theiaviral/#taxa-specific-tasks","title":"Taxa-Specific Tasks","text":"<p>The TheiaViral workflows activate taxa-specific sub-workflows after the identification of relevant taxa. These characterization modules are activated by populating <code>taxon</code> with an exact match to a taxon listed in parentheses below (case-insensitive):</p> <ul> <li>SARS-CoV-2 (<code>\"2697049\"</code>, <code>\"3418604\"</code>, <code>\"sars-cov-2\"</code>)</li> <li>Monkeypox virus (<code>\"10244\"</code>, <code>\"mpxv\"</code>, <code>\"mpox\"</code>, <code>\"monkeypox virus\"</code>)</li> <li>Human Immunodeficiency Virus 1 (<code>\"11676\"</code>, <code>\"hiv1\"</code>)</li> <li>Human Immunodeficiency Virus 2 (<code>\"11709\"</code>, <code>\"hiv2\"</code>)</li> <li>West Nile Virus (<code>\"11082\"</code>, <code>\"wnv\"</code>, <code>\"west nile virus\"</code>)</li> <li>Influenza (<code>\"11320\"</code>, <code>\"11309\"</code>, <code>\"11520\"</code>, <code>\"flu\"</code>, <code>\"influenza\"</code>)</li> <li>RSV-A (<code>\"208893\"</code>, <code>\"hrsv-a\"</code>)</li> <li>RSV-B (<code>\"208895\"</code>, <code>\"hrsv-b\"</code>)</li> <li>Measles (<code>\"11234\"</code>, <code>\"measles\"</code>)</li> <li>Rabies (<code>\"11286\"</code>, <code>\"11292\"</code>, <code>\"rabies\"</code>, <code>\"lyssavirus rabies\"</code>, <code>\"lyssavirus\"</code>)</li> <li>Mumps (<code>\"2560602\"</code>, <code>\"mumps virus\"</code>, <code>\"Mumps orthorubulavirus\"</code>)</li> <li>Rubella (<code>\"11041\"</code>, <code>\"rubella virus\"</code>, <code>\"Rubella virus\"</code>)</li> </ul>"},{"location":"workflows/genomic_characterization/theiaviral/#outputs","title":"Outputs","text":"TheiaViral_Illumina_PETheiaViral_ONT Variable Type Description abricate_flu_database String ABRicate database used for analysis abricate_flu_results File File containing all results from ABRicate abricate_flu_subtype String Flu subtype as determined by ABRicate abricate_flu_type String Flu type as determined by ABRicate abricate_flu_version String Version of ABRicate assembly_consensus_fasta File Final consensus assembly in FASTA format assembly_denovo_fasta File De novo assembly in FASTA format auspice_json_flu_ha File Auspice-compatable JSON output generated from Nextclade analysis on Influenza HA segment that includes the Nextclade default samples for clade-typing and the single sample placed on this tree auspice_json_flu_na File Auspice-compatable JSON output generated from Nextclade analysis on Influenza NA segment that includes the Nextclade default samples for clade-typing and the single sample placed on this tree auspice_json_mpxv File Auspice-compatable JSON output generated from Nextclade analysis on Monkeypox virus that includes the Nextclade default samples for clade-typing and the single sample placed on this tree auspice_json_rabies File Auspice-compatable JSON output generated from Nextclade analysis on Rabies virus that includes the Nextclade default samples for clade-typing and the single sample placed on this tree bbduk_docker String The Docker image for bbduk, which was used to remove the adapters from the sequences bbduk_read1_clean File Clean forward reads after BBDuk processing bbduk_read2_clean File Clean reverse reads after BBDuk processing bwa_read1_aligned File Forward reads aligned to reference bwa_read1_unaligned File Forward reads not aligned to reference bwa_read2_aligned File Reverse reads aligned to reference bwa_read2_unaligned File Reverse reads not aligned to reference bwa_samtools_version String Version of samtools used by BWA bwa_sorted_bai File Sorted BAM index file of reads aligned to reference bwa_sorted_bam File Sorted BAM file of reads aligned to reference bwa_sorted_bam_unaligned File A BAM file that only contains reads that did not align to the reference bwa_sorted_bam_unaligned_bai File Index companion file to a BAM file that only contains reads that did not align to the reference bwa_version String Version of BWA software used checkv_consensus_contamination File Contamination estimate for consensus assembly from CheckV checkv_consensus_summary File Summary report from CheckV for consensus assembly checkv_consensus_total_genes Int Number of genes detected in consensus assembly by CheckV checkv_consensus_version String Version of CheckV used for consensus assembly checkv_consensus_weighted_completeness Float Weighted completeness score for consensus assembly from CheckV checkv_consensus_weighted_contamination Float Weighted contamination score for consensus assembly from CheckV checkv_denovo_contamination File Contamination estimate for de novo assembly from CheckV checkv_denovo_summary File Summary report from CheckV for de novo assembly checkv_denovo_total_genes Int Number of genes detected in de novo assembly by CheckV checkv_denovo_version String Version of CheckV used for de novo assembly checkv_denovo_weighted_completeness Float Weighted completeness score for de novo assembly from CheckV checkv_denovo_weighted_contamination Float Weighted contamination score for de novo assembly from CheckV consensus_n_variant_min_depth Int Minimum read depth to call variants for iVar consensus and iVar variants. Also represents the minimum consensus support threshold used by IRMA with Illumina Influenza data. consensus_qc_assembly_length_unambiguous Int Length of consensus assembly excluding ambiguous bases consensus_qc_number_Degenerate Int Number of degenerate bases in consensus assembly consensus_qc_number_N Int Number of N bases in consensus assembly consensus_qc_number_Total Int Total number of bases in consensus assembly consensus_qc_percent_reference_coverage Float Percent of reference genome covered in consensus assembly dehost_wf_dehost_read1 File Reads that did not map to host dehost_wf_dehost_read2 File Paired-reads that did not map to host dehost_wf_host_accession String Host genome accession dehost_wf_host_fasta File Host genome FASTA file dehost_wf_host_flagstat File Output from the SAMtools flagstat command to assess quality of the alignment file (BAM) dehost_wf_host_mapped_bai File Indexed bam file of the reads aligned to the host reference dehost_wf_host_mapped_bam File Sorted BAM file containing the alignments of reads to the host reference genome dehost_wf_host_mapping_cov_hist File Coverage histogram from host read mapping dehost_wf_host_mapping_coverage Float Average coverage from host read mapping dehost_wf_host_mapping_mean_depth Float Average depth from host read mapping dehost_wf_host_mapping_metrics File File of mapping metrics dehost_wf_host_mapping_stats File File of mapping statistics dehost_wf_host_percent_mapped_reads Float Percentage of reads mapped to host reference genome fastp_html_report File The HTML report made with fastp fastp_version String The version of fastp used fastq_scan_clean1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about clean forward read quality and length fastq_scan_clean2_json File The JSON file output from <code>fastq-scan</code> containing summary stats about clean reverse read quality and length fastq_scan_clean_pairs String Number of read pairs after cleaning fastq_scan_docker String The Docker image of fastq_scan fastq_scan_num_reads_clean1 Int The number of forward reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_clean2 Int The number of reverse reads after cleaning as calculated by fastq_scan fastq_scan_num_reads_raw1 Int The number of input forward reads as calculated by fastq_scan fastq_scan_num_reads_raw2 Int The number of input reserve reads as calculated by fastq_scan fastq_scan_raw1_json File The JSON file output from <code>fastq-scan</code> containing summary stats about raw forward read quality and length fastq_scan_raw2_json File The JSON file output from <code>fastq-scan</code> containing summary stats about raw reverse read quality and length fastq_scan_raw_pairs String Number of raw read pairs fastq_scan_version String The version of fastq_scan genoflu_all_segments String The genotypes for each individual flu segment genoflu_genotype String The genotype of the whole genome, based off of the individual segments types genoflu_output_tsv File The output file from GenoFLU genoflu_version String The version of GenoFLU used irma_docker String Docker image used to run IRMA irma_subtype String Flu subtype as determined by IRMA irma_subtype_notes String Helpful note to user about Flu B subtypes. Output will be blank for Flu A samples. For Flu B samples it will state: \"IRMA does not differentiate Victoria and Yamagata Flu B lineages. See abricate_flu_subtype output column\" irma_type String Flu type as determined by IRMA irma_version String Version of IRMA used ivar_tsv File Variant descriptor file generated by iVar variants ivar_variant_proportion_intermediate String The proportion of variants of intermediate frequency ivar_variant_version String Version of iVar for running the iVar variants command ivar_vcf File iVar tsv output converted to VCF format ivar_version_consensus String Version of iVar for running the iVar consensus command kraken2_extracted_read1 File Forward reads extracted by taxonomic classification kraken2_extracted_read2 File Reverse reads extracted by taxonomic classification kraken_database String Database used for Kraken classification kraken_docker String Docker image used for Kraken kraken_report String Full Kraken report kraken_version String Version of Kraken software used megahit_docker String Docker image used for MEGAHIT megahit_status String Status of the MEGAHIT assembly megahit_version String Version of MEGAHIT used metaviralspades_docker String Docker image used for MetaviralSPAdes metaviralspades_status String Status of MetaviralSPAdes assembly metaviralspades_version String Version of MetaviralSPAdes used morgana_magic_organism String Standardized organism name used for characterization morgana_magic_organism String Organism identified ncbi_datasets_docker String Docker image used for NCBI datasets ncbi_datasets_version String Version of NCBI datasets used ncbi_identify_accession String NCBI accession ID of identified taxon ncbi_identify_avg_genome_length Int Average genome length from NCBI taxon summary ncbi_identify_genome_summary_tsv File TSV file with genome summary from NCBI ncbi_identify_read_extraction_rank String Taxonomic rank used for read extraction ncbi_identify_taxon_id String NCBI taxonomy ID of identified organism ncbi_identify_taxon_name String Name of identified taxon ncbi_identify_taxon_summary_tsv File TSV file with taxa specific summary from NCBI ncbi_scrub_docker String The Docker image for NCBI's HRRT (human read removal tool) ncbi_scrub_human_spots_removed Int Number of spots removed (or masked) nextclade_aa_dels_flu_ha String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for HA segment nextclade_aa_dels_flu_ha String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for HA segment nextclade_aa_dels_flu_na String Amino-acid deletions as detected by NextClade. Specific to Flu; it includes deletions for NA segment nextclade_aa_dels_flu_na String Amino-acid deletions as detected by NextClade. Specific to Flu; it includes deletions for NA segment nextclade_aa_dels_mpxv String Amino-acid deletions as detected by Nextclade. Specific to Monkeypox nextclade_aa_dels_rabies String Amino-acid deletions as detected by Nextclade. Specific to Monkeypox nextclade_aa_subs_flu_ha String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for HA segment nextclade_aa_subs_flu_ha String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for HA segment nextclade_aa_subs_flu_na String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for NA segment nextclade_aa_subs_flu_na String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for NA segment nextclade_aa_subs_mpxv String Amino-acid substitutions as detected by Nextclade. Specific to Monkeypox nextclade_aa_subs_rabies String Amino-acid substitutions as detected by Nextclade. Specific to Monkeypox nextclade_clade_flu_ha String Nextclade clade designation, specific to Flu NA segment nextclade_clade_flu_na String Nextclade clade designation, specific to Flu HA segment nextclade_clade_mpxv String Nextclade clade designation, specific to Monkeypox nextclade_clade_rabies String Nextclade clade designation, specific to Rabies nextclade_docker String Docker image used to run Nextclade nextclade_ds_tag String Dataset tag used to run Nextclade. Will be blank for Flu nextclade_ds_tag_flu_ha String Dataset tag used to run Nextclade, specific to Flu HA segment nextclade_ds_tag_flu_na String Dataset tag used to run Nextclade, specific to Flu NA segment nextclade_json_flu_ha File Nextclade output in JSON file format, specific to Flu HA segment nextclade_json_flu_na File Nextclade output in JSON file format, specific to Flu NA segment nextclade_json_mpxv File Nextclade output in JSON file format, specific to Monkeypox nextclade_json_rabies File Nextclade output in JSON file format, specific to Rabies nextclade_lineage_mpxv String Nextclade lineage designation, specific to Monkeypox nextclade_lineage_rabies String Nextclade lineage designation, specific to Rabies nextclade_qc_flu_ha String QC metric as determined by Nextclade, specific to Flu HA segment nextclade_qc_flu_ha String QC metric as determined by Nextclade, specific to Flu HA segment nextclade_qc_flu_na String QC metric as determined by Nextclade, specific to Flu NA segment nextclade_qc_flu_na String QC metric as determined by Nextclade, specific to Flu NA segment nextclade_qc_mpxv String QC metric as determined by Nextclade, specific to Monkeypox nextclade_qc_rabies String QC metric as determined by Nextclade, specific to Rabies nextclade_tsv_flu_ha File Nextclade output in TSV file format, specific to Flu HA segment nextclade_tsv_flu_na File Nextclade output in TSV file format, specific to Flu NA segment nextclade_tsv_mpxv File Nextclade output in TSV file format, specific to Monkeypox nextclade_tsv_rabies File Nextclade output in TSV file format, specific to Rabies nextclade_version String The version of Nextclade software used pango_lineage String Pango lineage as determined by Pangolin pango_lineage_expanded String Pango lineage without use of aliases; e.g., \"BA.1\" \u2192 \"B.1.1.529.1\" pango_lineage_report File Full Pango lineage report generated by Pangolin pangolin_assignment_version String The version of the pangolin software (e.g. PANGO or PUSHER) used for lineage assignment pangolin_conflicts String Number of lineage conflicts as determined by Pangolin pangolin_docker String Docker image used to run Pangolin pangolin_notes String Lineage notes as determined by Pangolin pangolin_versions String All Pangolin software and database versions quasitools_coverage_file File The coverage report created by Quasitools HyDRA quasitools_date String Date of Quasitools analysis quasitools_dr_report File Drug resistance report created by Quasitools HyDRA quasitools_hydra_vcf File The VCF created by Quasitools HyDRA quasitools_mutations_report File The mutation report created by Quasitools HyDRA quasitools_version String Version of Quasitools used quast_denovo_docker String Docker image used for QUAST quast_denovo_gc_percent Float GC percentage of de novo assembly from QUAST quast_denovo_genome_length Int Genome length of de novo assembly from QUAST quast_denovo_largest_contig Int Size of largest contig in de novo assembly from QUAST quast_denovo_n50_value Int N50 value of de novo assembly from QUAST quast_denovo_number_contigs Int Number of contigs in de novo assembly from QUAST quast_denovo_report File QUAST report for de novo assembly quast_denovo_uncalled_bases Float Number of uncalled bases in de novo assembly from QUAST quast_denovo_version String Version of QUAST used read1_dehosted File The dehosted forward reads file; suggested read file for SRA submission read2_dehosted File The dehosted reverse reads file; suggested read file for SRA submission read_mapping_cov_hist File Coverage histogram from read mapping read_mapping_cov_stats File Coverage statistics from read mapping read_mapping_coverage Float Average coverage from read mapping read_mapping_date String Date of read mapping analysis read_mapping_depth Float Average depth from read mapping read_mapping_flagstat File Flagstat file from read mapping read_mapping_meanbaseq Float Mean base quality from read mapping read_mapping_meanmapq Float Mean mapping quality from read mapping read_mapping_percentage_mapped_reads Float Percentage of mapped reads read_mapping_report File Report file from read mapping read_mapping_samtools_version String Version of samtools used in read mapping read_mapping_statistics File Statistics file from read mapping read_screen_clean String PASS or FAIL result from clean read screening; FAIL accompanied by the reason(s) for failure read_screen_clean_tsv File Clean read screening report TSV depicting read counts, total read base pairs, and estimated genome length reference_taxon_name String NCBI derived taxon name from best ANI hit accession skani_database String Database used for Skani skani_docker String Docker image used for Skani skani_report File Report from Skani skani_status String Status of Skani analysis skani_top_accession String Top accession ID from Skani skani_top_ani Float Top ANI score from Skani skani_top_ani_fasta File FASTA file of top ANI match from Skani skani_top_query_coverage Float Query coverage of top match from Skani skani_top_score Float Top score from Skani skani_version String Version of Skani used skani_warning String Skani warning message theiaviral_illumina_pe_date String Date of TheiaViral Illumina PE workflow run theiaviral_illumina_pe_version String Version of TheiaViral Illumina PE workflow trimmomatic_docker String The docker image used for the trimmomatic module in this workflow trimmomatic_version String The version of Trimmomatic used vadr_alerts_list File A file containing all of the fatal alerts as determined by VADR vadr_all_outputs_tar_gz File A .tar.gz file (gzip-compressed tar archive file) containing all outputs from the VADR command v-annotate.pl. This file must be uncompressed &amp; extracted to see the many files within. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description of all files present within the archive. Useful when deeply investigating a sample's genome &amp; annotations. vadr_classification_summary_file File Per-sequence tabular classification file. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#explanation-of-sqc-suffixed-output-files for more complete description. vadr_docker String Docker image used to run VADR vadr_fastas_zip_archive File Zip archive containing all fasta files created during VADR analysis vadr_feature_tbl_fail File 5 column feature table output for failing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_feature_tbl_pass File 5 column feature table output for passing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_num_alerts String Number of fatal alerts as determined by VADR Variable Type Description abricate_flu_database String ABRicate database used for analysis abricate_flu_results File File containing all results from ABRicate abricate_flu_subtype String Flu subtype as determined by ABRicate abricate_flu_type String Flu type as determined by ABRicate abricate_flu_version String Version of ABRicate assembly_consensus_fasta File Final consensus assembly in FASTA format assembly_denovo_fasta File De novo assembly in FASTA format assembly_to_ref_bai File BAM index file for reads aligned to reference assembly_to_ref_bam File BAM file of reads aligned to reference auspice_json_flu_ha File Auspice-compatable JSON output generated from Nextclade analysis on Influenza HA segment that includes the Nextclade default samples for clade-typing and the single sample placed on this tree auspice_json_flu_na File Auspice-compatable JSON output generated from Nextclade analysis on Influenza NA segment that includes the Nextclade default samples for clade-typing and the single sample placed on this tree auspice_json_mpxv File Auspice-compatable JSON output generated from Nextclade analysis on Monkeypox virus that includes the Nextclade default samples for clade-typing and the single sample placed on this tree auspice_json_rabies File Auspice-compatable JSON output generated from Nextclade analysis on Rabies virus that includes the Nextclade default samples for clade-typing and the single sample placed on this tree bcftools_docker String Docker image used for bcftools bcftools_filtered_vcf File Filtered variant calls in VCF format from bcftools bcftools_version String Version of bcftools used checkv_consensus_contamination File Contamination estimate for consensus assembly from CheckV checkv_consensus_summary File Summary report from CheckV for consensus assembly checkv_consensus_total_genes Int Number of genes detected in consensus assembly by CheckV checkv_consensus_version String Version of CheckV used for consensus assembly checkv_consensus_weighted_completeness Float Weighted completeness score for consensus assembly from CheckV checkv_consensus_weighted_contamination Float Weighted contamination score for consensus assembly from CheckV checkv_denovo_contamination File Contamination estimate for de novo assembly from CheckV checkv_denovo_summary File Summary report from CheckV for de novo assembly checkv_denovo_total_genes Int Number of genes detected in de novo assembly by CheckV checkv_denovo_version String Version of CheckV used for de novo assembly checkv_denovo_weighted_completeness Float Weighted completeness score for de novo assembly from CheckV checkv_denovo_weighted_contamination Float Weighted contamination score for de novo assembly from CheckV clair3_docker String Docker image used for Clair3 clair3_gvcf File Genomic VCF file from Clair3 clair3_model String Model used for Clair3 variant calling clair3_vcf File Variant calls in VCF format from Clair3 clair3_version String Clair3 Version being used consensus_qc_assembly_length_unambiguous Int Length of consensus assembly excluding ambiguous bases consensus_qc_number_Degenerate Int Number of degenerate bases in consensus assembly consensus_qc_number_N Int Number of N bases in consensus assembly consensus_qc_number_Total Int Total number of bases in consensus assembly consensus_qc_percent_reference_coverage Float Percent of reference genome covered in consensus assembly dehost_wf_dehost_read1 File Reads that did not map to host dehost_wf_host_accession String Host genome accession dehost_wf_host_fasta File Host genome FASTA file dehost_wf_host_flagstat File Output from the SAMtools flagstat command to assess quality of the alignment file (BAM) dehost_wf_host_mapped_bai File Indexed bam file of the reads aligned to the host reference dehost_wf_host_mapped_bam File Sorted BAM file containing the alignments of reads to the host reference genome dehost_wf_host_mapping_cov_hist File Coverage histogram from host read mapping dehost_wf_host_mapping_coverage Float Average coverage from host read mapping dehost_wf_host_mapping_mean_depth Float Average depth from host read mapping dehost_wf_host_mapping_metrics File File of mapping metrics dehost_wf_host_mapping_stats File File of mapping statistics dehost_wf_host_percent_mapped_reads Float Percentage of reads mapped to host reference genome fasta_utilities_fai File FASTA index file fasta_utilities_samtools_docker String Docker image used for samtools in fasta utilities fasta_utilities_samtools_version String Version of samtools used in fasta utilities flye_denovo_docker String Docker image used for Flye flye_denovo_info File Information file from Flye assembly flye_denovo_status String Status of Flye assembly flye_denovo_version String Version of Flye used genoflu_all_segments String The genotypes for each individual flu segment genoflu_genotype String The genotype of the whole genome, based off of the individual segments types genoflu_output_tsv File The output file from GenoFLU genoflu_version String The version of GenoFLU used irma_docker String Docker image used to run IRMA irma_subtype String Flu subtype as determined by IRMA irma_subtype_notes String Helpful note to user about Flu B subtypes. Output will be blank for Flu A samples. For Flu B samples it will state: \"IRMA does not differentiate Victoria and Yamagata Flu B lineages. See abricate_flu_subtype output column\" irma_type String Flu type as determined by IRMA irma_version String Version of IRMA used mask_low_coverage_all_coverage_bed File BED file showing all coverage regions mask_low_coverage_bed File BED file showing masked low coverage regions mask_low_coverage_bedtools_docker String Docker image used for bedtools in masking mask_low_coverage_bedtools_version String Version of bedtools used in masking mask_low_coverage_reference_fasta File Reference FASTA with low coverage regions masked metabuli_classified File Classified reads from Metabuli metabuli_database String Database used for Metabuli metabuli_docker String Docker image used for Metabuli metabuli_krona_report File Krona visualization report from Metabuli metabuli_read1_extract File Extracted reads from Metabuli metabuli_report File Classification report from Metabuli metabuli_version String Version of Metabuli used minimap2_docker String The Docker image of minimap2 minimap2_out File Output file from Minimap2 alignment minimap2_version String The version of minimap2 morgana_magic_organism String Standardized organism name used for characterization morgana_magic_organism String Organism identified nanoplot_html_clean File An HTML report describing the clean reads nanoplot_html_raw File An HTML report describing the raw reads nanoplot_num_reads_clean1 Int Number of clean reads nanoplot_num_reads_raw1 Int Number of raw reads nanoplot_r1_mean_q_clean Float Mean quality score of clean forward reads nanoplot_r1_mean_q_raw Float Mean quality score of raw forward reads nanoplot_r1_mean_readlength_clean Float Mean read length of clean forward reads nanoplot_r1_mean_readlength_raw Float Mean read length of raw forward reads nanoplot_r1_median_q_clean Float Median quality score of clean forward reads nanoplot_r1_median_q_raw Float Median quality score of raw forward reads nanoplot_r1_median_readlength_clean Float Median read length of clean forward reads nanoplot_r1_median_readlength_raw Float Median read length of raw forward reads nanoplot_r1_n50_clean Float N50 of clean forward reads nanoplot_r1_n50_raw Float N50 of raw forward reads nanoplot_r1_stdev_readlength_clean Float Standard deviation read length of clean forward reads nanoplot_r1_stdev_readlength_raw Float Standard deviation read length of raw forward reads nanoplot_tsv_clean File A TSV report describing the clean reads nanoplot_tsv_raw File A TSV report describing the raw reads nanoq_filtered_read1 File Filtered reads from NanoQ nanoq_version String Version of nanoq used in analysis ncbi_datasets_docker String Docker image used for NCBI datasets ncbi_datasets_version String Version of NCBI datasets used ncbi_identify_accession String NCBI accession ID of identified taxon ncbi_identify_avg_genome_length Int Average genome length from NCBI taxon summary ncbi_identify_docker String Docker image used for NCBI identify ncbi_identify_genome_summary_tsv File TSV file with genome summary from NCBI ncbi_identify_read_extraction_rank String Taxonomic rank used for read extraction ncbi_identify_taxon_id String NCBI taxonomy ID of identified organism ncbi_identify_taxon_name String Name of identified taxon ncbi_identify_taxon_summary_tsv File TSV file with taxa specific summary from NCBI ncbi_identify_version String Version of NCBI identify tool used ncbi_scrub_docker String The Docker image for NCBI's HRRT (human read removal tool) ncbi_scrub_human_spots_removed Int Number of spots removed (or masked) ncbi_scrub_read1_dehosted File Dehosted reads after NCBI scrub nextclade_aa_dels_flu_ha String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for HA segment nextclade_aa_dels_flu_ha String Amino-acid deletions as detected by NextClade. Specific to flu; it includes deletions for HA segment nextclade_aa_dels_flu_na String Amino-acid deletions as detected by NextClade. Specific to Flu; it includes deletions for NA segment nextclade_aa_dels_flu_na String Amino-acid deletions as detected by NextClade. Specific to Flu; it includes deletions for NA segment nextclade_aa_dels_mpxv String Amino-acid deletions as detected by Nextclade. Specific to Monkeypox nextclade_aa_dels_rabies String Amino-acid deletions as detected by Nextclade. Specific to Monkeypox nextclade_aa_subs_flu_ha String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for HA segment nextclade_aa_subs_flu_ha String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for HA segment nextclade_aa_subs_flu_na String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for NA segment nextclade_aa_subs_flu_na String Amino-acid substitutions as detected by Nextclade. Specific to Flu; it includes substitutions for NA segment nextclade_aa_subs_mpxv String Amino-acid substitutions as detected by Nextclade. Specific to Monkeypox nextclade_aa_subs_rabies String Amino-acid substitutions as detected by Nextclade. Specific to Monkeypox nextclade_clade_flu_ha String Nextclade clade designation, specific to Flu NA segment nextclade_clade_flu_na String Nextclade clade designation, specific to Flu HA segment nextclade_clade_mpxv String Nextclade clade designation, specific to Monkeypox nextclade_clade_rabies String Nextclade clade designation, specific to Rabies nextclade_docker String Docker image used to run Nextclade nextclade_ds_tag String Dataset tag used to run Nextclade. Will be blank for Flu nextclade_ds_tag_flu_ha String Dataset tag used to run Nextclade, specific to Flu HA segment nextclade_ds_tag_flu_na String Dataset tag used to run Nextclade, specific to Flu NA segment nextclade_json_flu_ha File Nextclade output in JSON file format, specific to Flu HA segment nextclade_json_flu_na File Nextclade output in JSON file format, specific to Flu NA segment nextclade_json_mpxv File Nextclade output in JSON file format, specific to Monkeypox nextclade_json_rabies File Nextclade output in JSON file format, specific to Rabies nextclade_lineage_mpxv String Nextclade lineage designation, specific to Monkeypox nextclade_lineage_rabies String Nextclade lineage designation, specific to Rabies nextclade_qc_flu_ha String QC metric as determined by Nextclade, specific to Flu HA segment nextclade_qc_flu_ha String QC metric as determined by Nextclade, specific to Flu HA segment nextclade_qc_flu_na String QC metric as determined by Nextclade, specific to Flu NA segment nextclade_qc_flu_na String QC metric as determined by Nextclade, specific to Flu NA segment nextclade_qc_mpxv String QC metric as determined by Nextclade, specific to Monkeypox nextclade_qc_rabies String QC metric as determined by Nextclade, specific to Rabies nextclade_tsv_flu_ha File Nextclade output in TSV file format, specific to Flu HA segment nextclade_tsv_flu_na File Nextclade output in TSV file format, specific to Flu NA segment nextclade_tsv_mpxv File Nextclade output in TSV file format, specific to Monkeypox nextclade_tsv_rabies File Nextclade output in TSV file format, specific to Rabies nextclade_version String The version of Nextclade software used pango_lineage String Pango lineage as determined by Pangolin pango_lineage_expanded String Pango lineage without use of aliases; e.g., \"BA.1\" \u2192 \"B.1.1.529.1\" pango_lineage_report File Full Pango lineage report generated by Pangolin pangolin_assignment_version String The version of the pangolin software (e.g. PANGO or PUSHER) used for lineage assignment pangolin_conflicts String Number of lineage conflicts as determined by Pangolin pangolin_docker String Docker image used to run Pangolin pangolin_notes String Lineage notes as determined by Pangolin pangolin_versions String All Pangolin software and database versions parse_mapping_samtools_docker String Docker image used for samtools in parse mapping parse_mapping_samtools_version String Version of samtools used in parse mapping porechop_trimmed_read1 File Trimmed reads from Porechop porechop_version String Version of Porechop used quasitools_coverage_file File The coverage report created by Quasitools HyDRA quasitools_date String Date of Quasitools analysis quasitools_dr_report File Drug resistance report created by Quasitools HyDRA quasitools_hydra_vcf File The VCF created by Quasitools HyDRA quasitools_mutations_report File The mutation report created by Quasitools HyDRA quasitools_version String Version of Quasitools used quast_denovo_docker String Docker image used for QUAST quast_denovo_gc_percent Float GC percentage of de novo assembly from QUAST quast_denovo_genome_length Int Genome length of de novo assembly from QUAST quast_denovo_largest_contig Int Size of largest contig in de novo assembly from QUAST quast_denovo_n50_value Int N50 value of de novo assembly from QUAST quast_denovo_number_contigs Int Number of contigs in de novo assembly from QUAST quast_denovo_report File QUAST report for de novo assembly quast_denovo_uncalled_bases Float Number of uncalled bases in de novo assembly from QUAST quast_denovo_version String Version of QUAST used rasusa_read1_subsampled File Subsampled read file from Rasusa rasusa_read2_subsampled File Subsampled read file from Rasusa (paired file) rasusa_version String Version of RASUSA used for the analysis raven_denovo_docker String Docker image used for Raven raven_denovo_status String Status of Raven assembly raven_denovo_version String Version of Raven used read_mapping_cov_hist File Coverage histogram from read mapping read_mapping_cov_stats File Coverage statistics from read mapping read_mapping_coverage Float Average coverage from read mapping read_mapping_date String Date of read mapping analysis read_mapping_depth Float Average depth from read mapping read_mapping_flagstat File Flagstat file from read mapping read_mapping_meanbaseq Float Mean base quality from read mapping read_mapping_meanmapq Float Mean mapping quality from read mapping read_mapping_percentage_mapped_reads Float Percentage of mapped reads read_mapping_report File Report file from read mapping read_mapping_samtools_version String Version of samtools used in read mapping read_mapping_statistics File Statistics file from read mapping read_screen_clean String PASS or FAIL result from clean read screening; FAIL accompanied by the reason(s) for failure read_screen_clean_tsv File Clean read screening report TSV depicting read counts, total read base pairs, and estimated genome length reference_taxon String NCBI derived taxon name from best ANI hit accession skani_database String Database used for Skani skani_docker String Docker image used for Skani skani_report File Report from Skani skani_status String Status of Skani analysis skani_top_accession String Top accession ID from Skani skani_top_ani Float Top ANI score from Skani skani_top_ani_fasta File FASTA file of top ANI match from Skani skani_top_query_coverage Float Query coverage of top match from Skani skani_top_score Float Top score from Skani skani_version String Version of Skani used skani_warning String Skani warning message theiaviral_ont_date String Date of TheiaViral ONT workflow run theiaviral_ont_version String Version of TheiaViral ONT workflow vadr_alerts_list File A file containing all of the fatal alerts as determined by VADR vadr_all_outputs_tar_gz File A .tar.gz file (gzip-compressed tar archive file) containing all outputs from the VADR command v-annotate.pl. This file must be uncompressed &amp; extracted to see the many files within. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description of all files present within the archive. Useful when deeply investigating a sample's genome &amp; annotations. vadr_classification_summary_file File Per-sequence tabular classification file. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#explanation-of-sqc-suffixed-output-files for more complete description. vadr_docker String Docker image used to run VADR vadr_fastas_zip_archive File Zip archive containing all fasta files created during VADR analysis vadr_feature_tbl_fail File 5 column feature table output for failing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_feature_tbl_pass File 5 column feature table output for passing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_num_alerts String Number of fatal alerts as determined by VADR What are the differences between the de novo and consensus assemblies? <p>De novo genomes are generated from scratch without a reference to guide read assembly, while consensus genomes are generated by mapping reads to a reference and replacing reference positions with identified variants (structural and nucleotide). De novo assemblies are thus not biased by requiring reads map to the reference, though they may be more fragmented. Consensus assembly can generate more robust assemblies from lower coverage samples if the reference genome is sufficient quality and sufficiently closely related to the inputted sequence, though consensus assembly may not perform well in instances of significant structural variation. TheiaViral uses de novo assemblies as an intermediate to acquire the best reference genome for consensus assembly.     </p> <p>We generally recommend TheiaViral users focus on the consensus assembly as the desired assembly output. While we chose the best de novo assemblers for TheiaViral based on internal benchmarking, the consensus assembly will often be higher quality than the de novo assembly. However, the de novo assembly can approach or exceed consensus quality if the read inputs largely comprise one virus, have high depth of coverage, and/or are derived from a virus with high potential for recombination. TheiaViral does conduct assembly contiguity and viral completeness quality control for de novo assemblies, so de novo assembly that meets quality control standards can certainly be used for downstream analysis.</p> How is de novo assembly quality evaluated? <p>De novo assembly quality evaluation focuses on the completeness and contiguity of the genome. While a ground truth genome does not truly exist for quality comparison, reference genome selection can help contextualize quality if the reference is sufficiently similar to the de novo assembly. TheiaViral uses QUAST to acquire basic contiguity statistics and CheckV to assess viral genome completeness and contamination. Additionally, the reference selection software, Skani, can provide a quantitative comparison between the de novo assembly and the best reference genome.</p> <p>Completeness and contamination </p> <ul> <li><code>checkv_denovo_summary</code>: The summary file reports CheckV results on a contig-by-contig basis. Ideally completeness is 100% for a single contig, or 100% for all segments. If there are multiple extraneous contigs in the assembly, one is ideally 100%. The same principles apply to contamination, though it ideally is 0%.</li> <li><code>checkv_denovo_total_genes</code>: The total genes is ideally the same number of genes as expected from the inputted viral taxon. Sometimes CheckV can fail to recover all the genes from a complete genome, so other statistics should be weighted more heavily in quality evaluation.</li> <li><code>checkv_denovo_weighted_completeness</code>: The weighted completeness is ideally 100%.</li> <li><code>checkv_denovo_weighted_contamination</code>: The weighted contamination is ideally 0%.</li> </ul> <p>Length and contiguity </p> <ul> <li><code>quast_denovo_genome_length</code>: The de novo genome length is ideally the same as the expected genome length of the focal virus.</li> <li><code>quast_denovo_largest_contig</code>: The largest contig is ideally the size of the genome, or the size of the largest expected segment. If there are multiple contigs, and the largest contig is the ideal size, then the smaller contigs may be discarded based on the CheckV completeness for the largest contig (see CheckV outputs).</li> <li><code>quast_denovo_n50_value</code>: The N50 is an evaluation of contiguity and is ideally as close as possible to the genome size. For segmented viruses, the N50 should be as close as possible to the size of the segment molecule that would cover at least 50% of the total genome size when segment lengths are added after sorting largest to smallest.</li> <li><code>quast_denovo_number_contigs</code>: The number of contigs is ideally 1 or the total number of segments expected.</li> </ul> <p>Reference genome similarity </p> <ul> <li><code>skani_top_ani</code>: The percent average nucleotide identity (ANI) for the top Skani hit is ideally 100% if the sequenced virus is highly similar to a reference genome. However, if the virus is divergent, ANI is not a good indication of assembly quality.</li> <li><code>skani_top_query_coverage</code>: The percent query coverage for the top Skani hit is ideally 100% if the sequenced virus has not undergone significant recombination/structural variation. </li> <li><code>skani_top_score</code>: The score for the top Skani hit is the ANI x Query (de novo assembly) coverage and is ideally 100% if the sequenced virus is not substantially divergent from the reference dataset.</li> </ul> How is consensus assembly quality evaluated? <p>Consensus assemblies are derived from a reference genome, so quality assessment focuses on coverage and variant quality. Bases with insufficient coverage are denoted as \"N\". Additionally, the size and contiguity of a TheiaViral consensus assembly is expected to approximate the reference genome, so any discrepancy here is likely due to inferred structural variation.</p> <p>Completeness and contamination </p> <ul> <li><code>checkv_consensus_weighted_completeness</code>: The weighted completeness is ideally 100%.</li> </ul> <p>Consensus variant calls </p> <ul> <li><code>consensus_qc_number_Degenerate</code>: The number of degenerate bases is ideally 0. While degenerate bases indicate ambiguity in the sequence, non-N degenerate bases indicate that some information about the base was obtained.</li> <li><code>consensus_qc_number_N</code>: The number of \"N\" bases is ideally 0.</li> </ul> <p>Coverage </p> <ul> <li><code>consensus_qc_percent_reference_coverage</code>: The percent reference coverage is ideally 100%.</li> <li><code>read_mapping_cov_hist</code>: The read mapping coverage histogram ideally depicts normally distributed coverage, which may indicate uniform coverage across the reference genome. However, uniform coverage is unlikely with repetitive regions that approach/exceed read length.</li> <li><code>read_mapping_coverage</code>: The average read mapping coverage is ideally as high as possible.</li> <li><code>read_mapping_meanbaseq</code>: The average mean mapping base quality is ideally as high as possible.</li> <li><code>read_mapping_meanmapq</code>: The average mean mapping alignment quality is ideally as high as possible.</li> <li><code>read_mapping_percentage_mapped_reads</code>: The percent of mapped reads is ideally 100% of the reads classified as the lineage of interest. Some unclassified reads may also map, which may indicate they were erroneously unclassified. Alternatively, these reads could have been erroneously mapped.</li> </ul> Why did the workflow complete without generating a consensus? <p>TheiaViral is designed to \"soft fail\" when specific steps do not succeed due to input data quality. This means the workflow will be reported as successful, with an output that delineates the step that failed. If the workflow fails, please look for the following outputs in this order (sorted by timing of failure, latest first):</p> <ul> <li><code>skani_status</code>: If this output is populated with something other than \"PASS\" and <code>skani_top_accession</code> is populated with \"N/A\", this indicates that Skani did not identify a sufficiently similar reference genome. The Skani database comprises a broad array of NCBI viral genomes, so a failure here likely indicates poor read quality because viral contigs are not found in the de novo assembly or are too small. It may be useful to BLAST whatever contigs do exist in the de novo to determine if there is contamination that can be removed via the <code>host</code> input parameter. Additionally, review CheckV de novo outputs to assess if viral contigs were retrieved. Finally, consider keeping <code>extract_unclassified</code> to \"true\", using a higher <code>read_extraction_rank</code> if it will not introduce contaminant viruses, and invoking a <code>host</code> input to remove host reads if host contigs are present.</li> <li><code>megahit_status</code> / <code>flye_status</code>: If this output is populated with something other than \"PASS\", it indicates the fallback assembler did not successfully complete. The fallback assemblers are permissive, so failure here likely indicates poor read quality. Review read QC to check read quality, particularly following read classification. If read classification is dispensing with a significant number of reads, consider <code>extract_unclassified</code>, <code>read_extraction_rank</code>, and <code>host</code> input adjustment. Otherwise, sequencing quality may be poor.</li> <li><code>metaviralspades_status</code> / <code>raven_denovo_status</code>: If this output is populated with something other than \"PASS\", it indicates the default assembler did not successfully complete or extract viral contigs (MetaviralSPAdes). On their own, these statuses do not correspond directly to workflow failure because fallback de novo assemblers are implemented for both TheiaViral workflows.</li> <li><code>read_screen_clean</code>: If this output is populated with something other than \"PASS\", it indicates the reads did not pass the imposed thresholds. Either the reads are poor quality or the thresholds are too stringent, in which case the thresholds can be relaxed or <code>skip_screen</code> can be set to \"true\".</li> <li><code>dehost_wf_download_status</code>: If this output is populated with something other than \"PASS\", it indicates a host genome could not be retrieved for decontamination. See the <code>host</code> input explanation for more information and review the <code>download_accession</code>/<code>download_taxonomy</code> task output logs for advanced error parsing.</li> </ul> Known errors associated with read quality <ul> <li>ONT workflows may fail at Metabuli if no reads are classified as the <code>taxon</code>. Check the Metabuli <code>classification.tsv</code> or <code>krona</code> report for the read extraction taxon ID to determine if any reads were classified. This error will report <code>out of memory (OOM)</code>, but increasing memory will not resolve it.</li> <li>Illumina workflows may fail at CheckV (de novo) with <code>Error: 80 hmmsearch tasks failed. Program should be rerun</code> if no viral contigs were identified in the de novo assembly.</li> </ul>"},{"location":"workflows/genomic_characterization/theiaviral/#acknowlegments","title":"Acknowlegments","text":"<p>We would like to thank Danny Park at the Broad institute and Jared Johnson at the Washington State Department of Public Health for correspondence during the development of TheiaViral. TheiaViral was built referencing viral-assemble, VAPER, and Artic.</p>"},{"location":"workflows/genomic_characterization/vadr_update/","title":"VADR_Update","text":""},{"location":"workflows/genomic_characterization/vadr_update/#vadr_update","title":"VADR_Update","text":""},{"location":"workflows/genomic_characterization/vadr_update/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Genomic Characterization HAV, Influenza, Monkeypox virus, RSV-A, RSV-B, SARS-CoV-2, Viral, WNV vX.X.X Yes Sample-level VADR_Update_PHB"},{"location":"workflows/genomic_characterization/vadr_update/#vadr_update_phb","title":"VADR_Update_PHB","text":"<p>VADR_Update_PHB is a standalone workflow dedicated to running VADR. By default, the workflow uses a slimmed-down docker image running VADR (v1.6.4), which requires models to be provided separately. The table below outlines the recommended models and VADR parameters for use in the workflow.</p> Organism vadr_model_file vadr_opts max_length sars-cov-2 <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-sarscov2-1.3-2.tar.gz\"</code> <code>\"--mkey sarscov2 --glsearch -s -r --nomisc --lowsim5seq 6 --lowsim3seq 6 --alt_fail lowscore,insertnn,deletinn --noseqnamemax --out_allfasta\"</code> <code>30000</code> MPXV <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-mpxv-1.4.2-1.tar.gz\"</code> <code>\"--mkey mpxv --glsearch --minimap2 -s -r --nomisc --r_lowsimok --r_lowsimxd 100 --r_lowsimxl 2000 --alt_pass discontn,dupregin --s_overhang 150 --out_allfasta\"</code> <code>210000</code> WNV <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-flavi-1.2-1.tar.gz\"</code> <code>\"--mkey flavi --nomisc --noprotid --out_allfasta\"</code> <code>11000</code> flu <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-flu-1.6.3-2.tar.gz\"</code> <code>\"--mkey flu --atgonly --xnocomp --nomisc --alt_fail extrant5,extrant3\"</code> <code>13500</code> rsv_a <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-rsv-1.5-2.tar.gz\"</code> <code>\"--mkey rsv --xnocomp -r\"</code> <code>15500</code> rsv_b <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-rsv-1.5-2.tar.gz\"</code> <code>\"--mkey rsv --xnocomp -r\"</code> <code>15500</code> measles <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-mev-1.02.tar.gz\"</code> <code>\"--mkey mev -r --indefclass 0.01\"</code> <code>18000</code> mumps <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-muv-1.01.tar.gz\"</code> <code>\"--mkey muv -r --indefclass 0.025\"</code> <code>18000</code> rubella <code>\"gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-ruv-1.01.tar.gz\"</code> <code>\"--mkey ruv -r\"</code> <code>10000</code>"},{"location":"workflows/genomic_characterization/vadr_update/#inputs","title":"Inputs","text":"<p>Please note the default values are for SARS-CoV-2.</p> <p>This workflow runs on the sample level.</p> Terra Task Name Variable Type Description Default Value Terra Status vadr_update genome_fasta File Consensus genome assembly Required consensus_qc cpu Int Number of CPUs to allocate to the task 1 Optional consensus_qc disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional consensus_qc docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional consensus_qc genome_length Int Internal component, do not modify Optional consensus_qc memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional consensus_qc reference_genome File Internal component, do not modify Optional organism_parameters auspice_config File Internal component, do not modify Optional organism_parameters clades_tsv File Internal component, do not modify Optional organism_parameters flu_genoflu_genotype String Internal component, do not modify N/A Optional organism_parameters flu_segment String Internal component, do not modify N/A Optional organism_parameters flu_subtype String Internal component, do not modify N/A Optional organism_parameters gene_locations_bed_file File Internal component, do not modify Optional organism_parameters genome_length_input Int Internal component, do not modify Optional organism_parameters hiv_primer_version String Internal component, do not modify v1 Optional organism_parameters kraken_target_organism_input String Internal component, do not modify Optional organism_parameters lat_longs_tsv File Internal component, do not modify Optional organism_parameters min_date Float Internal component, do not modify Optional organism_parameters min_num_unambig Int Internal component, do not modify Optional organism_parameters narrow_bandwidth Float Internal component, do not modify Optional organism_parameters nextclade_dataset_name_input String Internal component, do not modify Optional organism_parameters nextclade_dataset_tag_input String Internal component, do not modify Optional organism_parameters pangolin_docker_image String Internal component, do not modify Optional organism_parameters pivot_interval Int Internal component, do not modify Optional organism_parameters primer_bed_file File Internal component, do not modify Optional organism_parameters proportion_wide Float Internal component, do not modify Optional organism_parameters reference_genbank File Internal component, do not modify Optional organism_parameters reference_genome File Internal component, do not modify Optional organism_parameters reference_gff_file File Internal component, do not modify Optional vadr cpu Int Number of CPUs to allocate to the task 4 Optional vadr disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional vadr docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/vadr:1.6.4 Optional vadr min_length Int Minimum length subsequence to possibly replace Ns for the fasta-trim-terminal-ambigs.pl VADR script 50 Optional vadr_update organism String Target organism for VADR sars-cov-2 Optional vadr_update vadr_max_length Int Maximum length for the fasta-trim-terminal-ambigs.pl VADR script 30000 Optional vadr_update vadr_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional vadr_update vadr_model_file File Path to the a tar + gzipped VADR model file gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-sarscov2-1.3-2.tar.gz Optional vadr_update vadr_opts String Options for the v-annotate.pl VADR script \"--noseqnamemax --glsearch -s -r --nomisc --mkey sarscov2 --lowsim5seq 6 --lowsim3seq 6 --alt_fail lowscore,insertnn,deletinn --out_allfasta\" Optional vadr_update vadr_skip_length Int Minimum assembly length (unambiguous) to run VADR 10000 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/genomic_characterization/vadr_update/#outputs","title":"Outputs","text":"Variable Type Description vadr_alerts_list File A file containing all of the fatal alerts as determined by VADR vadr_all_outputs_tar_gz File A .tar.gz file (gzip-compressed tar archive file) containing all outputs from the VADR command v-annotate.pl. This file must be uncompressed &amp; extracted to see the many files within. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description of all files present within the archive. Useful when deeply investigating a sample's genome &amp; annotations. vadr_classification_summary_file File Per-sequence tabular classification file. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#explanation-of-sqc-suffixed-output-files for more complete description. vadr_docker String Docker image used to run VADR vadr_fastas_zip_archive File Zip archive containing all fasta files created during VADR analysis vadr_feature_tbl_fail File 5 column feature table output for failing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_feature_tbl_pass File 5 column feature table output for passing sequences. See https://github.com/ncbi/vadr/blob/master/documentation/formats.md#format-of-v-annotatepl-output-files for more complete description. vadr_num_alerts String Number of fatal alerts as determined by VADR vadr_update_analysis_date String Date of analysis vadr_update_version String Version of the Public Health Bioinformatics (PHB) repository used"},{"location":"workflows/phylogenetic_construction/augur/","title":"Augur","text":""},{"location":"workflows/phylogenetic_construction/augur/#augur","title":"Augur","text":""},{"location":"workflows/phylogenetic_construction/augur/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Construction Viral v3.0.0 Yes Sample-level, Set-level Augur_Prep_PHB, Augur_PHB"},{"location":"workflows/phylogenetic_construction/augur/#augur-workflows","title":"Augur Workflows","text":"<p>Genomic Epidemiology is an important approach in the effort to understand and mitigate against disease transmission. An often-critical step in viral genomic epidemiology is the generation of phylogenetic trees to explore the genetic relationship between viruses on a local, regional, national or global scale. The Augur workflows, currently only targeted for viral pathogens, facilitate this process by generating files for the visualization of phylogenetic trees with accompanying metadata.</p> <p>Two workflows are offered: Augur_Prep_PHB and Augur_PHB. These must be run sequentially, respectively, to first prepare each individual sample for running Augur, and secondly to run Augur itself on the set of samples, generating the phylogenetic tree files with accompanying metadata. The outputs from these workflows can be visualized in\u00a0Auspice\u00a0and\u00a0UShER.</p> <p>Helpful resources for epidemiological interpretation</p> <ul> <li>introduction to Nextstrain\u00a0(which includes Auspice)</li> <li>guide to Nextstrain\u00a0interactive trees</li> <li>an\u00a0introduction to UShER</li> <li>a video about\u00a0how to read trees\u00a0if this is new to you</li> <li>documentation on how to identify SARS-CoV-2 recombinants</li> </ul>"},{"location":"workflows/phylogenetic_construction/augur/#augur_prep_phb","title":"Augur_Prep_PHB","text":"<p>The Augur_Prep_PHB workflow was written to prepare individual sample assemblies and their metadata for running the Augur_PHB analysis.</p>"},{"location":"workflows/phylogenetic_construction/augur/#augur_prep-inputs","title":"Augur_Prep Inputs","text":"<p>The Augur_Prep_PHB workflow takes assembly FASTA files and associated metadata formatted in a data table. FASTA files may be generated with one of the TheiaCoV Characterization workflows and should adhere to quality control guidelines, (e.g.\u00a0QC guidelines produced by PHA4GE). The metadata can be uploaded to Terra as TSV file, formatted as in this\u00a0example.</p> <p>This workflow runs on the sample level.</p> Terra Task Name Variable Type Description Default Value Terra Status augur_prep assembly File The assembly file for your sample in FASTA format Required augur_prep collection_date String Collection date of the sample Optional augur_prep continent String Continent where sample was collected Optional augur_prep country String Country where sample was collected Optional augur_prep county String County (or smaller locality) where sample was collected Optional augur_prep nextclade_clade String The Nextclade clade of the sample Optional augur_prep pango_lineage String The Pangolin lineage of the sample Optional augur_prep state String State (or province) where sample was collected Optional prep_augur_metadata cpu Int Number of CPUs to allocate to the task 1 Optional prep_augur_metadata disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional prep_augur_metadata docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional prep_augur_metadata memory Int Amount of memory/RAM (in GB) to allocate to the task 3 Optional prep_augur_metadata organism String The organism to be analyzed in Augur; options: \"sars-cov-2\", \"flu\", \"MPXV\", \"rsv-a\", \"rsv-b\" sars-cov-2 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/phylogenetic_construction/augur/#augur_prep-outputs","title":"Augur_Prep Outputs","text":"Variable Type Description augur_metadata File TSV file of the metadata provided as input to the workflow in the proper format for Augur analysis augur_prep_phb_analysis_date String Date of analysis augur_prep_phb_version String Version of the Public Health Bioinformatics (PHB) repository used"},{"location":"workflows/phylogenetic_construction/augur/#augur_phb","title":"Augur_PHB","text":"<p>Helpful Hint</p> <p>You may have to generate phylogenies multiple times, running the Augur_PHB workflow, assessing results, and amending inputs to generate a final tree with sufficient diversity and high-quality data of interest.</p> <p>The Augur_PHB workflow takes a set of assembly/consensus files (FASTA format) and sample metadata files (TSV format) that have been reformatted using\u00a0Augur_Prep_PHB\u00a0and runs Augur to generate the phylogenetic tree files with accompanying metadata. Additionally, the workflow infers pairwise SNP distances.</p>"},{"location":"workflows/phylogenetic_construction/augur/#augur-inputs","title":"Augur Inputs","text":"<p>The Augur_PHB workflow takes in a\u00a0set\u00a0of SARS-CoV-2 (or any other viral pathogen) FASTA and metadata files. If running the workflow via Terra, individual samples will need to be added to a set before running the workflow. Input FASTAs should meet QA metrics. Sets of FASTAs with highly discordant quality metrics may result in the inaccurate inference of genetic relatedness. There must be some sequence diversity among the set of input assemblies. If insufficient diversity is present, it may be necessary to add a more divergent sequence to the set.</p> <p>Optional Inputs</p> <p>There are many optional user inputs. For SARS-CoV-2, Flu, rsv-a, rsv-b, and mpxv, default values that mimic the NextStrain builds have been preselected. To use these defaults, you must write either <code>\"sars-cov-2\"</code>,<code>\"flu\"</code>, <code>\"rsv-a\"</code>, <code>\"rsv-b\"</code>, or <code>\"mpxv\"</code> for the <code>organism</code> variable.</p> <p>For Flu - it is required to set <code>flu_segment</code> to either <code>\"HA\"</code> or <code>\"NA\"</code> &amp; <code>flu_subtype</code> to either <code>\"H1N1\"</code> or <code>\"H3N2\"</code> or <code>\"Victoria\"</code> or <code>\"Yamagata\"</code> or <code>\"H5N1\"</code> (<code>\"H5N1\"</code> will only work with <code>\"HA\"</code>) depending on your set of samples.</p> A Note on Optional Inputs Default values for SARS-CoV-2 <ul> <li>min_num_unambig = 27000</li> <li>clades_tsv = defaults/clades.tsv</li> <li>lat_longs_tsv = defaults/lat_longs.tsv</li> <li>reference_fasta = defaults/reference_seq.fasta</li> <li>reference_genbank = defaults/reference_seq.gb</li> <li>auspice_config = defaults/auspice_config.json</li> <li>min_date = 2020.0</li> <li>pivot_interval = 1</li> <li>pivot_interval_units = \"weeks\"</li> <li>narrow_bandwidth = 0.05</li> <li>proportion_wide = 0.0</li> </ul> Default values for Flu <ul> <li>lat_longs_tsv = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/lat_longs.tsv\"</code></li> <li>min_num_unambig = 900</li> <li>min_date = 2020.0</li> <li>pivot_interval = 1</li> <li>narrow_bandwidth = 0.1666667</li> <li>proportion_wide = 0.0</li> </ul> H1N1 <ul> <li>auspice_config = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/auspice_config_h1n1pdm.json\"</code></li> <li>HA<ul> <li>reference_fasta = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_h1n1pdm_ha.gb\"</code></li> <li>clades_tsv = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/clades_h1n1pdm_ha.tsv\"</code></li> </ul> </li> <li>NA<ul> <li>reference_fasta = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_h1n1pdm_na.gb\"</code></li> </ul> </li> </ul> H3N2 <ul> <li>auspice_config = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/auspice_config_h3n2.json\"</code></li> <li>HA<ul> <li>reference_fasta = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_h3n2_ha.gb\"</code></li> <li>clades_tsv = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/clades_h3n2_ha.tsv\"</code></li> </ul> </li> <li>NA<ul> <li>reference_fasta = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_h3n2_na.gb\"</code></li> </ul> </li> </ul> Victoria <ul> <li>auspice_config = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/auspice_config_vic.json\"</code></li> <li>HA<ul> <li>reference_fasta = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_vic_ha.gb\"</code></li> <li>clades_tsv = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/clades_vic_ha.tsv\"</code></li> </ul> </li> <li>NA<ul> <li>reference_fasta = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_vic_na.gb\"</code></li> </ul> </li> </ul> Yamagata <ul> <li>auspice_config = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/auspice_config_yam.json\"</code></li> <li>HA<ul> <li>reference_fasta = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_yam_ha.gb\"</code></li> <li>clades_tsv = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/clades_yam_ha.tsv\"</code></li> </ul> </li> <li>NA<ul> <li>reference_fasta = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_yam_na.gb\"</code></li> </ul> </li> </ul> H5N1 <ul> <li>auspice_config = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/auspice_config_h5n1.json\"</code></li> <li>HA<ul> <li>reference_fasta = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/reference_h5n1_ha.gb\"</code></li> <li>clades_tsv = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/h5nx-clades.tsv\"</code></li> </ul> </li> </ul> Default values for MPXV <ul> <li>min_num_unambig = 150000</li> <li>clades_tsv = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/mpox_clades.tsv\"</code></li> <li>lat_longs_tsv = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/lat_longs.tsv\"</code></li> <li>reference_fasta = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/NC_063383.1.reference.fasta\"</code></li> <li>reference_genbank = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/NC_063383.1_reference.gb\"</code></li> <li>auspice_config = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/mpox_auspice_config_mpxv.json\"</code></li> <li>min_date = 2020.0</li> <li>pivot_interval = 1</li> <li>narrow_bandwidth = 0.1666667</li> <li>proportion_wide = 0.0</li> </ul> Default values for RSV-A <ul> <li>min_num_unambig = 10850</li> <li>clades_tsv = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/rsv/rsv_a_clades.tsv\"</code></li> <li>lat_longs_tsv = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/lat_longs.tsv\"</code></li> <li>reference_fasta = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/rsv/reference_rsv_a.EPI_ISL_412866.fasta\"</code></li> <li>reference_genbank = <code>\"\"gs://theiagen-public-resources-rp/reference_data/viral/rsv/reference_rsv_a.gb\"</code></li> <li>auspice_config = <code>\"\"gs://theiagen-public-resources-rp/reference_data/viral/rsv/rsv_auspice_config.json\"</code></li> <li>min_date = 2020.0</li> <li>pivot_interval = 1</li> <li>narrow_bandwidth = 0.1666667</li> <li>proportion_wide = 0.0</li> </ul> Default values for RSV-B <ul> <li>min_num_unambig = 10850</li> <li>clades_tsv = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/rsv/rsv_b_clades.tsv\"</code></li> <li>lat_longs_tsv = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/flu/lat_longs.tsv\"</code></li> <li>reference_fasta = <code>\"gs://theiagen-public-resources-rp/reference_data/viral/rsv/reference_rsv_b.EPI_ISL_1653999.fasta\"</code></li> <li>reference_genbank = <code>\"\"gs://theiagen-public-resources-rp/reference_data/viral/rsv/reference_rsv_b.gb\"</code></li> <li>auspice_config = <code>\"\"gs://theiagen-public-resources-rp/reference_data/viral/rsv/rsv_auspice_config.json\"</code></li> <li>min_date = 2020.0</li> <li>pivot_interval = 1</li> <li>narrow_bandwidth = 0.1666667</li> <li>proportion_wide = 0.0</li> </ul> <p>For more information regarding these optional inputs, please view Nextrain's detailed documentation on Augur</p> <p>What's required or not?</p> <p>For organisms other than SARS-CoV-2 or Flu, the required variables have both the \"required\" and \"optional\" tags.</p> <p>This workflow runs on the set level. Please note that for every task, runtime parameters are modifiable (cpu, disk_size, docker, and memory); most of these values have been excluded from the table below for convenience.</p> Terra Task Name Variable Type Description Default Value Terra Status augur assembly_fastas Array[File]+ The assembly files for your samples in FASTA format Required augur build_name String Name to give to the Augur build Required augur clades_tsv File TSV file containing clade mutation positions in four columns Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, an empty clades file is provided to prevent workflow failure, \"gs://theiagen-public-resources-rp/empty_files/minimal-clades.tsv\", but will not be as useful as an organism specific clades file. Optional, Required augur flu_subtype String Required if organism = \"flu\". The subtype of the flu samples being analyzed; options: \"H1N1\", \"H3N2\", \"Victoria\", \"Yamagata\", \"H5N1\" Optional, Required augur reference_fasta File The reference FASTA file used to align the genomes and build the trees Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, a reference fasta file must be provided otherwise the workflow fails. Optional, Required augur reference_genbank File The GenBank .gb file for the same reference genome used for the reference_fasta Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, a reference genbank file must be provided otherwise the workflow fails. Optional, Required augur alignment_fasta File The alignment fasta file in Augur Optional augur augur_trait_columns String Comma-separated list of columns to use for trait analysis in Augur Optional augur auspice_config File Auspice config file for customizing visualizations; takes priority over the other customization values available for augur_export Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, a minimal auspice config file is provided to prevent workflow failure, \"gs://theiagen-public-resources-rp/empty_files/minimal-auspice-config.json\", but will not be as useful as an organism specific config file. Optional augur build_name_updated String Internal component, do not modify Optional augur distance_tree_only Boolean Create only a distance tree (skips all Augur steps after augur_tree) FALSE Optional augur flu_segment String Required if organism = \"flu\". The name of the segment to be analyzed; options: \"HA\" or \"NA\" HA Optional augur lat_longs_tsv File Tab-delimited file of geographic location names with corresponding latitude and longitude values Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, a minimal lat-long file is provided to prevent workflow failure, \"gs://theiagen-public-resources-rp/empty_files/minimal-lat-longs.tsv\", but will not be as useful as a detailed lat-longs file covering all the locations for the samples to be visualized. Optional augur midpoint_root_tree Boolean Boolean variable that will instruct the workflow to reroot the tree at the midpoint TRUE Optional augur min_date Float Minimum date to begin filtering or frequencies calculations Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, the default value is 0.0 Optional augur min_num_unambig Int Minimum number of called bases in genome to pass prefilter Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, the default value is 0 Optional augur narrow_bandwidth Float The bandwidth for the narrow KDE 0.08333 Optional augur organism String Organism used to preselect default values; options: \"sars-cov-2\", \"flu\", \"mpxv\", \"rsv-a\", \"rsv-b\" sars-cov-2 Optional augur pivot_interval Int Number of units between pivots 3 Optional augur proportion_wide Float The proportion of the wide bandwidth to use in the KDE mixture model 0.2 Optional augur remove_reference Boolean Whether or not to remove the reference in Augur FALSE Optional augur run_traits Boolean Whether or not to run trait analysis in Augur FALSE Optional augur sample_metadata_tsvs Array[File] An array of the metadata files produced in Augur_Prep_PHB Optional augur skip_alignment Boolean Whether or not to skip alignment in Augur FALSE Optional augur_align cpu Int Number of CPUs to allocate to the task 64 Optional augur_align disk_size Int Amount of storage (in GB) to allocate to the task 750 Optional augur_align docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Optional augur_align fill_gaps Boolean If true, gaps represent missing data rather than true indels and so are replaced by N after aligning. FALSE Optional augur_align memory Int Amount of memory/RAM (in GB) to allocate to the task 128 Optional augur_ancestral cpu Int Number of CPUs to allocate to the task 4 Optional augur_ancestral disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional augur_ancestral docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Optional augur_ancestral infer_ambiguous Boolean If true, infer nucleotides and ambiguous sites and replace with most likely FALSE Optional augur_ancestral inference String Calculate joint or marginal maximum likelihood ancestral sequence states; options: \"joint\", \"marginal\" joint Optional augur_ancestral keep_ambiguous Boolean If true, do not infer nucleotides at ambiguous (N) sides FALSE Optional augur_ancestral keep_overhangs Boolean If true, do not infer nucleotides for gaps on either side of the alignment FALSE Optional augur_ancestral memory Int Amount of memory/RAM (in GB) to allocate to the task 50 Optional augur_clades cpu Int Number of CPUs to allocate to the task 1 Optional augur_clades disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional augur_clades docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Optional augur_clades memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional augur_export colors_tsv File Custom color defintiions, one per line in the format TRAIT_TYPE\\tTRAIT_VALUE\\tHEX_CODE Optional augur_export cpu Int Number of CPUs to allocate to the task 4 Optional augur_export description_md File Markdown file with description of build and/or acknowledgements Optional augur_export disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional augur_export docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Optional augur_export include_root_sequence Boolean Export an additional JSON containing the root sequence used to identify mutations FALSE Optional augur_export memory Int Amount of memory/RAM (in GB) to allocate to the task 64 Optional augur_export title String The title to be displayed by auspice Optional augur_refine branch_length_inference String Branch length mode of timetree to use; options: \"auto\", \"joint\", \"marginal\", \"input\" auto Optional augur_refine clock_filter_iqd Int Remove tips that deviate more than n_iqd interquartile ranges from the root-to-tip vs time regression 4 Optional augur_refine clock_rate Float Fixed clock rate to use for time tree calculations Optional augur_refine clock_std_dev Float Standard deviation of the fixed clock_rate estimate Optional augur_refine coalescent String Coalescent time scale in units of inverse clock rate (float), optimize as scalar (\"opt\") or skyline (\"skyline\") Optional augur_refine covariance Boolean If true, account for covariation when estimating rates and/or rerooting TRUE Optional augur_refine cpu Int Number of CPUs to allocate to the task 2 Optional augur_refine date_confidence Boolean If true, calculate confidence intervals for node dates TRUE Optional augur_refine date_inference String Assign internal nodes to their marginally most likely dates; options: \"joint\", \"marginal\" marginal Optional augur_refine disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional augur_refine divergence_units String Units in which sequence divergences is exported; options: \"mutations\" or \"mutations-per-site\" mutations Optional augur_refine docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Optional augur_refine gen_per_year Int Number of generations per year 50 Optional augur_refine keep_polytomies Boolean If true, don't attempt to resolve polytomies FALSE Optional augur_refine keep_root Boolean If true, do not reroot the tree; use it as-is (overrides anything specified by root) TRUE Optional augur_refine memory Int Amount of memory/RAM (in GB) to allocate to the task 50 Optional augur_refine precision Int Precision used by TreeTime to determine the number of grid points that are used for the evaluation of the branch length interpolation objects. Values range from 0 (rough) to 3 (ultra fine) and default to 'auto' auto' Optional augur_refine root String Rooting mechanism; options: \"best\", \"least-squares\", \"min_dev\", \"oldest\", etc. Optional augur_traits cpu Int Number of CPUs to allocate to the task 4 Optional augur_traits disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional augur_traits docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Optional augur_traits memory Int Amount of memory/RAM (in GB) to allocate to the task 30 Optional augur_traits metadata_id_columns String The names of possible metadata columns containing identifier information, ordered by priority ('strain', 'name) Optional augur_traits weights File a dictionary of key/value mappings in JSON format used to weight KDE tip frequencies Optional augur_translate cpu Int Number of CPUs to allocate to the task 1 Optional augur_translate disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional augur_translate docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Optional augur_translate genes File A file containing a list of genes to translate (from nucleotides to amino acids) Optional augur_translate memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional augur_tree cpu Int Number of CPUs to allocate to the task 64 Optional augur_tree disk_size Int Amount of storage (in GB) to allocate to the task 750 Optional augur_tree docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Optional augur_tree exclude_sites File File of one-based sites to exclude for raw tree building (BED format in .bed files, DRM format in tab-delimited files, or one position per line) Optional augur_tree memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional augur_tree method String The method used to build the tree. Options: \"fasttree\", \"raxml\", \"iqtree\" (default) iqtree Optional augur_tree override_default_args Boolean If true, override default tree builder arguments instead of augmenting them FALSE Optional augur_tree substitution_model String The substitution model to use; only available for iqtree. Specify \"auto\" to run ModelTest; model options can be found here GTR Optional augur_tree tree_builder_args String Additional tree builder arguments either augmenting or overriding the default arguments. FastTree defaults: \"-nt -nosupport\". RAxML defaults: \"-f d -m GTRCAT -c 25 -p 235813\". IQ-TREE defaults: \"-ninit 2 -n 2 -me 0.05 -nt AUTO -redo\" Optional cat_files cpu Int Number of CPUs to allocate to the task 2 Optional cat_files disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional cat_files docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional cat_files memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional cat_files skip_extra_headers Boolean If the files you are concatenating have identical headers, you can include only the first instance of the header and skip all of the others so they do not appear duplicated in the concatenated file. To activate this, set to true. FALSE Optional fasta_to_ids cpu Int Number of CPUs to allocate to the task 1 Optional fasta_to_ids disk_size Int Amount of storage (in GB) to allocate to the task 375 Optional fasta_to_ids docker String The Docker container to use for the task ubuntu Optional fasta_to_ids memory Int Amount of memory/RAM (in GB) to allocate to the task 1 Optional filter_sequences_by_length cpu Int Number of CPUs to allocate to the task 1 Optional filter_sequences_by_length disk_size Int Amount of storage (in GB) to allocate to the task 300 Optional filter_sequences_by_length docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/broadinstitute/viral-core:2.1.33 Optional filter_sequences_by_length memory Int Amount of memory/RAM (in GB) to allocate to the task 1 Optional mutation_context cpu Int Number of CPUs to allocate to the task 1 Optional mutation_context disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional mutation_context docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/nextstrain-mpox-mutation-context:2024-06-27 Optional mutation_context memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional organism_parameters flu_genoflu_genotype String Internal component, do not modify N/A Optional organism_parameters gene_locations_bed_file File Use to provide locations of interest where average coverage will be calculated Default provided for SARS-CoV-2 (\"gs://theiagen-public-resources-rp/reference_data/viral/sars-cov-2/sc2_gene_locations.bed\") and mpox (\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/mpox_gene_locations.bed\") Optional organism_parameters genome_length_input Int Use to specify the expected genome length; provided by default for all supported organisms Default provided for SARS-CoV-2 (29903), mpox (197200), WNV (11000), flu (13000), RSV-A (16000), RSV-B (16000), HIV (primer versions 1 [9181] and 2 [9840]) Optional organism_parameters hiv_primer_version String The version of HIV primers used. Options are https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl#L156 and https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl#L164. This input is ignored if provided for TheiaCoV_Illumina_SE and TheiaCoV_ClearLabs v1 Optional organism_parameters kraken_target_organism_input String The organism whose abundance the user wants to check in their reads. This should be a proper taxonomic name recognized by the Kraken database. Default provided for mpox (Monkeypox virus), WNV (West Nile virus), and HIV (Human immunodeficiency virus 1) Optional organism_parameters nextclade_dataset_name_input String NextClade organism dataset name Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, the default is \"NA\". Optional organism_parameters nextclade_dataset_tag_input String NextClade organism dataset tag Defaults are organism-specific. Please find default values for all organisms (and for Flu - their respective genome segments and subtypes) here: https://github.com/theiagen/public_health_bioinformatics/blob/main/workflows/utilities/wf_organism_parameters.wdl. For an organism without set defaults, the default is \"NA\". Optional organism_parameters pangolin_docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/pangolin:4.3.1-pdata-1.34 Optional organism_parameters primer_bed_file File The bed file containing the primers used when sequencing was performed REQUIRED FOR SARS-CoV-2, MPOX, WNV, RSV-A &amp; RSV-B. Provided by default only for HIV primer versions 1 (\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/HIV-1_v1.0.primer.hyphen.bed\" and 2 (\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/HIV-1_v2.0.primer.hyphen400.1.bed\") Optional organism_parameters reference_gff_file File Reference GFF file for the organism being analyzed Default provided for mpox (\"gs://theiagen-public-resources-rp/reference_data/viral/mpox/Mpox-MT903345.1.reference.gff3\") and HIV (primer versions 1 [\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/NC_001802.1.gff3\"] and 2 [\"gs://theiagen-public-resources-rp/reference_data/viral/hiv/AY228557.1.gff3\"]) Optional organism_parameters vadr_max_length Int Maximum length for the fasta-trim-terminal-ambigs.pl VADR script Default provided for SARS-CoV-2 (30000), mpox (210000), WNV (11000), flu (0), RSV-A (15500) and RSV-B (15500). Optional organism_parameters vadr_mem Int Amount of memory/RAM (in GB) to allocate to the task 32 (RSV-A, RSV-B, WNV) and 16 (all other TheiaCoV organisms) Optional organism_parameters vadr_model File Path to the a tar + gzipped VADR model file gs://theiagen-public-resources-rp/reference_data/databases/vadr_models/vadr-models-sarscov2-1.3-2.tar.gz Optional organism_parameters vadr_options String Options for the v-annotate.pl VADR script --mkey sarscov2 --glsearch -s -r --nomisc --lowsim5seq 6 --lowsim3seq 6 --alt_fail lowscore,insertnn,deletinn --noseqnamemax --out_allfasta Optional organism_parameters vadr_skip_length Int Minimum assembly length (unambiguous) to run VADR 10000 Optional reorder_matrix cpu Int Number of CPUs to allocate to the task 1 Optional reorder_matrix disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional reorder_matrix docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Optional reorder_matrix memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional reorder_matrix phandango_coloring Boolean Whether or not Phandango coloring will color all items from the same column the same FALSE Optional sc2_defaults cpu Int Number of CPUs to allocate to the task 1 Optional sc2_defaults disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional sc2_defaults docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/augur:22.0.2--pyhdfd78af_0 Optional sc2_defaults memory Int Amount of memory/RAM (in GB) to allocate to the task 1 Optional sc2_defaults nextstrain_ncov_repo_commit String The version of the https://github.com/nextstrain/ncov/ from which to draw default values for SARS-CoV-2. cec4fa0ecd8612e4363d40662060a5a9c712d67e Optional snp_dists cpu Int Number of CPUs to allocate to the task 1 Optional snp_dists disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional snp_dists docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snp-dists:0.8.2 Optional snp_dists memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional tsv_join cpu Int Number of CPUs to allocate to the task 2 Optional tsv_join disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional tsv_join docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/broadinstitute/viral-core:2.1.33 Optional tsv_join memory Int Amount of memory/RAM (in GB) to allocate to the task 7 Optional tsv_join out_suffix String Suffix of merged tsv files .tsv Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Workflow Tasks"},{"location":"workflows/phylogenetic_construction/augur/#augur-tasks","title":"Augur Workflow Tasks","text":"<p>The Augur_PHB workflow uses the inputs to generate a phylogenetic tree in JSON format that is compatible with phylogenetic tree visualization software.</p> <p>In Augur_PHB, the tasks below are called. For the Augur subcommands, please view the Nextstrain Augur documentation for more details and explanations.</p> <ol> <li><code>cat_files</code> - concatenate all of the input fasta files together</li> <li><code>sc2_defaults</code> - if organism is SARS-CoV-2, establish default parameters</li> <li><code>flu_defaults</code> - if organism is Flu, establish default parameters</li> <li><code>filter_sequences_by_length</code> - remove any sequences that do not meet the quality threshold set by <code>min_num_unambig</code></li> <li><code>tsv_join</code> - merge the metadata files</li> <li><code>fasta_to_ids</code> - extract a list of remaining sequences so we know which ones were dropped</li> <li><code>augur_align</code> - perform MAFFT alignment on the sequences</li> <li><code>augur_tree</code> - create a distance tree</li> <li><code>augur_refine</code> - create a timetree</li> <li><code>augur_ancestral</code> - infer ancestral sequences</li> <li><code>augur_translate</code> - translate gene regions from nucleotides to amino acids</li> <li><code>mutation_context</code> - if organism is MPXV, calculates the mutation fraction of G-&gt;A or C-&gt;T changes</li> <li><code>augur_clades</code> - if clade information is provided, assign clades to nodes based on amino-acid or nucleotide signatures</li> <li><code>augur_export</code> - export all the results in a JSON file suitable for Auspice visualization</li> <li><code>snp_dists</code> - create a SNP matrix from the alignment</li> <li><code>reorder_matrix</code> - reorder the SNP matrix to match the distance tree</li> </ol>"},{"location":"workflows/phylogenetic_construction/augur/#augur-outputs","title":"Augur Outputs","text":"<p>Diversity dependent</p> <p>Note that the node &amp; branch coloring by clade or lineage assignment might be dependent on the diversity of your input dataset. This is because the clade assignment is done using the ancestrally reconstructed amino acid or nucleotide changes at the tree nodes rather than a direct sequence-to-reference mutation comparison. You may notice this happening when you get clade/lineage assignments from NextClade when running TheiaCoV workflows, but no clade/lineage assignment on the Augur Auspice tree.</p> <p>To get around this issue, you can upload the Augur output file <code>merged-metadata.tsv</code> to Auspice that includes the correct clade/lineage assignments to allow for coloring by Clade.</p> <p>Flu clade assignments</p> <p>Note that for flu, the clade assignment is usually mostly done for the more recent seasonal influenza viruses. Older strains may get an \"unassigned\" designation for clades. Therefore, it is important to counter check with the NextClade results from TheiaCoV if the lack of clade assignment is due to analyzing older sequences or sequence related.</p> <p>The <code>auspice_input_json</code> is intended to be uploaded to\u00a0Auspice\u00a0to view the phylogenetic tree. This provides a visualization of the genetic relationships between your set of samples. The <code>metadata_merged</code> output can also be uploaded to add context to the phylogenetic visualization. The <code>combined_assemblies</code> output can be uploaded to\u00a0UShER\u00a0to view the samples on a global tree of representative sequences from the public repositories.</p> <p>The Nextstrain team hosts documentation surrounding the Augur workflow \u2192 Auspice visualization here, which details the various components of the Auspice interface: How data is exported by Augur for visualisation in Auspice.</p> Variable Type Description aligned_fastas File A FASTA file of the aligned genomes augur_fasttree_version String The fasttree version used, blank if other tree method used augur_iqtree_model_used String The iqtree model used during augur tree, blank if iqtree not used augur_iqtree_version String The iqtree version used during augur tree (defualt), blank if other tree method used augur_mafft_version String The mafft version used in augur align augur_phb_analysis_date String The date the analysis was run augur_phb_version String The version of the Public Health Bioinformatics (PHB) repository used augur_raxml_version String The version of raxml used during augur tree, blank if other tree method used augur_version String Version of Augur used auspice_input_json File JSON file used as input to Auspice combined_assemblies File Concatenated FASTA file containing all samples distance_tree File The distance tree created in Newick (.nwk) format keep_list File A list of samples included in the phylogenetic tree metadata_merged File Tab-delimited text file of the merged augur_metadata input files from all samples snp_matrix File The SNP distance matrix for all samples used in the phylogenetic tree time_tree File The time tree created in Newick (.nwk) format traits_json File A JSON file containing sample traits"},{"location":"workflows/phylogenetic_construction/augur/#mpox-specific-auspice-output-json","title":"Mpox-specific Auspice Output JSON","text":"<p>If you are building a tree for Mpox samples and set the optional input parameter <code>organism</code> to <code>\"mpox\"</code> , an additional step will be carried out in the Augur_PHB workflow. This additional step will calculate the mutation fraction of G\u2192A or C\u2192T changes. These mutations have been shown to be a characteristic of APOBEC3-type editing, which indicate adaptation of the virus to circulation among humans as was observed with the 2022 clade IIb outbreak, and more recently (2024) with the clade Ib outbreak in South Kivu, Democratic Republic of the Congo.</p> <p>When visualizing the output <code>auspice_input_json</code> file, there will be 2 new choices in the drop-down menu for \"Color By\":</p> <ul> <li>G\u2192A or C\u2192T fraction</li> <li>NGA/TCN context of G\u2192A or C\u2192T mutations.</li> </ul> <p>An example Mpox tree with these \"Color By\" options can be viewed here: https://nextstrain.org/mpox/clade-IIb?c=GA_CT_fraction</p>"},{"location":"workflows/phylogenetic_construction/augur/#references","title":"References","text":"<p>When publishing work using the Augur_PHB workflow, please reference the following:</p> <p>Nextstrain:\u00a0Hadfield J, Megill C, Bell SM, Huddleston J, Potter B, Callender C, Sagulenko P, Bedford T, Neher RA. Nextstrain: real-time tracking of pathogen evolution. Bioinformatics. 2018 Dec 1;34(23):4121-3.</p> <p>When publishing work using inferences from UShER, please reference:</p> <p>UShER:\u00a0Turakhia Y, Thornlow B, Hinrichs AS, De Maio N, Gozashti L, Lanfear R, Haussler D, Corbett-Detig R. Ultrafast Sample placement on Existing tRees (UShER) enables real-time phylogenetics for the SARS-CoV-2 pandemic. Nature Genetics. 2021 Jun;53(6):809-16.</p>"},{"location":"workflows/phylogenetic_construction/clair3_variants/","title":"Clair3_Variants_ONT","text":""},{"location":"workflows/phylogenetic_construction/clair3_variants/#clair3-variants","title":"Clair3 Variants","text":""},{"location":"workflows/phylogenetic_construction/clair3_variants/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Construction Any taxa v3.0.0 Yes Sample-level Clair3_Variants_ONT_PHB"},{"location":"workflows/phylogenetic_construction/clair3_variants/#clair3_variants_ont","title":"Clair3_Variants_ONT","text":"<p>The <code>Clair3_Variants</code> workflow processes Oxford Nanopore Technologies (ONT) sequencing data to identify genetic variations compared to a reference genome. It combines minimap2's long-read alignment capabilities with Clair3's deep learning-based variant calling, designed specifically for ONT data characteristics. The workflow first aligns raw reads to a reference genome using ONT-optimized parameters, processes these alignments into sorted and indexed BAM files, and then employs Clair3's specialized models to detect variants including single nucleotide polymorphisms (SNPs) and insertions/deletions (indels). If enabled, the workflow can also identify longer indels and generate genome-wide variant calls in gVCF format for downstream analysis.</p> <p>Clair3_Variants Workflow Diagram</p> <p></p> <p>Example Use Cases</p> <ul> <li>Variant Discovery: Identify genetic variations in ONT sequencing data compared to a reference genome</li> <li>SNP and Indel Detection: Accurately detect both small variants and longer indels</li> <li>Population Studies: Generate standardized variant calls suitable for population-level analyses</li> </ul>"},{"location":"workflows/phylogenetic_construction/clair3_variants/#supported-clair3-models","title":"Supported Clair3 Models","text":"Model Chemistry Source <code>r941_prom_sup_g5014</code> R9.4.1 Clair3 1.0.10 Release <code>r941_prom_hac_g360+g422</code> R9.4.1 Clair3 1.0.10 Release <code>r941_prom_hac_g238</code> R9.4.1 Clair3 1.0.10 Release <code>r1041_e82_400bps_sup_v500</code> R10.4.1 nanoporetech/rerio <code>r1041_e82_400bps_hac_v500</code> R10.4.1 nanoporetech/rerio <code>r1041_e82_400bps_sup_v410</code> R10.4.1 nanoporetech/rerio <code>r1041_e82_400bps_hac_v410</code> R10.4.1 nanoporetech/rerio <code>ont</code> Various Legacy (Recommended for Guppy3 and Guppy4) <code>ont_guppy2</code> Various Legacy (For Guppy2 data) <code>ont_guppy5</code> Various Legacy (For Guppy5 data) <p>The latest models for ONT are downloaded from the nanoporetech/rerio github. Please let us know if there is a model not included you would like to see added. </p>"},{"location":"workflows/phylogenetic_construction/clair3_variants/#inputs","title":"Inputs","text":"<p>Note on Haploid Settings</p> <p>Several parameters are set by default for haploid genome analysis:</p> <ul> <li>clair3_disable_phasing is set to <code>true</code> since phasing is not relevant for haploid genomes</li> <li>clair3_include_all_contigs is set to <code>true</code> to ensure complete genome coverage</li> <li>clair3_enable_haploid_precise is set to <code>true</code> to only consider homozygous variants (1/1), which is appropriate for haploid genomes</li> </ul> Terra Task Name Variable Type Description Default Value Terra Status clair3_variants_ont read1 File ONT read file in FASTQ file format (compression optional) Required clair3_variants_ont reference_genome_file File Reference genome in FASTA format Required clair3_variants_ont samplename String The name of the sample being analyzed Required clair3_variants indel_min_af Float Minimum Indel AF required for a candidate variant Optional clair3_variants snp_min_af Float Minimum SNP AF required for a candidate variant Optional clair3_variants_ont clair3_cpu Int Number of CPUs to allocate to the task 4 Optional clair3_variants_ont clair3_disable_phasing Boolean Disable whatshap phasing TRUE Optional clair3_variants_ont clair3_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional clair3_variants_ont clair3_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/clair3:1.0.10 Optional clair3_variants_ont clair3_enable_gvcf Boolean Output gVCF format FALSE Optional clair3_variants_ont clair3_enable_haploid_precise Boolean Enable haploid precise calling, only 1/1 is considered as a variant TRUE Optional clair3_variants_ont clair3_enable_long_indel Boolean Enable long indel calling FALSE Optional clair3_variants_ont clair3_include_all_contigs Boolean Call variants on all contigs, should always be true for non-human samples TRUE Optional clair3_variants_ont clair3_memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional clair3_variants_ont clair3_model String Model name for variant calling (see supported models for available options) r1041_e82_400bps_sup_v500 Optional clair3_variants_ont clair3_variant_quality Int Minimum variant quality score 2 Optional minimap2 cpu Int Number of CPUs to allocate to the task 2 Optional minimap2 disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional minimap2 docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/minimap2:2.22 Optional minimap2 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional minimap2 query2 File Internal component, do not modify Optional sam_to_sorted_bam cpu Int Number of CPUs to allocate to the task 2 Optional sam_to_sorted_bam disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional sam_to_sorted_bam docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Optional sam_to_sorted_bam memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional sam_to_sorted_bam min_qual Int Minimum quality score for reads to be included in the analysis Optional samtools_faidx cpu Int Number of CPUs to allocate to the task 1 Optional samtools_faidx disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional samtools_faidx docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/samtools:1.17 Optional samtools_faidx memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/phylogenetic_construction/clair3_variants/#workflow-tasks","title":"Workflow Tasks","text":"<code>minimap2</code>: Read Alignment Details <p><code>minimap2</code> is a popular aligner that is used to align reads (or assemblies) to an assembly file. In minimap2, \"modes\" are a group of preset options.</p> <p>The mode used in this task is <code>map-ont</code> with additional long-read-specific parameters (the <code>-L --cs --MD</code> flags) to align ONT reads to the reference genome. These specialized parameters are essential for proper handling of long read error profiles, generation of detailed alignment information, and improved mapping accuracy for long reads.</p> <p><code>map-ont</code> is the default mode for long reads and it indicates that long reads of ~10% error rates should be aligned to the reference genome. The output file is in SAM format.</p> <p>For more information regarding modes and the available options for <code>minimap2</code>, please see the minimap2 manpage</p> <p>minimap2 Technical Details</p> Links Task task_minimap2.wdl Software Source Code minimap2 on GitHub Software Documentation minimap2 Original Publication(s) Minimap2: pairwise alignment for nucleotide sequences <code>samtools</code>: BAM Processing <p>The bam processing step aligns files through several coordinate-based steps to prepare for variant calling. The task converts SAM format to BAM, sorts the BAM file by coordinate, and creates a BAM index file. This processed BAM is required for Clair3's variant calling pipeline.</p> <p>samtools Technical Details</p> Links Task task_samtools.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <code>samtools faidx</code>: Reference Genome Indexing <p><code>samtools faidx</code> creates necessary index files for the reference. This indexing step is    essential for enabling efficient random access to the reference sequence during variant calling.</p> <p>samtools Technical Details</p> Links Task task_samtools.wdl Software Source Code samtools on GitHub Software Documentation samtools Original Publication(s) The Sequence Alignment/Map format and SAMtoolsTwelve Years of SAMtools and BCFtools <code>Clair3</code>: Variant Calling <p><code>Clair3</code> performs deep learning-based variant detection using a multi-stage approach. The process begins with pileup-based calling for initial variant identification, followed by full-alignment analysis for comprehensive variant detection. Results are merged into a final high-confidence call set.</p> <p>The variant calling pipeline employs specialized neural networks trained on ONT data to accurately identify: - Single nucleotide variants (SNVs) - Small insertions and deletions (indels) - Structural variants</p> <p>Clair3 Technical Details</p> Links Task task_clair3_variants.wdl Software Source Code Clair3 on GitHub Software Documentation Clair3 Documentation Original Publication(s) Symphonizing pileup and full-alignment for deep learning-based long-read variant calling"},{"location":"workflows/phylogenetic_construction/clair3_variants/#outputs","title":"Outputs","text":"Variable Type Description aligned_bai File Index companion file to the bam file generated during the consensus assembly process aligned_bam File Sorted BAM file containing the alignments of reads to the reference genome aligned_fai File Index file for the reference genome clair3_docker_image String Version of the Docker container used for Clair3 variant calling clair3_model_used String Name of the Clair3 model used for variant calling clair3_variants_gvcf File Optional genome VCF file containing information about all genomic positions, including non-variant sites clair3_variants_vcf File Final merged VCF file containing high-confidence variant calls, combining results from both pileup and full-alignment approaches clair3_variants_wf_version String Version of the PHB workflow used clair3_version String Clair3 Version being used samtools_version String The version of SAMtools used to sort and index the alignment file"},{"location":"workflows/phylogenetic_construction/core_gene_snp/","title":"Core_Gene_SNP","text":""},{"location":"workflows/phylogenetic_construction/core_gene_snp/#core_gene_snp","title":"Core_Gene_SNP","text":""},{"location":"workflows/phylogenetic_construction/core_gene_snp/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Construction Bacteria v3.0.0 Some optional features incompatible, Yes Set-level Core_Gene_SNP_PHB"},{"location":"workflows/phylogenetic_construction/core_gene_snp/#core_gene_snp_phb","title":"Core_Gene_SNP_PHB","text":"<p>Core Gene SNP Workflow Diagram</p> <p></p> <p>The Core_Gene_SNP workflow is intended for pangenome analysis, core gene alignment, and phylogenetic analysis. The workflow takes in gene sequence data in GFF3 format from a set of samples. It first produces a pangenome summary using <code>Pirate</code>, which clusters genes within the sample set into orthologous gene families. By default, the workflow also instructs <code>Pirate</code> to produce both core gene and pangenome alignments. The workflow subsequently triggers the generation of a phylogenetic tree and SNP distance matrix from the core gene alignment using <code>iqtree</code> and <code>snp-dists</code>, respectively. Optionally, the workflow will also run this analysis using the pangenome alignment. This workflow also features an optional module, <code>summarize_data</code>, that creates a presence/absence matrix for the analyzed samples from a list of indicated columns (such as AMR genes, etc.) that can be used in Phandango.</p> <p>Default Parameters</p> <p>Please note that while default parameters for pangenome construction and phylogenetic tree generation are provided, these default parameters may not suit every dataset and have not been validated against known phylogenies. Users should take care to select the parameters that are most appropriate for their dataset. Please reach out to support@theiagen.com or one of the other resources listed at the bottom of this page if you would like assistance with this task.</p>"},{"location":"workflows/phylogenetic_construction/core_gene_snp/#inputs","title":"Inputs","text":"<p>For further detail regarding Pirate options, please see PIRATE's documentation. For further detail regarding IQ-TREE options, please see <code>http://www.iqtree.org/doc/Command-Reference</code>.</p> <p>This workflow runs on the set level.</p> Terra Task Name Variable Type Description Default Value Terra Status core_gene_snp_workflow cluster_name String Name of sample set Required core_gene_snp_workflow gff3 Array[File] Array of gff3 files to include in analysis, output gff files from both prokka and bakta using TheiaProk workflows are compatible Required core_gene_snp_workflow align Boolean Boolean variable that instructs the workflow to generate core and pangenome alignments if \"true\". If \"false\", the workflow will produce only a pangenome summary. TRUE Optional core_gene_snp_workflow core_tree Boolean Boolean variable that instructs the workflow to create a phylogenetic tree and SNP distance matrix from the core gene alignment. Align must also be set to true. TRUE Optional core_gene_snp_workflow data_summary_column_names String A comma-separated list of the column names from the sample-level data table for generating a data summary (presence/absence .csv matrix); e.g., \"amrfinderplus_amr_genes,amrfinderplus_virulence_genes\" Optional core_gene_snp_workflow data_summary_terra_project String The billing project for your current workspace. This can be found after the \"#workspaces/\" section in the workspace's URL Optional core_gene_snp_workflow data_summary_terra_table String The name of the sample-level Terra data table that will be used for generating a data summary Optional core_gene_snp_workflow data_summary_terra_workspace String The name of the Terra workspace you are in. This can be found at the top of the webpage, or in the URL after the billing project. Optional core_gene_snp_workflow midpoint_root_tree Boolean Boolean variable that will instruct the workflow to reroot the tree at the midpoint TRUE Optional core_gene_snp_workflow pan_tree Boolean Boolean variable that instructs the workflow to create a phylogenetic tree and SNP distance matrix from the pangenome alignment. Align must also be set to true. FALSE Optional core_gene_snp_workflow phandango_coloring Boolean Boolean variable that tells the data summary task and the reorder matrix task to include a suffix that enables consistent coloring on Phandango; by default, this suffix is not added. To add this suffix set this variable to true. FALSE Optional core_gene_snp_workflow sample_names Array[String] Array of sample_ids from the data table used Optional core_iqtree alrt Int Number of replicates to use for the SH-like approximate likelihood ratio test (Minimum recommended= 1000). Follows IQ-TREE \"-alrt\" option 1000 Optional core_iqtree cpu Int Number of CPUs to allocate to the task 4 Optional core_iqtree disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional core_iqtree docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/iqtree:1.6.7 Optional core_iqtree iqtree_bootstraps Int Number of ultrafast bootstrap replicates. Follows IQ-TREE \"-bb\" option. 1000 Optional core_iqtree iqtree_model String Substitution model, frequency type (optional) and rate heterogeneity type (optional) used by IQ-TREE. This string follows the IQ-TREE \"-m\" option. For comparison to other tools use HKY for Bactopia, GTR+F+I for Grandeur, GTR+G4 for Nullarbor, GTR+G for Dryad GTR+I+G Optional core_iqtree iqtree_opts String Additional options for IQ-TREE, see http://www.iqtree.org/doc/Command-Reference Optional core_iqtree memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional core_reorder_matrix cpu Int Number of CPUs to allocate to the task 1 Optional core_reorder_matrix disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional core_reorder_matrix docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Optional core_reorder_matrix memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional core_snp_dists cpu Int Number of CPUs to allocate to the task 1 Optional core_snp_dists disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional core_snp_dists docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snp-dists:0.8.2 Optional core_snp_dists memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional pan_iqtree alrt Int Number of replicates to use for the SH-like approximate likelihood ratio test (Minimum recommended= 1000). Follows IQ-TREE \"-alrt\" option 1000 Optional pan_iqtree cpu Int Number of CPUs to allocate to the task 4 Optional pan_iqtree disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional pan_iqtree docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/iqtree:1.6.7 Optional pan_iqtree iqtree_bootstraps Int Number of ultrafast bootstrap replicates. Follows IQ-TREE \"-bb\" option. 1000 Optional pan_iqtree iqtree_model String Substitution model, frequency type (optional) and rate heterogeneity type (optional) used by IQ-TREE. This string follows the IQ-TREE \"-m\" option. For comparison to other tools use HKY for Bactopia, GTR+F+I for Grandeur, GTR+G4 for Nullarbor, GTR+G for Dryad GTR+I+G Optional pan_iqtree iqtree_opts String Additional options for IQ-TREE, see http://www.iqtree.org/doc/Command-Reference Optional pan_iqtree memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional pan_reorder_matrix cpu Int Number of CPUs to allocate to the task 1 Optional pan_reorder_matrix disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional pan_reorder_matrix docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Optional pan_reorder_matrix memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional pan_snp_dists cpu Int Number of CPUs to allocate to the task 1 Optional pan_snp_dists disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional pan_snp_dists docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snp-dists:0.8.2 Optional pan_snp_dists memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional pirate cpu Int Number of CPUs to allocate to the task 4 Optional pirate disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional pirate docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/pirate:1.0.5--hdfd78af_0 Optional pirate features String Features to use for pangenome construction [default: CDS] CDS Optional pirate memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional pirate nucl Boolean Boolean variable that instructs pirate to create a pangenome on CDS features using nucleotide identity, rather than amino acid identity, if true. FALSE Optional pirate panopt String Additional arguments for Pirate Optional pirate steps String Identity thresholds to use for pangenome construction 50,60,70,80,90,95,98 Optional summarize_data cpu Int Number of CPUs to allocate to the task 8 Optional summarize_data disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional summarize_data docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional summarize_data id_column_name String If the sample IDs are in a different column to samplenames, it can be passed here and it will be used instead. Optional summarize_data memory Int Amount of memory/RAM (in GB) to allocate to the task 1 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/phylogenetic_construction/core_gene_snp/#workflow-tasks","title":"Workflow Tasks","text":"<p>By default, the Core_Gene_SNP workflow will begin by analyzing the input sample set using PIRATE. Pirate takes in GFF3 files and classifies the genes into gene families by sequence identity, outputting a pangenome summary file. The workflow will instruct Pirate to create core gene and pangenome alignments using this gene family data. Setting the \"align\" input variable to false will turn off this behavior, and the workflow will output only the pangenome summary. The workflow will then use the core gene alignment from <code>Pirate</code> to infer a phylogenetic tree using <code>IQ-TREE</code>. It will also produce an SNP distance matrix from this alignment using snp-dists. This behavior can be turned off by setting the <code>core_tree</code> input variable to false. The workflow will not create a pangenome tree or SNP-matrix by default, but this behavior can be turned on by setting the <code>pan_tree</code> input variable to true.</p> <p>The optional <code>summarize_data</code> task performs the following only if all of the <code>data_summary_*</code> and <code>sample_names</code> optional variables are filled out:</p> <ol> <li>Digests a comma-separated  list of column names, such as <code>\"amrfinderplus_virulence_genes,amrfinderplus_stress_genes\"</code>, etc. that can be found within the origin Terra data table.</li> <li>It will then parse through those column contents and extract each value; for example, if the <code>amrfinder_amr_genes</code> column for a sample contains these values: <code>\"aph(3')-IIIa,tet(O),blaOXA-193\"</code>, the <code>summarize_data</code> task will check each sample in the set to see if they also have those AMR genes detected.</li> <li>Outputs a .csv file that indicates presence (TRUE) or absence (empty) for each item in those columns; that is, it will check each sample in the set against the detected items in each column to see if that value was also detected.</li> </ol> <p>By default, this task appends a Phandango coloring tag to color all items from the same column the same; this can be turned off by setting the optional <code>phandango_coloring</code> variable to <code>false</code>.</p>"},{"location":"workflows/phylogenetic_construction/core_gene_snp/#outputs","title":"Outputs","text":"Variable Type Description core_gene_snp_wf_analysis_date String Date of analysis using Core_Gene_SNP workflow core_gene_snp_wf_version String Version of PHB used for analysis pirate_core_alignment_fasta File Nucleotide alignments of the core genes as created using MAFFT within Pirate. Loci are ordered according to the gene_families.ordered file. pirate_core_alignment_gff File Annotation data for the gene family within the corresponding fasta file pirate_core_snp_matrix File SNP distance matrix created from the core gene alignment pirate_docker_image String Pirate docker image used pirate_filtered_metadata File Filtered metadata for the core gene alignment pirate_gene_families_ordered File Summary of all gene families, as estimated by Pirate pirate_iqtree_core_tree File Phylogenetic tree produced by IQ-TREE from the core gene alignment pirate_iqtree_pan_tree File Phylogenetic tree produced by IQ-TREE from the pangenome alignment pirate_iqtree_version String IQ-TREE version used pirate_pan_alignment_fasta File Nucleotide alignments of the pangenome by gene as created using MAFFT within Pirate. Loci are ordered according to the gene_families.ordered file. pirate_pan_alignment_gff File Annotation data for the gene family within the corresponding fasta file pirate_pan_snp_matrix File SNP distance matrix created from the pangenome alignment pirate_pangenome_summary File Summary of the number and frequency of genes in the pangenome, as estimated by Pirate pirate_presence_absence_csv File A file generated by Pirate that allows many post-alignment tools created for Roary to be used on the output from Pirate pirate_snps_dists_version String Version of snp-dists used pirate_summarized_data File The presence/absence matrix generated by the summarize_data task from the list of columns provided"},{"location":"workflows/phylogenetic_construction/core_gene_snp/#references","title":"References","text":"<p>Sion C Bayliss, Harry A Thorpe, Nicola M Coyle, Samuel K Sheppard, Edward J Feil, PIRATE: A fast and scalable pangenomics toolbox for clustering diverged orthologues in bacteria,\u00a0GigaScience, Volume 8, Issue 10, October 2019, giz119,\u00a0https://doi.org/10.1093/gigascience/giz119</p> <p>Lam-Tung Nguyen, Heiko A. Schmidt, Arndt von Haeseler, Bui Quang Minh, IQ-TREE: A Fast and Effective Stochastic Algorithm for Estimating Maximum-Likelihood Phylogenies,\u00a0Molecular Biology and Evolution, Volume 32, Issue 1, January 2015, Pages 268\u2013274,\u00a0https://doi.org/10.1093/molbev/msu300</p> <p>https://github.com/tseemann/snp-dists</p>"},{"location":"workflows/phylogenetic_construction/czgenepi_prep/","title":"CZGenEpi_Prep","text":""},{"location":"workflows/phylogenetic_construction/czgenepi_prep/#czgenepi_prep","title":"CZGenEpi_Prep","text":""},{"location":"workflows/phylogenetic_construction/czgenepi_prep/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Construction Monkeypox virus, SARS-CoV-2, Viral v1.3.0 Yes Set-level CZGenEpi_Prep_PHB"},{"location":"workflows/phylogenetic_construction/czgenepi_prep/#czgenepi_prep_phb","title":"CZGenEpi_Prep_PHB","text":"<p>The CZGenEpi_Prep workflow prepares data for upload to the Chan Zuckerberg GEN EPI platform, where phylogenetic trees and additional data processing can occur. This workflow extracts the necessary metadata fields from your Terra table.</p>"},{"location":"workflows/phylogenetic_construction/czgenepi_prep/#inputs","title":"Inputs","text":"<p>In order to enable customization for where certain fields should be pulled from the Terra table, the user can specify different column names in the appropriate location. For example, if the user wants to use the \"clearlabs_fasta\" column for the assembly file instead of the default \"assembly_fasta\" column, they can write \"clearlabs_fasta\" for the <code>assembly_fasta_column_name</code> optional variable.</p> <p>Variables with both the \"Optional\" and \"Required\" tag require the column (regardless of name) to be present in the data table.</p> <p>This workflow runs on the set level.</p> Terra Task Name Variable Type Description Default Value Terra Status czgenepi_prep assembly_fasta_column_name String The column name where the sample's assembly file can be found Required czgenepi_prep collection_date_column_name String The column name where the sample's collection date can be found Required czgenepi_prep continent_column_name String The column name where the sample's originating continent can be found Required czgenepi_prep country_column_name String The column name where the sample's originating country can be found Required czgenepi_prep county_column_name String The column name where the samples' originating county can be found Required czgenepi_prep sample_names Array[String] The array of sample ids you want to prepare for CZ GEN EPI Required czgenepi_prep state_column_name String The column name where the sample's originating state can be found Required czgenepi_prep terra_project_name String The name of the Terra project where the data is hosted Required czgenepi_prep terra_table_name String The name of the Terra table where the data is hosted Required czgenepi_prep terra_workspace_name String The name of the Terra workspace where the data is hosted Required czgenepi_prep genbank_accession_column_name String The column name where the genbank accession for the sample can be found genbank_accession Optional czgenepi_prep is_private Boolean Sets whether sample status is provate, or not TRUE Optional czgenepi_prep organism String The organism for data preparation. Options: \"mpox\" or \"sars-cov-2\" sars-cov-2 Optional czgenepi_prep private_id_column_name String The column name where the Private ID for the sample can be found terra_table_name_id Optional czgenepi_prep sequencing_date_column_name String The column name where the sample's sequencing data can be found sequencing_date Optional czgenepi_wrangling cpu Int Number of CPUs to allocate to the task 1 Optional czgenepi_wrangling disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional czgenepi_wrangling docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-08-08-2 Optional czgenepi_wrangling memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional download_terra_table cpu Int Number of CPUs to allocate to the task 1 Optional download_terra_table disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional download_terra_table docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Optional download_terra_table memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/phylogenetic_construction/czgenepi_prep/#outputs","title":"Outputs","text":"<p>The concatenated_czgenepi_fasta and concatenated_czgenepi_metadata files can be uploaded directly to CZ GEN EPI without any adjustments.</p> Variable Type Description concatenated_czgenepi_fasta File The concatenated fasta file with the renamed headers (the headers are renamed to account for clearlabs data which has unique headers) concatenated_czgenepi_metadata File The concatenated metadata that was extracted from the terra table using the specified columns czgenepi_prep_analysis_date String The date the workflow was run czgenepi_prep_version String The version of PHB the workflow is in"},{"location":"workflows/phylogenetic_construction/czgenepi_prep/#references","title":"References","text":"<p>CZ GEN EPI Help Center \"Uploading Data\" https://help.czgenepi.org/hc/en-us/articles/6160372401172-Uploading-data</p>"},{"location":"workflows/phylogenetic_construction/find_shared_variants/","title":"Find_Shared_Variants","text":""},{"location":"workflows/phylogenetic_construction/find_shared_variants/#find_shared_variants","title":"Find_Shared_Variants","text":""},{"location":"workflows/phylogenetic_construction/find_shared_variants/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Construction Bacteria, Mycotics v2.0.0 Yes Set-level Find_Shared_Variants_PHB"},{"location":"workflows/phylogenetic_construction/find_shared_variants/#find_shared_variants_phb","title":"Find_Shared_Variants_PHB","text":"<p><code>Find_Shared_Variants_PHB</code> is a workflow for concatenating the variant results produced by the <code>Snippy_Variants_PHB</code> workflow across multiple samples and reshaping the data to illustrate variants that are shared among multiple samples.</p> <p>Find_Shared_Variants Workflow Diagram</p> <p></p>"},{"location":"workflows/phylogenetic_construction/find_shared_variants/#inputs","title":"Inputs","text":"<p>The primary intended input of the workflow is the <code>snippy_variants_results</code> output from <code>Snippy_Variants_PHB</code> or the <code>theiaeuk_snippy_variants_results</code> output of the TheiaEuk workflow. Variant results files from other tools may not be compatible at this time.</p> <p>All variant data included in the sample set should be generated from aligning sequencing reads to the same reference genome. If variant data was generated using different reference genomes, shared variants cannot be identified and results will be less useful.</p> Terra Task Name Variable Type Description Default Value Terra Status shared_variants_wf concatenated_file_name String String of your choice to prefix output files Required shared_variants_wf samplenames Array[String] The names of the samples being analyzed Required shared_variants_wf variants_to_cat Array[File] The result file from the Snippy_Variants workflow Required cat_variants docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional shared_variants cpu Int Number of CPUs to allocate to the task 1 Optional shared_variants disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional shared_variants docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional shared_variants memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/phylogenetic_construction/find_shared_variants/#tasks","title":"Tasks","text":"Concatenate Variants Shared Variants"},{"location":"workflows/phylogenetic_construction/find_shared_variants/#concatenate-variants","title":"Concatenate Variants","text":"<p>The <code>cat_variants</code> task concatenates variant data from multiple samples into a single file <code>concatenated_variants</code>. It is very similar to the <code>cat_files</code> task, but also adds a column to the output file that indicates the sample associated with each row of data.</p> <p>The <code>concatenated_variants</code> file will be in the following format:</p> samplename CHROM POS TYPE REF ALT EVIDENCE FTYPE STRAND NT_POS AA_POS EFFECT LOCUS_TAG GENE PRODUCT sample1 PEKT02000007 5224 snp C G G:21 C:0 sample2 PEKT02000007 34112 snp C G G:32 C:0 CDS + 153/1620 51/539 missense_variant c.153C&gt;G p.His51Gln B9J08_002604 hypothetical protein sample3 PEKT02000007 34487 snp T A A:41 T:0 CDS + 528/1620 176/539 missense_variant c.528T&gt;A p.Asn176Lys B9J08_002604 hypothetical protein <p>Technical Details</p> Links Task task_cat_files.wdl"},{"location":"workflows/phylogenetic_construction/find_shared_variants/#shared-variants","title":"Shared Variants","text":"<p>The <code>shared_variants</code> task takes in the <code>concatenated_variants</code> output from the <code>cat_variants</code> task and reshapes the data so that variants are rows and samples are columns. For each variant, samples where the variant was detected are populated with a \"1\" and samples were either the variant was not detected or there was insufficient coverage to call variants are populated with a \"0\". The resulting table is available as the <code>shared_variants_table</code> output.</p> <p>The <code>shared_variants_table</code> file will be in the following format:</p> CHROM POS TYPE REF ALT FTYPE STRAND NT_POS AA_POS EFFECT LOCUS_TAG GENE PRODUCT sample1 sample2 sample3 PEKT02000007 2693938 snp T C CDS - 1008/3000 336/999 synonymous_variant c.1008A&gt;G p.Lys336Lys B9J08_003879 NA chitin synthase 1 1 1 0 PEKT02000007 2529234 snp G C CDS + 282/336 94/111 missense_variant c.282G&gt;C p.Lys94Asn B9J08_003804 NA cytochrome c 1 1 1 PEKT02000002 1043926 snp A G CDS - 542/1464 181/487 missense_variant c.542T&gt;C p.Ile181Thr B9J08_000976 NA dihydrolipoyl dehydrogenase 1 1 0 <p>Technical Details</p> Links Task task_shared_variants.wdl"},{"location":"workflows/phylogenetic_construction/find_shared_variants/#outputs","title":"Outputs","text":"<p>The outputs of this workflow are the <code>concatenated_variants</code> file and the <code>shared_variants_table</code> file.</p> Variable Type Description concatenated_variants File The concatenated variants without presence/absence shared_variants_analysis_date String The date the workflow was run shared_variants_table File The shared variants table listing presence/absence for each mutation identified in the samples shared_variants_version String The version of PHB the workflow is in"},{"location":"workflows/phylogenetic_construction/ksnp3/","title":"kSNP3","text":""},{"location":"workflows/phylogenetic_construction/ksnp3/#ksnp3","title":"kSNP3","text":""},{"location":"workflows/phylogenetic_construction/ksnp3/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Construction Bacteria, Mycotics, Viral v3.0.0 Some optional features incompatible, Yes Set-level kSNP3_PHB"},{"location":"workflows/phylogenetic_construction/ksnp3/#ksnp3_phb","title":"kSNP3_PHB","text":"<p>The kSNP3 workflow is for phylogenetic analysis of bacterial genomes using single nucleotide polymorphisms (SNPs). The kSNP3 workflow identifies SNPs amongst a set of genome assemblies, then calculates a number of phylogenetic trees based on those SNPs:</p> <ul> <li>Pan-genome phylogenetic trees: The term \"pan-genome\" is used here to describe the collective genetic content amongst the set of genomes, including regions outside of genes and other coding sequences.  Outputs based on the pan-genome are labeled with <code>_pan</code>.</li> <li>Core-genome phylogenetic trees: The kSNP3 workflow will also generate phylogenetic trees based on the core genome (genetic content that is present in all members of the set of genomes). Outputs based on the core-genome are labeled with <code>_core</code>.</li> </ul> <p>This workflow also features an optional module, <code>summarize_data</code> that creates a presence/absence matrix for the analyzed samples from a list of indicated columns (such as AMR genes, plasmid types etc.). If the <code>phandango_coloring</code> variable is set to <code>true</code>, this will be formatted for visualization in Phandango, else it can be viewed in Excel.</p> <p>You can learn more about the kSNP3 workflow, including how to visualize the outputs with MicrobeTrace in the following video: \ud83d\udcfa Using KSNP3 in Terra and Visualizing Bacterial Genomic Networks in MicrobeTrace</p>"},{"location":"workflows/phylogenetic_construction/ksnp3/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status ksnp3_workflow assembly_fasta Array[File] The assembly files for your samples in FASTA format Required ksnp3_workflow cluster_name String Free text string used to label output files Required ksnp3_workflow samplename Array[String] The names of the samples being analyzed Required core_ksnp3_shared_snps_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional core_reorder_matrix cpu Int Number of CPUs to allocate to the task 1 Optional core_reorder_matrix disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional core_reorder_matrix docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Optional core_reorder_matrix memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional core_snp_dists cpu Int Number of CPUs to allocate to the task 1 Optional core_snp_dists disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional core_snp_dists docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snp-dists:0.8.2 Optional core_snp_dists memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional ksnp3_task cpu Int Number of CPUs to allocate to the task 2 Optional ksnp3_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ksnp3_task docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ksnp3:3.1 Optional ksnp3_task kmer_size Int The length of kmer containing the SNP you want kSNP3 to use 19 Optional ksnp3_task ksnp3_args String Additional arguments you want kSNP3 to use; e.g., \"-ML\" or \"-NJ\" Optional ksnp3_task memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional ksnp3_task previous_ksnp3_snps File File with existing SNPs for the current run to be appended to. Optional ksnp3_workflow cluster_name_updated String Internal component, do not modify Optional ksnp3_workflow data_summary_column_names String A comma-separated list of the column names from the sample-level data table for generating a data summary (presence/absence .csv matrix); e.g., \"amrfinderplus_amr_genes,amrfinderplus_virulence_genes\" Optional ksnp3_workflow data_summary_terra_project String The billing project for your current workspace. This can be found after the \"#workspaces/\" section in the workspace's URL Optional ksnp3_workflow data_summary_terra_table String The name of the sample-level Terra data table that will be used for generating a data summary Optional ksnp3_workflow data_summary_terra_workspace String The name of the Terra workspace you are in. This can be found at the top of the webpage, or in the URL after the billing project. Optional ksnp3_workflow midpoint_root_tree Boolean If true, midpoint root the final tree TRUE Optional ksnp3_workflow phandango_coloring Boolean Boolean variable that tells the data summary task and the reorder matrix task to include a suffix that enables consistent coloring on Phandango; by default, this suffix is not added. To add this suffix set this variable to true. FALSE Optional pan_reorder_matrix cpu Int Number of CPUs to allocate to the task 1 Optional pan_reorder_matrix disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional pan_reorder_matrix docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Optional pan_reorder_matrix memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional pan_snp_dists cpu Int Number of CPUs to allocate to the task 1 Optional pan_snp_dists disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional pan_snp_dists docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snp-dists:0.8.2 Optional pan_snp_dists memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional summarize_data cpu Int Number of CPUs to allocate to the task 8 Optional summarize_data disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional summarize_data docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional summarize_data id_column_name String If the sample IDs are in a different column to samplenames, it can be passed here and it will be used instead. Optional summarize_data memory Int Amount of memory/RAM (in GB) to allocate to the task 1 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/phylogenetic_construction/ksnp3/#workflow-tasks","title":"Workflow Tasks","text":"kSNP3 Details <p>This workflow is run on a set of assembly files to produce both pan-genome and core-genome phylogenies. This also results in alignment files which are used by downstream tasks.</p> <p>kSNP3 Technical Details</p> Links Task task_ksnp3.wdl Software Source Code kSNP on SourceForge via the WayBack Machine Software Documentation kSNP on SourceForge via the WayBack Machine Original Publication(s) kSNP3.0: SNP detection and phylogenetic analysis of genomes without genome alignment or reference genome SNP-dists <p><code>SNP-dists</code> computes pairwise SNP distances between genomes. It takes the same alignment of genomes used to generate your phylogenetic tree and produces a matrix of pairwise SNP distances between sequences. This means that if you generated pairwise core-genome phylogeny, the output will consist of pairwise core-genome SNP (cgSNP) distances. Otherwise, these will be whole-genome SNP distances. Regardless of whether core-genome or whole-genome SNPs, this SNP distance matrix will exclude all SNPs in masked regions (i.e. masked with a bed file or gubbins). </p> <p>The SNP-distance output can be visualized using software such as Phandango to explore the relationships between the genomic sequences. The task can optionally add a Phandango coloring tag (:c1) to the column names in the output matrix to ensure that all columns are colored with the same color scheme throughout by setting <code>phandango_coloring</code> to <code>true</code>.</p> <p>SNP-dists Technical Details</p> Links Task task_snp_dists.wdl Software Source Code SNP-dists on GitHub Software Documentation SNP-dists on GitHub Data summary (optional) <p>Command-line incompatible</p> <p>This task is not compatible with command-line use, even with modifications. It is engineered to run on Terra. To run this workflow on the command line, you must leave the <code>data_summary_*</code> and <code>sample_names</code> optional variables blank to prevent this task from running.</p> <p>If you fill out the <code>data_summary_*</code> and <code>sample_names</code> optional variables, you can use the optional <code>summarize_data</code> task. The task takes a comma-separated list of column names from the Terra data table, which should each contain a list of comma-separated items. For example, <code>\"amrfinderplus_virulence_genes,amrfinderplus_stress_genes\"</code> (with quotes, comma separated, no spaces) for these output columns from running TheiaProk. The task checks whether those comma-separated items are present in each row of the data table (sample), then creates a CSV file of these results. The CSV file indicates presence (TRUE) or absence (empty) for each item. By default, the task does not add a Phandango coloring tag to group items from the same column, but you can turn this on by setting <code>phandango_coloring</code> to <code>true</code>.</p> Example output CSV <pre><code>Sample_Name,aph(3')-IIa,blaCTX-M-65,blaOXA-193,tet(O)\nsample1,TRUE,,TRUE,TRUE\nsample2,,,FALSE,TRUE\nsample3,,,FALSE,\n</code></pre> Example use of Phandango coloring <p>Data summary produced using the <code>phandango_coloring</code> option, visualized alongside Newick tree at http://jameshadfield.github.io/phandango/#/main</p> <p>Example phandango_coloring output</p> <p></p> <p>Data summary technical details</p> Links Task task_summarize_data.wdl"},{"location":"workflows/phylogenetic_construction/ksnp3/#outputs","title":"Outputs","text":"Variable Type Description ksnp3_core_snp_matrix File The SNP matrix made with the core genome; formatted for Phandango if <code>phandango_coloring</code> input is <code>true</code> ksnp3_core_snp_matrix_status String Will print either <code>The core SNP matrix was produced</code> OR <code>The core SNP matrix could not be produced</code> ksnp3_core_snp_table File Formatted version of ksnp3_vcf_ref_genome file with only core SNPs, sorted by number of occurrences in the sample set ksnp3_core_tree File The phylogenetic tree made with the core genome ksnp3_docker String The docker image used ksnp3_filtered_metadata File Optional output file with filtered metadata that is only produced if the optional <code>summarize_data</code> task is used. ksnp3_ml_tree File Maximum likelihood tree that is only produced if <code>ksnp3_args</code> includes <code>\"-ML\"</code> ksnp3_nj_tree File Neighbor joining tree that is only produced if <code>ksnp3_args</code> includes <code>\"-NJ\"</code> ksnp3_number_core_snps String Number of core SNPs in the sample set ksnp3_number_snps String Number of SNPs in the sample set ksnp3_pan_snp_matrix File The SNP matrix made with the pangenome; formatted for Phandango if <code>phandango_coloring</code> input is <code>true</code> ksnp3_pan_tree File The phylogenetic tree made with the pangenome ksnp3_snp_dists_version String The version of snp_dists used in the workflow ksnp3_snps File File containing the set of SNPs used in the analysis. Required if more trees are to be appended to the existing one. ksnp3_summarized_data File CSV presence/absence matrix generated by the <code>summarize_data</code> task from the list of columns provided; formatted for Phandango if <code>phandango_coloring</code> input is <code>true</code> ksnp3_vcf_ref_genome File A VCF file containing the variants detected in the core genome ksnp3_vcf_ref_samplename String The name of the (user-supplied) sample used as the reference for calling SNPs. ksnp3_vcf_snps_not_in_ref File A TSV file of the SNPs not present in the reference genome, but were identified by kSNP3. ksnp3_wf_analysis_date String The date the workflow was run ksnp3_wf_version String The version of the repository the workflow is hosted in"},{"location":"workflows/phylogenetic_construction/ksnp3/#references","title":"References","text":"<p>Shea N Gardner, Tom Slezak, Barry G. Hall, kSNP3.0: SNP detection and phylogenetic analysis of genomes without genome alignment or reference genome,\u00a0Bioinformatics, Volume 31, Issue 17, 1 September 2015, Pages 2877\u20132878,\u00a0https://doi.org/10.1093/bioinformatics/btv271</p> <p>https://github.com/tseemann/snp-dists</p>"},{"location":"workflows/phylogenetic_construction/ksnp4/","title":"kSNP4","text":""},{"location":"workflows/phylogenetic_construction/ksnp4/#ksnp4","title":"kSNP4","text":""},{"location":"workflows/phylogenetic_construction/ksnp4/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Construction Bacteria, Mycotics, Viral v3.0.0 Some optional features incompatible, Yes Set-level kSNP4_PHB"},{"location":"workflows/phylogenetic_construction/ksnp4/#ksnp4_phb","title":"kSNP4_PHB","text":"<p>The kSNP4 workflow is for phylogenetic analysis of bacterial genomes using single nucleotide polymorphisms (SNPs) and is significantly faster and more memory efficient than its predecessor, kSNP3. There are no significant algorithmic changes between the two versions, and most modifications are transparent to the user. The kSNP4 workflow identifies SNPs amongst a set of genome assemblies, then calculates a number of phylogenetic trees based on those SNPs:</p> <ul> <li>Pan-genome phylogenetic trees: The term \"pan-genome\" is used here to describe the collective genetic content amongst the set of genomes, including regions outside of genes and other coding sequences.  Outputs based on the pan-genome are labeled with <code>_pan</code>.</li> <li>Core-genome phylogenetic trees: The kSNP4 workflow will also generate phylogenetic trees based on the core genome (genetic content that is present in all members of the set of genomes). Outputs based on the core-genome are labeled with <code>_core</code>.</li> </ul> <p>This workflow also features an optional module, <code>summarize_data</code> that creates a presence/absence matrix for the analyzed samples from a list of indicated columns (such as AMR genes, plasmid types etc.). If the <code>phandango_coloring</code> variable is set to <code>true</code>, this will be formatted for visualization in Phandango, else it can be viewed in Excel.</p> <p>While kSNP4 introduces enhancements, much of the foundational information from kSNP3 remains relevant. You can learn more about the kSNP3 workflow, including how to visualize the outputs with MicrobeTrace in the following video, which is still applicable to kSNP4: \ud83d\udcfa Using kSNP3 in Terra and Visualizing Bacterial Genomic Networks in MicrobeTrace</p>"},{"location":"workflows/phylogenetic_construction/ksnp4/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status ksnp4_workflow assembly_fasta Array[File] The assembly files for your samples in FASTA format Required ksnp4_workflow cluster_name String Free text string used to label output files Required ksnp4_workflow samplename Array[String] The names of the samples being analyzed Required core_ksnp4_shared_snps_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional core_reorder_matrix cpu Int Number of CPUs to allocate to the task 1 Optional core_reorder_matrix disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional core_reorder_matrix docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Optional core_reorder_matrix memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional core_snp_dists cpu Int Number of CPUs to allocate to the task 1 Optional core_snp_dists disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional core_snp_dists docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snp-dists:0.8.2 Optional core_snp_dists memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional ksnp4_task cpu Int Number of CPUs to allocate to the task 2 Optional ksnp4_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ksnp4_task docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ksnp4:4.1 Optional ksnp4_task kmer_size Int The length of kmer containing the SNP you want ksnp4 to use 19 Optional ksnp4_task ksnp4_args String Additional arguments you want kSNP4 to use; e.g., \"-ML\" or \"-NJ\" Optional ksnp4_task memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional ksnp4_task previous_ksnp4_snps File File with existing SNPs for the current run to be appended to. Optional ksnp4_workflow cluster_name_updated String Internal component, do not modify Optional ksnp4_workflow data_summary_column_names String A comma-separated list of the column names from the sample-level data table for generating a data summary (presence/absence .csv matrix); e.g., \"amrfinderplus_amr_genes,amrfinderplus_virulence_genes\" Optional ksnp4_workflow data_summary_terra_project String The billing project for your current workspace. This can be found after the \"#workspaces/\" section in the workspace's URL Optional ksnp4_workflow data_summary_terra_table String The name of the sample-level Terra data table that will be used for generating a data summary Optional ksnp4_workflow data_summary_terra_workspace String The name of the Terra workspace you are in. This can be found at the top of the webpage, or in the URL after the billing project. Optional ksnp4_workflow midpoint_root_tree Boolean If true, midpoint root the final tree TRUE Optional ksnp4_workflow phandango_coloring Boolean Boolean variable that tells the data summary task and the reorder matrix task to include a suffix that enables consistent coloring on Phandango; by default, this suffix is not added. To add this suffix set this variable to true. FALSE Optional pan_reorder_matrix cpu Int Number of CPUs to allocate to the task 1 Optional pan_reorder_matrix disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional pan_reorder_matrix docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Optional pan_reorder_matrix memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional pan_snp_dists cpu Int Number of CPUs to allocate to the task 1 Optional pan_snp_dists disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional pan_snp_dists docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snp-dists:0.8.2 Optional pan_snp_dists memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional summarize_data cpu Int Number of CPUs to allocate to the task 8 Optional summarize_data disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional summarize_data docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional summarize_data id_column_name String If the sample IDs are in a different column to samplenames, it can be passed here and it will be used instead. Optional summarize_data memory Int Amount of memory/RAM (in GB) to allocate to the task 1 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/phylogenetic_construction/ksnp4/#workflow-actions","title":"Workflow Actions","text":"kSNP4 Details <p>This workflow is run on a set of assembly files to produce both pan-genome and core-genome phylogenies. This also results in alignment files which are used by downstream tasks.</p> <p>kSNP4 Technical Details</p> Links Task task_ksnp4.wdl Software Source Code kSNP4 on SourceForge Software Documentation kSNP4 on SourceForge Original Publication(s) Building Phylogenetic Trees from Genome Sequences With kSNP4 SNP-dists <p><code>SNP-dists</code> computes pairwise SNP distances between genomes. It takes the same alignment of genomes used to generate your phylogenetic tree and produces a matrix of pairwise SNP distances between sequences. This means that if you generated pairwise core-genome phylogeny, the output will consist of pairwise core-genome SNP (cgSNP) distances. Otherwise, these will be whole-genome SNP distances. Regardless of whether core-genome or whole-genome SNPs, this SNP distance matrix will exclude all SNPs in masked regions (i.e. masked with a bed file or gubbins). </p> <p>The SNP-distance output can be visualized using software such as Phandango to explore the relationships between the genomic sequences. The task can optionally add a Phandango coloring tag (:c1) to the column names in the output matrix to ensure that all columns are colored with the same color scheme throughout by setting <code>phandango_coloring</code> to <code>true</code>.</p> <p>SNP-dists Technical Details</p> Links Task task_snp_dists.wdl Software Source Code SNP-dists on GitHub Software Documentation SNP-dists on GitHub Data summary (optional) <p>Command-line incompatible</p> <p>This task is not compatible with command-line use, even with modifications. It is engineered to run on Terra. To run this workflow on the command line, you must leave the <code>data_summary_*</code> and <code>sample_names</code> optional variables blank to prevent this task from running.</p> <p>If you fill out the <code>data_summary_*</code> and <code>sample_names</code> optional variables, you can use the optional <code>summarize_data</code> task. The task takes a comma-separated list of column names from the Terra data table, which should each contain a list of comma-separated items. For example, <code>\"amrfinderplus_virulence_genes,amrfinderplus_stress_genes\"</code> (with quotes, comma separated, no spaces) for these output columns from running TheiaProk. The task checks whether those comma-separated items are present in each row of the data table (sample), then creates a CSV file of these results. The CSV file indicates presence (TRUE) or absence (empty) for each item. By default, the task does not add a Phandango coloring tag to group items from the same column, but you can turn this on by setting <code>phandango_coloring</code> to <code>true</code>.</p> Example output CSV <pre><code>Sample_Name,aph(3')-IIa,blaCTX-M-65,blaOXA-193,tet(O)\nsample1,TRUE,,TRUE,TRUE\nsample2,,,FALSE,TRUE\nsample3,,,FALSE,\n</code></pre> Example use of Phandango coloring <p>Data summary produced using the <code>phandango_coloring</code> option, visualized alongside Newick tree at http://jameshadfield.github.io/phandango/#/main</p> <p>Example phandango_coloring output</p> <p></p> <p>Data summary technical details</p> Links Task task_summarize_data.wdl"},{"location":"workflows/phylogenetic_construction/ksnp4/#outputs","title":"Outputs","text":"Variable Type Description ksnp4_core_snp_matrix File The SNP matrix made with the core genome; formatted for Phandango if <code>phandango_coloring</code> input is <code>true</code> ksnp4_core_snp_matrix_status String Will print either <code>The core SNP matrix was produced</code> OR <code>The core SNP matrix could not be produced</code> ksnp4_core_snp_table File Formatted version of ksnp4_vcf_ref_genome file with only core SNPs, sorted by number of occurrences in the sample set ksnp4_core_tree File The phylogenetic tree made with the core genome ksnp4_docker String The docker image used ksnp4_filtered_metadata File Optional output file with filtered metadata that is only produced if the optional <code>summarize_data</code> task is used. ksnp4_ml_tree File Maximum likelihood tree that is only produced if <code>ksnp4_args</code> includes <code>\"-ML\"</code> ksnp4_nj_tree File Neighbor joining tree that is only produced if <code>ksnp4_args</code> includes <code>\"-NJ\"</code> ksnp4_number_core_snps String Number of core SNPs in the sample set ksnp4_number_snps String Number of SNPs in the sample set ksnp4_pan_snp_matrix File The SNP matrix made with the pangenome; formatted for Phandango if <code>phandango_coloring</code> input is <code>true</code> ksnp4_pan_tree File The phylogenetic tree made with the pangenome ksnp4_snp_dists_version String The version of snp_dists used in the workflow ksnp4_snps File File containing the set of SNPs used in the analysis. Required if more trees are to be appended to the existing one. ksnp4_summarized_data File CSV presence/absence matrix generated by the <code>summarize_data</code> task from the list of columns provided; formatted for Phandango if <code>phandango_coloring</code> input is <code>true</code> ksnp4_vcf_ref_genome File A VCF file containing the variants detected in the core genome ksnp4_vcf_ref_samplename String The name of the (user-supplied) sample used as the reference for calling SNPs. ksnp4_vcf_snps_not_in_ref File A TSV file of the SNPs not present in the reference genome, but were identified by kSNP4. ksnp4_wf_analysis_date String The date the workflow was run ksnp4_wf_version String The version of the repository the workflow is hosted in"},{"location":"workflows/phylogenetic_construction/ksnp4/#references","title":"References","text":"<p>Barry G Hall, Jeremiah Nisbet, Building Phylogenetic Trees From Genome Sequences With kSNP4, Molecular Biology and Evolution, Volume 40, Issue 11, November 2023, msad235, https://doi.org/10.1093/molbev/msad235</p> <p>https://github.com/tseemann/snp-dists</p>"},{"location":"workflows/phylogenetic_construction/lyve_set/","title":"Lyve_SET","text":""},{"location":"workflows/phylogenetic_construction/lyve_set/#lyve_set","title":"Lyve_SET","text":""},{"location":"workflows/phylogenetic_construction/lyve_set/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Construction Bacteria v2.1.0 Yes Set-level Lyve_SET_PHB"},{"location":"workflows/phylogenetic_construction/lyve_set/#lyve_set_phb","title":"Lyve_SET_PHB","text":"<p>The Lyve_SET WDL workflow runs the Lyve-SET pipeline developed by Lee Katz et al. for phylogenetic analysis of bacterial genomes using high quality single nucleotide polymorphisms (hqSNPs). The Lyve_SET workflow identifies SNPs amongst a set of samples by mapping sequencing reads to a reference genome, identifying high quality SNPs, and inferring phylogeny using RAxML.</p>"},{"location":"workflows/phylogenetic_construction/lyve_set/#lyve-set-pipeline-from-lyve-set-paper","title":"Lyve-SET Pipeline (from Lyve-SET paper)","text":"<p>Lyve-SET Workflow Diagram</p> <p></p>"},{"location":"workflows/phylogenetic_construction/lyve_set/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status lyveset_workflow dataset_name String Free text string used to label output files Required lyveset_workflow read1 Array[File] FASTQ files containing read1 sequences; we recommend using cleaned reads instead of raw reads Required lyveset_workflow read2 Array[File] FASTQ files containing read2 sequences; we recommend using cleaned reads instead of raw reads Required lyveset_workflow reference_genome File Path to reference genome in a Terra-accessible Google bucket. For considerations when choosing a reference genome, see: https://github.com/lskatz/lyve-SET/blob/master/docs/FAQ.md Required lyveset_workflow samplename Array[String] The names of the samples being analyzed Required lyveset allowedFlanking Int Allowed flanking distance in base pairs. Nucleotides this close together cannot be considered as high-quality. 0 Optional lyveset cpu Int Number of CPUs to allocate to the task 16 Optional lyveset disk_size Int Amount of storage (in GB) to allocate to the task 250 Optional lyveset docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/lyveset:1.1.4f Optional lyveset downsample Boolean If true, downsample all reads to 50x. Approximated according to the ref genome assembly FALSE Optional lyveset fast Boolean Shorthand for --downsample --mapper snap --nomask-phages --nomask-cliffs --sample-sites FALSE Optional lyveset mapper String Which mapper? Choices: \"smalt\", \"snap\" smalt Optional lyveset mask_cliffs Boolean If true, search for and mask 'Cliffs' in pileups FALSE Optional lyveset mask_phages Boolean If true, search for and mask phages in the reference genome FALSE Optional lyveset memory Int Amount of memory/RAM (in GB) to allocate to the task 64 Optional lyveset min_alt_frac Float The percent consensus that needs to be reached before a SNP is called. Otherwise, 'N' 0.75 Optional lyveset min_coverage Int Minimum coverage needed before a SNP is called. Otherwise, 'N' 10 Optional lyveset nomatrix Boolean If true, do not create an hqSNP matrix FALSE Optional lyveset nomsa Boolean If true, do not make a multiple sequence alignment FALSE Optional lyveset notrees Boolean If true, do not make phylogenies FALSE Optional lyveset presets String See presets.conf for more information Optional lyveset read_cleaner String Which read cleaner? Choices: \"none\", \"CGP\", \"BayesHammer\" CGP Optional lyveset sample_sites Boolean If true, randomly choose a genome and find SNPs in a quick and dirty way. Then on the SNP-calling stage, only interrogate those sites for SNPs for each genome (including the randomly-sampled genome). FALSE Optional lyveset snpcaller String Which SNP caller? Choices: \"varscan\", \"vcftools\" varscan Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/phylogenetic_construction/lyve_set/#workflow-actions","title":"Workflow Actions","text":"<p>The Lyve_SET WDL workflow is run using read data from a set of samples. The workflow will produce a pairwise SNP matrix for the sample set and a maximum likelihood phylogenetic tree. Details regarding the default implementation of Lyve_SET and optional modifications are listed below.</p> <ol> <li>Read processing<ol> <li>By default, the Lyve_SET WDL workflow will perform read cleaning using the CG-Pipeline \"CGP\". However, read cleaning can be turned off or performed using \"BayesHammer\" using the <code>read_cleaner</code> input variable.</li> </ol> </li> <li>Reference procurement<ol> <li>By default, the Lyve_SET WDL workflow will not mask phages or cliffs in the reference genome. Cliffs refer to regions of the reference genome where read coverage rises or falls abruptly. Masking phages and cliffs is intended to remove low quality SNPs. Users can invoke phage and cliff masking by setting the <code>mask_cliffs</code> and <code>mask_phages</code> variables to \"true\".</li> </ol> </li> <li>SNP discovery<ol> <li>The Lyve_SET WDL workflow uses the default read mapper and variant caller from the Lyve-SET pipeline  (<code>smalt</code> and <code>varscan</code>). Additional options for each are available using the <code>mapper</code> and <code>snpcaller</code> input variables.</li> <li>The workflow also uses the default parameters for variant calling from the Lyve-SET pipeline: the minimum percent consensus to call a base is 0.75 and minimum read depth is 10X. These parameters can be manually modified using the <code>min_alt_frac</code> and <code>min_coverage</code> input variables.</li> </ol> </li> <li>Phylogenetic analysis<ol> <li>The Lyve_SET workflow will attempt to produce a multiple sequence alignment, SNP distance matrix, and phylogenetic tree. These actions can be skipped by indicating <code>nomsa</code> = true, <code>nomatrix</code> = true, or <code>notrees</code> = true, respectively.</li> </ol> </li> </ol>"},{"location":"workflows/phylogenetic_construction/lyve_set/#outputs","title":"Outputs","text":"<p>For full descriptions of Lyve-SET pipeline outputs, we recommend consulting the Lyve-SET documentation: https://github.com/lskatz/lyve-SET/blob/master/docs/OUTPUT.md</p> <p>The following output files are populated to the Terra data table. However, please note that certain files may not appear in the data table following a run for two main reasons:</p> <ol> <li>The user instructed the workflow to skip an analysis step<ol> <li>For example, if <code>notrees</code> = true, no tree file will appear</li> </ol> </li> <li>The workflow skipped an analysis step due to an issue with the input data<ol> <li>For example, the workflow will not attempt to produce a phylogenetic tree if there are too few samples or if samples are too closely related</li> </ol> </li> </ol> Variable Type Description lyveset_alignment_fasta File The output alignment file in fasta format lyveset_docker_image String Lyve_SET docker image used for analysis lyveset_log File Lyve_SET task log file lyveset_pairwise_matrix File Pairwise SNP distances matrix lyveset_pooled_snps_vcf File SNPs vcf lyveset_raxml_tree File RAxML-generated tree in newick format lyveset_wf_analysis_date String Date analysis was run lyveset_wf_version String Version of PHB used when running Lyveset_PHB <p>In addition to these outputs, all of the files produced by the Lyve-SET pipeline are available in the task-level outputs, including intermediate files and individual bam and vcf files for each sample. These files can be accessed viewing the execution directory for the run.</p>"},{"location":"workflows/phylogenetic_construction/lyve_set/#references","title":"References","text":"<p>Lyve-SET Katz LS, Griswold T, Williams-Newkirk AJ, Wagner D, Petkau A, et al. (2017) A Comparative Analysis of the Lyve-SET Phylogenomics Pipeline for Genomic Epidemiology of Foodborne Pathogens. Frontiers in Microbiology 8.</p>"},{"location":"workflows/phylogenetic_construction/mashtree_fasta/","title":"MashTree_FASTA","text":""},{"location":"workflows/phylogenetic_construction/mashtree_fasta/#mashtree_fasta","title":"MashTree_FASTA","text":""},{"location":"workflows/phylogenetic_construction/mashtree_fasta/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Construction Bacteria, Mycotics, Viral v3.0.0 Some optional features incompatible, Yes Set-level MashTree_FASTA_PHB"},{"location":"workflows/phylogenetic_construction/mashtree_fasta/#mashtree_fasta_phb","title":"MashTree_FASTA_PHB","text":"<p><code>MashTree_FASTA</code> creates a phylogenetic tree using Mash distances.</p> <p>Mash distances are representations of how many kmers two sequences have in common. These distances are generated by transforming all kmers from a sequence into an integer value with hashing and Bloom filters. The hashed kmers are sorted and a \"sketch\" is created by only using the kmers that appear at the top of the sorted list. These sketches can be compared by counting the number of hashed kmers they have in common. Mashtree uses a neighbor-joining algorithm to cluster these \"distances\" into phylogenetic trees.</p> <p>This workflow also features an optional module, <code>summarize_data</code>, that creates a presence/absence matrix for the analyzed samples from a list of indicated columns (such as AMR genes, etc.) that can be used in Phandango.</p>"},{"location":"workflows/phylogenetic_construction/mashtree_fasta/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status mashtree_fasta assembly_fasta Array[File] The assembly files for your samples in FASTA format Required mashtree_fasta cluster_name String Free text string used to label output files Required mashtree_fasta data_summary_column_names String A comma-separated list of the column names from the sample-level data table for generating a data summary (presence/absence .csv matrix); e.g., \"amrfinderplus_amr_genes,amrfinderplus_virulence_genes\" Optional mashtree_fasta data_summary_terra_project String The billing project for your current workspace. This can be found after the \"#workspaces/\" section in the workspace's URL Optional mashtree_fasta data_summary_terra_table String The name of the sample-level Terra data table that will be used for generating a data summary Optional mashtree_fasta data_summary_terra_workspace String The name of the Terra workspace you are in. This can be found at the top of the webpage, or in the URL after the billing project. Optional mashtree_fasta midpoint_root_tree Boolean If true, midpoint root the final tree TRUE Optional mashtree_fasta phandango_coloring Boolean Boolean variable that tells the data summary task and the reorder matrix task to include a suffix that enables consistent coloring on Phandango; by default, this suffix is not added. To add this suffix set this variable to true. FALSE Optional mashtree_fasta sample_names Array[String] The list of samples Optional mashtree_task cpu Int Number of CPUs to allocate to the task 16 Optional mashtree_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional mashtree_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mashtree:1.2.0 Optional mashtree_task genomesize Int Genome size of the input samples 5000000 Optional mashtree_task kmerlength Int Hashes will be based on strings of this many nucleotides 21 Optional mashtree_task memory Int Amount of memory/RAM (in GB) to allocate to the task 64 Optional mashtree_task mindepth Int If set to zero, mashtree will run in \"accurate\" mode as it will chose a mindepth by itself in a slower method; this value otherwise indicates the minimum number of times a kmer must appear in order to be included 5 Optional mashtree_task sketchsize Int Each sketch will have at most this many non-redundant min-hashes 10000 Optional mashtree_task sort_order String For neighbor-joining, the sort order can make a difference. Options include: \"ABC\" (alphabetical), \"random\", \"input-order\" ABC Optional mashtree_task truncLength Int How many characters to keep in a filename 250 Optional reorder_matrix cpu Int Number of CPUs to allocate to the task 1 Optional reorder_matrix disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional reorder_matrix docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Optional reorder_matrix memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional summarize_data cpu Int Number of CPUs to allocate to the task 8 Optional summarize_data disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional summarize_data docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional summarize_data id_column_name String If the sample IDs are in a different column to samplenames, it can be passed here and it will be used instead. Optional summarize_data memory Int Amount of memory/RAM (in GB) to allocate to the task 1 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/phylogenetic_construction/mashtree_fasta/#workflow-actions","title":"Workflow Actions","text":"MashTree_FASTA Details <p><code>MashTree_FASTA</code> is run on a set of assembly fastas and creates a phylogenetic tree and matrix.</p> <p>MashTree_FASTA Technical Details</p> Links Task task_mashtree_fasta.wdl Software Source Code Mashtree on GitHub Software Documentation Mashtree on GitHub Original Publication(s) Mashtree: a rapid comparison of whole genome sequence files Data summary (optional) <p>Command-line incompatible</p> <p>This task is not compatible with command-line use, even with modifications. It is engineered to run on Terra. To run this workflow on the command line, you must leave the <code>data_summary_*</code> and <code>sample_names</code> optional variables blank to prevent this task from running.</p> <p>If you fill out the <code>data_summary_*</code> and <code>sample_names</code> optional variables, you can use the optional <code>summarize_data</code> task. The task takes a comma-separated list of column names from the Terra data table, which should each contain a list of comma-separated items. For example, <code>\"amrfinderplus_virulence_genes,amrfinderplus_stress_genes\"</code> (with quotes, comma separated, no spaces) for these output columns from running TheiaProk. The task checks whether those comma-separated items are present in each row of the data table (sample), then creates a CSV file of these results. The CSV file indicates presence (TRUE) or absence (empty) for each item. By default, the task does not add a Phandango coloring tag to group items from the same column, but you can turn this on by setting <code>phandango_coloring</code> to <code>true</code>.</p> Example output CSV <pre><code>Sample_Name,aph(3')-IIa,blaCTX-M-65,blaOXA-193,tet(O)\nsample1,TRUE,,TRUE,TRUE\nsample2,,,FALSE,TRUE\nsample3,,,FALSE,\n</code></pre> Example use of Phandango coloring <p>Data summary produced using the <code>phandango_coloring</code> option, visualized alongside Newick tree at http://jameshadfield.github.io/phandango/#/main</p> <p>Example phandango_coloring output</p> <p></p> <p>Data summary technical details</p> Links Task task_summarize_data.wdl"},{"location":"workflows/phylogenetic_construction/mashtree_fasta/#outputs","title":"Outputs","text":"Variable Type Description mashtree_docker String The Docker image used to run the mashtree task mashtree_filtered_metadata File Optional output file with filtered metadata that is only produced if the optional <code>summarize_data</code> task is used mashtree_matrix File The distance matrix made mashtree_summarized_data File CSV presence/absence matrix generated by the <code>summarize_data</code> task from the list of columns provided; formatted for Phandango if <code>phandango_coloring</code> input is <code>true</code> mashtree_tree File The phylogenetic tree made mashtree_version String The version of mashtree used in the workflow mashtree_wf_analysis_date String The date the workflow was run mashtree_wf_version String The version of PHB the workflow is hosted in"},{"location":"workflows/phylogenetic_construction/mashtree_fasta/#references","title":"References","text":"<p>Katz, L. S., Griswold, T., Morrison, S., Caravas, J., Zhang, S., den Bakker, H.C., Deng, X., and Carleton, H. A., (2019). Mashtree: a rapid comparison of whole genome sequence files. Journal of Open Source Software, 4(44), 1762,\u00a0https://doi.org/10.21105/joss.01762</p> <p>Ondov, B. D., Treangen, T. J., Melsted, P., Mallonee, A. B., Bergman, N. H., Koren, S., &amp; Phillippy, A. M. (2016). Mash: Fast genome and metagenome distance estimation using minhash. Genome Biology, 17(1), 132. doi:10.1186/s13059-016-0997-x</p>"},{"location":"workflows/phylogenetic_construction/snippy_streamline/","title":"Snippy_Streamline","text":""},{"location":"workflows/phylogenetic_construction/snippy_streamline/#snippy_streamline","title":"Snippy_Streamline","text":""},{"location":"workflows/phylogenetic_construction/snippy_streamline/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Construction Bacteria v3.0.0 Some optional features incompatible, Yes Set-level Snippy_Streamline_PHB"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#snippy_streamline_phb","title":"Snippy_Streamline_PHB","text":"<p>Snippy_Streamline_PHB Workflow Diagram</p> <p></p> <p></p> <p>The <code>Snippy_Streamline</code> workflow is an all-in-one approach to generating a reference-based phylogenetic tree and associated SNP-distance matrix. The workflow can be run in multiple ways.</p> <p>Reference Genome Options</p> <p>In order to generate a phylogenetic tree, a reference genome is required. This can be:</p> <ol> <li>provided by the user by filling the <code>reference_genome_file</code> input variable</li> <li>the identified <code>centroid</code> genome by setting <code>use_centroid_as_reference</code> to true</li> <li>automatically selected using the <code>centroid</code> task and <code>reference_seeker</code> task to find a close reference genome to your dataset by providing data in the <code>assembly_fasta</code> input variable and leaving the <code>reference_genome_file</code> and <code>use_centroid_as_reference</code> fields blank</li> </ol> <p>Automatic Reference Selection</p> <p>If no reference genome is provided, then the user MUST fill in the <code>assembly_fasta</code> field for automatic reference genome selection.</p> <p>Phylogenetic Tree Construction Options</p> <p>There are several options that can be used to customize the phylogenetic tree, including:</p> <ol> <li>masking user-specified regions of the genome (by providing a bed file to <code>snippy_core_bed</code>)</li> <li>producing either a core or pan-genome phylogeny and SNP-matrix (by altering <code>core_genome</code>; true [default] = core genome, false = pan-genome)</li> <li>choosing the nucleotide substitution (by altering <code>iqtree2_model</code> [see below for possible nucleotide substitution models]), or allowing IQ-Tree's ModelFinder to identify the best model for your dataset (default)</li> <li>masking recombination detected by gubbins, or not (by altering <code>use_gubbins</code>; true [default] = recombination masking, false = no recombination masking)</li> </ol> <p>Multiple Contigs in Reference Genomes</p> <p>If reference genomes have multiple contigs, they are incompatible with Gubbins to mask recombination in the phylogenetic tree. The automatic selection of a reference genome by the workflow may result in a reference with multiple contigs. In this case, an alternative reference genome should be sought, or Gubbins should be turned off (via <code>use_gubbins = false</code>).</p>"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#inputs","title":"Inputs","text":"<p>To run Snippy_Streamline, either a reference genome must be provided (<code>reference_genome_file</code>), or you must provide assemblies of the samples in your tree so that the workflow can automatically find and download the closest reference genome to your dataset (via <code>assembly_fasta</code>)</p> <p>Input Sequencing Data Requirements</p> <p>Sequencing data used in the Snippy_Streamline workflow must:</p> <ul> <li>Be Illumina reads</li> <li>Be generated by unbiased whole genome shotgun sequencing</li> <li>Pass appropriate QC thresholds for the taxa to ensure that the reads represent reasonably complete genomes that are free of contamination from other taxa or cross-contamination of the same taxon.</li> <li>If masking recombination with <code>Gubbins</code>, input data should represent complete genomes from the same strain/lineage (e.g. MLST) that share a recent common ancestor.</li> </ul> <p>Guidance for optional inputs</p> <p>Several core and optional tasks can be used to generate the Snippy phylogenetic tree, making it highly flexible and suited to a wide range of datasets. You will need to decide which tasks to use depending on the genomes that you are analyzing. Some guidelines for the optional tasks to use for different genome types are provided below.</p> Default settings (suitable for most bacteria) <p>The default settings are as follows and are suitable for generating phylogenies for most bacteria</p> <ul> <li><code>core_genome</code> = true (creates core genome phylogeny)</li> <li><code>use_gubbins</code> = true (recombination masked)</li> <li>nucleotide substitution model will be defined by IQTree's Model Finder</li> </ul> Phylogenies of Mycobacterium tuberculosis complex <p>Phylogenies of MTBC are typically constructed with the following options:</p> <ul> <li>Using the H37Rv reference genome<ul> <li><code>reference_genome_file</code> = <code>\"gs://theiagen-public-resources-rp/reference_data/bacterial/mycobacterium/MTB-NC_000962.3.fasta\"</code></li> </ul> </li> <li>Masking repetitive regions of the genome (e.g. PE/PPE genes) that are often misaligned<ul> <li><code>snippy_core_bed</code> = <code>\"gs://theiagen-public-resources-rp/reference_data/bacterial/mycobacterium/MTB-NC_000962.3.bed\"</code></li> </ul> </li> <li>Without masking recombination because TB can be considered non-recombinant<ul> <li><code>use_gubbins</code> = false</li> </ul> </li> <li>Using the core genome<ul> <li><code>core_genome</code> = true (as default)</li> </ul> </li> </ul> Terra Task Name Variable Type Description Default Value Terra Status snippy_streamline read1 Array[File] FASTQ files containing read1 sequences Required snippy_streamline read2 Array[File] FASTQ files containing read2 sequences Required snippy_streamline samplenames Array[String] The names of the samples being analyzed Required snippy_streamline tree_name String String of your choice to prefix output files Required centroid cpu Int Number of CPUs to allocate to the task 1 Optional centroid disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional centroid docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/centroid:0.1.0 Optional centroid memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional ncbi_datasets_download_genome_accession cpu Int Number of CPUs to allocate to the task 1 Optional ncbi_datasets_download_genome_accession disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional ncbi_datasets_download_genome_accession docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ncbi-datasets:16.38.1 Optional ncbi_datasets_download_genome_accession include_gbff Boolean Set to true if you would like the GenBank Flat File (GBFF) file included in the output. It contains nucleotide sequence, metadata, and annotations. FALSE Optional ncbi_datasets_download_genome_accession include_gff3 Boolean Set to true if you would like the Genomic Feature File v3 (GFF3) file included in the output. It contains nucleotide sequence, metadata, and annotations FALSE Optional ncbi_datasets_download_genome_accession memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional ncbi_datasets_download_genome_accession use_ncbi_virus Boolean Set to true to download from NCBI Virus Datasets FALSE Optional referenceseeker cpu Int Number of CPUs to allocate to the task 4 Optional referenceseeker disk_size Int Amount of storage (in GB) to allocate to the task 200 Optional referenceseeker docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/referenceseeker:1.8.0--pyhdfd78af_0 Optional referenceseeker memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional referenceseeker referenceseeker_ani_threshold Float Bidirectional average nucleotide identity to use as a cut off for identifying reference assemblies with ReferenceSeeker; default value set according to https://github.com/oschwengers/referenceseeker#description 0.95 Optional referenceseeker referenceseeker_conserved_dna_threshold Float Conserved DNA % to use as a cut off for identifying reference assemblies with ReferenceSeeker; default value set according to https://github.com/oschwengers/referenceseeker#description 0.69 Optional referenceseeker referenceseeker_db File Database used by the referenceseeker tool that contains bacterial genomes from RefSeq release 205. Downloaded from the referenceseeker GitHub repository. gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-bacteria-refseq-205.v20210406.tar.gz Optional snippy_streamline assembly_fasta Array[File] The assembly files for your samples (Required if a reference genome is not provided) Optional snippy_streamline reference_genome_file File Reference genome in FASTA or GENBANK format (must be the same reference used in Snippy_Variants workflow); provide this if you want to skip the detection of a suitable reference Optional snippy_streamline use_centroid_as_reference Boolean Set to true if you want to use the centroid sample as the reference sample instead of using the centroid to detect a suitable one FALSE Optional snippy_tree_wf call_shared_variants Boolean When true, workflow generates table that combines variants across all samples and a table showing variants shared across samples TRUE Optional snippy_tree_wf core_genome Boolean When true, workflow generates core genome phylogeny; when false, whole genome is used TRUE Optional snippy_tree_wf data_summary_column_names String A comma-separated list of the column names from the sample-level data table for generating a data summary (presence/absence .csv matrix) Optional snippy_tree_wf data_summary_terra_project String The billing project for your current workspace. This can be found after the \"#workspaces/\" section in the workspace's URL Optional snippy_tree_wf data_summary_terra_table String The name of the sample-level Terra data table that will be used for generating a data summary Optional snippy_tree_wf data_summary_terra_workspace String The name of the Terra workspace you are in. This can be found at the top of the webpage, or in the URL after the billing project. Optional snippy_tree_wf gubbins_cpu Int Number of CPUs to allocate to the task 4 Optional snippy_tree_wf gubbins_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional snippy_tree_wf gubbins_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/gubbins:3.3--py310pl5321h8472f5a_0 Optional snippy_tree_wf gubbins_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional snippy_tree_wf iqtree2_bootstraps Int Number of replicates for http://www.iqtree.org/doc/Tutorial#assessing-branch-supports-with-ultrafast-bootstrap-approximation (Minimum recommended= 1000) 1000 Optional snippy_tree_wf iqtree2_cpu Int Number of CPUs to allocate to the task 4 Optional snippy_tree_wf iqtree2_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional snippy_tree_wf iqtree2_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/iqtree2:2.1.2 Optional snippy_tree_wf iqtree2_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional snippy_tree_wf iqtree2_model String Nucelotide substitution model to use when generating the final tree with IQTree2. By default, IQtree runs its ModelFinder algorithm to identify the model it thinks best fits your dataset Optional snippy_tree_wf iqtree2_opts String Additional options to pass to IQTree2 Optional snippy_tree_wf midpoint_root_tree Boolean A True/False option that determines whether the tree used in the SNP matrix re-ordering task should be re-rooted or not. Options: true or false TRUE Optional snippy_tree_wf phandango_coloring Boolean Boolean variable that tells the data summary task and the reorder matrix task to include a suffix that enables consistent coloring on Phandango; by default, this suffix is not added. To add this suffix set this variable to true. FALSE Optional snippy_tree_wf snippy_core_bed File User-provided bed file to mask out regions of the genome when creating multiple sequence alignments Optional snippy_tree_wf snippy_core_cpu Int Number of CPUs to allocate to the task 8 Optional snippy_tree_wf snippy_core_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional snippy_tree_wf snippy_core_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snippy:4.6.0 Optional snippy_tree_wf snippy_core_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional snippy_tree_wf snp_dists_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snp-dists:0.8.2 Optional snippy_tree_wf snp_sites_cpu Int Number of CPUs to allocate to the task 1 Optional snippy_tree_wf snp_sites_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional snippy_tree_wf snp_sites_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snp-sites:2.5.1 Optional snippy_tree_wf snp_sites_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional snippy_tree_wf use_gubbins Boolean When \"true\", workflow removes recombination with gubbins tasks; when \"false\", gubbins is not used TRUE Optional snippy_variants_wf assembly_fasta File The assembly file for your sample in FASTA format Optional snippy_variants_wf base_quality Int Minimum quality for a nucleotide to be used in variant calling 13 Optional snippy_variants_wf cpu Int Number of CPUs to allocate to the task 4 Optional snippy_variants_wf docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snippy:4.6.0 Optional snippy_variants_wf map_qual Int Minimum mapping quality to accept in variant calling 60 Optional snippy_variants_wf maxsoft Int Number of bases of alignment to soft-clip before discarding the alignment 10 Optional snippy_variants_wf memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional snippy_variants_wf min_coverage Int Minimum read coverage of a position to identify a mutation 10 Optional snippy_variants_wf min_frac Float Minimum fraction of bases at a given position to identify a mutation 0 Optional snippy_variants_wf min_quality Int Minimum VCF variant call \"quality\" 100 Optional snippy_variants_wf query_gene String Comma-separated strings (e.g. gene names) in which to search for mutations to output to data table Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#workflow-tasks","title":"Workflow Tasks","text":""},{"location":"workflows/phylogenetic_construction/snippy_streamline/#automatic-reference-selection","title":"Automatic Reference Selection","text":"<p>The following tasks perform automatic reference selection (if no reference genome is provided by the user and <code>assembly_fasta</code> is provided).</p> Centroid ReferenceSeeker Details (Optional) NCBI Datasets"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#centroid","title":"Centroid","text":"<p>Centroid selects the most central genome among a list of assemblies by computing pairwise mash distances. In <code>Snippy_Streamline</code>, this centroid assembly is then used to find a closely related reference genome that can be used to generate the tree.  In order to use <code>Centroid</code>, should complete the <code>samplenames</code> input. </p> <p><code>centroid</code> Technical Details</p> Links Task task_centroid.wdl Software Source Code https://github.com/theiagen/centroid Software Documentation https://github.com/theiagen/centroid"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#referenceseeker","title":"ReferenceSeeker","text":"<p><code>ReferenceSeeker</code> uses your draft assembly to identify closely related bacterial, viral, fungal, or plasmid genome assemblies in RefSeq.</p> <p>Databases that can be used with ReferenceSeeker are as follows, and can be used by pasting the GSURI in double quotation marks <code>\" \"</code> into the <code>referenceseeker_db</code> optional input:</p> <ul> <li>archea:  <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-archaea-refseq-205.v20210406.tar.gz</code></li> <li>bacterial (default): <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-bacteria-refseq-205.v20210406.tar.gz</code></li> <li>fungi: <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-fungi-refseq-205.v20210406.tar.gz</code></li> <li>plasmids: <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-plasmids-refseq-205.v20210406.tar.gz</code></li> <li>viral: <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-viral-refseq-205.v20210406.tar.gz</code></li> </ul> <p>For ReferenceSeeker to identify a genome, it must meet user-specified thresholds for sequence coverage (<code>referenceseeker_conserved_dna_threshold</code>; default &gt;= 0.69) and identity (<code>referenceseeker_ani_threshold</code>; default &gt;= 0.95 ). </p> <p>A list of closely related genomes is provided in <code>referenceseeker_tsv</code>. The reference genome that ranks highest according to ANI and conserved DNA values is considered the closest match and will be downloaded, with information about this provided in the <code>assembly_fetch_referenceseeker_top_hit_ncbi_accession</code> output.</p> <p>ReferenceSeeker Technical Details</p> Links Task task_referenceseeker.wdl Software Source Code ReferenceSeeker on GitHub Software Documentation ReferenceSeeker on GitHub Original Publication(s) ReferenceSeeker: rapid determination of appropriate reference genomes"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#ncbi-datasets","title":"NCBI Datasets","text":"<p>The <code>NCBI Datasets</code> task downloads specified assemblies from NCBI using either the virus or genome (for all other genome types) package as appropriate.</p> <p><code>include_gbff</code> behavior</p> <p>If <code>include_gbff</code> is set to <code>true</code>, the gbff file will be used as the reference for <code>Snippy_Variants</code> and <code>Snippy_Tree</code>. If <code>include_gbff</code> is set to <code>false</code>, the fasta file will be used as the reference for <code>Snippy_Variants</code> and <code>Snippy_Tree</code>. Tree topology should not differ, though annotations may.</p> <p>NCBI Datasets Technical Details</p> Links Task task_ncbi_datasets.wdl Software Source Code NCBI Datasets on GitHub Software Documentation NCBI Datasets Documentation on NCBI Original Publication(s) Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#variant-calling","title":"Variant Calling","text":"<p>The following task performs variant calling on the samples using a reference genome (either selected in the previous steps, or provided by the user)</p> <p>Please see the full documentation for Snippy_Variants for more information.</p> Snippy_Variants"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#snippy_variants","title":"Snippy_Variants","text":"<p><code>Snippy_Variants</code> uses Snippy to align the assemblies for each sample against the reference genome to call SNPs, MNPs and INDELs according to optional input parameters. </p> <p>Optionally, if the user provides a value for <code>query_gene</code>, the variant file will be searched for any mutations in the specified regions or annotations. The query string MUST match the gene name or annotation as specified in the GenBank file and provided in the output variant file in the <code>snippy_results</code> column.</p> QC Metrics from Snippy_Variants <p>Warning</p> <p>The following QC metrics may not be applicable to your dataset as they are geared towards read data, not assemblies. Use these metrics with caution.</p> <p>This task also extracts QC metrics from the Snippy output for each sample and saves them in per-sample TSV files (<code>snippy_variants_qc_metrics</code>). These per-sample QC metrics include the following columns:</p> <ul> <li>samplename: The name of the sample.</li> <li>reads_aligned_to_reference: The number of reads that aligned to the reference genome.</li> <li>total_reads: The total number of reads in the sample.</li> <li>percent_reads_aligned: The percentage of reads that aligned to the reference genome.</li> <li>variants_total: The total number of variants detected between the sample and the reference genome.</li> <li>percent_ref_coverage: The percentage of the reference genome covered by reads with a depth greater than or equal to the <code>min_coverage</code> threshold (default is 10).</li> <li>#rname: Reference sequence name (e.g., chromosome or contig name).</li> <li>startpos: Starting position of the reference sequence.</li> <li>endpos: Ending position of the reference sequence.</li> <li>numreads: Number of reads covering the reference sequence.</li> <li>covbases: Number of bases with coverage.</li> <li>coverage: Percentage of the reference sequence covered (depth \u2265 1).</li> <li>meandepth: Mean depth of coverage over the reference sequence.</li> <li>meanbaseq: Mean base quality over the reference sequence.</li> <li>meanmapq: Mean mapping quality over the reference sequence.</li> </ul> <p>Note that the last set of columns (<code>#rname</code> to <code>meanmapq</code>) may repeat for each chromosome or contig in the reference genome.</p> <p>Snippy Variants Technical Details</p> Links Task task_snippy_variants.wdltask_snippy_gene_query.wdl Software Source Code Snippy on GitHub Software Documentation Snippy on GitHub"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#phylogenetic-construction","title":"Phylogenetic Construction","text":"<p>The following tasks are a simplified version of the <code>Snippy_Tree</code> workflow, which is used to build the phylogenetic tree. The tasks undertaken are exactly the same between both workflows, but user inputs and outputs have been reduced for clarity and ease.</p> <p>Please see the full documentation for Snippy_Tree for more information.</p> <p>Gubbins Nucleotide Substitution Model</p> <p>In Snippy Streamline, the nucleotide substitution model used by gubbins will always be GTR+GAMMA.</p> Snippy Gubbins (optional) SNP-sites (optional) IQTree2 SNP-dists Data summary (optional) Concatenate Variants (optional) Shared Variants (optional) Snippy_Variants QC Metrics Concatenation (optional)"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#snippy","title":"Snippy","text":"<p>Snippy is used to generate a whole-genome multiple sequence alignment (fasta file) of reads from all the samples we'd like in our tree. </p> <p>When generating the multiple sequence alignment, a bed file can be provided by users to mask certain areas of the genome in the alignment. This is particularly relevant for masking known repetitive regions in Mycobacterium tuberculosis  genomes, or masking known regions containing phage sequences.</p> <p>Why do I see <code>snippy_core</code> in Terra?</p> <p>In Terra, this task is named \"snippy_core\" after the name of the command in the original Snippy tool. Despite the name, this command is NOT being used to make a core genome, but instead a multiple sequence alignment of the whole genome (without any sections masked using a bed file).</p> <p>Snippy Technical Details</p> Links Task task_snippy_core.wdl Software Source Code Snippy on GitHub Software Documentation Snippy on GitHub"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#gubbins-optional","title":"Gubbins (optional)","text":"<p>Turn on Gubbins with <code>use_gubbins</code></p> <p>Gubbins runs when the <code>use_gubbins</code> option is set to <code>true</code> (default=true).</p> <p>Most optional inputs are hidden in Snippy_Streamline for simplification of the workflow. If you would like to use Gubbins with additional options, please use the <code>Snippy_Tree</code> workflow.</p> <p>In Snippy Streamline, the nucleotide substitution model used by gubbins will always be GTR+GAMMA.</p> <p>Genealogies Unbiased By recomBinations In Nucleotide Sequences (Gubbins) identifies and masks genomic regions that are predicted to have arisen via recombination. It works by iteratively identifying loci containing elevated densities of SNPs and constructing phylogenies based on the putative single nucleotide variants outside these regions (for more details, see here). By default, these phylogenies are constructed using RaxML and a GTR-GAMMA nucleotide substitution model, which will be the most suitable model for most bacterial phylogenetics, though this can be modified with the <code>tree_builder</code> and <code>nuc_subst_model</code> inputs.</p> <p>Gubbins is the industry standard for masking recombination from bacterial genomes when building phylogenies, but limitations to recombination removal exist. Gubbins cannot distinguish recombination from high densities of SNPs that may result from assembly or alignment errors, mutational hotspots, or regions of the genome with relaxed selection. The tool is also intended only to find recombinant regions that are short relative to the length of the genome, so large regions of recombination may not be masked. These factors should be considered when interpreting resulting phylogenetic trees, but overwhelmingly Gubbins improves our ability to understand ancestral relationships between bacterial genomes.</p> <p>Gubbins Technical Details</p> Links Task task_gubbins.wdl Software Source Code Gubbins on GitHub Software Documentation Gubbins v3.3 manual Original Publication(s) Rapid phylogenetic analysis of large samples of recombinant bacterial whole genome sequences using Gubbins"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#snp-sites-optional","title":"SNP-sites (optional)","text":"<p>Turn on SNP-Sites with <code>core_genome</code></p> <p>SNP-sites runs when the <code>core_genome</code> option is set to true.</p> <p>SNP-sites is used to filter out invariant sites in the whole-genome alignment, thereby creating a core genome alignment for phylogenetic inference. The output is a fasta file containing the core genome of each sample only. If Gubbins has been used, this output fasta will not contain any sites that are predicted to have arisen via recombination.</p> <p>SNP-sites technical details</p> Links Task task_snp_sites.wdl Software Source Code SNP-sites on GitHub Software Documentation SNP-sites on GitHub Original Publication(s) SNP-sites: rapid efficient extraction of SNPs from multi-FASTA alignments"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#iqtree2","title":"IQTree2","text":"<p>IQTree2 is used to build the final phylogeny. It uses the alignment generated in the previous steps of the workflow. The contents of this alignment will depend on whether any sites were masked with recombination.</p> <p>The phylogeny is generated using the maximum-likelihood method and a specified nucleotide substitution model. By default, the Snippy_Tree workflow will run Model Finder to determine the most appropriate nucleotide substitution model for your data, but you may specify the nucleotide substitution model yourself using the <code>iqtree2_model</code> optional input (see here for available models).</p> <p>IQTree will perform assessments of the tree using the Shimodaira\u2013Hasegawa approximate likelihood-ratio test (SH-aLRT test), and ultrafast bootstrapping with UFBoot2, a quicker but less biased alternative to standard bootstrapping. A clade should not typically be trusted if it has less than 80% support from the SH-aLRT test and less than 95% support with ultrafast bootstrapping.</p> <p>Nucleotide substitution model</p> <p>When <code>core_genome</code>= <code>true</code>, the default nucleotide substitution model is set to the General Time Reverside model with Gamma distribution (GTR+G). </p> <p>When the user sets <code>core_genome</code>= <code>false</code>, the default nucleotide substitution model is set to the General Time Reversible model with invariant sites and Gamma distribution (<code>GTR+I+G</code>).</p> <p>IQTree2 technical details</p> Links Task task_iqtree2.wdl Software Source Code IQ-TREE on GitHub Software Documentation IQTree documentation for the latest version (not necessarily the version used in this workflow) Original Publication(s) IQ-TREE 2: New Models and Efficient Methods for Phylogenetic Inference in the Genomic EraNew Algorithms and Methods to Estimate Maximum-Likelihood Phylogenies: Assessing the Performance of PhyML 3.0Ultrafast Approximation for Phylogenetic Bootstrap UFBoot2: Improving the Ultrafast Bootstrap ApproximationModelFinder: fast model selection for accurate phylogenetic estimates"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#snp-dists","title":"SNP-dists","text":"<p><code>SNP-dists</code> computes pairwise SNP distances between genomes. It takes the same alignment of genomes used to generate your phylogenetic tree and produces a matrix of pairwise SNP distances between sequences. This means that if you generated pairwise core-genome phylogeny, the output will consist of pairwise core-genome SNP (cgSNP) distances. Otherwise, these will be whole-genome SNP distances. Regardless of whether core-genome or whole-genome SNPs, this SNP distance matrix will exclude all SNPs in masked regions (i.e. masked with a bed file or gubbins). </p> <p>The SNP-distance output can be visualized using software such as Phandango to explore the relationships between the genomic sequences. The task can optionally add a Phandango coloring tag (:c1) to the column names in the output matrix to ensure that all columns are colored with the same color scheme throughout by setting <code>phandango_coloring</code> to <code>true</code>.</p> <p>SNP-dists Technical Details</p> Links Task task_snp_dists.wdl Software Source Code SNP-dists on GitHub Software Documentation SNP-dists on GitHub"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#data-summary-optional","title":"Data Summary (optional)","text":"<p>Command-line incompatible</p> <p>This task is not compatible with command-line use, even with modifications. It is engineered to run on Terra. To run this workflow on the command line, you must leave the <code>data_summary_*</code> and <code>sample_names</code> optional variables blank to prevent this task from running.</p> <p>If you fill out the <code>data_summary_*</code> and <code>sample_names</code> optional variables, you can use the optional <code>summarize_data</code> task. The task takes a comma-separated list of column names from the Terra data table, which should each contain a list of comma-separated items. For example, <code>\"amrfinderplus_virulence_genes,amrfinderplus_stress_genes\"</code> (with quotes, comma separated, no spaces) for these output columns from running TheiaProk. The task checks whether those comma-separated items are present in each row of the data table (sample), then creates a CSV file of these results. The CSV file indicates presence (TRUE) or absence (empty) for each item. By default, the task does not add a Phandango coloring tag to group items from the same column, but you can turn this on by setting <code>phandango_coloring</code> to <code>true</code>.</p> Example output CSV <pre><code>Sample_Name,aph(3')-IIa,blaCTX-M-65,blaOXA-193,tet(O)\nsample1,TRUE,,TRUE,TRUE\nsample2,,,FALSE,TRUE\nsample3,,,FALSE,\n</code></pre> Example use of Phandango coloring <p>Data summary produced using the <code>phandango_coloring</code> option, visualized alongside Newick tree at http://jameshadfield.github.io/phandango/#/main</p> <p>Example phandango_coloring output</p> <p></p> <p>Data summary technical details</p> Links Task task_summarize_data.wdl"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#concatenate-variants-optional","title":"Concatenate Variants (optional)","text":"<p>This task activates when <code>call_shared_variants</code> is true. The <code>cat_variants</code> task concatenates variant data from multiple samples into a single file <code>concatenated_variants</code>. It is very similar to the <code>cat_files</code> task, but also adds a column to the output file that indicates the sample associated with each row of data.</p> <p>The <code>concatenated_variants</code> file will be in the following format:</p> samplename CHROM POS TYPE REF ALT EVIDENCE FTYPE STRAND NT_POS AA_POS EFFECT LOCUS_TAG GENE PRODUCT sample1 PEKT02000007 5224 snp C G G:21 C:0 sample2 PEKT02000007 34112 snp C G G:32 C:0 CDS + 153/1620 51/539 missense_variant c.153C&gt;G p.His51Gln B9J08_002604 hypothetical protein sample3 PEKT02000007 34487 snp T A A:41 T:0 CDS + 528/1620 176/539 missense_variant c.528T&gt;A p.Asn176Lys B9J08_002604 hypothetical protein <p>Technical Details</p> Links Task task_cat_files.wdl"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#shared-variants-optional","title":"Shared Variants (optional)","text":"<p>This task activates when <code>call_shared_variants</code> is true.</p> <p>The <code>shared_variants</code> task takes in the <code>concatenated_variants</code> output from the <code>cat_variants</code> task and reshapes the data so that variants are rows and samples are columns. For each variant, samples where the variant was detected are populated with a \"1\" and samples were either the variant was not detected or there was insufficient coverage to call variants are populated with a \"0\". The resulting table is available as the <code>shared_variants_table</code> output.</p> <p>The <code>shared_variants_table</code> file will be in the following format:</p> CHROM POS TYPE REF ALT FTYPE STRAND NT_POS AA_POS EFFECT LOCUS_TAG GENE PRODUCT sample1 sample2 sample3 PEKT02000007 2693938 snp T C CDS - 1008/3000 336/999 synonymous_variant c.1008A&gt;G p.Lys336Lys B9J08_003879 NA chitin synthase 1 1 1 0 PEKT02000007 2529234 snp G C CDS + 282/336 94/111 missense_variant c.282G&gt;C p.Lys94Asn B9J08_003804 NA cytochrome c 1 1 1 PEKT02000002 1043926 snp A G CDS - 542/1464 181/487 missense_variant c.542T&gt;C p.Ile181Thr B9J08_000976 NA dihydrolipoyl dehydrogenase 1 1 0 <p>Technical Details</p> Links Task task_shared_variants.wdl"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#snippy_variants-qc-metric-concatenation-optional","title":"Snippy_Variants QC Metric Concatenation (optional)","text":"<p>Optionally, the user can provide the <code>snippy_variants_qc_metrics</code> file produced by the Snippy_Variants workflow as input to the workflow to concatenate the reports for each sample in the tree. These per-sample QC metrics include the following columns:</p> <ul> <li>samplename: The name of the sample.</li> <li>reads_aligned_to_reference: The number of reads that aligned to the reference genome.</li> <li>total_reads: The total number of reads in the sample.</li> <li>percent_reads_aligned: The percentage of reads that aligned to the reference genome.</li> <li>variants_total: The total number of variants detected between the sample and the reference genome.</li> <li>percent_ref_coverage: The percentage of the reference genome covered by reads with a depth greater than or equal to the <code>min_coverage</code> threshold (default is 10).</li> <li>#rname: Reference sequence name (e.g., chromosome or contig name).</li> <li>startpos: Starting position of the reference sequence.</li> <li>endpos: Ending position of the reference sequence.</li> <li>numreads: Number of reads covering the reference sequence.</li> <li>covbases: Number of bases with coverage.</li> <li>coverage: Percentage of the reference sequence covered (depth \u2265 1).</li> <li>meandepth: Mean depth of coverage over the reference sequence.</li> <li>meanbaseq: Mean base quality over the reference sequence.</li> <li>meanmapq: Mean mapping quality over the reference sequence.</li> </ul> <p>The combined QC metrics file includes the same columns as above for all samples. Note that the last set of columns (<code>#rname</code> to <code>meanmapq</code>) may repeat for each chromosome or contig in the reference genome.</p> <p>QC Metrics for Phylogenetic Analysis</p> <p>These QC metrics provide valuable insights into the quality and coverage of your sequencing data relative to the reference genome. Monitoring these metrics can help identify samples with low coverage, poor alignment, or potential issues that may affect downstream analyses, and we recommend examining them before proceeding with phylogenetic analysis if performing Snippy_Variants and Snippy_Tree separately.</p> <p>Technical Details</p> Links Task task_cat_files.wdl"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#outputs","title":"Outputs","text":"Variable Type Description snippy_centroid_docker String Docker file used for Centroid snippy_centroid_fasta File FASTA file for the centroid sample snippy_centroid_mash_tsv File TSV file containing mash distances computed by centroid snippy_centroid_samplename String Name of the centroid sample snippy_centroid_version String Centroid version used snippy_cg_snp_matrix File CSV file of core genome pairwise SNP distances between samples, calculated from the final alignment snippy_combined_qc_metrics File Combined QC metrics file containing concatenated QC metrics from all samples. snippy_concatenated_variants File Concatenated snippy_results file across all samples in the set snippy_filtered_metadata File TSV recording the columns of the Terra data table that were used in the summarize_data task snippy_final_alignment File Final alignment (FASTA file) used to generate the tree (either after snippy alignment, gubbins recombination removal, and/or core site selection with SNP-sites) snippy_final_tree File Newick tree produced from the final alignment. Depending on user input for core_genome, the tree could be a core genome tree (default when core_genome is true) or whole genome tree (if core_genome is false) snippy_gubbins_branch_stats File CSV file showing https://github.com/nickjcroucher/gubbins/blob/master/docs/gubbins_manual.md#output-statistics for each branch of the tree snippy_gubbins_docker String Docker file used for running Gubbins snippy_gubbins_recombination_gff File Recombination statistics in GFF format; these can be viewed in Phandango against the phylogenetic tree snippy_gubbins_version String Gubbins version used snippy_iqtree2_docker String Docker file used for running IQTree2 snippy_iqtree2_model_used String Nucleotide substitution model used by IQTree2 snippy_iqtree2_version String IQTree2 version used snippy_msa_snps_summary File TXT file containing summary statistics for each alignment of each input genome against the reference. This indicates how good the alignment is. Pay particular attention to # unaligned sites, and heterogeneous positions. See also https://github.com/nickjcroucher/gubbins/blob/master/docs/gubbins_manual.md#output-statistics snippy_ncbi_datasets_docker String Docker file used for NCBI datasets snippy_ncbi_datasets_version String NCBI datasets version used snippy_ref File Reference genome (FASTA or GenBank file) used for generating phylogeny snippy_ref_metadata_json File Metadata associated with the refence genome used by Snippy, in JSON format snippy_referenceseeker_database String ReferenceSeeker database used snippy_referenceseeker_docker String Docker file used for ReferenceSeeker snippy_referenceseeker_top_hit_ncbi_accession String NCBI Accession for the top hit identified by referenceseeker snippy_referenceseeker_tsv File TSV file of the top hits between the query genome and the Reference Seeker database snippy_referenceseeker_version String ReferenceSeeker version used snippy_shared_variants_table File Table illustrating variants shared among samples snippy_snp_dists_docker String Docker file used for running SNP-dists snippy_snp_dists_version String SNP-dists version used snippy_snp_sites_docker String Docker file used for running SNP-sites snippy_snp_sites_version String SNP-sites version used snippy_streamline_analysis_date String Date of workflow run snippy_streamline_version String Version of Snippy_Streamline used snippy_summarized_data File CSV presence/absence matrix generated by the summarize_data task from the list of columns provided; formatted for Phandango if phandango_coloring input is true snippy_tree_snippy_docker String Docker file used for running Snippy snippy_tree_snippy_version String Snippy version used snippy_variants_outdir_tarball Array[File] A compressed file containing the whole directory of snippy output files. This is used when running Snippy_Tree snippy_variants_percent_reads_aligned Array[Float] Percentage of reads aligned to the reference genome snippy_variants_percent_ref_coverage Array[Float] Proportion of the reference genome covered by reads with a depth greater than or equal to the <code>min_coverage</code> threshold (default is 10). snippy_variants_snippy_docker Array[String] Docker file used for Snippy in the Snippy_Variants subworkfow snippy_variants_snippy_version Array[String] Version of Snippy_Tree subworkflow used snippy_wg_snp_matrix File CSV file of whole genome pairwise SNP distances between samples, calculated from the final alignment"},{"location":"workflows/phylogenetic_construction/snippy_streamline/#references","title":"References","text":"<p>Gubbins: Croucher, Nicholas J., Andrew J. Page, Thomas R. Connor, Aidan J. Delaney, Jacqueline A. Keane, Stephen D. Bentley, Julian Parkhill, and Simon R. Harris. 2015. \"Rapid Phylogenetic Analysis of Large Samples of Recombinant Bacterial Whole Genome Sequences Using Gubbins.\" Nucleic Acids Research 43 (3): e15.</p> <p>SNP-sites: Page, Andrew J., Ben Taylor, Aidan J. Delaney, Jorge Soares, Torsten Seemann, Jacqueline A. Keane, and Simon R. Harris. 2016. \"SNP-Sites: Rapid Efficient Extraction of SNPs from Multi-FASTA Alignments.\" Microbial Genomics 2 (4): e000056.</p> <p>IQTree: Nguyen, Lam-Tung, Heiko A. Schmidt, Arndt von Haeseler, and Bui Quang Minh. 2015. \"IQ-TREE: A Fast and Effective Stochastic Algorithm for Estimating Maximum-Likelihood Phylogenies.\" Molecular Biology and Evolution 32 (1): 268\u201374.</p>"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/","title":"Snippy_Streamline_FASTA","text":""},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#snippy_streamline_fasta","title":"Snippy_Streamline_FASTA","text":""},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Construction Bacteria v3.0.0 Some optional features incompatible, Yes Set-level Snippy_Streamline_FASTA_PHB"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#snippy_streamline_fasta_phb","title":"Snippy_Streamline_FASTA_PHB","text":"<p>This workflow is a FASTA-compatible version of Snippy_Streamline. Please see the Snippy_Streamline documentation for more information regarding the workflow tasks.</p> <p>Snippy_Streamline_FASTA_PHB Workflow Diagram</p> <p></p> <p></p> <p>The <code>Snippy_Streamline_FASTA</code> workflow is an all-in-one approach to generating a reference-based phylogenetic tree and associated SNP-distance matrix. The workflow can be run in multiple ways.</p> <p>Reference Genome Options</p> <p>In order to generate a phylogenetic tree, a reference genome is required. This can be:</p> <ol> <li>provided by the user by filling the <code>reference_genome_file</code> input variable</li> <li>the identified <code>centroid</code> genome by setting <code>use_centroid_as_reference</code> to true</li> <li>automatically selected using the <code>centroid</code> task and <code>reference_seeker</code> task to find a close reference genome to your dataset by leaving the <code>reference_genome_file</code> and <code>use_centroid_as_reference</code> fields blank</li> </ol> <p>Phylogenetic Tree Construction Options</p> <p>There are several options that can be used to customize the phylogenetic tree, including:</p> <ol> <li>masking user-specified regions of the genome (by providing a bed file to <code>snippy_core_bed</code>)</li> <li>producing either a core or pan-genome phylogeny and SNP-matrix (by altering <code>core_genome</code>; true [default] = core genome, false = pan-genome)</li> <li>choosing the nucleotide substitution (by altering <code>iqtree2_model</code> [see below for possible nucleotide substitution models]), or allowing IQ-Tree's ModelFinder to identify the best model for your dataset (default)</li> <li>masking recombination detected by gubbins, or not (by altering <code>use_gubbins</code>; true [default] = recombination masking, false = no recombination masking)</li> </ol> <p>Multiple Contigs in Reference Genomes</p> <p>If reference genomes have multiple contigs, they are incompatible with Gubbins to mask recombination in the phylogenetic tree. The automatic selection of a reference genome by the workflow may result in a reference with multiple contigs. In this case, an alternative reference genome should be sought, or Gubbins should be turned off (via <code>use_gubbins = false</code>).</p>"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#inputs","title":"Inputs","text":"<p>Assembly Data Requirements</p> <p>Input data used in the Snippy_Streamline_FASTA workflow must:</p> <ul> <li>Be assembled genomes in FASTA format</li> <li>Be generated by unbiased whole genome shotgun sequencing</li> <li>Pass appropriate QC thresholds for the taxa to ensure that the assemblies represent reasonably complete genomes that are free of contamination from other taxa or cross-contamination of the same taxon.</li> <li>If masking recombination with <code>Gubbins</code>, input data should represent complete genomes from the same strain/lineage (e.g. MLST) that share a recent common ancestor.</li> </ul> <p>Guidance for optional inputs</p> <p>Several core and optional tasks can be used to generate the Snippy phylogenetic tree, making it highly flexible and suited to a wide range of datasets. You will need to decide which tasks to use depending on the genomes that you are analyzing. Some guidelines for the optional tasks to use for different genome types are provided below.</p> Default settings (suitable for most bacteria) <p>The default settings are as follows and are suitable for generating phylogenies for most bacteria</p> <ul> <li><code>core_genome</code> = true (creates core genome phylogeny)</li> <li><code>use_gubbins</code> = true (recombination masked)</li> <li>nucleotide substitution model will be defined by IQTree's Model Finder</li> </ul> Phylogenies of Mycobacterium tuberculosis complex <p>Phylogenies of MTBC are typically constructed with the following options:</p> <ul> <li>Using the H37Rv reference genome<ul> <li><code>reference_genome_file</code> = <code>\"gs://theiagen-public-resources-rp/reference_data/bacterial/mycobacterium/MTB-NC_000962.3.fasta\"</code></li> </ul> </li> <li>Masking repetitive regions of the genome (e.g. PE/PPE genes) that are often misaligned<ul> <li><code>snippy_core_bed</code> = <code>\"gs://theiagen-public-resources-rp/reference_data/bacterial/mycobacterium/MTB-NC_000962.3.bed\"</code></li> </ul> </li> <li>Without masking recombination because TB can be considered non-recombinant<ul> <li><code>use_gubbins</code> = false</li> </ul> </li> <li>Using the core genome<ul> <li><code>core_genome</code> = true (as default)</li> </ul> </li> </ul> Terra Task Name Variable Type Description Default Value Terra Status snippy_streamline_fasta assembly_fasta Array[File] The assembly files for your samples in FASTA format Required snippy_streamline_fasta samplenames Array[String] The names of the samples being analyzed Required snippy_streamline_fasta tree_name String String of your choice to prefix output files Required centroid cpu Int Number of CPUs to allocate to the task 1 Optional centroid disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional centroid docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/centroid:0.1.0 Optional centroid memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional ncbi_datasets_download_genome_accession cpu Int Number of CPUs to allocate to the task 1 Optional ncbi_datasets_download_genome_accession disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional ncbi_datasets_download_genome_accession docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ncbi-datasets:16.38.1 Optional ncbi_datasets_download_genome_accession include_gbff Boolean Set to true if you would like the GenBank Flat File (GBFF) file included in the output. It contains nucleotide sequence, metadata, and annotations. FALSE Optional ncbi_datasets_download_genome_accession include_gff3 Boolean Set to true if you would like the Genomic Feature File v3 (GFF3) file included in the output. It contains nucleotide sequence, metadata, and annotations FALSE Optional ncbi_datasets_download_genome_accession memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional ncbi_datasets_download_genome_accession use_ncbi_virus Boolean Set to true to download from NCBI Virus Datasets FALSE Optional referenceseeker cpu Int Number of CPUs to allocate to the task 4 Optional referenceseeker disk_size Int Amount of storage (in GB) to allocate to the task 200 Optional referenceseeker docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/referenceseeker:1.8.0--pyhdfd78af_0 Optional referenceseeker memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional referenceseeker referenceseeker_ani_threshold Float Bidirectional average nucleotide identity to use as a cut off for identifying reference assemblies with ReferenceSeeker; default value set according to https://github.com/oschwengers/referenceseeker#description 0.95 Optional referenceseeker referenceseeker_conserved_dna_threshold Float Conserved DNA % to use as a cut off for identifying reference assemblies with ReferenceSeeker; default value set according to https://github.com/oschwengers/referenceseeker#description 0.69 Optional referenceseeker referenceseeker_db File Database used by the referenceseeker tool that contains bacterial genomes from RefSeq release 205. Downloaded from the referenceseeker GitHub repository. gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-bacteria-refseq-205.v20210406.tar.gz Optional snippy_streamline_fasta reference_genome_file File Reference genome in FASTA or GENBANK format (must be the same reference used in Snippy_Variants workflow); provide this if you want to skip the detection of a suitable reference Optional snippy_streamline_fasta use_centroid_as_reference Boolean Set to true if you want to use the centroid sample as the reference sample instead of using the centroid to detect a suitable one FALSE Optional snippy_tree_wf call_shared_variants Boolean When true, workflow generates table that combines variants across all samples and a table showing variants shared across samples TRUE Optional snippy_tree_wf core_genome Boolean When true, workflow generates core genome phylogeny; when false, whole genome is used TRUE Optional snippy_tree_wf data_summary_column_names String A comma-separated list of the column names from the sample-level data table for generating a data summary (presence/absence .csv matrix) Optional snippy_tree_wf data_summary_terra_project String The billing project for your current workspace. This can be found after the \"#workspaces/\" section in the workspace's URL Optional snippy_tree_wf data_summary_terra_table String The name of the sample-level Terra data table that will be used for generating a data summary Optional snippy_tree_wf data_summary_terra_workspace String The name of the Terra workspace you are in. This can be found at the top of the webpage, or in the URL after the billing project. Optional snippy_tree_wf gubbins_cpu Int Number of CPUs to allocate to the task 4 Optional snippy_tree_wf gubbins_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional snippy_tree_wf gubbins_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/gubbins:3.3--py310pl5321h8472f5a_0 Optional snippy_tree_wf gubbins_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional snippy_tree_wf iqtree2_bootstraps Int Number of replicates for http://www.iqtree.org/doc/Tutorial#assessing-branch-supports-with-ultrafast-bootstrap-approximation (Minimum recommended= 1000) 1000 Optional snippy_tree_wf iqtree2_cpu Int Number of CPUs to allocate to the task 4 Optional snippy_tree_wf iqtree2_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional snippy_tree_wf iqtree2_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/iqtree2:2.1.2 Optional snippy_tree_wf iqtree2_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional snippy_tree_wf iqtree2_model String Nucelotide substitution model to use when generating the final tree with IQTree2. By default, IQtree runs its ModelFinder algorithm to identify the model it thinks best fits your dataset Optional snippy_tree_wf iqtree2_opts String Additional options to pass to IQTree2 Optional snippy_tree_wf midpoint_root_tree Boolean A True/False option that determines whether the tree used in the SNP matrix re-ordering task should be re-rooted or not. Options: true or false TRUE Optional snippy_tree_wf phandango_coloring Boolean Boolean variable that tells the data summary task and the reorder matrix task to include a suffix that enables consistent coloring on Phandango; by default, this suffix is not added. To add this suffix set this variable to true. FALSE Optional snippy_tree_wf snippy_core_bed File User-provided bed file to mask out regions of the genome when creating multiple sequence alignments Optional snippy_tree_wf snippy_core_cpu Int Number of CPUs to allocate to the task 8 Optional snippy_tree_wf snippy_core_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional snippy_tree_wf snippy_core_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snippy:4.6.0 Optional snippy_tree_wf snippy_core_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional snippy_tree_wf snp_dists_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snp-dists:0.8.2 Optional snippy_tree_wf snp_sites_cpu Int Number of CPUs to allocate to the task 1 Optional snippy_tree_wf snp_sites_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional snippy_tree_wf snp_sites_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snp-sites:2.5.1 Optional snippy_tree_wf snp_sites_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional snippy_tree_wf use_gubbins Boolean When \"true\", workflow removes recombination with gubbins tasks; when \"false\", gubbins is not used TRUE Optional snippy_variants_wf base_quality Int Minimum quality for a nucleotide to be used in variant calling 13 Optional snippy_variants_wf cpu Int Number of CPUs to allocate to the task 4 Optional snippy_variants_wf docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snippy:4.6.0 Optional snippy_variants_wf map_qual Int Minimum mapping quality to accept in variant calling 60 Optional snippy_variants_wf maxsoft Int Number of bases of alignment to soft-clip before discarding the alignment 10 Optional snippy_variants_wf memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional snippy_variants_wf min_coverage Int Minimum read coverage of a position to identify a mutation 10 Optional snippy_variants_wf min_frac Float Minimum fraction of bases at a given position to identify a mutation 0 Optional snippy_variants_wf min_quality Int Minimum VCF variant call \"quality\" 100 Optional snippy_variants_wf query_gene String Comma-separated strings (e.g. gene names) in which to search for mutations to output to data table Optional snippy_variants_wf read1 File Internal component, do not modify Optional snippy_variants_wf read2 File Internal component, do not modify Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#workflow-tasks","title":"Workflow Tasks","text":""},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#automatic-reference-selection","title":"Automatic Reference Selection","text":"<p>The following tasks perform automatic reference selection (if no reference genome is provided by the user and <code>assembly_fasta</code> is provided).</p> Centroid ReferenceSeeker Details (Optional) NCBI Datasets"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#centroid","title":"Centroid","text":"<p>Centroid selects the most central genome among a list of assemblies by computing pairwise mash distances. In <code>Snippy_Streamline</code>, this centroid assembly is then used to find a closely related reference genome that can be used to generate the tree.  In order to use <code>Centroid</code>, should complete the <code>samplenames</code> input. </p> <p><code>centroid</code> Technical Details</p> Links Task task_centroid.wdl Software Source Code https://github.com/theiagen/centroid Software Documentation https://github.com/theiagen/centroid"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#referenceseeker","title":"ReferenceSeeker","text":"<p><code>ReferenceSeeker</code> uses your draft assembly to identify closely related bacterial, viral, fungal, or plasmid genome assemblies in RefSeq.</p> <p>Databases that can be used with ReferenceSeeker are as follows, and can be used by pasting the GSURI in double quotation marks <code>\" \"</code> into the <code>referenceseeker_db</code> optional input:</p> <ul> <li>archea:  <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-archaea-refseq-205.v20210406.tar.gz</code></li> <li>bacterial (default): <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-bacteria-refseq-205.v20210406.tar.gz</code></li> <li>fungi: <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-fungi-refseq-205.v20210406.tar.gz</code></li> <li>plasmids: <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-plasmids-refseq-205.v20210406.tar.gz</code></li> <li>viral: <code>gs://theiagen-public-resources-rp/reference_data/databases/referenceseeker/referenceseeker-viral-refseq-205.v20210406.tar.gz</code></li> </ul> <p>For ReferenceSeeker to identify a genome, it must meet user-specified thresholds for sequence coverage (<code>referenceseeker_conserved_dna_threshold</code>; default &gt;= 0.69) and identity (<code>referenceseeker_ani_threshold</code>; default &gt;= 0.95 ). </p> <p>A list of closely related genomes is provided in <code>referenceseeker_tsv</code>. The reference genome that ranks highest according to ANI and conserved DNA values is considered the closest match and will be downloaded, with information about this provided in the <code>assembly_fetch_referenceseeker_top_hit_ncbi_accession</code> output.</p> <p>ReferenceSeeker Technical Details</p> Links Task task_referenceseeker.wdl Software Source Code ReferenceSeeker on GitHub Software Documentation ReferenceSeeker on GitHub Original Publication(s) ReferenceSeeker: rapid determination of appropriate reference genomes"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#ncbi-datasets","title":"NCBI Datasets","text":"<p>The <code>NCBI Datasets</code> task downloads specified assemblies from NCBI using either the virus or genome (for all other genome types) package as appropriate.</p> <p><code>include_gbff</code> behavior</p> <p>If <code>include_gbff</code> is set to <code>true</code>, the gbff file will be used as the reference for <code>Snippy_Variants</code> and <code>Snippy_Tree</code>. If <code>include_gbff</code> is set to <code>false</code>, the fasta file will be used as the reference for <code>Snippy_Variants</code> and <code>Snippy_Tree</code>. Tree topology should not differ, though annotations may.</p> <p>NCBI Datasets Technical Details</p> Links Task task_ncbi_datasets.wdl Software Source Code NCBI Datasets on GitHub Software Documentation NCBI Datasets Documentation on NCBI Original Publication(s) Exploring and retrieving sequence and metadata for species across the tree of life with NCBI Datasets"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#variant-calling","title":"Variant Calling","text":"<p>The following task performs variant calling on the samples using a reference genome (either selected in the previous steps, or provided by the user)</p> <p>Please see the full documentation for Snippy_Variants for more information.</p> Snippy_Variants"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#snippy_variants","title":"Snippy_Variants","text":"<p><code>Snippy_Variants</code> uses Snippy to align the assemblies for each sample against the reference genome to call SNPs, MNPs and INDELs according to optional input parameters. </p> <p>Optionally, if the user provides a value for <code>query_gene</code>, the variant file will be searched for any mutations in the specified regions or annotations. The query string MUST match the gene name or annotation as specified in the GenBank file and provided in the output variant file in the <code>snippy_results</code> column.</p> QC Metrics from Snippy_Variants <p>Warning</p> <p>The following QC metrics may not be applicable to your dataset as they are geared towards read data, not assemblies. Use these metrics with caution.</p> <p>This task also extracts QC metrics from the Snippy output for each sample and saves them in per-sample TSV files (<code>snippy_variants_qc_metrics</code>). These per-sample QC metrics include the following columns:</p> <ul> <li>samplename: The name of the sample.</li> <li>reads_aligned_to_reference: The number of reads that aligned to the reference genome.</li> <li>total_reads: The total number of reads in the sample.</li> <li>percent_reads_aligned: The percentage of reads that aligned to the reference genome.</li> <li>variants_total: The total number of variants detected between the sample and the reference genome.</li> <li>percent_ref_coverage: The percentage of the reference genome covered by reads with a depth greater than or equal to the <code>min_coverage</code> threshold (default is 10).</li> <li>#rname: Reference sequence name (e.g., chromosome or contig name).</li> <li>startpos: Starting position of the reference sequence.</li> <li>endpos: Ending position of the reference sequence.</li> <li>numreads: Number of reads covering the reference sequence.</li> <li>covbases: Number of bases with coverage.</li> <li>coverage: Percentage of the reference sequence covered (depth \u2265 1).</li> <li>meandepth: Mean depth of coverage over the reference sequence.</li> <li>meanbaseq: Mean base quality over the reference sequence.</li> <li>meanmapq: Mean mapping quality over the reference sequence.</li> </ul> <p>Note that the last set of columns (<code>#rname</code> to <code>meanmapq</code>) may repeat for each chromosome or contig in the reference genome.</p> <p>Snippy Variants Technical Details</p> Links Task task_snippy_variants.wdltask_snippy_gene_query.wdl Software Source Code Snippy on GitHub Software Documentation Snippy on GitHub"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#phylogenetic-construction","title":"Phylogenetic Construction","text":"<p>The following tasks are a simplified version of the <code>Snippy_Tree</code> workflow, which is used to build the phylogenetic tree. The tasks undertaken are exactly the same between both workflows, but user inputs and outputs have been reduced for clarity and ease.</p> <p>Please see the full documentation for Snippy_Tree for more information.</p> <p>Gubbins Nucleotide Substitution Model</p> <p>In Snippy Streamline, the nucleotide substitution model used by gubbins will always be GTR+GAMMA.</p> Snippy Gubbins (optional) SNP-sites (optional) IQTree2 SNP-dists Data summary (optional) Concatenate Variants (optional) Shared Variants (optional) Snippy_Variants QC Metrics Concatenation (optional)"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#snippy","title":"Snippy","text":"<p>Snippy is used to generate a whole-genome multiple sequence alignment (fasta file) of reads from all the samples we'd like in our tree. </p> <p>When generating the multiple sequence alignment, a bed file can be provided by users to mask certain areas of the genome in the alignment. This is particularly relevant for masking known repetitive regions in Mycobacterium tuberculosis  genomes, or masking known regions containing phage sequences.</p> <p>Why do I see <code>snippy_core</code> in Terra?</p> <p>In Terra, this task is named \"snippy_core\" after the name of the command in the original Snippy tool. Despite the name, this command is NOT being used to make a core genome, but instead a multiple sequence alignment of the whole genome (without any sections masked using a bed file).</p> <p>Snippy Technical Details</p> Links Task task_snippy_core.wdl Software Source Code Snippy on GitHub Software Documentation Snippy on GitHub"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#gubbins-optional","title":"Gubbins (optional)","text":"<p>Turn on Gubbins with <code>use_gubbins</code></p> <p>Gubbins runs when the <code>use_gubbins</code> option is set to <code>true</code> (default=true).</p> <p>Most optional inputs are hidden in Snippy_Streamline for simplification of the workflow. If you would like to use Gubbins with additional options, please use the <code>Snippy_Tree</code> workflow.</p> <p>In Snippy Streamline, the nucleotide substitution model used by gubbins will always be GTR+GAMMA.</p> <p>Genealogies Unbiased By recomBinations In Nucleotide Sequences (Gubbins) identifies and masks genomic regions that are predicted to have arisen via recombination. It works by iteratively identifying loci containing elevated densities of SNPs and constructing phylogenies based on the putative single nucleotide variants outside these regions (for more details, see here). By default, these phylogenies are constructed using RaxML and a GTR-GAMMA nucleotide substitution model, which will be the most suitable model for most bacterial phylogenetics, though this can be modified with the <code>tree_builder</code> and <code>nuc_subst_model</code> inputs.</p> <p>Gubbins is the industry standard for masking recombination from bacterial genomes when building phylogenies, but limitations to recombination removal exist. Gubbins cannot distinguish recombination from high densities of SNPs that may result from assembly or alignment errors, mutational hotspots, or regions of the genome with relaxed selection. The tool is also intended only to find recombinant regions that are short relative to the length of the genome, so large regions of recombination may not be masked. These factors should be considered when interpreting resulting phylogenetic trees, but overwhelmingly Gubbins improves our ability to understand ancestral relationships between bacterial genomes.</p> <p>Gubbins Technical Details</p> Links Task task_gubbins.wdl Software Source Code Gubbins on GitHub Software Documentation Gubbins v3.3 manual Original Publication(s) Rapid phylogenetic analysis of large samples of recombinant bacterial whole genome sequences using Gubbins"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#snp-sites-optional","title":"SNP-sites (optional)","text":"<p>Turn on SNP-Sites with <code>core_genome</code></p> <p>SNP-sites runs when the <code>core_genome</code> option is set to true.</p> <p>SNP-sites is used to filter out invariant sites in the whole-genome alignment, thereby creating a core genome alignment for phylogenetic inference. The output is a fasta file containing the core genome of each sample only. If Gubbins has been used, this output fasta will not contain any sites that are predicted to have arisen via recombination.</p> <p>SNP-sites technical details</p> Links Task task_snp_sites.wdl Software Source Code SNP-sites on GitHub Software Documentation SNP-sites on GitHub Original Publication(s) SNP-sites: rapid efficient extraction of SNPs from multi-FASTA alignments"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#iqtree2","title":"IQTree2","text":"<p>IQTree2 is used to build the final phylogeny. It uses the alignment generated in the previous steps of the workflow. The contents of this alignment will depend on whether any sites were masked with recombination.</p> <p>The phylogeny is generated using the maximum-likelihood method and a specified nucleotide substitution model. By default, the Snippy_Tree workflow will run Model Finder to determine the most appropriate nucleotide substitution model for your data, but you may specify the nucleotide substitution model yourself using the <code>iqtree2_model</code> optional input (see here for available models).</p> <p>IQTree will perform assessments of the tree using the Shimodaira\u2013Hasegawa approximate likelihood-ratio test (SH-aLRT test), and ultrafast bootstrapping with UFBoot2, a quicker but less biased alternative to standard bootstrapping. A clade should not typically be trusted if it has less than 80% support from the SH-aLRT test and less than 95% support with ultrafast bootstrapping.</p> <p>Nucleotide substitution model</p> <p>When <code>core_genome</code>= <code>true</code>, the default nucleotide substitution model is set to the General Time Reverside model with Gamma distribution (GTR+G). </p> <p>When the user sets <code>core_genome</code>= <code>false</code>, the default nucleotide substitution model is set to the General Time Reversible model with invariant sites and Gamma distribution (<code>GTR+I+G</code>).</p> <p>IQTree2 technical details</p> Links Task task_iqtree2.wdl Software Source Code IQ-TREE on GitHub Software Documentation IQTree documentation for the latest version (not necessarily the version used in this workflow) Original Publication(s) IQ-TREE 2: New Models and Efficient Methods for Phylogenetic Inference in the Genomic EraNew Algorithms and Methods to Estimate Maximum-Likelihood Phylogenies: Assessing the Performance of PhyML 3.0Ultrafast Approximation for Phylogenetic Bootstrap UFBoot2: Improving the Ultrafast Bootstrap ApproximationModelFinder: fast model selection for accurate phylogenetic estimates"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#snp-dists","title":"SNP-dists","text":"<p><code>SNP-dists</code> computes pairwise SNP distances between genomes. It takes the same alignment of genomes used to generate your phylogenetic tree and produces a matrix of pairwise SNP distances between sequences. This means that if you generated pairwise core-genome phylogeny, the output will consist of pairwise core-genome SNP (cgSNP) distances. Otherwise, these will be whole-genome SNP distances. Regardless of whether core-genome or whole-genome SNPs, this SNP distance matrix will exclude all SNPs in masked regions (i.e. masked with a bed file or gubbins). </p> <p>The SNP-distance output can be visualized using software such as Phandango to explore the relationships between the genomic sequences. The task can optionally add a Phandango coloring tag (:c1) to the column names in the output matrix to ensure that all columns are colored with the same color scheme throughout by setting <code>phandango_coloring</code> to <code>true</code>.</p> <p>SNP-dists Technical Details</p> Links Task task_snp_dists.wdl Software Source Code SNP-dists on GitHub Software Documentation SNP-dists on GitHub"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#data-summary-optional","title":"Data Summary (optional)","text":"<p>Command-line incompatible</p> <p>This task is not compatible with command-line use, even with modifications. It is engineered to run on Terra. To run this workflow on the command line, you must leave the <code>data_summary_*</code> and <code>sample_names</code> optional variables blank to prevent this task from running.</p> <p>If you fill out the <code>data_summary_*</code> and <code>sample_names</code> optional variables, you can use the optional <code>summarize_data</code> task. The task takes a comma-separated list of column names from the Terra data table, which should each contain a list of comma-separated items. For example, <code>\"amrfinderplus_virulence_genes,amrfinderplus_stress_genes\"</code> (with quotes, comma separated, no spaces) for these output columns from running TheiaProk. The task checks whether those comma-separated items are present in each row of the data table (sample), then creates a CSV file of these results. The CSV file indicates presence (TRUE) or absence (empty) for each item. By default, the task does not add a Phandango coloring tag to group items from the same column, but you can turn this on by setting <code>phandango_coloring</code> to <code>true</code>.</p> Example output CSV <pre><code>Sample_Name,aph(3')-IIa,blaCTX-M-65,blaOXA-193,tet(O)\nsample1,TRUE,,TRUE,TRUE\nsample2,,,FALSE,TRUE\nsample3,,,FALSE,\n</code></pre> Example use of Phandango coloring <p>Data summary produced using the <code>phandango_coloring</code> option, visualized alongside Newick tree at http://jameshadfield.github.io/phandango/#/main</p> <p>Example phandango_coloring output</p> <p></p> <p>Data summary technical details</p> Links Task task_summarize_data.wdl"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#concatenate-variants-optional","title":"Concatenate Variants (optional)","text":"<p>This task activates when <code>call_shared_variants</code> is true. The <code>cat_variants</code> task concatenates variant data from multiple samples into a single file <code>concatenated_variants</code>. It is very similar to the <code>cat_files</code> task, but also adds a column to the output file that indicates the sample associated with each row of data.</p> <p>The <code>concatenated_variants</code> file will be in the following format:</p> samplename CHROM POS TYPE REF ALT EVIDENCE FTYPE STRAND NT_POS AA_POS EFFECT LOCUS_TAG GENE PRODUCT sample1 PEKT02000007 5224 snp C G G:21 C:0 sample2 PEKT02000007 34112 snp C G G:32 C:0 CDS + 153/1620 51/539 missense_variant c.153C&gt;G p.His51Gln B9J08_002604 hypothetical protein sample3 PEKT02000007 34487 snp T A A:41 T:0 CDS + 528/1620 176/539 missense_variant c.528T&gt;A p.Asn176Lys B9J08_002604 hypothetical protein <p>Technical Details</p> Links Task task_cat_files.wdl"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#shared-variants-optional","title":"Shared Variants (optional)","text":"<p>This task activates when <code>call_shared_variants</code> is true.</p> <p>The <code>shared_variants</code> task takes in the <code>concatenated_variants</code> output from the <code>cat_variants</code> task and reshapes the data so that variants are rows and samples are columns. For each variant, samples where the variant was detected are populated with a \"1\" and samples were either the variant was not detected or there was insufficient coverage to call variants are populated with a \"0\". The resulting table is available as the <code>shared_variants_table</code> output.</p> <p>The <code>shared_variants_table</code> file will be in the following format:</p> CHROM POS TYPE REF ALT FTYPE STRAND NT_POS AA_POS EFFECT LOCUS_TAG GENE PRODUCT sample1 sample2 sample3 PEKT02000007 2693938 snp T C CDS - 1008/3000 336/999 synonymous_variant c.1008A&gt;G p.Lys336Lys B9J08_003879 NA chitin synthase 1 1 1 0 PEKT02000007 2529234 snp G C CDS + 282/336 94/111 missense_variant c.282G&gt;C p.Lys94Asn B9J08_003804 NA cytochrome c 1 1 1 PEKT02000002 1043926 snp A G CDS - 542/1464 181/487 missense_variant c.542T&gt;C p.Ile181Thr B9J08_000976 NA dihydrolipoyl dehydrogenase 1 1 0 <p>Technical Details</p> Links Task task_shared_variants.wdl"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#snippy_variants-qc-metric-concatenation-optional","title":"Snippy_Variants QC Metric Concatenation (optional)","text":"<p>Optionally, the user can provide the <code>snippy_variants_qc_metrics</code> file produced by the Snippy_Variants workflow as input to the workflow to concatenate the reports for each sample in the tree. These per-sample QC metrics include the following columns:</p> <ul> <li>samplename: The name of the sample.</li> <li>reads_aligned_to_reference: The number of reads that aligned to the reference genome.</li> <li>total_reads: The total number of reads in the sample.</li> <li>percent_reads_aligned: The percentage of reads that aligned to the reference genome.</li> <li>variants_total: The total number of variants detected between the sample and the reference genome.</li> <li>percent_ref_coverage: The percentage of the reference genome covered by reads with a depth greater than or equal to the <code>min_coverage</code> threshold (default is 10).</li> <li>#rname: Reference sequence name (e.g., chromosome or contig name).</li> <li>startpos: Starting position of the reference sequence.</li> <li>endpos: Ending position of the reference sequence.</li> <li>numreads: Number of reads covering the reference sequence.</li> <li>covbases: Number of bases with coverage.</li> <li>coverage: Percentage of the reference sequence covered (depth \u2265 1).</li> <li>meandepth: Mean depth of coverage over the reference sequence.</li> <li>meanbaseq: Mean base quality over the reference sequence.</li> <li>meanmapq: Mean mapping quality over the reference sequence.</li> </ul> <p>The combined QC metrics file includes the same columns as above for all samples. Note that the last set of columns (<code>#rname</code> to <code>meanmapq</code>) may repeat for each chromosome or contig in the reference genome.</p> <p>QC Metrics for Phylogenetic Analysis</p> <p>These QC metrics provide valuable insights into the quality and coverage of your sequencing data relative to the reference genome. Monitoring these metrics can help identify samples with low coverage, poor alignment, or potential issues that may affect downstream analyses, and we recommend examining them before proceeding with phylogenetic analysis if performing Snippy_Variants and Snippy_Tree separately.</p> <p>Technical Details</p> Links Task task_cat_files.wdl"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#outputs","title":"Outputs","text":"Variable Type Description snippy_centroid_docker String Docker file used for Centroid snippy_centroid_fasta File FASTA file for the centroid sample snippy_centroid_mash_tsv File TSV file containing mash distances computed by centroid snippy_centroid_samplename String Name of the centroid sample snippy_centroid_version String Centroid version used snippy_cg_snp_matrix File CSV file of core genome pairwise SNP distances between samples, calculated from the final alignment snippy_combined_qc_metrics File Combined QC metrics file containing concatenated QC metrics from all samples. snippy_concatenated_variants File Concatenated snippy_results file across all samples in the set snippy_filtered_metadata File TSV recording the columns of the Terra data table that were used in the summarize_data task snippy_final_alignment File Final alignment (FASTA file) used to generate the tree (either after snippy alignment, gubbins recombination removal, and/or core site selection with SNP-sites) snippy_final_tree File Newick tree produced from the final alignment. Depending on user input for core_genome, the tree could be a core genome tree (default when core_genome is true) or whole genome tree (if core_genome is false) snippy_gubbins_branch_stats File CSV file showing https://github.com/nickjcroucher/gubbins/blob/master/docs/gubbins_manual.md#output-statistics for each branch of the tree snippy_gubbins_docker String Docker file used for running Gubbins snippy_gubbins_recombination_gff File Recombination statistics in GFF format; these can be viewed in Phandango against the phylogenetic tree snippy_gubbins_version String Gubbins version used snippy_iqtree2_docker String Docker file used for running IQTree2 snippy_iqtree2_model_used String Nucleotide substitution model used by IQTree2 snippy_iqtree2_version String IQTree2 version used snippy_msa_snps_summary File TXT file containing summary statistics for each alignment of each input genome against the reference. This indicates how good the alignment is. Pay particular attention to # unaligned sites, and heterogeneous positions. See also https://github.com/nickjcroucher/gubbins/blob/master/docs/gubbins_manual.md#output-statistics snippy_ncbi_datasets_docker String Docker file used for NCBI datasets snippy_ncbi_datasets_version String NCBI datasets version used snippy_ref File Reference genome (FASTA or GenBank file) used for generating phylogeny snippy_ref_metadata_json File Metadata associated with the refence genome used by Snippy, in JSON format snippy_referenceseeker_database String ReferenceSeeker database used snippy_referenceseeker_docker String Docker file used for ReferenceSeeker snippy_referenceseeker_top_hit_ncbi_accession String NCBI Accession for the top hit identified by referenceseeker snippy_referenceseeker_tsv File TSV file of the top hits between the query genome and the Reference Seeker database snippy_referenceseeker_version String ReferenceSeeker version used snippy_shared_variants_table File Table illustrating variants shared among samples snippy_snp_dists_docker String Docker file used for running SNP-dists snippy_snp_dists_version String SNP-dists version used snippy_snp_sites_docker String Docker file used for running SNP-sites snippy_snp_sites_version String SNP-sites version used snippy_streamline_analysis_date String Date of workflow run snippy_streamline_version String Version of Snippy_Streamline used snippy_summarized_data File CSV presence/absence matrix generated by the summarize_data task from the list of columns provided; formatted for Phandango if phandango_coloring input is true snippy_tree_snippy_docker String Docker file used for running Snippy snippy_tree_snippy_version String Snippy version used snippy_variants_outdir_tarball Array[File] A compressed file containing the whole directory of snippy output files. This is used when running Snippy_Tree snippy_variants_snippy_docker Array[String] Docker file used for Snippy in the Snippy_Variants subworkfow snippy_variants_snippy_version Array[String] Version of Snippy_Tree subworkflow used snippy_wg_snp_matrix File CSV file of whole genome pairwise SNP distances between samples, calculated from the final alignment"},{"location":"workflows/phylogenetic_construction/snippy_streamline_fasta/#references","title":"References","text":"<p>Gubbins: Croucher, Nicholas J., Andrew J. Page, Thomas R. Connor, Aidan J. Delaney, Jacqueline A. Keane, Stephen D. Bentley, Julian Parkhill, and Simon R. Harris. 2015. \"Rapid Phylogenetic Analysis of Large Samples of Recombinant Bacterial Whole Genome Sequences Using Gubbins.\" Nucleic Acids Research 43 (3): e15.</p> <p>SNP-sites: Page, Andrew J., Ben Taylor, Aidan J. Delaney, Jorge Soares, Torsten Seemann, Jacqueline A. Keane, and Simon R. Harris. 2016. \"SNP-Sites: Rapid Efficient Extraction of SNPs from Multi-FASTA Alignments.\" Microbial Genomics 2 (4): e000056.</p> <p>IQTree: Nguyen, Lam-Tung, Heiko A. Schmidt, Arndt von Haeseler, and Bui Quang Minh. 2015. \"IQ-TREE: A Fast and Effective Stochastic Algorithm for Estimating Maximum-Likelihood Phylogenies.\" Molecular Biology and Evolution 32 (1): 268\u201374.</p>"},{"location":"workflows/phylogenetic_construction/snippy_tree/","title":"Snippy_Tree","text":""},{"location":"workflows/phylogenetic_construction/snippy_tree/#snippy_tree","title":"Snippy_Tree","text":""},{"location":"workflows/phylogenetic_construction/snippy_tree/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Construction Bacteria v3.0.0 Some optional features incompatible, Yes Set-level Snippy_Tree_PHB"},{"location":"workflows/phylogenetic_construction/snippy_tree/#snippy_tree_phb","title":"Snippy_Tree_PHB","text":"<p><code>Snippy_Tree</code> is a workflow for generating high-quality bacterial phylogenies. It produces a phylogenetic tree and pairwise SNP-distance matrix, with the option to summarize additional metadata to visualize with the tree.</p> <p>The tree produced by Snippy_Tree will always be a maximum-likelihood phylogeny using a reference-based alignment. There are key options for whether to:</p> <ul> <li>Generate a core-genome or whole-genome phylogeny (<code>core_genome</code>)</li> <li>Mask specified regions of the genome with a bed file (e.g. known repetitive regions for TB) (<code>bed_file</code>)</li> <li>Mask recombination (<code>use_gubbins</code>)</li> <li>Decide which nucleotide substitution model to use</li> </ul>"},{"location":"workflows/phylogenetic_construction/snippy_tree/#inputs","title":"Inputs","text":"<p><code>Snippy_Tree</code> is intended to be run after the <code>Snippy_Variants</code> workflow. It is a set-level workflow that takes in an array of directories generated by the <code>Snippy_Variants</code> workflow, which must be run for each sample that you wish to include in the phylogenetic tree. You should ensure that for all samples included in the phylogeny, <code>Snippy_Variants</code> has been run with identical inputs including the same reference genome. When running the <code>Snippy_Tree</code> workflow, you will need to provide the same reference genome that you used when running <code>Snippy_Variants</code>. <code>Snippy_Variants</code> and <code>Snippy_Tree</code> can both automatically be run by using the <code>Snippy_Streamline</code> workflow.</p> <p>Sequencing data used in the Snippy_Tree workflow must:</p> <ul> <li>Be Illumina reads</li> <li>Be generated by unbiased whole genome shotgun sequencing</li> <li>Pass appropriate QC thresholds for the taxa to ensure that the reads represent reasonably complete genomes that are free of contamination from other taxa or cross-contamination of the same taxa.</li> <li>If masking recombination with <code>Gubbins</code>, input data should represent whole genomes from the same strain/lineage (e.g. MLST) that share a recent common ancestor.</li> </ul> <p>Guidance for optional inputs</p> <p>Several core and optional tasks can be used to generate the Snippy phylogenetic tree, making it highly flexible and suited to a wide range of datasets. You will need to decide which tasks to use depending on the genomes that you are analyzing. Some guidelines for the optional tasks to use for different genome types are provided below.</p> Default settings (suitable for most bacteria) <p>The default settings are as follows and are suitable for generating phylogenies for most bacteria</p> <ul> <li><code>core_genome</code> = true (creates core genome phylogeny)</li> <li><code>use_gubbins</code> = true (recombination masked)</li> <li>nucleotide substitution model will be defined by IQTree's Model Finder</li> </ul> Phylogenies of Mycobacterium tuberculosis complex <p>Phylogenies of MTBC are typically constructed</p> <ul> <li>Using the H37Rv reference genome<ul> <li><code>reference_genome_file</code> = <code>\"gs://theiagen-public-resources-rp/reference_data/bacterial/mycobacterium/MTB-NC_000962.3.fasta\"</code></li> </ul> </li> <li>Masking repetitive regions of the genome (e.g. PE/PPE genes) that are often misaligned<ul> <li><code>snippy_core_bed</code> = <code>\"gs://theiagen-public-resources-rp/reference_data/bacterial/mycobacterium/MTB-NC_000962.3.bed\"</code></li> </ul> </li> <li>Without masking recombination because TB can be considered non-recombinant<ul> <li><code>use_gubbins</code> = false</li> </ul> </li> <li>Using the core genome<ul> <li><code>core_genome</code> = true (as default)</li> </ul> </li> </ul> Terra Task Name Variable Type Description Default Value Terra Status snippy_tree_wf reference_genome_file File Reference genome in FASTA or GENBANK format (must be the same reference used in Snippy_Variants workflow) Required snippy_tree_wf samplenames Array[String] The names of the samples being analyzed Required snippy_tree_wf snippy_variants_outdir_tarball Array[File] Output from the Snippy_Variants workflow Required snippy_tree_wf tree_name String String of your choice to prefix output files Required cg_reorder_matrix cpu Int Number of CPUs to allocate to the task 1 Optional cg_reorder_matrix disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional cg_reorder_matrix docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Optional cg_reorder_matrix memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional cg_snp_dists cpu Int Number of CPUs to allocate to the task 1 Optional cg_snp_dists disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional cg_snp_dists memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional concatenate_qc_metrics cpu Int Number of CPUs to allocate to the task 2 Optional concatenate_qc_metrics disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional concatenate_qc_metrics docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional concatenate_qc_metrics memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional concatenate_variants docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional gubbins filter_percent Int Maximum % gaps to include a sample in gubbins analysis and downstream analyses 25 Optional gubbins iterations Int Maximum number of trees to iteratively build to remove recombination 5 Optional gubbins nuc_subst_model String Nucleotide substitution model to use with Gubbins: \"JC\", \"K2P\", \"HKY\", \"GTR\", \"GTRGAMMA\" or \"GTRCAT\" (see https://github.com/nickjcroucher/gubbins/blob/v3.3/docs/gubbins_manual.md#nucleotide-substitution-model-options) GTRGAMMA Optional gubbins tree_args String Quoted string of further arguments passed to tree building algorithm Optional gubbins tree_builder String Application to use for Gubbins tree building algorithm: \"raxml\", \"raxmlng\", \"iqtree\", \"iqtree-fast\", \"fasttree\", \"hybrid\" (fasttree\u00a0is used for the first tree, and\u00a0raxml\u00a0is used for later iterations), \"rapidnj\" raxml Optional iqtree2 alrt Int Number of replicates to use for the SH-like approximate likelihood ratio test (Minimum recommended= 1000). Follows IQ-TREE \"-alrt\" option 1000 Optional shared_variants cpu Int Number of CPUs to allocate to the task 1 Optional shared_variants disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional shared_variants docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional shared_variants memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional snippy_tree_wf call_shared_variants Boolean When true, workflow generates table that combines variants across all samples and a table showing variants shared across samples TRUE Optional snippy_tree_wf core_genome Boolean When true, workflow generates core genome phylogeny; when false, whole genome is used TRUE Optional snippy_tree_wf data_summary_column_names String A comma-separated list of the column names from the sample-level data table for generating a data summary (presence/absence .csv matrix) Optional snippy_tree_wf data_summary_terra_project String The billing project for your current workspace. This can be found after the \"#workspaces/\" section in the workspace's URL Optional snippy_tree_wf data_summary_terra_table String The name of the sample-level Terra data table that will be used for generating a data summary Optional snippy_tree_wf data_summary_terra_workspace String The name of the Terra workspace you are in. This can be found at the top of the webpage, or in the URL after the billing project. Optional snippy_tree_wf gubbins_cpu Int Number of CPUs to allocate to the task 4 Optional snippy_tree_wf gubbins_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional snippy_tree_wf gubbins_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/biocontainers/gubbins:3.3--py310pl5321h8472f5a_0 Optional snippy_tree_wf gubbins_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional snippy_tree_wf iqtree2_bootstraps Int Number of replicates for http://www.iqtree.org/doc/Tutorial#assessing-branch-supports-with-ultrafast-bootstrap-approximation (Minimum recommended= 1000) 1000 Optional snippy_tree_wf iqtree2_cpu Int Number of CPUs to allocate to the task 4 Optional snippy_tree_wf iqtree2_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional snippy_tree_wf iqtree2_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/iqtree2:2.1.2 Optional snippy_tree_wf iqtree2_memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional snippy_tree_wf iqtree2_model String Nucelotide substitution model to use when generating the final tree with IQTree2. By default, IQtree runs its ModelFinder algorithm to identify the model it thinks best fits your dataset Optional snippy_tree_wf iqtree2_opts String Additional options to pass to IQTree2 Optional snippy_tree_wf midpoint_root_tree Boolean A True/False option that determines whether the tree used in the SNP matrix re-ordering task should be re-rooted or not. Options: true or false TRUE Optional snippy_tree_wf phandango_coloring Boolean Boolean variable that tells the data summary task and the reorder matrix task to include a suffix that enables consistent coloring on Phandango; by default, this suffix is not added. To add this suffix set this variable to true. FALSE Optional snippy_tree_wf snippy_core_bed File User-provided bed file to mask out regions of the genome when creating multiple sequence alignments Optional snippy_tree_wf snippy_core_cpu Int Number of CPUs to allocate to the task 8 Optional snippy_tree_wf snippy_core_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional snippy_tree_wf snippy_core_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snippy:4.6.0 Optional snippy_tree_wf snippy_core_memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional snippy_tree_wf snippy_variants_qc_metrics Array[File] Files produced by the Snippy_Variants workflow used to concatenate the reports for each sample in the tree Optional snippy_tree_wf snp_dists_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snp-dists:0.8.2 Optional snippy_tree_wf snp_sites_cpu Int Number of CPUs to allocate to the task 1 Optional snippy_tree_wf snp_sites_disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional snippy_tree_wf snp_sites_docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snp-sites:2.5.1 Optional snippy_tree_wf snp_sites_memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional snippy_tree_wf use_gubbins Boolean When \"true\", workflow removes recombination with gubbins tasks; when \"false\", gubbins is not used TRUE Optional summarize_data cpu Int Number of CPUs to allocate to the task 8 Optional summarize_data disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional summarize_data docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional summarize_data id_column_name String If the sample IDs are in a different column to samplenames, it can be passed here and it will be used instead. Optional summarize_data memory Int Amount of memory/RAM (in GB) to allocate to the task 1 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional wg_reorder_matrix cpu Int Number of CPUs to allocate to the task 1 Optional wg_reorder_matrix disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional wg_reorder_matrix docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/mykrobe:0.12.1 Optional wg_reorder_matrix memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional wg_snp_dists cpu Int Number of CPUs to allocate to the task 1 Optional wg_snp_dists disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional wg_snp_dists memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional"},{"location":"workflows/phylogenetic_construction/snippy_tree/#workflow-tasks","title":"Workflow Tasks","text":"Snippy Gubbins (optional) SNP-sites (optional) IQTree2 SNP-dists Data summary (optional) Concatenate Variants (optional) Shared Variants (optional) Snippy_Variants QC Metrics Concatenation (optional)"},{"location":"workflows/phylogenetic_construction/snippy_tree/#snippy","title":"Snippy","text":"<p>Snippy is a pipeline for calling SNPs and INDELs in haploid genomes. Before running <code>Snippy_Tree</code>, you must run <code>Snippy_Variants</code>, another workflow that uses the Snippy tool to align reads against a reference genome for individual samples. In <code>Snippy_Tree</code>, the snippy tool is used again to generate a whole-genome multiple sequence alignment (fasta file) of reads from all the samples we'd like in our tree. </p> <p>When generating the multiple sequence alignment, a bed file can be provided by users to mask certain areas of the genome in the alignment. This is particularly relevant for masking known repetitive regions in Mycobacterium tuberculosis  genomes, or masking known regions containing phage sequences.</p> <p>Why do I see <code>snippy_core</code> in Terra?</p> <p>In Terra, this task is named \"snippy_core\" after the name of the command in the original Snippy tool. Despite the name, this command is NOT being used to make a core genome, but instead a multiple sequence alignment of the whole genome (without any sections masked using a bed file).</p> <p>Snippy Technical Details</p> Links Task task_snippy_core.wdl Software Source Code Snippy on GitHub Software Documentation Snippy on GitHub"},{"location":"workflows/phylogenetic_construction/snippy_tree/#gubbins-optional","title":"Gubbins (optional)","text":"<p>Turn on Gubbins with <code>use_gubbins</code></p> <p>Gubbins runs when the <code>use_gubbins</code> option is set to <code>true</code> (default=true).</p> <p>Genealogies Unbiased By recomBinations In Nucleotide Sequences (Gubbins) identifies and masks genomic regions that are predicted to have arisen via recombination. It works by iteratively identifying loci containing elevated densities of SNPs and constructing phylogenies based on the putative single nucleotide variants outside these regions (for more details, see here). By default, these phylogenies are constructed using RaxML and a GTR-GAMMA nucleotide substitution model, which will be the most suitable model for most bacterial phylogenetics, though this can be modified with the <code>tree_builder</code> and <code>nuc_subst_model</code> inputs.</p> <p>Gubbins is the industry standard for masking recombination from bacterial genomes when building phylogenies, but limitations to recombination removal exist. Gubbins cannot distinguish recombination from high densities of SNPs that may result from assembly or alignment errors, mutational hotspots, or regions of the genome with relaxed selection. The tool is also intended only to find recombinant regions that are short relative to the length of the genome, so large regions of recombination may not be masked. These factors should be considered when interpreting resulting phylogenetic trees, but overwhelmingly Gubbins improves our ability to understand ancestral relationships between bacterial genomes.</p> <p>There are few optional inputs for Gubbins that can be modified by the user:</p> <ul> <li><code>iterations</code>: Gubbins works by iteratively identifying loci containing elevated densities of SNPs, while constructing phylogenies based on the putative single nucleotide variants outside these regions. It may take many iterations for Gubbins to converge on an alignment that it considers free of recombination, especially for phylogenies that contain large numbers of genomes. By default, Gubbins is limited to 5 iterations though this may be increased by the user with the <code>iterations</code>optional input (incurring increased computing time and cost, and possibly requiring increased memory allocation).</li> <li><code>nuc_subst_model</code>, <code>tree_builder</code> and <code>tree_args</code>:  When Gubbins constructs phylogenies, it can use a number of phylogenetic inference tools, each with different nucleotide substitution models and tree-building models. By default, the <code>Snippy_Tree</code> workflow uses a GTRGAMMA substitution model and RaxML for tree building (typically suitable for bacterial genomes), but these can be modified by the user depending on the genome sequences being used with the <code>nuc_subst_model</code> and <code>tree_builder</code> optional inputs, respectively. The nucleotide substitution models that are available depend on the tree building algorithm being used (see here). Additional options for generating the phylogenetic trees in Gubbins can be specified with the <code>tree_args</code> optional input, providing an input string that is consistent with the option formats of the Gubbins command.</li> <li><code>filter_percent</code>: By default, Gubbins removes genomes from the multiple sequence alignment if  more than 25 % of the genome is represented by gaps. The percentage of gaps can be modified by the user using the <code>filter_percent</code> optional input.</li> </ul> <p>Gubbins Technical Details</p> Links Task task_gubbins.wdl Software Source Code Gubbins on GitHub Software Documentation Gubbins v3.3 manual Original Publication(s) Rapid phylogenetic analysis of large samples of recombinant bacterial whole genome sequences using Gubbins"},{"location":"workflows/phylogenetic_construction/snippy_tree/#snp-sites-optional","title":"SNP-sites (optional)","text":"<p>Turn on SNP-Sites with <code>core_genome</code></p> <p>SNP-sites runs when the <code>core_genome</code> option is set to true.</p> <p>SNP-sites is used to filter out invariant sites in the whole-genome alignment, thereby creating a core genome alignment for phylogenetic inference. The output is a fasta file containing the core genome of each sample only. If Gubbins has been used, this output fasta will not contain any sites that are predicted to have arisen via recombination.</p> <p>SNP-sites technical details</p> Links Task task_snp_sites.wdl Software Source Code SNP-sites on GitHub Software Documentation SNP-sites on GitHub Original Publication(s) SNP-sites: rapid efficient extraction of SNPs from multi-FASTA alignments"},{"location":"workflows/phylogenetic_construction/snippy_tree/#iqtree2","title":"IQTree2","text":"<p>IQTree2 is used to build the final phylogeny. It uses the alignment generated in the previous steps of the workflow. The contents of this alignment will depend on whether any sites were masked with recombination.</p> <p>The phylogeny is generated using the maximum-likelihood method and a specified nucleotide substitution model. By default, the Snippy_Tree workflow will run Model Finder to determine the most appropriate nucleotide substitution model for your data, but you may specify the nucleotide substitution model yourself using the <code>iqtree2_model</code> optional input (see here for available models).</p> <p>IQTree will perform assessments of the tree using the Shimodaira\u2013Hasegawa approximate likelihood-ratio test (SH-aLRT test), and ultrafast bootstrapping with UFBoot2, a quicker but less biased alternative to standard bootstrapping. A clade should not typically be trusted if it has less than 80% support from the SH-aLRT test and less than 95% support with ultrafast bootstrapping.</p> <p>Nucleotide substitution model</p> <p>When <code>core_genome</code>= <code>true</code>, the default nucleotide substitution model is set to the General Time Reverside model with Gamma distribution (GTR+G). </p> <p>When the user sets <code>core_genome</code>= <code>false</code>, the default nucleotide substitution model is set to the General Time Reversible model with invariant sites and Gamma distribution (<code>GTR+I+G</code>).</p> <p>IQTree2 technical details</p> Links Task task_iqtree2.wdl Software Source Code IQ-TREE on GitHub Software Documentation IQTree documentation for the latest version (not necessarily the version used in this workflow) Original Publication(s) IQ-TREE 2: New Models and Efficient Methods for Phylogenetic Inference in the Genomic EraNew Algorithms and Methods to Estimate Maximum-Likelihood Phylogenies: Assessing the Performance of PhyML 3.0Ultrafast Approximation for Phylogenetic Bootstrap UFBoot2: Improving the Ultrafast Bootstrap ApproximationModelFinder: fast model selection for accurate phylogenetic estimates"},{"location":"workflows/phylogenetic_construction/snippy_tree/#snp-dists","title":"SNP-dists","text":"<p><code>SNP-dists</code> computes pairwise SNP distances between genomes. It takes the same alignment of genomes used to generate your phylogenetic tree and produces a matrix of pairwise SNP distances between sequences. This means that if you generated pairwise core-genome phylogeny, the output will consist of pairwise core-genome SNP (cgSNP) distances. Otherwise, these will be whole-genome SNP distances. Regardless of whether core-genome or whole-genome SNPs, this SNP distance matrix will exclude all SNPs in masked regions (i.e. masked with a bed file or gubbins). </p> <p>The SNP-distance output can be visualized using software such as Phandango to explore the relationships between the genomic sequences. The task can optionally add a Phandango coloring tag (:c1) to the column names in the output matrix to ensure that all columns are colored with the same color scheme throughout by setting <code>phandango_coloring</code> to <code>true</code>.</p> <p>SNP-dists Technical Details</p> Links Task task_snp_dists.wdl Software Source Code SNP-dists on GitHub Software Documentation SNP-dists on GitHub"},{"location":"workflows/phylogenetic_construction/snippy_tree/#data-summary-optional","title":"Data Summary (optional)","text":"<p>Command-line incompatible</p> <p>This task is not compatible with command-line use, even with modifications. It is engineered to run on Terra. To run this workflow on the command line, you must leave the <code>data_summary_*</code> and <code>sample_names</code> optional variables blank to prevent this task from running.</p> <p>If you fill out the <code>data_summary_*</code> and <code>sample_names</code> optional variables, you can use the optional <code>summarize_data</code> task. The task takes a comma-separated list of column names from the Terra data table, which should each contain a list of comma-separated items. For example, <code>\"amrfinderplus_virulence_genes,amrfinderplus_stress_genes\"</code> (with quotes, comma separated, no spaces) for these output columns from running TheiaProk. The task checks whether those comma-separated items are present in each row of the data table (sample), then creates a CSV file of these results. The CSV file indicates presence (TRUE) or absence (empty) for each item. By default, the task does not add a Phandango coloring tag to group items from the same column, but you can turn this on by setting <code>phandango_coloring</code> to <code>true</code>.</p> Example output CSV <pre><code>Sample_Name,aph(3')-IIa,blaCTX-M-65,blaOXA-193,tet(O)\nsample1,TRUE,,TRUE,TRUE\nsample2,,,FALSE,TRUE\nsample3,,,FALSE,\n</code></pre> Example use of Phandango coloring <p>Data summary produced using the <code>phandango_coloring</code> option, visualized alongside Newick tree at http://jameshadfield.github.io/phandango/#/main</p> <p>Example phandango_coloring output</p> <p></p> <p>Data summary technical details</p> Links Task task_summarize_data.wdl"},{"location":"workflows/phylogenetic_construction/snippy_tree/#concatenate-variants-optional","title":"Concatenate Variants (optional)","text":"<p>This task activates when <code>call_shared_variants</code> is true. The <code>cat_variants</code> task concatenates variant data from multiple samples into a single file <code>concatenated_variants</code>. It is very similar to the <code>cat_files</code> task, but also adds a column to the output file that indicates the sample associated with each row of data.</p> <p>The <code>concatenated_variants</code> file will be in the following format:</p> samplename CHROM POS TYPE REF ALT EVIDENCE FTYPE STRAND NT_POS AA_POS EFFECT LOCUS_TAG GENE PRODUCT sample1 PEKT02000007 5224 snp C G G:21 C:0 sample2 PEKT02000007 34112 snp C G G:32 C:0 CDS + 153/1620 51/539 missense_variant c.153C&gt;G p.His51Gln B9J08_002604 hypothetical protein sample3 PEKT02000007 34487 snp T A A:41 T:0 CDS + 528/1620 176/539 missense_variant c.528T&gt;A p.Asn176Lys B9J08_002604 hypothetical protein <p>Technical Details</p> Links Task task_cat_files.wdl"},{"location":"workflows/phylogenetic_construction/snippy_tree/#shared-variants-optional","title":"Shared Variants (optional)","text":"<p>This task activates when <code>call_shared_variants</code> is true.</p> <p>The <code>shared_variants</code> task takes in the <code>concatenated_variants</code> output from the <code>cat_variants</code> task and reshapes the data so that variants are rows and samples are columns. For each variant, samples where the variant was detected are populated with a \"1\" and samples were either the variant was not detected or there was insufficient coverage to call variants are populated with a \"0\". The resulting table is available as the <code>shared_variants_table</code> output.</p> <p>The <code>shared_variants_table</code> file will be in the following format:</p> CHROM POS TYPE REF ALT FTYPE STRAND NT_POS AA_POS EFFECT LOCUS_TAG GENE PRODUCT sample1 sample2 sample3 PEKT02000007 2693938 snp T C CDS - 1008/3000 336/999 synonymous_variant c.1008A&gt;G p.Lys336Lys B9J08_003879 NA chitin synthase 1 1 1 0 PEKT02000007 2529234 snp G C CDS + 282/336 94/111 missense_variant c.282G&gt;C p.Lys94Asn B9J08_003804 NA cytochrome c 1 1 1 PEKT02000002 1043926 snp A G CDS - 542/1464 181/487 missense_variant c.542T&gt;C p.Ile181Thr B9J08_000976 NA dihydrolipoyl dehydrogenase 1 1 0 <p>Technical Details</p> Links Task task_shared_variants.wdl"},{"location":"workflows/phylogenetic_construction/snippy_tree/#snippy_variants-qc-metric-concatenation-optional","title":"Snippy_Variants QC Metric Concatenation (optional)","text":"<p>Optionally, the user can provide the <code>snippy_variants_qc_metrics</code> file produced by the Snippy_Variants workflow as input to the workflow to concatenate the reports for each sample in the tree. These per-sample QC metrics include the following columns:</p> <ul> <li>samplename: The name of the sample.</li> <li>reads_aligned_to_reference: The number of reads that aligned to the reference genome.</li> <li>total_reads: The total number of reads in the sample.</li> <li>percent_reads_aligned: The percentage of reads that aligned to the reference genome.</li> <li>variants_total: The total number of variants detected between the sample and the reference genome.</li> <li>percent_ref_coverage: The percentage of the reference genome covered by reads with a depth greater than or equal to the <code>min_coverage</code> threshold (default is 10).</li> <li>#rname: Reference sequence name (e.g., chromosome or contig name).</li> <li>startpos: Starting position of the reference sequence.</li> <li>endpos: Ending position of the reference sequence.</li> <li>numreads: Number of reads covering the reference sequence.</li> <li>covbases: Number of bases with coverage.</li> <li>coverage: Percentage of the reference sequence covered (depth \u2265 1).</li> <li>meandepth: Mean depth of coverage over the reference sequence.</li> <li>meanbaseq: Mean base quality over the reference sequence.</li> <li>meanmapq: Mean mapping quality over the reference sequence.</li> </ul> <p>The combined QC metrics file includes the same columns as above for all samples. Note that the last set of columns (<code>#rname</code> to <code>meanmapq</code>) may repeat for each chromosome or contig in the reference genome.</p> <p>QC Metrics for Phylogenetic Analysis</p> <p>These QC metrics provide valuable insights into the quality and coverage of your sequencing data relative to the reference genome. Monitoring these metrics can help identify samples with low coverage, poor alignment, or potential issues that may affect downstream analyses, and we recommend examining them before proceeding with phylogenetic analysis if performing Snippy_Variants and Snippy_Tree separately.</p> <p>Technical Details</p> Links Task task_cat_files.wdl"},{"location":"workflows/phylogenetic_construction/snippy_tree/#outputs","title":"Outputs","text":"Variable Type Description snippy_cg_snp_matrix File CSV file of core genome pairwise SNP distances between samples, calculated from the final alignment snippy_combined_qc_metrics File Combined QC metrics file containing concatenated QC metrics from all samples. snippy_concatenated_variants File Concatenated snippy_results file across all samples in the set snippy_filtered_metadata File TSV recording the columns of the Terra data table that were used in the summarize_data task snippy_final_alignment File Final alignment (FASTA file) used to generate the tree (either after snippy alignment, gubbins recombination removal, and/or core site selection with SNP-sites) snippy_final_tree File Newick tree produced from the final alignment. Depending on user input for core_genome, the tree could be a core genome tree (default when core_genome is true) or whole genome tree (if core_genome is false) snippy_gubbins_branch_stats File CSV file showing https://github.com/nickjcroucher/gubbins/blob/master/docs/gubbins_manual.md#output-statistics for each branch of the tree snippy_gubbins_docker String Docker file used for running Gubbins snippy_gubbins_recombination_gff File Recombination statistics in GFF format; these can be viewed in Phandango against the phylogenetic tree snippy_gubbins_version String Gubbins version used snippy_iqtree2_docker String Docker file used for running IQTree2 snippy_iqtree2_model_used String Nucleotide substitution model used by IQTree2 snippy_iqtree2_version String IQTree2 version used snippy_msa_snps_summary File TXT file containing summary statistics for each alignment of each input genome against the reference. This indicates how good the alignment is. Pay particular attention to # unaligned sites, and heterogeneous positions. See also https://github.com/nickjcroucher/gubbins/blob/master/docs/gubbins_manual.md#output-statistics snippy_ref File Reference genome (FASTA or GenBank file) used for generating phylogeny snippy_shared_variants_table File Table illustrating variants shared among samples snippy_snp_dists_docker String Docker file used for running SNP-dists snippy_snp_dists_version String SNP-dists version used snippy_snp_sites_docker String Docker file used for running SNP-sites snippy_snp_sites_version String SNP-sites version used snippy_summarized_data File CSV presence/absence matrix generated by the summarize_data task from the list of columns provided; formatted for Phandango if phandango_coloring input is true snippy_tree_analysis_date String Date of workflow run snippy_tree_snippy_docker String Docker file used for running Snippy snippy_tree_snippy_version String Snippy version used snippy_tree_version String Version of Snippy_Tree workflow snippy_wg_snp_matrix File CSV file of whole genome pairwise SNP distances between samples, calculated from the final alignment"},{"location":"workflows/phylogenetic_construction/snippy_tree/#references","title":"References","text":"<p>Gubbins: Croucher, Nicholas J., Andrew J. Page, Thomas R. Connor, Aidan J. Delaney, Jacqueline A. Keane, Stephen D. Bentley, Julian Parkhill, and Simon R. Harris. 2015. \"Rapid Phylogenetic Analysis of Large Samples of Recombinant Bacterial Whole Genome Sequences Using Gubbins.\" Nucleic Acids Research 43 (3): e15.</p> <p>SNP-sites: Page, Andrew J., Ben Taylor, Aidan J. Delaney, Jorge Soares, Torsten Seemann, Jacqueline A. Keane, and Simon R. Harris. 2016. \"SNP-Sites: Rapid Efficient Extraction of SNPs from Multi-FASTA Alignments.\" Microbial Genomics 2 (4): e000056.</p> <p>IQTree: Nguyen, Lam-Tung, Heiko A. Schmidt, Arndt von Haeseler, and Bui Quang Minh. 2015. \"IQ-TREE: A Fast and Effective Stochastic Algorithm for Estimating Maximum-Likelihood Phylogenies.\" Molecular Biology and Evolution 32 (1): 268\u201374.</p>"},{"location":"workflows/phylogenetic_construction/snippy_variants/","title":"Snippy_Variants","text":""},{"location":"workflows/phylogenetic_construction/snippy_variants/#snippy_variants","title":"Snippy_Variants","text":""},{"location":"workflows/phylogenetic_construction/snippy_variants/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Construction Bacteria, Mycotics, Viral v2.3.0 Yes Sample-level Snippy_Variants_PHB"},{"location":"workflows/phylogenetic_construction/snippy_variants/#snippy_variants_phb","title":"Snippy_Variants_PHB","text":"<p>The <code>Snippy_Variants</code> workflow aligns single-end or paired-end reads (in FASTQ format), or assembled sequences (in FASTA format), against a reference genome, then identifies single-nucleotide polymorphisms (SNPs), multi-nucleotide polymorphisms (MNPs), and insertions/deletions (INDELs) across the alignment. If a GenBank file is used as the reference, mutations associated with user-specified query strings (e.g. genes of interest) can additionally be reported to the Terra data table.</p> <p>Snippy_Variants Workflow Diagram</p> <p></p> <p>Example Use Cases</p> <ul> <li>Finding mutations (SNPs, MNPs, and INDELs) in your own sample's reads relative to a reference, e.g. mutations in genes of phenotypic interest.</li> <li>Quality control: When undertaking quality control of sequenced isolates, it is difficult to identify contamination between multiple closely related genomes using the conventional approaches in TheiaProk (e.g. isolates from an outbreak or transmission cluster). Such contamination may be identified as allele heterogeneity at a significant number of genome positions. <code>Snippy_Variants</code> may be used to identify these heterogeneous positions by aligning reads to the assembly of the same reads, or to a closely related reference genome and lowering the thresholds to call SNPs.</li> <li>Assessing support for a mutation: <code>Snippy_Variants</code> produces a BAM file of the reads aligned to the reference genome. This BAM file can be visualized in IGV (see Theiagen Office Hours recordings) to assess the position of a mutation in supporting reads, or if the assembly of the reads was used as a reference, the position in the contig.<ul> <li>Mutations that are only found at the ends of supporting reads may be an error of sequencing.</li> <li>Mutations found at the end of contigs may be assembly errors.</li> </ul> </li> </ul>"},{"location":"workflows/phylogenetic_construction/snippy_variants/#inputs","title":"Inputs","text":"<ul> <li>Single or paired-end reads resulting from Illumina or IonTorrent sequencing can be used. For single-end data, simply omit a value for <code>read2</code></li> <li>Assembled genomes can be used. Use the <code>assembly_fasta</code> input and omit <code>read1</code> and <code>read2</code></li> <li>The reference file should be in fasta (e.g. <code>.fa</code>, <code>.fasta</code>) or full GenBank (<code>.gbk</code>) format. The mutations identified by Snippy_Variants are highly dependent on the choice of reference genome. Mutations cannot be identified in genomic regions that are present in your query sequence and not the reference.</li> </ul> <p>Query String</p> <p>The query string can be a gene or any other annotation that matches the GenBank file/output VCF EXACTLY</p> Terra Task Name Variable Type Description Default Value Terra Status snippy_variants_wf reference_genome_file File Reference genome (GenBank file or fasta) Required snippy_variants_wf samplename String The name of the sample being analyzed Required snippy_gene_query cpu Int Number of CPUs to allocate to the task 8 Optional snippy_gene_query disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional snippy_gene_query docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Optional snippy_gene_query memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional snippy_variants disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional snippy_variants_wf assembly_fasta File The assembly file for your sample in FASTA format Optional snippy_variants_wf base_quality Int Minimum quality for a nucleotide to be used in variant calling 13 Optional snippy_variants_wf cpu Int Number of CPUs to allocate to the task 4 Optional snippy_variants_wf docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/snippy:4.6.0 Optional snippy_variants_wf map_qual Int Minimum mapping quality to accept in variant calling 60 Optional snippy_variants_wf maxsoft Int Number of bases of alignment to soft-clip before discarding the alignment 10 Optional snippy_variants_wf memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional snippy_variants_wf min_coverage Int Minimum read coverage of a position to identify a mutation 10 Optional snippy_variants_wf min_frac Float Minimum fraction of bases at a given position to identify a mutation 0 Optional snippy_variants_wf min_quality Int Minimum VCF variant call \"quality\" 100 Optional snippy_variants_wf query_gene String Comma-separated strings (e.g. gene names) in which to search for mutations to output to data table Optional snippy_variants_wf read1 File FASTQ file containing read1 sequences Optional snippy_variants_wf read2 File FASTQ file containing read2 sequences Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/phylogenetic_construction/snippy_variants/#workflow-tasks","title":"Workflow Tasks","text":"Snippy_Variants"},{"location":"workflows/phylogenetic_construction/snippy_variants/#snippy_variants_1","title":"Snippy_Variants","text":"<p><code>Snippy_Variants</code> uses Snippy to align reads to the reference and call SNPs, MNPs and INDELs according to optional input parameters.</p> <p>Optionally, if the user provides a value for <code>query_gene</code>, the variant file will be searched for any mutations in the specified regions or annotations. The query string MUST match the gene name or annotation as specified in the GenBank file and provided in the output variant file in the <code>snippy_results</code> column.</p> QC Metrics from Snippy_Variants <p>This task also extracts QC metrics from the Snippy output for each sample and saves them in per-sample TSV files (<code>snippy_variants_qc_metrics</code>). These per-sample QC metrics include the following columns:</p> <ul> <li>samplename: The name of the sample.</li> <li>reads_aligned_to_reference: The number of reads that aligned to the reference genome.</li> <li>total_reads: The total number of reads in the sample.</li> <li>percent_reads_aligned: The percentage of reads that aligned to the reference genome.</li> <li>variants_total: The total number of variants detected between the sample and the reference genome.</li> <li>percent_ref_coverage: The percentage of the reference genome covered by reads with a depth greater than or equal to the <code>min_coverage</code> threshold (default is 10).</li> <li>#rname: Reference sequence name (e.g., chromosome or contig name).</li> <li>startpos: Starting position of the reference sequence.</li> <li>endpos: Ending position of the reference sequence.</li> <li>numreads: Number of reads covering the reference sequence.</li> <li>covbases: Number of bases with coverage.</li> <li>coverage: Percentage of the reference sequence covered (depth \u2265 1).</li> <li>meandepth: Mean depth of coverage over the reference sequence.</li> <li>meanbaseq: Mean base quality over the reference sequence.</li> <li>meanmapq: Mean mapping quality over the reference sequence.</li> </ul> <p>Note that the last set of columns (<code>#rname</code> to <code>meanmapq</code>) may repeat for each chromosome or contig in the reference genome.</p> <p>QC Metrics for Phylogenetic Analysis</p> <p>These QC metrics provide valuable insights into the quality and coverage of your sequencing data relative to the reference genome. Monitoring these metrics can help identify samples with low coverage, poor alignment, or potential issues that may affect downstream analyses, and we recommend examining them before proceeding with phylogenetic analysis if performing Snippy_Variants and Snippy_Tree separately.</p> <p>These per-sample QC metrics can also be combined into a single file (<code>snippy_combined_qc_metrics</code>) in downstream workflows, such as <code>snippy_tree</code>, providing an overview of QC metrics across all samples.</p> <p>Snippy Variants Technical Details</p> Links Task task_snippy_variants.wdltask_snippy_gene_query.wdl Software Source Code Snippy on GitHub Software Documentation Snippy on GitHub"},{"location":"workflows/phylogenetic_construction/snippy_variants/#outputs","title":"Outputs","text":"<p>Visualize your outputs in IGV</p> <p>Output bam/bai files may be visualized using IGV to manually assess read placement and SNP support.</p> <p>Note on coverage calculations</p> <p>The outputs from <code>samtools coverage</code> (found in the <code>snippy_variants_coverage_tsv</code> file) may differ from the <code>snippy_variants_percent_ref_coverage</code> due to different calculation methods. <code>samtools coverage</code> computes genome-wide coverage metrics (e.g., the proportion of bases covered at depth \u2265 1), while <code>snippy_variants_percent_ref_coverage</code> uses a user-defined minimum coverage threshold (default is 10), calculating the proportion of the reference genome with a depth greater than or equal to this threshold.</p> Variable Type Description snippy_variants_bai File Indexed bam file of the reads aligned to the reference snippy_variants_bam File Bam file of reads aligned to the reference snippy_variants_coverage_tsv File Coverage statistics TSV file output by the <code>samtools coverage</code> command, providing genome-wide metrics such as the proportion of bases covered (depth \u2265 1), mean depth, and other related statistics. snippy_variants_docker String Docker image for snippy variants task snippy_variants_gene_query_results File CSV file detailing results for mutations associated with the query strings specified by the user snippy_variants_hits String A summary of mutations associated with the query strings specified by the user snippy_variants_num_reads_aligned Int Number of reads that aligned to the reference genome as calculated by samtools view -c command snippy_variants_num_variants Int Number of variants detected between sample and reference genome snippy_variants_outdir_tarball File A compressed file containing the whole directory of snippy output files. This is used when running Snippy_Tree snippy_variants_percent_reads_aligned Float Percentage of reads aligned to the reference genome snippy_variants_percent_ref_coverage Float Proportion of the reference genome covered by reads with a depth greater than or equal to the <code>min_coverage</code> threshold (default is 10). snippy_variants_qc_metrics File TSV file containing quality control metrics for the sample snippy_variants_query String Query strings specified by the user when running the workflow snippy_variants_query_check String Verification that query strings are found in the reference genome snippy_variants_results File CSV file detailing results for all mutations identified in the query sequence relative to the reference snippy_variants_summary File A summary TXT fie showing the number of mutations identified for each mutation type snippy_variants_version String Version of Snippy used snippy_variants_wf_version String Version of Snippy_Variants used"},{"location":"workflows/phylogenetic_placement/nextclade_batch/","title":"Nextclade_Batch","text":""},{"location":"workflows/phylogenetic_placement/nextclade_batch/#nextclade_batch","title":"Nextclade_Batch","text":""},{"location":"workflows/phylogenetic_placement/nextclade_batch/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Placement Monkeypox virus, SARS-CoV-2, Viral vX.X.X Yes Set-level Nextclade_Batch_PHB"},{"location":"workflows/phylogenetic_placement/nextclade_batch/#nextclade_batch_phb","title":"Nextclade_Batch_PHB","text":"<p>Nextclade Batch rapidly calls mutations, places samples on a reference phylogenetic tree, and rapidly genotypes batches of samples using Nextclade. Phylogenetic placement is done by comparing the mutations of the query sequence (relative to the reference) with the mutations of every node and tip in the reference tree, and finding the node which has the most similar set of mutations. This operation is repeated for each query sequence, until all of them are placed onto the tree. This workflow uses the Nextstrain-maintained nextclade datasets for manually inputted datasets or downloaded datasets (e.g. SARS-CoV-2, mpox, influenza A and B, HIV, and RSV-A and RSV-B).</p> <p>Contact us if you need help generating your own mutation-annotated tree, or follow the instructions available on the Augur wiki here.</p> <p>Placement not construction</p> <p>This workflow is not for building a tree from scratch, but rather for genotyping and placement of new sequences onto an existing high-quality input reference tree with representative samples on it. In effect, query samples are only compared to reference samples and never to the other query samples.</p>"},{"location":"workflows/phylogenetic_placement/nextclade_batch/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status nextclade_batch assembly_fastas Array[File] The assembly files for your samples in FASTA format Required nextclade_batch dataset_name String What nextclade dataset name to run nextclade on; some options are: \"sars-cov-2\", \"flu_h1n1pdm_ha\", \"flu_h1n1pdm_na\", \"flu_h3n2_ha\", \"flu_h3n2_na\", \"flu_vic_ha\", \"flu_vic_na\", \"flu_yam_ha\", \"hMPXV\", \"hMPXV_B1\", \"MPXV\", \"rsv_a\" and \"rsv_b\" Required nextclade_batch dataset_tag String nextclade dataset tag Uses the dataset tag associated with the nextclade docker image version Optional nextclade_batch gene_annotations_gff File A genome annotations file for codon-aware alignment, gene translation and calling of amino acid mutations Uses the genome annotation associated with the nextclade dataset name Optional nextclade_batch input_ref File An optional FASTA file containing reference sequence. This file should contain exactly 1 sequence Uses the reference fasta associated with the specified nextclade dataset name Optional nextclade_batch pathogen_json File An optional pathogen JSON file containing configuration and data specific to a pathogen Uses the reference pathogen JSON file associated with the specified nextclade dataset name Optional nextclade_batch reference_tree_json File An optional phylogenetic reference tree file which serves as a target for phylogenetic placement Uses the reference tree associated with the specified nextclade dataset name Optional nextclade_v3_set cpu Int Number of CPUs to allocate to the task 2 Optional nextclade_v3_set disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional nextclade_v3_set docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/nextstrain/nextclade:3.14.5 Optional nextclade_v3_set memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional nextclade_v3_set verbosity String Set the nextclade output verbosity level. Options: off, error, warn, info, debug, trace warn Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/phylogenetic_placement/nextclade_batch/#outputs","title":"Outputs","text":"Variable Type Description nextclade_batch_analysis_date String Date of analysis nextclade_batch_auspice_json File Phylogenetic tree with user placed samples nextclade_batch_nextclade_docker String Nextclade docker image used nextclade_batch_nextclade_json File JSON file with the results of the Nextclade analysis nextclade_batch_nextclade_tsv File Tab-delimited file with Nextclade results nextclade_batch_nextclade_version String Nextclade version used nextclade_batch_version String Version of the Public Health Bioinformatics (PHB) repository used"},{"location":"workflows/phylogenetic_placement/usher/","title":"Usher","text":""},{"location":"workflows/phylogenetic_placement/usher/#usher","title":"Usher","text":""},{"location":"workflows/phylogenetic_placement/usher/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Phylogenetic Placement Monkeypox virus, SARS-CoV-2, Viral v2.1.0 Yes Sample-level, Set-level Usher_PHB"},{"location":"workflows/phylogenetic_placement/usher/#usher_phb","title":"Usher_PHB","text":"<p>UShER (Ultrafast Sample Placement on Existing Trees) rapidly places new samples onto an existing phylogeny using maximum parsimony. This workflow uses the UCSC-maintained global trees for SARS-CoV-2, mpox, RSV-A, and RSV-B if those organisms are specified in the <code>organism</code> input field. However, UShER can be used on any organism as long as a mutation-annotated tree (MAT) is provided in protobuf format. Contact us if you need help generating your own mutation-annotated tree, or follow the instructions available on the UShER wiki here.</p>"},{"location":"workflows/phylogenetic_placement/usher/#inputs","title":"Inputs","text":"<p>While this workflow is technically a set-level workflow, it works on the sample-level too. When run on the set-level, the samples are placed with respect to each other.</p> Terra Task Name Variable Type Description Default Value Terra Status usher_workflow assembly_fasta Array[File] The assembly files for your samples in FASTA format; can either be a set of samples, an individual sample, or multiple individual samples Required usher_workflow organism String What organism to run UShER on; the following organism have default global phylogenies and reference files provided: sars-cov-2, mpox, RSV-A, RSV-B. Required usher_workflow tree_name String The output prefix for the uncondensed tree output and the clades output. Required usher mutation_annotated_tree_pb File Required for organisms other than sars-cov-2, mpox, RSV-A or RSV-B. This is the mutation-annotated global phylogeny upon which your samples will be placed Optional, Required usher reference_genome File Required for organisms other than sars-cov-2, mpox, RSV-A or RSV-B. This is the reference genome used to determine your sequence's mutations to accurately place the sample on the phylogeny. Optional, Required usher cpu Int Number of CPUs to allocate to the task 4 Optional usher disk_size Int Amount of storage (in GB) to allocate to the task 200 Optional usher docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/pathogengenomics/usher:0.6.2 Optional usher memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional usher subtree_size Int Indicates how many of the closest-related samples you want to show in a subtree; more subtrees are made if there is more sequence diversity in the set of input samples (multiple subtrees are only generated if this workflow is run on the set level). 20 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/phylogenetic_placement/usher/#outputs","title":"Outputs","text":"Variable Type Description usher_clades File The clades predicted for the samples usher_phb_analysis_date String The date the analysis was run usher_phb_version String The version of PHB the workflow is from usher_protobuf_version String The version of the mutation-annotated protobuf tree (what day and what samples are included, if a default organism was used; otherwise, says it was user-provided) usher_subtree_mutations Array[File] An array of files showing the mutations at each internal node for the subtree usher_subtrees Array[File] An array of subtrees where your samples have been placed usher_uncondensed_tree File The entire global tree with your samples included (warning: may be a very large file if the organism is \"sars-cov-2\") usher_version String The version of UShER used"},{"location":"workflows/public_data_sharing/mercury_prep_n_batch/","title":"Mercury_Prep_N_Batch","text":""},{"location":"workflows/public_data_sharing/mercury_prep_n_batch/#mercury_prep_n_batch","title":"Mercury_Prep_N_Batch","text":""},{"location":"workflows/public_data_sharing/mercury_prep_n_batch/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Public Data Sharing Influenza, Monkeypox virus, SARS-CoV-2, Viral vX.X.X No Set-level Mercury_Prep_N_Batch_PHB"},{"location":"workflows/public_data_sharing/mercury_prep_n_batch/#mercury_prep_n_batch_phb","title":"Mercury_Prep_N_Batch_PHB","text":"<p>Command-line incompatible</p> <p>This workflow is not compatible with command-line use, but the underlying tool (<code>mercury</code>) is. If you want to run Mercury on the command-line, please see the tool's README for more details.</p> <p>Mercury prepares and formats metadata and sequencing files\u00a0located in Google Cloud Platform (GCP) buckets\u00a0for submission to national &amp; international databases, currently NCBI &amp; GISAID. Mercury was initially developed to ingest read, assembly, and metadata files associated with SARS-CoV-2 amplicon reads from clinical samples and format that data for submission per the\u00a0Public Health Alliance for Genomic Epidemiology (PH4GE)'s SARS-CoV-2 Contextual Data Specifications.</p> <p>Currently, Mercury supports submission preparation for SARS-CoV-2, mpox, and influenza. These organisms have different metadata requirements, and are submitted to different repositories; the following table lists the repositories for each organism &amp; what is supported in Mercury:</p> BankIt (NCBI) BioSample (NCBI) GenBank (NCBI) GISAID SRA (NCBI) <code>\"flu\"</code> \u2713 \u2713 <code>\"mpox\"</code> \u2713 \u2713 \u2713 \u2713 <code>\"sars-cov-2\"</code> \u2713 \u2713 \u2713 \u2713 <p>Mercury expects data tables made with TheiaCoV</p> <p>Mercury was designed to work with metadata tables that were partially created after running the TheiaCoV workflows. If you are using a different pipeline, please ensure that the metadata table is formatted correctly. See this file for the hard-coded list of all of the different metadata fields expected for each organism.</p>"},{"location":"workflows/public_data_sharing/mercury_prep_n_batch/#metadata-formatters","title":"Metadata Formatters","text":"<p>To help users collect all required metadata, we have created the following Excel spreadsheets that can help you collect the necessary metadata and allow for easy upload of this metadata into your Terra data tables:</p> For flu <p>Flu Metadata Formatter</p> <p>Flu uses the same metadata formatter as the Terra_2_NCBI Pathogen BioSample package.</p> <p>If neither <code>strain</code> nor <code>isolate</code> are found in the Terra data table, Mercury will automatically generate an isolate, using the following format  <code>ABRicate flu type / State / sample name / year (ABRicate flu subtype)</code>. Example: <code>A/California/Sample-01/2024 (H1N1)</code></p> <p>The ABRicate flu type and subtype (<code>abricate_flu_type</code> and <code>abricate_flu_subtype</code> columns) are extracted from your table, and are required to generate the isolate field if it is not provided.</p> For mpox <p>Mpox Metadata Formatter</p> For sars-cov-2 <p>SARS-CoV-2 Metadata Formatter</p> <p>Usage on Terra</p>"},{"location":"workflows/public_data_sharing/mercury_prep_n_batch/#usage-on-terra","title":"Usage on Terra","text":"<p>A note on the <code>using_clearlabs_data</code>\u00a0&amp;\u00a0<code>using_reads_dehosted</code> optional input parameters</p> <p>The\u00a0<code>using_clearlabs_data</code>\u00a0and\u00a0<code>using_reads_dehosted</code>\u00a0arguments change the default values for the\u00a0<code>read1_column_name</code>,\u00a0<code>assembly_fasta_column_name</code>, and\u00a0<code>assembly_mean_coverage_column_name</code>\u00a0metadata columns. The default values are shown in the table below in addition to what they are changed to depending on what arguments are used.</p> Variable Default Value with\u00a0<code>using_clearlabs_data</code> with\u00a0<code>using_reads_dehosted</code> with both\u00a0 <code>using_clearlabs_data</code> and <code>using_reads_dehosted</code> <code>read1_column_name</code> <code>\"read1_dehosted\"</code> <code>\"clearlabs_fastq_gz\"</code> <code>\"reads_dehosted\"</code> <code>\"reads_dehosted\"</code> <code>assembly_fasta_column_name</code> <code>\"assembly_fasta\"</code> <code>\"clearlabs_fasta\"</code> <code>\"assembly_fasta\"</code> <code>\"clearlabs_fasta\"</code> <code>assembly_mean_coverage_column_name</code> <code>\"assembly_mean_coverage\"</code> <code>\"clearlabs_sequencing_depth\"</code> <code>\"assembly_mean_coverage\"</code> <code>\"clearlabs_sequencing_depth\"</code>"},{"location":"workflows/public_data_sharing/mercury_prep_n_batch/#inputs","title":"Inputs","text":"<p>Use the sample table for the <code>terra_table_name</code> input</p> <p>Make sure your entry for <code>terra_table_name</code> is for the sample table! While the root entity needs to be the set table, the input value for <code>terra_table_name</code> should be the sample table.</p> <p>This workflow runs on the set-level.</p> Terra Task Name Variable Type Description Default Value Terra Status mercury_prep_n_batch gcp_bucket_uri String Google bucket where your SRA reads will be temporarily stored before transferring to SRA. Example: \"gs://theiagen_sra_transfer\" Required mercury_prep_n_batch sample_names Array[String] The samples you want to submit Required mercury_prep_n_batch terra_project_name String The name of your Terra project. You can find this information in the URL of the webpage of your Terra dashboard. For example, if your URL contains #workspaces/example/my_workspace/ then your project name is example Required mercury_prep_n_batch terra_table_name String The name of the Terra table where your samples can be found. Do not include the entity: prefix, the _id suffix, or the _set_id suffix, just the name of the sample-level data table as listed in the sidebar on lefthand side of the Terra Data tab. Required mercury_prep_n_batch terra_workspace_name String The name of your Terra workspace where your samples can be found. For example, if your URL contains #workspaces/example/my_workspace/ then your project name is my_workspace Required download_terra_table cpu Int Number of CPUs to allocate to the task 1 Optional download_terra_table disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional download_terra_table docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Optional download_terra_table memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional mercury amplicon_primer_scheme String Populate to overwrite amplicon_primer_scheme column Optional mercury amplicon_size String Populate to overwrite amplicon_size column Optional mercury authors String Populate to overwrite authors column Optional mercury bioproject_accession String Populate to overwrite bioproject_accession column Optional mercury continent String Populate to overwrite continent column Optional mercury country String Populate to overwrite country column Optional mercury cpu Int Number of CPUs to allocate to the task 2 Optional mercury disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional mercury docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/mercury:1.1.3 Optional mercury gisaid_submitter String Populate to overwrite gisaid_submitter column Optional mercury host_disease String Populate to overwrite host_disease column Optional mercury instrument_model String Populate to overwrite instrument_model column Optional mercury isolation_source String Populate to overwrite isolation_source column Optional mercury library_layout String Populate to overwrite library_layout column Optional mercury library_selection String Populate to overwrite library_selection column Optional mercury library_source String Populate to overwrite library_source column Optional mercury library_strategy String Populate to overwrite library_strategy column Optional mercury memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional mercury metadata_organism String Organism name for metadata population Optional mercury number_N_threshold Int Only for \"sars-cov-2\" submissions; used to filter out any samples that contain more than the indicated number of Ns in the assembly file 5000 Optional mercury purpose_of_sequencing String Populate to overwrite purpose_of_sequencing column Optional mercury seq_platform String Populate to overwrite seq_platform column Optional mercury single_end Boolean Set to true if your data is single-end; this ensures that a read2 column is not included in the metadata FALSE Optional mercury skip_county Boolean Use if your Terra table contains a county column that you do not want to include in your submission. FALSE Optional mercury state String Populate to overwrite state column Optional mercury submitter_email String Populate to overwrite submitter_email column Optional mercury submitting_lab String Populate to overwrite submitting_lab column Optional mercury submitting_lab_address String Populate to overwrite submitting_lab_address column Optional mercury usa_territory Boolean If true, the \"state\" column will be used in place of the \"country\" column. For example, if \"state\" is Puerto Rico, then the GISAID virus name will be\u00a0hCoV-19/Puerto Rico//. The NCBI\u00a0geo_loc_name\u00a0will be\u00a0\"USA: Puerto Rico\". This optional Boolean variable should only be used with clear understanding of what it does. FALSE Optional mercury using_clearlabs_data Boolean When set to true will change read1_dehosted \u2192 clearlabs_fastq_gz; assembly_fasta \u2192 clearlabs_fasta; assembly_mean_coverage \u2192 clearlabs_sequencing_depth FALSE Optional mercury using_reads_dehosted Boolean When set to true will only change read1_dehosted \u2192 reads_dehosted. Takes priority over the replacement for read1_dehosted made with the using_clearlabs_data Boolean input FALSE Optional mercury vadr_alert_limit Int Only for \"sars-cov-2\" submissions; used to filter out any samples that contain more than the indicated number of vadr alerts 0 Optional mercury_prep_n_batch authors_sbt File Only for \"mpox\" submissions; a file that contains author information. This file can be created here: https://submit.ncbi.nlm.nih.gov/genbank/template/submission/ Optional mercury_prep_n_batch organism String The organism that you want submission prepare for \u2014 each organism requires different metadata fields so please ensure this field is accurate. Options: \"flu\", \"mpox\"\" or \"sars-cov-2\" sars-cov-2 Optional mercury_prep_n_batch output_name String Free text prefix for all output files mercury Optional mercury_prep_n_batch skip_ncbi Boolean Set to true if you only want to prepare GISAID submission files FALSE Optional table2asn cpu Int Number of CPUs to allocate to the task 1 Optional table2asn disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional table2asn docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ncbi-table2asn:1.26.678 Optional table2asn memory Int Amount of memory/RAM (in GB) to allocate to the task 1 Optional trim_genbank_fastas cpu Int Number of CPUs to allocate to the task 1 Optional trim_genbank_fastas disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional trim_genbank_fastas docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/vadr:1.3 Optional trim_genbank_fastas max_length Int Only for \"sars-cov-2\" submissions; the maximum genome length for trimming terminal ambiguous nucleotides. If your sample's genome is higher than this value, the workflow will error/fail. 30000 Optional trim_genbank_fastas memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional trim_genbank_fastas min_length Int Only for \"sars-cov-2\" submissions; the minimum genome length for trimming terminal ambiguous nucleotides. If your sample's genome is lower than this value, the workflow will error/fail. 50 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/public_data_sharing/mercury_prep_n_batch/#outputs","title":"Outputs","text":"Variable Type Description bankit_fasta File Only for mpox submission: the fasta file that you will use to submit mpox assembly files to NCBI via email bankit_metadata File Only for mpox submission: the metadata file that you will use to submit mpox assembly files to NCBI via email bankit_sqn_to_email File Only for mpox submission: the sqn file that you will use to submit mpox assembly files to NCBI via email biosample_metadata File BioSample metadata TSV file for upload to NCBI excluded_samples File A file that contains the names and reasons why a sample was excluded from submission. For SARS-CoV-2, there are two sections: First, a section for any samples that failed to meet pre-determined quality thresholds (<code>number_N</code> and <code>vadr_num_alert</code>). Second, a section that includes a table that describes any missing required metadata for each sample. This table has the sample name for rows and any columns that have missing metadata as headers. If a sample is missing a piece of required metadata, the corresponding cell will be blank. However, if a different sample does have metadata for that column, the associated value will appear in the corresponding cell. For flu and mpox, only the second section described above exists. Please see the example below for more details. genbank_fasta File Only for SARS-CoV-2 submission: GenBank fasta file for upload genbank_metadata File Only for SARS-CoV-2 submission: GenBank metadata for upload gisaid_fasta File Only for mpox and SARS-CoV-2 submission: GISAID fasta file for upload gisaid_metadata File Only for mpox and SARS-CoV-2 submission: GISAID metadata for upload mercury_prep_n_batch_analysis_date String Date analysis was run mercury_prep_n_batch_version String Version of the PHB repository that hosts this workflow mercury_script_version String Version of the Mercury tool that was used in this workflow sra_metadata File SRA metadata TSV file for upload An example excluded_samples.tsv file"},{"location":"workflows/public_data_sharing/mercury_prep_n_batch/#example-excluded-samples","title":"An example excluded_samples.tsv file","text":"<p>Due to the nature of tsv files, it may be easier to download and open this file in Excel. </p> <p>example_excluded_samples.tsv</p> <pre><code>Samples excluded for quality thresholds:\nsample_name message \nsample2 VADR skipped due to poor assembly\nsample3 VADR number alerts too high: 3 greater than limit of 0\nsample4 Number of Ns was too high: 10000 greater than limit of 5000\n\nSamples excluded for missing required metadata (will have empty values in indicated columns):\ntablename_id    organism    country library_layout\nsample5         paired\nsample6 SARS-CoV-2  USA\n</code></pre> <p>This example informs the user that samples 2-4 were excluded for quality reasons (the exact reason is listed in the <code>message</code> column), and that samples 5 and 6 were excluded because they were missing required metadata fields (sample5 was missing the <code>organism</code> and <code>country</code> fields, and sample6 was missing the <code>library_layout</code> field).</p>"},{"location":"workflows/public_data_sharing/mercury_prep_n_batch/#usage-outside-of-terra","title":"Usage outside of Terra","text":"<p>This tool can also be used on the command-line. Please see the Mercury GitHub for more information on how to run Mercury with a Docker image or in your local command-line environment.</p>"},{"location":"workflows/public_data_sharing/terra_2_ena/","title":"Terra_2_ENA","text":""},{"location":"workflows/public_data_sharing/terra_2_ena/#terra_2_ena","title":"Terra_2_ENA","text":""},{"location":"workflows/public_data_sharing/terra_2_ena/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Public Data Sharing Bacteria, Viral v3.1.0 No Set-level Terra_2_ENA_PHB"},{"location":"workflows/public_data_sharing/terra_2_ena/#terra_2_ena_phb","title":"Terra_2_ENA_PHB","text":"<p>This workflow utilizes the ENA Webin-CLI Bulk Submission Tool to bulk submit read data to the ENA.</p>"},{"location":"workflows/public_data_sharing/terra_2_ena/#ena-submissions","title":"ENA Submissions","text":"<p>Before you can submit data to ENA you must register a Webin submission account. ENA allows submissions via the Webin-CLI program which validates your submissions entirely before you complete them. Submissions made through Webin are represented using a number of different metadata objects. Submissions to ENA result in accession numbers and these accessions can be used to identify each unique part of your submission. See the ENA submission documentation for more information.</p>"},{"location":"workflows/public_data_sharing/terra_2_ena/#pre-requisites","title":"Pre-requisites","text":"<p>Before running the <code>Terra_2_ENA</code> workflow, make sure you have registered a study and are using the correct study accession number</p> <ul> <li> <p>To submit data into ENA you must first register a study to contain and manage it. Studies (also referred to as projects) can be registered through the Webin Portal. Log in with your Webin credentials and select the \u2018Register Study\u2019 button to bring up the interface. Once registration is complete, you will be assigned accession numbers. You may return to the dashboard and select the \u2018Studies Report\u2019 button to review registered studies.</p> </li> <li> <p>Additionally, before submitting most types of data to ENA, samples must be registered. To register samples, ensure that your Terra data table includes all the samples you intend to submit, along with their raw read data (<code>FASTQ</code>, <code>BAM</code>, or <code>CRAM</code> format) and associated metadata. To meet ENA\u2019s requirements, each sample must include a minimum set of metadata. See below for the mandatory and recommended metadata fields, as well as the default column names used to identify them in your Terra data table.</p> </li> </ul>"},{"location":"workflows/public_data_sharing/terra_2_ena/#what-needs-to-be-included-in-your-terra-data-table","title":"What needs to be included in your Terra data table?","text":""},{"location":"workflows/public_data_sharing/terra_2_ena/#read-data-fields","title":"Read Data Fields","text":"<ul> <li> Mandatory Fields <p>These columns are required for submission and must be included in the Terra data table. The column names must appear exactly as shown and cannot be substituted or modified using column mappings.</p> Terra Column Name Description <code>read1</code>/<code>read2</code>/<code>bam_file</code>/<code>cram_file</code> The path to two paired end <code>FASTQ</code> files, <code>BAM</code> file, or <code>CRAM</code> file containing sequencing data. <code>experiment_name</code> Unique name of the experiment. <code>sequencing_platform</code> The platform used to generate the sequence data. See permitted values. <code>sequencing_instrument</code> The instrument used to generate the sequence data. See permitted values. <code>library_source</code> The source of the library. See permitted values. <code>library_selection</code> The method used to select the library. See permitted values. <code>library_strategy</code> The strategy used to generate the library. See permitted values. </li> </ul> <ul> <li> Optional Fields Terra Column Name Description <code>insert_size</code> The insert size for paired reads. <code>library_description</code> Free text library description. </li> </ul>"},{"location":"workflows/public_data_sharing/terra_2_ena/#sample-metadata-fields","title":"Sample Metadata Fields","text":"Using Customized Column Names in Terra Tables <p>In some cases, users may have data tables in Terra with column names that differ from the field names expected by ENA. The <code>Terra_2_ENA</code> workflow allows users to supply a custom column mapping file, enabling them to specify how their columns map to the required/mandatory field names.</p> <p>To use a custom column mapping file:</p> <ol> <li> <p>Create a tab-delimited <code>.tsv</code> file with the following structure:</p> <p>A header including <code>terra_column</code> and <code>ena_column</code> should be included in the first row. The <code>terra_column</code> column should contain the actual column names in your Terra table (e.g., 'my_fav_collection_date'), and the <code>ena_column</code> column should contain the column names expected by ENA (e.g., <code>collection date</code>). More information about the mandatory and recommended metadata fields and associated column names are described in the tables below.</p> <p>Example Mapping File: </p><pre><code>terra_column            ena_column\nmy_sample_title         title\nmy_fav_collection_date  collection_date\nmy_geo_loc_name         geo_loc_name\n</code></pre><p></p> </li> <li> <p>Upload the file to your Terra workspace and reference it in the <code>column_mappings</code> input parameter when running the workflow using Google Cloud Storage paths.</p> </li> </ol> <p>Ensure the mapping file includes all columns with custom names. Columns that match the default workflow names do not need to be included. Missing mappings for renamed columns may result in errors during execution if the column is required, and will not be found if the column is optional. The workflow will automatically map the specified column names from your Terra table to the required ENA field names as long as the mapping file is provided correctly.</p> Bacterial MetadataViral Metadata <ul> <li> Mandatory Fields <p>These fields are required for submission and must be included in the Terra data table or supplied as an input parameter</p> <p>If you cannot provide a value for a mandatory field within, set the <code>allow-missing</code> input parameter to <code>true</code> or alternatively, use one of the INDSC accepted terms for missing value reporting.</p> Terra Column Name ENA Field Name Description <code>title</code> sample_title Title of the sample. <code>taxon_id</code> and/or <code>organism</code> tax_id and/or scientific name Taxonomic identifier (NCBI taxon ID) or scientific name of the organism from which the sample was obtained. <code>collection_date</code> collection date The date the sample was collected with the intention of sequencing, either as an instance (single point in time) or interval. In case no exact time is available, the date/time can be right truncated i.e. all of these are valid ISO8601 compliant times: 2008-01-23T19:23:10+00:00; 2008-01-23T19:23:10; 2008-01-23; 2008-01; 2008. <code>geo_loc_name</code> geographic location (country and/or sea) The geographical origin of where the sample was collected from, with the intention of sequencing, as defined by the country or sea name. Country or sea names should be chosen from the INSDC country list. <code>host_health_state</code> host health state Health status of the host at the time of sample collection. Must be one of the following: <code>diseased</code>, <code>healthy</code>, <code>missing: control sample</code>, <code>missing: data agreement established pre-2023</code>, <code>missing: endangered species</code>, <code>missing: human-identifiable</code>, <code>missing: lab stock</code>, <code>missing: sample group</code>, <code>missing: synthetic construct</code>, <code>missing: third party data</code>, <code>not applicable</code>, <code>not collected</code>, <code>not provided</code>, <code>restricted access</code>. <code>host_scientific_name</code> host scientific name Scientific name of the natural (as opposed to laboratory) host to the organism from which sample was obtained. <code>isolation_source</code> isolation_source Describes the physical, environmental and/or local geographical source of the biological sample from which the sample was derived. <code>isolate</code> isolate Individual isolate from which the sample was obtained. </li> </ul> <ul> <li> Optional Fields Terra Column Name ENA Field Name Description <code>library_description</code> sample_description Description of the sample. <code>lat_lon</code> lat_lon Geographical coordinates of the location where the specimen was collected. <code>serovar</code> serovar Serological variety of a species (usually a prokaryote) characterized by its antigenic properties. <code>strain</code> strain Name of the strain from which the sample was obtained. </li> </ul> <p>Reference: ENA prokaryotic pathogen minimal sample checklist</p> <ul> <li> Mandatory Fields <p>These fields are required for submission and must be included in the Terra data table or supplied as an input parameter</p> <p>If you cannot provide a value for a mandatory field within, set the <code>allow-missing</code> input parameter to <code>true</code> or alternatively, use one of the INDSC accepted terms for missing value reporting.</p> Terra Column Name ENA Field Name Description <code>title</code> sample_title Title of the sample. <code>taxon_id</code> and/or <code>organism</code> tax_id and/or scientific name Taxonomic identifier (NCBI taxon ID) or scientific name of the organism from which the sample was obtained. <code>collection_date</code> collection date The date the sample was collected with the intention of sequencing, either as an instance (single point in time) or interval. In case no exact time is available, the date/time can be right truncated i.e. all of these are valid ISO8601 compliant times: 2008-01-23T19:23:10+00:00; 2008-01-23T19:23:10; 2008-01-23; 2008-01; 2008. <code>collecting_institution</code> collecting institution Name of the institution to which the person collecting the specimen belongs. Format: Institute Name, Institute Address <code>collector_name</code> collector name Name of the person who collected the specimen. Example: John Smith <code>geo_loc_name</code> geographic location (country and/or sea) The geographical origin of where the sample was collected from, with the intention of sequencing, as defined by the country or sea name. Country or sea names should be chosen from the INSDC country list. <code>host_common_name</code> host common name Common name of the host, e.g. human <code>host_health_state</code> host health state Health status of the host at the time of sample collection. Must be one of the following: <code>diseased</code>, <code>healthy</code>, <code>missing: control sample</code>, <code>missing: data agreement established pre-2023</code>, <code>missing: endangered species</code>, <code>missing: human-identifiable</code>, <code>missing: lab stock</code>, <code>missing: sample group</code>, <code>missing: synthetic construct</code>, <code>missing: third party data</code>, <code>not applicable</code>, <code>not collected</code>, <code>not provided</code>, <code>restricted access</code>. <code>host_scientific_name</code> host scientific name Scientific name of the natural (as opposed to laboratory) host to the organism from which sample was obtained. <code>host_sex</code> host sex Gender or sex of the host. Must be one of the following: <code>female</code>, <code>male</code>, <code>hermaphrodite</code>, <code>neuter</code>, <code>not applicable</code>, <code>not collected</code>, <code>not provided</code>, <code>other</code>, <code>missing: control sample</code>, <code>missing: data agreement established pre-2023</code>, <code>missing: endangered species</code>, <code>missing: human-identifiable</code>, <code>missing: lab stock</code>, <code>missing: sample group</code>, <code>missing: synthetic construct</code>, <code>missing: third party data</code>. <code>host_subject_id</code> host subject id A unique identifier by which each subject can be referred to, de-identified, e.g. #131 <code>isolation_source</code> isolation_source Describes the physical, environmental and/or local geographical source of the biological sample from which the sample was derived. <code>isolate</code> isolate Individual isolate from which the sample was obtained. </li> </ul> <ul> <li> Optional Fields Terra Column Name ENA Field Name Description <code>latitude</code> geographic location (latitude) The geographical origin of the sample as defined by latitude. The values should be reported in decimal degrees and in WGS84 system <code>longitude</code> geographic location (longitude) The geographical origin of the sample as defined by longitude. The values should be reported in decimal degrees and in WGS84 system <code>region_locality</code> geographic location (region and locality) The geographical origin of the sample as defined by the specific region name followed by the locality name. <code>host_disease_outcome</code> host disease outcome Disease outcome in the host. <code>host_age</code> host age Age of host at the time of sampling; relevant scale depends on species and study, e.g. could be seconds for amoebae or centuries for trees <code>host_behaviour</code> host behaviour Natural behaviour of the host. <code>host_habitat</code> host habitat Natural habitat of the avian or mammalian host. <code>isolation_source_host</code> isolation source host-associated Name of host tissue or organ sampled for analysis. Example: tracheal tissue <code>isolation_source_non_host</code> isolation source non-host-associated Describes the physical, environmental and/or local geographical source of the biological sample from which the sample was derived. Example: soil <code>receipt_date</code> receipt date Date on which the sample was received. Format:YYYY-MM-DD. Please provide the highest precision possible. If the sample was received by the institution and not collected, the 'receipt date' must be provided instead. <code>sample_capture_status</code> sample capture status Reason for the sample collection. <code>library_description</code> sample_description Description of the sample. <code>serotype</code> serotype Serological variety of a species characterised by its antigenic properties. For Influenza, HA subtype should be the letter H followed by a number between 1-16 unless novel subtype is identified and the NA subtype should be the letter N followed by a number between 1-9 unless novel subtype is identified. <code>virus_identifier</code> virus identifier Unique laboratory identifier assigned to the virus by the investigator. Strain name is not sufficient since it might not be unique due to various passsages of the same virus. Format: up to 50 alphanumeric characters </li> </ul> <p>Reference: ENA viral minimal sample checklist</p>"},{"location":"workflows/public_data_sharing/terra_2_ena/#workflow-inputs","title":"Workflow Inputs","text":"<p>It's important to note that the <code>Terra_2_ENA</code> workflow is designed to run on set-level data tables. This means that the workflow will process all samples within a set together, rather than handling each sample individually. The <code>samples</code> input variable expects an array of sample IDs, corresponding to a set table. In most cases, set tables are generated automatically when running a workflow. However, if you need to create one manually, refer to this guide on how to create a set table.</p> <p>The <code>submit_to_production</code> input parameter is set to <code>false</code> by default. This means that the workflow will not submit data to the production ENA server unless you explicitly set it to <code>true</code>. This is useful for testing purposes, allowing you to validate your data without making actual submissions.</p> Terra Task Name Variable Type Description Default Value Terra Status Terra_2_ENA ena_password String ENA password to authenticate submission Required Terra_2_ENA ena_username String ENA username to authenticate submission Required Terra_2_ENA sample_id_column String The column name in the Terra data table containing sample IDs Required Terra_2_ENA sample_type String Type of sample being submitted (\"prokaryotic_pathogen\" or \"virus_pathogen\") Required Terra_2_ENA samples Array[String] Array of sample IDs to submit Required Terra_2_ENA study_accession String ENA study accession number to associate submissions with Required Terra_2_ENA terra_project_name String The Terra project containing the data table Required Terra_2_ENA terra_table_name String The name of the Terra data table containing sample data Required Terra_2_ENA terra_workspace_name String The Terra workspace containing the data table Required Terra_2_ENA allow_missing Boolean Whether to allow missing values in metadata FALSE Optional Terra_2_ENA column_mappings File TSV file mapping Terra table columns to ENA submission fields Optional download_terra_table cpu Int Number of CPUs to allocate to the task 1 Optional download_terra_table disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional download_terra_table docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Optional download_terra_table memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional register_ena_samples batch_size Int Number of samples to process in each batch 100 Optional register_ena_samples center String Name of submitting center Optional register_ena_samples cpu Int Number of CPUs to allocate to the task 1 Optional register_ena_samples disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional register_ena_samples docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra_to_ena:0.6 Optional register_ena_samples memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional submit_ena_data bam_column String Column name containing BAM file paths bam_file Optional submit_ena_data cpu Int Number of CPUs to allocate to the task 1 Optional submit_ena_data cram_column String Column name containing CRAM file paths cram_file Optional submit_ena_data disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional submit_ena_data docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra_to_ena:0.6 Optional submit_ena_data experiment_name String Internal component, do not modify Optional submit_ena_data instrument String Internal component, do not modify Optional submit_ena_data library_selection String Internal component, do not modify RANDOM Optional submit_ena_data library_source String Internal component, do not modify GENOMIC Optional submit_ena_data library_strategy String Internal component, do not modify WGS Optional submit_ena_data memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional submit_ena_data platform String Internal component, do not modify ILLUMINA Optional submit_ena_data read1_column String Column name containing read1 file paths read1 Optional submit_ena_data read2_column String Column name containing read2 file paths read2 Optional submit_ena_data submit_to_production Boolean If false, performs a test submission of metadata FALSE Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/public_data_sharing/terra_2_ena/#workflow-outputs","title":"Workflow Outputs","text":"Variable Type Description Terra_2_ENA_analysis_date String Date the Terra to ENA workflow was run Terra_2_ENA_version String Version of the Terra to ENA workflow used ena_accessions File Text file containing the accession numbers generated by ENA submission ena_docker_image String Docker image used for ENA submission processing ena_excluded_samples File Text file listing samples that were excluded from ENA submission ena_file_paths_json File JSON file containing paths to the files submitted to ENA ena_metadata_accessions File File containing metadata and their corresponding accessions from ENA ena_registration_log File Log file detailing the ENA registration process ena_registration_success String String indicating whether the ENA registration was successful ena_registration_summary File Summary file of the ENA registration results ena_submission_manifest_files Array[File] Array of manifest files used for ENA submission. Each file corresponds to a sample and contains metadata and file paths ena_submission_report_files Array[File] Array of report files containing the results of the ENA submission ena_webincli_results File File containing the cumulative results of the ENA submission prepped_ena_data File Prepared data formatted for ENA submission terra_table File Terra table file used for submission to ENA"},{"location":"workflows/public_data_sharing/terra_2_ena/#references","title":"References","text":"<ul> <li>ENA prokaryotic pathogen minimal sample checklist</li> <li>ENA viral minimal sample checklist</li> <li>ENA Data Submission Documentation</li> </ul>"},{"location":"workflows/public_data_sharing/terra_2_gisaid/","title":"Terra_2_GISAID","text":""},{"location":"workflows/public_data_sharing/terra_2_gisaid/#terra_2_gisaid","title":"Terra_2_GISAID","text":""},{"location":"workflows/public_data_sharing/terra_2_gisaid/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Public Data Sharing SARS-CoV-2, Viral v1.2.1 Yes Set-level Terra_2_GISAID_PHB"},{"location":"workflows/public_data_sharing/terra_2_gisaid/#terra_2_gisaid_phb","title":"Terra_2_GISAID_PHB","text":"<p>Terra_2_GISAID programmatically submits SARS-CoV-2 assembly files to GISAID.</p> <p>This workflow expects data that has been prepared for submission using either Mercury_Batch or Mercury_Prep_N_Batch (recommended).</p> <p>client-ID</p> <p>To obtain a client-ID, contact <code>clisupport@gisaid.org</code> and include your username in your request.</p>"},{"location":"workflows/public_data_sharing/terra_2_gisaid/#inputs","title":"Inputs","text":"<p>The optional variable <code>frameshift_notification</code> has three options that correspond to the associated web-browser options:</p> <ul> <li>\"catch_all\" - \"Notify me about ALL DETECTED FRAMESHIFTS in this submission for reconfirmation of affected sequences\"</li> <li>\"catch_novel\" [DEFAULT] - \"Notify me only about NOT PREVIOUSLY REPORTED FRAMESHIFTS in this submission for reconfirmation of affected sequences\"</li> <li>\"catch_none\" - \"I confirm ANY FRAMESHIFTS in this submission and request their release without confirmation by a curator\"</li> </ul> <p>GISAID Credentials</p> <p>Please note that the user must provide either an authentication_file or a gisaid_credentials file to run this workflow; explanations for both can be found in the table below.</p> <p>This workflow runs on the sample level.</p> Terra Task Name Variable Type Description Default Value Terra Status Terra_2_GISAID client_id String This value should be filled with the client-ID provided by GISAID Required Terra_2_GISAID concatenated_fastas File The GISAID FASTA file generated by Mercury_Prep_N_Batch (or Mercury_Prep) Required Terra_2_GISAID concatenated_metadata File The GISAID metadata file generated by Mercury_Prep_N_Batch (or Mercury_Prep) Required gisaid_upload authentication_file File [EITHER] The GISAID authentication file generated by running cli3 authenticate for the submitter. Optional, Required gisaid_upload gisaid_credentials File [EITHER] A tab-delimited file containing the submitter's GISAID username followed by their password, used to generate the GISAID authentication file. Optional, Required gisaid_upload cpu Int Number of CPUs to allocate to the task 1 Optional gisaid_upload disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional gisaid_upload docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/broadinstitute/gisaid-cli:3.0 Optional gisaid_upload frameshift_notification String See top of inputs section for explanation; the notification preference regarding frameshifts in your submission catch_novel Optional gisaid_upload memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/public_data_sharing/terra_2_gisaid/#outputs","title":"Outputs","text":"Variable Type Description failed_uploads File The metadata for any failed uploads gisaid_cli_version String The verison of the GISAID CLI tool gisaid_logs File The log files regarding the submission terra_2_gisaid_analysis_date String The date of the analysis terra_2_gisaid_version String The version of the PHB repository that this workflow is hosted in"},{"location":"workflows/public_data_sharing/terra_2_ncbi/","title":"Terra_2_NCBI","text":""},{"location":"workflows/public_data_sharing/terra_2_ncbi/#terra_2_ncbi","title":"Terra_2_NCBI","text":""},{"location":"workflows/public_data_sharing/terra_2_ncbi/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Public Data Sharing Bacteria, Mycotics, Viral vX.X.X No Set-level Terra_2_NCBI_PHB"},{"location":"workflows/public_data_sharing/terra_2_ncbi/#terra_2_ncbi_phb","title":"Terra_2_NCBI_PHB","text":"<p>Do not resubmit!</p> <p>If the Terra_2_NCBI workflow fails, DO NOT resubmit.</p> <p>Resubmission risks duplicate submissions and future failures.</p> <p>Contact Theiagen (<code>support@theiagen.com</code>) to determine the reason for failure, and only move forward with Theiagen's guidance.</p> <p>Key Resources</p> <ul> <li>Pathogen metadata formatter</li> <li>Microbe metadata formatter</li> <li>Virus metadata formatter</li> <li>SARS-CoV-2 Wastewater metadata formatter</li> </ul> <p>The Terra_2_NCBI workflow is a programmatic data submission method to share metadata information with NCBI BioSample and paired-end Illumina reads with NCBI SRA directly from Terra without having to use the NCBI portal.</p>"},{"location":"workflows/public_data_sharing/terra_2_ncbi/#prerequisites","title":"Prerequisites","text":"Before running the Terra_2_NCBI workflow <ol> <li> <p>The user must have access to the NCBI FTP. To gain these credentials, we recommend emailing <code>**sra@ncbi.nlm.nih.gov**</code> a variation of the following example, including all the information:</p> <p>Hello,</p> <p>We would like to automate submissions to the Submission Portal using XML metadata to accompany our cloud-hosted data files.\u00a0\u00a0We would like to upload via FTP and need to create a submission group.</p> <p>Here is the relevant information:</p> <ol> <li>Suggested group abbreviation:</li> <li>Full group name:</li> <li>Institution and department:</li> <li>Contact person (someone likely to remain at the location for an extended time):</li> <li>Contact email:</li> <li>Mailing address (including country and postcode):</li> </ol> <p>We will be using an existing submission pipeline that is known to work and would like to request that the production folder be activated.\u00a0Thank you for your assistance!</p> </li> <li> <p>From NCBI, you will need to get in response:</p> <ol> <li>an FTP address (it will likely be ftp-private.ncbi.nih.gov)</li> <li>Username (typically the suggested group abbreviation)</li> <li>Password</li> <li>an acknowledgment that the production folder has been activated.</li> </ol> <p>Please confirm that the production folder has been activated, or else the submission pipeline will either fail or only run test submissions and not actually submit to NCBI.</p> </li> <li> <p>Before you can run the workflow for the first time, we also recommend scheduling a meeting with Theiagen to get additional things set up, including</p> <ul> <li>adding a correctly-formatted configuration file to your workspace data elements that includes your FTP username and password, laboratory details, and other important information.</li> <li>ensuring your proxy account has been given permission to write to the google bucket where SRA reads are temporarily stored before being transferred to NCBI.</li> </ul> What is the configuration file used for? <p>The configuration file tells the workflow your username and password so you can access the FTP. It also provides important information about who should be contacted regarding the submission. We recommend contacting a member of Theiagen for help in the creation of this configuration file to ensure that everything is formatted correctly.</p> </li> </ol>"},{"location":"workflows/public_data_sharing/terra_2_ncbi/#collating-biosample-metadata","title":"Collating BioSample Metadata","text":"<p>In order to create BioSamples, you need to choose the correct BioSample package and have the appropriate metadata included in your data table.</p> <p>Currently, Terra_2_NCBI only supports Pathogen, Virus, Microbe, and SARS-CoV-2 Wastewater Surveillance BioSample packages. Most organisms should be submitted using the Pathogen package unless you have been specifically directed otherwise (either through CDC communications or another reliable source). Definitions of packages supported by Terra_2_NCBI are listed below with more requirements provided via the links:</p> <ul> <li>Pathogen.cl - any clinical or host-associated pathogen</li> <li>Pathogen.env - environmental, food or other pathogen (no metadata formatter available at this time)</li> <li>Microbe - bacteria or other unicellular microbes that do not fit under the MIxS, Pathogen, or Virus packages.</li> <li>Virus -  viruses not directly associated with disease<ul> <li>Viral pathogens should be submitted using the Pathogen: Clinical or host-associated pathogen package.</li> </ul> </li> <li>SARS-CoV-2.wwsurv - SARS-CoV-2 wastewater surveillance samples</li> </ul>"},{"location":"workflows/public_data_sharing/terra_2_ncbi/#metadata-formatters","title":"Metadata Formatters","text":"<p>For each package, we have created a metadata template spreadsheet to help you organize your metadata:</p> <p>Please note that the pathogen metadata formatter is for the clinical pathogen package, not the environmental pathogen.</p> <ul> <li>Terra_2_NCBI-PATHOGEN-metadata-2024-04-30.xlsx</li> <li>Terra_2_NCBI-MICROBE-metadata-2022-07-11.xlsx</li> <li>Terra_2_NCBI-VIRUS-metadata-2022-09-09.xlsx</li> <li>Terra_2_NCBI-SC2WW-metadata-2025-01-10.xlsx</li> </ul> <p>We are constantly working on improving these spreadsheets and they will be updated in due course.</p>"},{"location":"workflows/public_data_sharing/terra_2_ncbi/#running-the-workflow","title":"Running the Workflow","text":"<p>We recommend running a test submission before your first production submission to ensure that all data has been formatted correctly. Please contact Theiagen (support@theiagen.com) to get this set up.</p> <p>In the test submission, any real BioProject accession numbers you provide will not be recognized. You will have to make a \"fake\" or \"test\" BioProject. This cannot be done through the NCBI portal. Theiagen can provide assistance in creating this as it requires manual command-line work on the NCBI FTP using the account they provided for you.</p> What's the difference between a test submission and a production submission? <p>A production submission means that your submission using Terra_2_NCBI will be submitted to NCBI as if you were using the online portal. That means that anything you submit on production will be given to the *real* NCBI servers and appear and become searchable on the NCBI website.</p> <p>A test submission gives your data to a completely detached replica of the production server. This means that any data you submit as a test will behave exactly like a real submission, but since it's detached, nothing will appear on the NCBI website, and anything returned from the workflow (such as BioSample accession numbers) will be fake. If you search for these test BioSample accession numbers on the NCBI website, either (a) nothing will appear, or (b) it will link to a random sample. </p> <p>If you want your data to be on NCBI, you must run a production submission. Initially, NCBI locks the production folder so that the user doesn't accidentally submit test data to the main database. You must have requested activation of the production folder prior to your first production submission.</p>"},{"location":"workflows/public_data_sharing/terra_2_ncbi/#inputs","title":"Inputs","text":"<p>This workflow runs on set-level data tables.</p> <p>Production Submissions</p> <p>Please note that an optional Boolean variable, <code>submit_to_production</code>, is required for a production submission.</p> Using Customized Column Names in Terra Tables <p>In some cases, users may have data tables in Terra with column names that differ from the default expected by the workflow. The <code>Terra_2_NCBI</code> workflow allows users to supply a custom column mapping file, enabling them to specify how their columns map to the required workflow variables.</p> <p>To use a custom column mapping file:</p> <ol> <li> <p>Create a tab-delimited <code>.tsv</code> file with the following structure:</p> <p>A header including \"Custom\" and \"Required\" should be included in the first row. The \"Custom\" column should contain the actual column names in your Terra table (e.g., 'collection-date'), and the \"Required\" column should contain the column names expected by the workflow (e.g., 'collection_date').</p> <p>Example Mapping File: </p><pre><code>Custom  Required\nCollection-Date collection_date\ngeo_location    geo_loc_name\nbioproject_column   bioproject\nsample_id_column    sample_names\n</code></pre><p></p> </li> <li> <p>Upload the file to your Terra workspace and reference it in the <code>column_mapping_file</code> parameter when running the workflow using Google Cloud Storage paths.</p> </li> </ol> <p>Ensure the mapping file includes all columns with custom names. Columns that match the default workflow names do not need to be included. Missing mappings for renamed columns may result in errors during execution if the column is required, and will not be found if the column is optional.</p> <p>The workflow will automatically map the specified column names from your Terra table to the required workflow variables using the 'custom_mapping_file'.</p> <p>To find a list of the expected required and optional column names, please refer to the code blocks that can be found here. The required and optional metadata fields are organized by the BioSample type.</p> <p>Below, you can find the required metadata fields for the currently supported BioSample types:</p> Microbe Required Metadata <ul> <li>submission_id</li> <li>organism</li> <li>collection_date</li> <li>geo_loc_name</li> <li>sample_type</li> </ul> Wastewater Required Metadata <ul> <li>submission_id</li> <li>organism</li> <li>collection_date</li> <li>geo_loc_name</li> <li>isolation_source</li> <li>ww_population</li> <li>ww_sample_duration</li> <li>ww_sample_matrix</li> <li>ww_sample_type</li> <li>ww_surv_target_1</li> <li>ww_surv_target_1_known_present</li> </ul> Pathogen.cl Required Metadata <ul> <li>submission_id</li> <li>organism</li> <li>collected_by</li> <li>collection_date</li> <li>geo_loc_name</li> <li>host</li> <li>host_disease</li> <li>isolation_source</li> <li>lat_lon</li> </ul> Pathogen.env Required Metadata <ul> <li>submission_id</li> <li>organism</li> <li>collected_by</li> <li>collection_date</li> <li>geo_loc_name</li> <li>isolation_source</li> <li>lat_lon</li> </ul> Virus Required Metadata <ul> <li>submission_id</li> <li>organism</li> <li>isolate</li> <li>collection_date</li> <li>geo_loc_name</li> <li>isolation_source</li> </ul> <p>For further assistance in setting up a custom column mapping file, please contact Theiagen at support@theiagen.com.</p> Terra Task Name Variable Type Description Default Value Terra Status Terra_2_NCBI bioproject String BioProject accession that the samples will be submitted to Required Terra_2_NCBI biosample_package String The BioSample package that the samples will be submitted under Required Terra_2_NCBI ncbi_config_js File Configuration file that contains your username and password for the NCBI FTP Required Terra_2_NCBI project_name String The name of your Terra project. You can find this information in the url of the webpage you are on. It is the section right after \"#workspaces/\" Required Terra_2_NCBI sample_names Array[String] The list of samples you want to submit Required Terra_2_NCBI sra_transfer_gcp_bucket String Google bucket where your SRA reads will be temporarily stored before transferring to SRA Required Terra_2_NCBI table_name String The name of the Terra table where your samples are found Required Terra_2_NCBI workspace_name String The name of the workspace where your samples are found Required Terra_2_NCBI submit_to_production Boolean Used to indicate whether or not the workflow should submit to NCBI's production environment. If set to true, then a Production submission will occur. Otherwise, by default (false), it will perform a Test submission. FALSE Optional, Required Terra_2_NCBI column_mapping_file File TSV file mapping Terra table columns to NCBI submission fields Optional Terra_2_NCBI input_table File Internal component, do not modify Optional Terra_2_NCBI skip_biosample Boolean Boolean switch to turn on actual production level submission FALSE Optional add_biosample_accessions cpu Int Number of CPUs to allocate to the task 4 Optional add_biosample_accessions disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional add_biosample_accessions docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional add_biosample_accessions memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional biosample_submit_tsv_ftp_upload cpu Int Number of CPUs to allocate to the task 2 Optional biosample_submit_tsv_ftp_upload disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional biosample_submit_tsv_ftp_upload docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/broadinstitute/ncbi-tools:2.10.7.10 Optional biosample_submit_tsv_ftp_upload memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional ncbi_sftp_upload additional_files Array[File] Internal component, do not modify Optional ncbi_sftp_upload cpu Int Number of CPUs to allocate to the task 2 Optional ncbi_sftp_upload disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ncbi_sftp_upload docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/broadinstitute/ncbi-tools:2.10.7.10 Optional ncbi_sftp_upload memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional ncbi_sftp_upload wait_for String Internal component, do not modify 1 Optional prune_table cpu Int Number of CPUs to allocate to the task 4 Optional prune_table disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional prune_table docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional prune_table memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional prune_table read1_column_name String The column header of the read1 column read1 Optional prune_table read2_column_name String The column header of the read2 column read2 Optional sra_tsv_to_xml cpu Int Number of CPUs to allocate to the task 1 Optional sra_tsv_to_xml disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional sra_tsv_to_xml docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/broadinstitute/ncbi-tools:2.10.7.10 Optional sra_tsv_to_xml memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Workflow Tasks"},{"location":"workflows/public_data_sharing/terra_2_ncbi/#workflow-tasks","title":"Workflow Tasks","text":"<p>The workflow will perform the following tasks, each highlighted as <code>code</code></p> <ol> <li><code>prune_table</code>formats all incoming metadata for submission.</li> <li> <p>If you are submitting BioSamples:</p> <ol> <li><code>biosample_submit_tsv_ftp_upload</code> will <ol> <li>format the BioSample table into XML format</li> <li>submit BioSamples to NCBI</li> <li>return all NCBI communications in XML format, and</li> <li>parse those communications for any and all BioSample accessions.</li> </ol> </li> <li> <ol> <li>add the BioSample accessions to SRA metadata</li> <li>upload the BioSample accessions to the origin Terra table</li> </ol> <p><code>add_biosample_accessions</code> will</p> <p>If BioSample accessions fail to be generated, this task ends the workflow and users should contact Theiagen for further support. Otherwise, the workflow will continue and outputs are returned to the Terra data table. </p> </li> </ol> </li> <li> <p>If BioSample accessions were generated or if BioSample submission was skipped</p> <ol> <li><code>sra_tsv_to_xml</code> converts the SRA metadata (including any generated or pre-provided BioSample accessions) into XML format.</li> <li><code>ncbi_sftp_upload</code> <ol> <li>uploads the SRA metadata to NCBI </li> <li>returns any XML communications from NCBI.</li> </ol> </li> </ol> </li> </ol>"},{"location":"workflows/public_data_sharing/terra_2_ncbi/#workflow-success","title":"Workflow Success","text":"<p>If the workflow ends successfully, it returns the outputs to the Terra data table and the XML communications from NCBI will say that submission is underway. The workflow does not declare successful sample submission since SRA sometimes takes a while to do this. If the submission was successful, the point of contact for the submission will receive the SRA accessions via email from NCBI.</p> <p>If the workflow ends unsuccessfully, no outputs will be shown on Terra and the <code>biosample_status</code> output variable will indicate that the BioSample submission failed.</p>"},{"location":"workflows/public_data_sharing/terra_2_ncbi/#outputs","title":"Outputs","text":"<p>The output files contain information mostly for debugging purposes. Additionally, if your submission is successful, the point of contact for the submission should also receive an email from NCBI notifying them of their submission success.</p> Variable Type Description Terra_2_NCBI_analysis_date String Date that the workflow was run Terra_2_NCBI_version String Version of the PHB repository where the workflow is hosted biosample_failures File Text file listing samples that failed BioSample submission biosample_metadata File Metadata used for BioSample submission in proper BioSample formatting biosample_report_xmls Array[File] One or more XML files that contain the response from NCBI regarding your BioSample submission. These can be pretty cryptic, but often contain information to determine  if anything went wrong biosample_status String String showing whether BioSample submission was successful biosample_submission_xml File XML file used to submit your BioSamples to NCBI excluded_samples File Text file listing samples that were excluded from BioSample submission for missing required metadata generated_accessions File Text file mapping the BioSample accession with its sample name. sra_metadata File Metadata used for SRA submission in proper SRA formatting sra_report_xmls Array[File] One or more XML files containing the response from NCBI regarding your SRA submission. These can be pretty cryptic, but often contain information to determine  if anything went wrong sra_submission_xml File XML file that was used to submit your SRA reads to NCBI An example excluded_samples.tsv file"},{"location":"workflows/public_data_sharing/terra_2_ncbi/#example-excluded-samples","title":"An example excluded_samples.tsv file","text":"<p>Due to the nature of tsv files, it may be easier to download and open this file in Excel. </p> <p>example_excluded_samples.tsv</p> <pre><code>Samples excluded for quality thresholds:\nsample_name message \nsample2 VADR skipped due to poor assembly\nsample3 VADR number alerts too high: 3 greater than limit of 0\nsample4 Number of Ns was too high: 10000 greater than limit of 5000\n\nSamples excluded for missing required metadata (will have empty values in indicated columns):\ntablename_id    organism    country library_layout\nsample5         paired\nsample6 SARS-CoV-2  USA\n</code></pre> <p>This example informs the user that samples 2-4 were excluded for quality reasons (the exact reason is listed in the <code>message</code> column), and that samples 5 and 6 were excluded because they were missing required metadata fields (sample5 was missing the <code>organism</code> and <code>country</code> fields, and sample6 was missing the <code>library_layout</code> field).</p>"},{"location":"workflows/public_data_sharing/terra_2_ncbi/#limitations","title":"Limitations","text":"<ul> <li>The maximum number of samples that can be submitted at once appears to be 300. We recommend submitting less than 300 samples at a time to avoid errors due to large submission sizes.</li> <li>A workflow on returning SRA accessions using the generated BioSample accessions is in progress.</li> </ul>"},{"location":"workflows/public_data_sharing/terra_2_ncbi/#acknowledgments","title":"Acknowledgments","text":"<p>This workflow would not have been possible without the invaluable contributions of Dr. Danny Park.</p>"},{"location":"workflows/standalone/amr_search/","title":"AMR_Search","text":""},{"location":"workflows/standalone/amr_search/#amr-search","title":"AMR Search","text":""},{"location":"workflows/standalone/amr_search/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Standalone Any taxa v3.0.1 Yes Sample-level AMR_Search_PHB"},{"location":"workflows/standalone/amr_search/#amr_search_phb","title":"AMR_Search_PHB","text":"<p>AMR_Search Workflow Diagram</p> <p></p> <p>The AMR_Search workflow is a standalone version of Pathogenwatch's AMR profiling functionality utilizing <code>AMRsearch</code> tool from Pathogenwatch.</p> <p>A limited number of species are currently supported and are listed below. NCBI codes are needed from this table to select the correct library.</p> Species NCBI Code Neisseria gonorrhoeae 485 Staphylococcus aureus 1280 Salmonella typhi 90370 Streptococcus pneumoniae 1313 Klebisiella 570 Klebsiella pneumoniae 573 Candida auris 498019 Vibrio cholerae 666 Campylobacter 194"},{"location":"workflows/standalone/amr_search/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status amr_search_workflow amr_search_database String NCBI taxon code of samples known taxonomy, see above supported species Required amr_search_workflow input_fasta File A microbial assembly file Required amr_search_workflow samplename String The name of the sample being analyzed Required amr_search cpu Int Number of CPUs to allocate to the task 2 Optional amr_search disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional amr_search docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/amrsearch:0.2.1 Optional amr_search memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/standalone/amr_search/#workflow-tasks","title":"Workflow Tasks","text":"<code>amr_search</code>: Antimicrobial resistance profiling <p>This task performs in silico antimicrobial resistance (AMR) profiling for supported species using AMRsearch, the primary tool used by Pathogenwatch to genotype and infer antimicrobial resistance (AMR) phenotypes from assembled microbial genomes.</p> <p>AMRsearch screens against Pathogenwatch's library of curated genotypes and inferred phenotypes, developed in collaboration with community experts. Resistance phenotypes are determined based on both resistance genes and mutations, and the system accounts for interactions between multiple SNPs, genes, and suppressors. Predictions follow S/I/R classification (Sensitive, Intermediate, Resistant).</p> <p>Currently, only a subset of species are supported by this task.</p> Supported Species <p>The following table shows the species name and the associated NCBI Code. If you are running AMR Search as part of TheiaProk and TheiaEuk, these codes will be automatically determined based on the GAMBIT predicted taxon, or the user-provided <code>expected_taxon</code> input.</p> Species NCBI Code Neisseria gonorrhoeae 485 Staphylococcus aureus 1280 Salmonella Typhi 90370 Streptococcus pneumoniae 1313 Klebisiella 570 Escherichia 561 Mycobacterium tuberculosis 1773 Candida auris 498019 Vibrio cholerae 666 Campylobacter 194 <p>Outputs:</p> <ul> <li>JSON Output: Contains the complete AMR profile, including detailed resistance state, detected resistance genes/mutations, and supporting BLAST results.</li> <li>CSV &amp; PDF Tables: An incorporated Python script, <code>parse_amr_json.py</code>, extracts and formats results into a CSV file and PDF summary table for easier visualization.</li> </ul> <p>amr_search Technical Details</p> Links Task task_amr_search.wdl Software Source Code AMRsearch on GitHub Software Documentation AMRsearch on GitHub Original Publication(s) PAARSNP: rapid genotypic resistance prediction for Neisseria gonorrhoeae"},{"location":"workflows/standalone/amr_search/#outputs","title":"Outputs","text":"Variable Type Description amr_results_csv File CSV formatted AMR profile amr_results_pdf File PDF formatted AMR profile amr_search_docker String Docker image used to run AMR_Search amr_search_results File JSON formatted AMR profile including BLAST results amr_search_version String Version of AMR_Search libraries used amr_search_wf_analysis_date String Date of analysis amr_search_wf_version String Version of PHB used for analysis"},{"location":"workflows/standalone/amr_search/#references","title":"References","text":"<p>Pathogenwatch AMRsearch</p> <p>PAARSNP</p>"},{"location":"workflows/standalone/cauris_cladetyper/","title":"Cauris_CladeTyper","text":""},{"location":"workflows/standalone/cauris_cladetyper/#cauris_cladetyper","title":"Cauris_CladeTyper","text":""},{"location":"workflows/standalone/cauris_cladetyper/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Standalone Mycotics vX.X.X Yes Sample-level Cauris_CladeTyper_PHB"},{"location":"workflows/standalone/cauris_cladetyper/#cauris_cladetyper_phb","title":"Cauris_CladeTyper_PHB","text":"<p>The Cauris_CladeTyper_PHB Workflow is designed to assign the clade to Candidozyma auris (also known as Candida auris) WGS assemblies based on their genomic sequence similarity to the six clade-specific reference files. Clade typing is essential for understanding the epidemiology and evolutionary dynamics of this emerging multidrug-resistant fungal pathogen.</p>"},{"location":"workflows/standalone/cauris_cladetyper/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status cauris_cladetyper assembly_fasta File The assembly file for your sample in FASTA format Required cauris_cladetyper samplename String The name of the sample being analyzed Required cladetyper cpu Int Number of CPUs to allocate to the task 8 Optional cladetyper disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional cladetyper docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Optional cladetyper kmer_size Int The kmer size to use for generating the GAMBIT signatures file; see GAMBIT documentation for more details 11 Optional cladetyper max_distance Float The maximum GAMBIT distance to report a clade hit 0.1 Optional cladetyper memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional cladetyper ref_clade1 File The reference assembly for clade 1 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade1_GCA_002759435.3_Cand_auris_B8441_V3_genomic.fasta Optional cladetyper ref_clade1_annotated String The path to the annotated reference for clade 1 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade1_GCA_002759435.3_Cand_auris_B8441_V3_genomic.gbff Optional cladetyper ref_clade2 File The reference assembly for clade 2 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade2_GCA_003013715.2_ASM301371v2_genomic.fasta Optional cladetyper ref_clade2_annotated String The path to the annotated reference for clade 2 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade2_GCA_003013715.2_ASM301371v2_genomic.gbff Optional cladetyper ref_clade3 File The reference assembly for clade 3 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade3_GCF_002775015.1_Cand_auris_B11221_V1_genomic.fasta Optional cladetyper ref_clade3_annotated String The path to the annotated reference for clade 3 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade3_GCF_002775015.1_Cand_auris_B11221_V1_genomic.gbff Optional cladetyper ref_clade4 File The reference assembly for clade 4 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade4_GCA_003014415.1_Cand_auris_B11243_genomic.fasta Optional cladetyper ref_clade4_annotated String The path to the annotated reference for clade 4 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade4_GCA_003014415.1_Cand_auris_B11243_genomic.gbff Optional cladetyper ref_clade5 File The reference assembly for clade 5 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade5_GCA_016809505.1_ASM1680950v1_genomic.fasta Optional cladetyper ref_clade5_annotated String The path to the annotated reference for clade 5 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade5_GCA_016809505.1_ASM1680950v1_genomic.gbff Optional cladetyper ref_clade6 File The reference assembly for clade 6 gs://theiagen-public-resources-rp/reference_data/eukaryotic/candidozyma/Cauris_Clade6_GCA_032714025.1_ASM3271402v1_genomic.fasta Optional cladetyper ref_clade6_annotated String The path to the annotated reference for clade 6 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/standalone/cauris_cladetyper/#workflow-tasks","title":"Workflow Tasks","text":"Cladetyping: clade determination <p>The Cauris_Cladetyper Workflow for Candidozyma auris employs GAMBIT for taxonomic identification, comparing whole genome sequencing data against reference databases to accurately classify Candidozyma auris isolates.</p> <p>A custom GAMBIT database is created using six clade-specific Candidozyma auris reference genomes. Sequences undergo genomic signature comparison against this database, which then enables assignment to one of the six Candidozyma auris clades (Clade I to Clade VI) based on sequence similarity and phylogenetic relationships. This integrated approach ensures precise clade assignments, crucial for understanding the genetic diversity and epidemiology of Candidozyma auris.</p> <p>See more information on the reference information for the six clades below:</p> Clade Genome Accession Assembly Name Strain BioSample Accession Clade I GCA_002759435.3 Cand_auris_B8441_V3 B8441 SAMN05379624 Clade II GCA_003013715.2 ASM301371v2 B11220 SAMN05379608 Clade III GCA_002775015.1 Cand_auris_B11221_V1 B11221 SAMN05379609 Clade IV GCA_003014415.1 Cand_auris_B11243 B11243 SAMN05379619 Clade V GCA_016809505.1 ASM1680950v1 IFRC2087 SAMN11570381 Clade VI GCA_032714025.1 ASM3271402v1 F1580 SAMN36753179 <p>Clade VI annotation</p> <p>Clade VI does not have an available reference genome annotation at the time of adding the reference genome into Cladetyping. While Clade VI assignment is functional, downstream variant calling is not currently possible without an annotation. Users may provide a close relative annotation, such as Clade IV, though it is unknown if Clade VI variants can reliably be called with respect to such a reference. </p> <p>Cauris_Cladetyper Technical Details</p> Links Task task_cauris_cladetyper.wdl Software Source Code GAMBIT on GitHub Software Documentation GAMBIT Overview Original Publication(s) GAMBIT (Genomic Approximation Method for Bacterial Identification and Tracking): A methodology to rapidly leverage whole genome sequencing of bacterial isolates for clinical identification TheiaEuk: a species-agnostic bioinformatics workflow for fungal genomic characterization"},{"location":"workflows/standalone/cauris_cladetyper/#outputs","title":"Outputs","text":"Variable Type Description cauris_cladetyper_wf_analysis_date String Date of analysis cauris_cladetyper_wf_version String Version of PHB used for the analysis cladetyper_annotated_reference String The annotated reference file for the identified clade, \"None\" if no clade was identified/no annotation is inputted cladetyper_clade String The clade assigned to the input assembly cladetyper_docker_image String The Docker container used for the task cladetyper_gambit_version String The version of GAMBIT used for the analysis"},{"location":"workflows/standalone/cauris_cladetyper/#references","title":"References","text":"<p>Lumpe J, Gumbleton L, Gorzalski A, Libuit K, Varghese V, Lloyd T, et al. (2023) GAMBIT (Genomic Approximation Method for Bacterial Identification and Tracking): A methodology to rapidly leverage whole genome sequencing of bacterial isolates for clinical identification. PLoS ONE 18(2): e0277575. https://doi.org/10.1371/journal.pone.0277575</p> <p>Ambrosio, Frank, Michelle Scribner, Sage Wright, James Otieno, Emma Doughty, Andrew Gorzalski, Danielle Siao, et al. 2023. \"TheiaEuk: A Species-Agnostic Bioinformatics Workflow for Fungal Genomic Characterization.\" Frontiers in Public Health 11. https://doi.org/10.3389/fpubh.2023.1198213.</p>"},{"location":"workflows/standalone/concatenate_illumina_lanes/","title":"Concatenate_Illumina_Lanes","text":""},{"location":"workflows/standalone/concatenate_illumina_lanes/#concatenate-illumina-lanes","title":"Concatenate Illumina Lanes","text":""},{"location":"workflows/standalone/concatenate_illumina_lanes/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Standalone Any taxa v2.3.0 Yes Sample-level Concatenate_Illumina_Lanes_PHB"},{"location":"workflows/standalone/concatenate_illumina_lanes/#concatenate_illumina_lanes_phb","title":"Concatenate_Illumina_Lanes_PHB","text":"<p>Some Illumina machines produce multi-lane FASTQ files for a single sample. This workflow concatenates the multiple lanes into a single FASTQ file per read type (forward or reverse).</p>"},{"location":"workflows/standalone/concatenate_illumina_lanes/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status concatenate_illumina_lanes read1_lane1 File The first lane for the forward reads Required concatenate_illumina_lanes read1_lane2 File The second lane for the forward reads Required concatenate_illumina_lanes samplename String The name of the sample being analyzed Required cat_lanes cpu Int Number of CPUs to allocate to the task 2 Optional cat_lanes disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional cat_lanes docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.2 Optional cat_lanes memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional concatenate_illumina_lanes read1_lane3 File The third lane for the forward reads Optional concatenate_illumina_lanes read1_lane4 File The fourth lane for the forward reads Optional concatenate_illumina_lanes read2_lane1 File The first lane for the reverse reads Optional concatenate_illumina_lanes read2_lane2 File The second lane for the reverse reads Optional concatenate_illumina_lanes read2_lane3 File The third lane for the reverse reads Optional concatenate_illumina_lanes read2_lane4 File The fourth lane for the reverse reads Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/standalone/concatenate_illumina_lanes/#workflow-tasks","title":"Workflow Tasks","text":"<p>This workflow concatenates the Illumina lanes for forward and (if provided) reverse reads. The output files are named as followed:</p> <ul> <li>Forward reads: <code>&lt;samplename&gt;_merged_R1.fastq.gz</code></li> <li>Reverse reads: <code>&lt;samplename&gt;_merged_R2.fastq.gz</code></li> </ul>"},{"location":"workflows/standalone/concatenate_illumina_lanes/#outputs","title":"Outputs","text":"Variable Type Description concatenate_illumina_lanes_analysis_date String Date of analysis concatenate_illumina_lanes_version String Version of PHB used for the analysis read1_concatenated File Concatenated forward reads read2_concatenated File Concatenated reverse reads"},{"location":"workflows/standalone/dorado_basecalling/","title":"Dorado_Basecalling","text":""},{"location":"workflows/standalone/dorado_basecalling/#dorado-basecalling","title":"Dorado Basecalling","text":""},{"location":"workflows/standalone/dorado_basecalling/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Standalone Any taxa v3.0.1 No Sample-level Dorado_Basecalling_PHB"},{"location":"workflows/standalone/dorado_basecalling/#dorado_basecalling_phb","title":"Dorado_Basecalling_PHB","text":"<p>The Dorado Basecalling workflow is used to convert Oxford Nanopore <code>POD5</code> sequencing files into <code>FASTQ</code> format by using a GPU-accelerated environment. This workflow is ideal for high-throughput applications where fast and accurate basecalling is essential. Users upload POD5 files to a Google Cloud Storage (GCS) bucket, and then provide that directory's path as a workflow input. The workflow basecalls all POD5 files in the provided location, and then outputs final FASTQ files to a user-designated Terra table for downstream analysis.</p> <p>Dorado_Basecalling_PHB Workflow Diagram</p> <p></p>"},{"location":"workflows/standalone/dorado_basecalling/#configuring-workflow-in-terra","title":"Configuring Workflow in Terra","text":"<p>We recommend running this workflow with \"Run workflow with inputs defined by file paths\" selected in Terra. This allows the user to skip the step of creating a Terra table for the POD5 files. The user will only need to provide the GCS path of the POD5 files, and the workflow will automatically find and basecall all POD5 files in that location. The resulting FASTQ files will be added to a Terra table of your choice.</p> Uploading POD5 Files to Terra <code>pod5_bucket_path</code> <p>To run the Dorado Basecalling Workflow, you must first upload your <code>POD5 files</code> to a Google Cloud Storage (GCS) bucket within your Terra workspace. Follow these steps:</p> <ol> <li> <p>Use the Terra Data Uploader</p> <p>Go to the \"Data\" tab in your Terra workspace. Click \"Upload Files\" and select your <code>POD5</code> files for upload. Confirm the upload process and wait for the files to be uploaded.</p> </li> <li> <p>Copy the GCS Path</p> <p>After the upload is complete, right-click the collection name and select \"Copy link address\"</p> <p>Copy link address</p> <p></p> </li> <li> <p>Paste the GCS Path into the Workflow Input</p> <p>Open the workflow configuration screen in Terra. Paste the copied GCS path into the <code>pod5_bucket_path</code> input field for the Dorado Basecalling Workflow. </p> <p>Make sure the select the <code>\"Run workflow with inputs defined by file paths\"</code> option, as shown.</p> <p>Workflow Inputs</p> <p></p> </li> </ol>"},{"location":"workflows/standalone/dorado_basecalling/#model-type-selection","title":"Model Type Selection","text":"<p>Users can configure the basecalling model by setting the <code>dorado_model</code> input parameter.</p> <p>Automatic Model Detection: When <code>dorado_model</code> is set to either <code>sup</code>, <code>hac</code>, or <code>fast</code>, Dorado will automatically select the appropriate model version if available.</p> <ul> <li><code>sup</code> (super-accurate): This model is the most accurate and is recommended for applications requiring the highest basecall accuracy. It is the slowest of the three model types and requires the most computational resources. This is the default model for this workflow.</li> <li><code>hac</code> (high-accuracy): This model provides a balance between speed and accuracy. This model basecalls faster than <code>sup</code>, but those basecalls will be less accurate. It is recommended for most users by the Dorado developers.</li> <li><code>fast</code> (fast model): This model is the fastest and least accurate and is recommended when speed is prioritized over accuracy, such as for initial analyses or non-critical applications.</li> </ul> <p>Manual Model Input: Alternatively, users can specify either a simplex model path or a model complex (e.g.<code>dna_r10.4.1_e8.2_400bps_hac@v4.2.0</code> or <code>hac,5mCG_5hmCG</code>). Please see the Dorado documentation for more details on the manual model naming conventions. You can also find the full list of available simplex and modified basecalling models here.</p> <p>Example Manual Models</p> <ul> <li><code>sup,5mCG_5hmCG,6mA</code></li> <li><code>dna_r10.4.1_e8.2_400bps_hac@v4.3.0_6mA@v1</code></li> <li><code>sup@v4.2.0,6mA@v1</code></li> </ul>"},{"location":"workflows/standalone/dorado_basecalling/#supported-kit-names","title":"Supported Kit Names","text":"<p>Ensure you use an accepted barcoding kit name in the <code>kit_name</code> parameter. Check if your barcoding kit is supported by the Dorado workflow by clicking the toggle below. If not, please contact support@theiagen.com for assistance</p> Click to see a list of currently accepted kit names <ul> <li>EXP-NBD103</li> <li>EXP-NBD104</li> <li>EXP-NBD114</li> <li>EXP-NBD114-24</li> <li>EXP-NBD196</li> <li>EXP-PBC001</li> <li>EXP-PBC096</li> <li>SQK-16S024</li> <li>SQK-16S114-24</li> <li>SQK-LWB001</li> <li>SQK-MLK111-96-XL</li> <li>SQK-MLK114-96-XL</li> <li>SQK-NBD111-24</li> <li>SQK-NBD111-96</li> <li>SQK-NBD114-24</li> <li>SQK-NBD114-96</li> <li>SQK-PBK004</li> <li>SQK-PCB109</li> <li>SQK-PCB110</li> <li>SQK-PCB111-24</li> <li>SQK-PCB114-24</li> <li>SQK-RAB201</li> <li>SQK-RAB204</li> <li>SQK-RBK001</li> <li>SQK-RBK004</li> <li>SQK-RBK110-96</li> <li>SQK-RBK111-24</li> <li>SQK-RBK111-96</li> <li>SQK-RBK114-24</li> <li>SQK-RBK114-96</li> <li>SQK-RLB001</li> <li>SQK-RPB004</li> <li>SQK-RPB114-24</li> <li>TWIST-16-UDI</li> <li>TWIST-96A-UDI</li> <li>VSK-PTC001</li> <li>VSK-VMK001</li> <li>VSK-VMK004</li> <li>VSK-VPS001</li> </ul>"},{"location":"workflows/standalone/dorado_basecalling/#inputs","title":"Inputs","text":"<p>Detailed Input Information</p> <ul> <li>dorado_model: If set to 'sup', 'hac', or 'fast', the workflow will run with automatic model selection. If a full model name is provided, Dorado will use that model directly. See the Model Type Selection section for more details.</li> <li> <p>output_file_prefix: This will serve as a prefix for the output FASTQ files. For example, if you provide <code>project001</code>, the resulting files will be named <code>project001-barcodeXX.fastq.gz</code>.</p> <p><code>output_file_prefix</code> suggestions</p> <ul> <li>Avoid special characters: Do not include special characters (such as <code>/</code>, or <code>&amp;</code>) or whitespace in the <code>output_file_prefix</code> variable</li> <li>Use a clear, simple prefix: The prefix <code>projectname</code> will be automatically prepended to identifiers like <code>-barcodeXX.fastq.gz</code> or <code>-unclassified.fastq.gz</code> to name each output file, ensuring each one is distinct.</li> </ul> </li> <li> <p>kit_name: Ensure the correct kit name is provided, as it determines the barcoding and adapter trimming behavior. See the Supported Kit Names section for a list of accepted kit names.</p> </li> </ul> <p>Increasing Chunk Size</p> <p>The identified pod5 files will be split into four groups (or the number indicated by <code>number_chunks</code>) for basecalling. You can decrease runtime by raising the number of chunks with the <code>number_chunks</code> variable.</p> <p>We recommend keeping the number of chunks under 20 if running this workflow on Terra in order to prevent VM allocation times from drastically increasing. Walltime drastically increases as the number of chunks nears 20 (upwards of hours to days longer) despite relatively low CPU time.</p> <p>If the number of chunks is MORE than the number of pod5 files identified, the number of chunks will be set to the number of identified pod5 files.</p> Terra Task Name Variable Type Description Default Value Terra Status dorado_basecalling kit_name String Sequencing kit name used (e.g., SQK-RPB114-24); see above for all available options. Required dorado_basecalling new_table_name String The desired name for a newly created Terra table that will contain the basecalled FASTQ files. This value should be the name as you want the table to appear as in the sidebar on the lefthand side of the Terra Data tab. Required dorado_basecalling output_file_prefix String Prefix for naming output FASTQ files Required dorado_basecalling pod5_bucket_path String GCS path of the bucket containing POD5 files. Required dorado_basecalling terra_project String The name of your Terra project. You can find this information in the URL of the webpage of your Terra dashboard. For example, if your URL contains #workspaces/example/my_workspace/ then your project name is example Required dorado_basecalling terra_workspace String The name of your Terra workspace where your samples can be found. For example, if your URL contains #workspaces/example/my_workspace/ then your workspace name is my_workspace Required chunk_files cpu Int Number of CPUs to allocate to the task 1 Optional chunk_files disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional chunk_files docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/utility:1.1 Optional chunk_files memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional create_table_from_array cpu Int Number of CPUs to allocate to the task 1 Optional create_table_from_array disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional create_table_from_array docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-06-21 Optional create_table_from_array memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional dorado_basecall cpu Int Number of CPUs to allocate to the task 8 Optional dorado_basecall disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional dorado_basecall docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/dorado:0.9.0-cuda12.2.0 Optional dorado_basecall memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional dorado_basecalling custom_primers File A FASTA file containing custom primer sequences for PCR primer trimming during demultiplexing. Optional dorado_basecalling demux_no_trim Boolean Set to true to disable barcode trimming during demultiplexing. FALSE Optional dorado_basecalling dorado_model String The model to use during basecalling ('sup' for super accuracy, 'hac' for high accuracy, or 'fast' for high speed). Users may also specify a full model name (see above for more details). sup Optional dorado_basecalling number_chunks Int The number of chunks to split the input files into for basecalling; increasing chunk size can decrease runtime, though too high of a chunk size will be detrimental instead of beneficial due to resource allocation and quota limits 4 Optional dorado_demux cpu Int Number of CPUs to allocate to the task 4 Optional dorado_demux disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional dorado_demux docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/dorado:0.9.0-cuda12.2.0 Optional dorado_demux memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional dorado_trim cpu Int Number of CPUs to allocate to the task 4 Optional dorado_trim disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional dorado_trim docker String The Docker container to use for the task. This is not the most up-to-date image since there is a bug with this Dorado subcommand in v0.9.0 us-docker.pkg.dev/general-theiagen/staphb/dorado:0.8.3 Optional dorado_trim memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional find_files cpu Int Number of CPUs to allocate to the task 1 Optional find_files disk_size Int Amount of storage (in GB) to allocate to the task 25 Optional find_files docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/cloudsdktool/google-cloud-cli:427.0.0-alpine Optional find_files memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/standalone/dorado_basecalling/#workflow-tasks","title":"Workflow Tasks","text":"<p>This workflow is composed of several tasks to process, basecall, and analyze Oxford Nanopore <code>POD5</code> files.</p> <code>find_files</code>: Identifying all POD5 files in the <code>pod5_bucket_path</code> <p>Since this workflow only recieves a location for the POD5 files, this task was created to search the <code>pod5_bucket_path</code> location in order to create a list of all included POD5 files so that later tasks can perform basecalling on them. By default, this task is configured to search for <code>.pod5</code> files.</p> <p>Find Files Technical Details</p> Links Task task_find_files.wdl <code>chunk_files</code>: Splitting POD5 files into groups for parallel basecalling <p>In order to improve runtime, POD5 files are split into groups or \"chunks\" for basecalling. The number of chunks can be indicated by providing a value for the <code>number_chunks</code> value. By default, the number of chunks is four.</p> <p>Chunk Files Technical Details</p> Links Task task_chunk_files.wdl <code>dorado_basecall</code>: Basecalling POD5 files <p>The basecalling task takes POD5 files as input and converts each individual POD5 into 'BAM' format using the either the default or user-specified model. This step leverages GPU acceleration for efficient processing.</p> <p>Please see the Dorado documentation for more details, but what follows is a brief overview of the basecalling process:</p> <ol> <li>POD5 files are pre-processed via signal scaling and normalization.</li> <li>The machine learning algorithm decodes the sequence signals into nucleotide base calls. There are different machine learning models that can be specified as input; more details can be found above here.</li> <li> <p>Barcode classification is performed based on the indicated kit name to enable downstream demultiplexing. </p> <p>Barcode Trimming</p> <p>Barcode trimming is purposefully disabled during the basecalling step to ensure accurate demultiplexing in subsequent workflow steps.</p> </li> <li> <p>Modified basecalling can be performed if indicated through modification to the model name.</p> </li> <li>Reads are split when a single read contains multiple concatenated reads.</li> </ol> <p>Other options are available, but currently Dorado_Basecalling_PHB does not support them. Please contact support@theiagen.com if you would like additional options.</p> <p>Dorado Basecalling Technical Details</p> Links Task task_dorado_basecall.wdl Software Source Code Dorado on GitHub Software Documentation Dorado ReadTheDocs <code>dorado_demux</code>: Produces barcode-specific FASTQ files <p>This task takes every basecalled BAM files and demultiplexes them based on the identified barcodes found during basecalling. An individual FASTQ file is generated for each barcode found per BAM file. All FASTQ files that are associated with a single barcode are then merged.</p> <p>Disabling Barcode Trimming</p> <p>By default, barcodes are trimmed during demultiplexing. </p> <p>This can be disabled by setting the optional input variable <code>demux_no_trim</code> to <code>true</code>. This allows users to retain untrimmed reads for troubleshooting, such as inspecting reads in the \"unclassified\" folder when reads are mis-binned or other data issues occur.</p> <p>Dorado Demultiplexing Technical Details</p> Links Task task_dorado_demux.wdl Software Source Code Dorado on GitHub Software Documentation Dorado ReadTheDocs <code>dorado_trim</code>: Custom Primer Trimming (optional) <p>If a the optional input <code>custom_primers</code> is provided, this task is activated that will trim the primer sequences from the beginning and end of the demultiplexed reads.</p> <p>To determine how to format the FASTA file that is expected in <code>custom_primers</code> please see the Dorado documentation, specifically the section on \"Custom adapter/primer file format\".</p> <p>Older Dorado Version Used</p> <p>The Dorado version used in this task is not the most up-to-date version (set to v0.8.3) due to a bug in the Dorado subcommand in the latest version (v0.9.0). This will be updated in the future when the bug has been resolved by the Dorado developers. </p> <p>Dorado Trimming Technical Details</p> Links Task task_dorado_trim.wdl Software Source Code Dorado on GitHub Software Documentation Dorado ReadTheDocs <code>create_table_from_array</code>: Creates a Terra table with FASTQ files <p>The final task in this workflow will create a Terra table using the array of generated FASTQ files. This table will be named according to the <code>new_table_name</code> input variable and will contain all the FASTQ files generated during the workflow. The new table will contain the following columns with a row for each identified barcode and a single row for any unclassified reads.</p> <ul> <li><code>dorado_basecalling_analysis_date</code>: Date of Dorado analysis</li> <li><code>dorado_basecalling_phb_version</code>: Version of PHB used for the analysis</li> <li><code>dorado_docker</code>: Docker image used in the <code>dorado_basecall</code> task</li> <li><code>dorado_version</code>: Version of Dorado used in the <code>dorado_basecall</code> task</li> <li><code>dorado_model_name</code>: Model used for basecalling</li> <li><code>read1</code>: the FASTQ file containing the read name</li> <li><code>table_created_by</code>: this column will indicate that this table was created by \"Dorado_Basecalling_PHB\"</li> <li><code>upload_date</code>: the date the table was uploaded to Terra</li> </ul> <p>This table will be uploaded to the Terra workspace as indicated through the <code>terra_project</code> and <code>terra_workspace</code> input variables.</p> <p>Create Table from Array Technical Details</p> Links Task task_create_terra_table.wdl"},{"location":"workflows/standalone/dorado_basecalling/#outputs","title":"Outputs","text":"<p>Please note that if you run this workflow with the <code>\"Run workflow with inputs defined by file paths\"</code> option selected in Terra, these outputs will not be visible in a Terra table, but can be found in the Job Manager.</p> Variable Type Description dorado_basecall_docker String Docker image used in the <code>dorado_basecall</code> task dorado_basecall_version String Version of Dorado used in the <code>dorado_basecall</code> task dorado_basecalling_analysis_date String Date of Dorado analysis dorado_basecalling_phb_version String Version of PHB used for the analysis dorado_demux_version String Version of Dorado used in the <code>dorado_demux</code> task dorado_model_used String Model used for basecalling dorado_trim_version String Version of Dorado used in the <code>dorado_trim</code> task fastq_files Array[File] FASTQ files produced from basecalling and demultiplexing terra_table_tsv File TSV file used when uploading the Terra table of FASTQ files"},{"location":"workflows/standalone/dorado_basecalling/#references","title":"References","text":"<p>https://github.com/nanoporetech/dorado/</p>"},{"location":"workflows/standalone/gambit_query/","title":"GAMBIT_Query","text":""},{"location":"workflows/standalone/gambit_query/#gambit_query","title":"GAMBIT_Query","text":""},{"location":"workflows/standalone/gambit_query/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Standalone Bacteria, Mycotics v2.0.0 Yes Sample-level Gambit_Query_PHB"},{"location":"workflows/standalone/gambit_query/#gambit_query_phb","title":"GAMBIT_Query_PHB","text":"<p>The GAMBIT_Query_PHB workflow performs taxon assignment of a genome assembly using the GAMBIT task.</p>"},{"location":"workflows/standalone/gambit_query/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status gambit_query assembly_fasta File The assembly file for your sample in FASTA format Required gambit_query samplename String The name of the sample being analyzed Required gambit cpu Int Number of CPUs to allocate to the task 1 Optional gambit disk_size Int Amount of storage (in GB) to allocate to the task 20 Optional gambit docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/gambit:1.0.0 Optional gambit gambit_db_genomes File Database of metadata for assembled query genomes; requires complementary signatures file. If not provided, uses default database \"/gambit-db\" gs://gambit-databases-rp/2.0.0/gambit-metadata-2.0.1-20250505.gdb Optional gambit gambit_db_signatures File Signatures file; requires complementary genomes file. If not specified, the file from the docker container will be used. gs://gambit-databases-rp/2.0.0/gambit-signatures-2.0.1-20250505.gs Optional gambit memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/standalone/gambit_query/#workflow-tasks","title":"Workflow Tasks","text":"<code>GAMBIT</code>: Taxon Assignment <p><code>GAMBIT</code> determines the taxon of the genome assembly using a k-mer based approach to match the assembly sequence to the closest complete genome in a database, thereby predicting its identity. Sometimes, GAMBIT can confidently designate the organism to the species level. Other times, it is more conservative and assigns it to a higher taxonomic rank.</p> <p>For additional details regarding the GAMBIT tool and a list of available GAMBIT databases for analysis, please consult the GAMBIT tool documentation.</p> <p>GAMBIT Technical Details</p> Links Task task_gambit.wdl Software Source Code GAMBIT on GitHub Software Documentation GAMBIT ReadTheDocs Original Publication(s) GAMBIT (Genomic Approximation Method for Bacterial Identification and Tracking): A methodology to rapidly leverage whole genome sequencing of bacterial isolates for clinical identification"},{"location":"workflows/standalone/gambit_query/#outputs","title":"Outputs","text":"Variable Type Description gambit_closest_genomes File CSV file listing genomes in the GAMBIT database that are most similar to the query assembly gambit_db_version String Version of the GAMBIT database used gambit_docker String GAMBIT Docker used gambit_predicted_taxon String Taxon predicted by GAMBIT gambit_predicted_taxon_rank String Taxon rank of GAMBIT taxon prediction gambit_query_wf_analysis_date String Date of analysis gambit_query_wf_version String PHB repository version gambit_report File GAMBIT report in a machine-readable format gambit_version String Version of GAMBIT software used <p>GAMBIT (Genomic Approximation Method for Bacterial Identification and Tracking): A methodology to rapidly leverage whole genome sequencing of bacterial isolates for clinical identification. Lumpe et al. PLOS ONE, 2022. DOI: 10.1371/journal.pone.0277575</p>"},{"location":"workflows/standalone/kraken2/","title":"Kraken2","text":""},{"location":"workflows/standalone/kraken2/#kraken2","title":"Kraken2","text":""},{"location":"workflows/standalone/kraken2/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Standalone Any taxa v3.1.0 Yes Sample-level Kraken2_PE_PHB, Kraken2_SE_PHB, Kraken2_ONT_PHB"},{"location":"workflows/standalone/kraken2/#kraken2-workflows","title":"Kraken2 Workflows","text":"<p>The Kraken2 workflows assess the taxonomic profile of raw sequencing data (FASTQ files).</p> <p>Kraken2 is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>There are three Kraken2 workflows:</p> <ul> <li><code>Kraken2_PE</code> is compatible with Illumina paired-end data</li> <li><code>Kraken2_SE</code> is compatible with Illumina single-end data</li> <li><code>Kraken2_ONT</code> is compatible with Oxford Nanopore data</li> </ul> <p>Besides the data input types, there are minimal differences between these two workflows.</p> <p>Kraken2 Workflow Diagram</p> <p></p>"},{"location":"workflows/standalone/kraken2/#databases","title":"Databases","text":"<p>Database selection</p> <p>The Kraken2 software is database-dependent and taxonomic assignments are highly sensitive to the database used. An appropriate database should contain the expected organism(s) (e.g. Escherichia coli) and other taxa that may be present in the reads (e.g. Citrobacter freundii, a common contaminant).</p>"},{"location":"workflows/standalone/kraken2/#suggested-databases","title":"Suggested databases","text":"Database name Database Description Suggested Applications GCP URI (for usage in Terra) Source Database Size (GB) Date of Last Update Kalamari v5.1 Kalamari is a database of complete public assemblies, that has been fine-tuned for enteric pathogens and is backed by trusted institutions. Full list available here ( in chromosomes.tsv and plasmids.tsv) Single-isolate enteric bacterial pathogen analysis (Salmonella, Escherichia, Shigella, Listeria, Campylobacter, Vibrio, Yersinia) <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2.kalamari_5.1.tar.gz</code> \u2023 1.5 18/5/2022 standard 8GB Standard RefSeq database (archaea, bacteria, viral, plasmid, human, UniVec_Core) capped at 8GB Prokaryotic or viral organisms, but for enteric pathogens, we recommend Kalamari <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/k2_standard_08gb_20240112.tar.gz</code> https://benlangmead.github.io/aws-indexes/k2 7.5 12/1/2024 standard 16GB Standard RefSeq database (archaea, bacteria, viral, plasmid, human, UniVec_Core) capped at 16GB Prokaryotic or viral organisms, but for enteric pathogens, we recommend Kalamari <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/k2_standard_16gb_20240112.tar.gz</code> https://benlangmead.github.io/aws-indexes/k2 15 12/1/2024 standard Standard RefSeq database (archaea, bacteria, viral, plasmid, human, UniVec_Core) Prokaryotic or viral organisms, but for enteric pathogens, we recommend Kalamari <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/k2_standard_20240112.tar.gz</code> https://benlangmead.github.io/aws-indexes/k2 72 18/4/2023 viral RefSeq viral Viral metagenomics <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/k2_viral_20240112.tar.gz</code> https://benlangmead.github.io/aws-indexes/k2 0.6 12/1/2024 EuPathDB48 Eukaryotic pathogen genomes with contaminants removed. Full list available here Eukaryotic organisms (Candida spp., Aspergillus spp., etc) <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/k2_eupathdb48_20201113.tar.gz</code> https://benlangmead.github.io/aws-indexes/k2 30.3 13/11/2020 EuPathDB48 Eukaryotic pathogen genomes with contaminants removed. Full list available here Eukaryotic organisms (Candida spp., Aspergillus spp., etc) <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/k2_eupathdb48_20230407.tar.gz</code> https://benlangmead.github.io/aws-indexes/k2 11 7/4/2023"},{"location":"workflows/standalone/kraken2/#inputs","title":"Inputs","text":"Kraken_PEKraken_SEKraken_ONT Terra Task Name Variable Type Description Default Value Terra Status kraken2_pe_wf kraken2_db File A Kraken2 database in .tar.gz format Required kraken2_pe_wf read1 File Forward read in FASTQ file format (compression optional) Required kraken2_pe_wf read2 File Illumina reverse read file in FASTQ file format (compression optional) Required kraken2_pe_wf samplename String The name of the sample being analyzed Required kraken2_pe classified_out String Allows user to rename the classified FASTQ files output. Must include .fastq as the suffix classified#.fastq Optional kraken2_pe cpu Int Number of CPUs to allocate to the task 4 Optional kraken2_pe disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional kraken2_pe docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Optional kraken2_pe kraken2_args String Allows a user to supply additional kraken2 command-line arguments Optional kraken2_pe memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional kraken2_pe unclassified_out String Allows user to rename unclassified FASTQ files output. Must include .fastq as the suffix unclassified#.fastq Optional krona cpu Int Number of CPUs to allocate to the task 2 Optional krona disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional krona docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/krona:2.8.1 Optional krona memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status kraken2_se_wf kraken2_db File A Kraken2 database in .tar.gz format Required kraken2_se_wf read1 File Forward read in FASTQ file format (compression optional) Required kraken2_se_wf samplename String The name of the sample being analyzed Required kraken2_se classified_out String Allows user to rename the classified FASTQ files output. Must include .fastq as the suffix classified#.fastq Optional kraken2_se cpu Int Number of CPUs to allocate to the task 4 Optional kraken2_se disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional kraken2_se docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Optional kraken2_se kraken2_args String Allows a user to supply additional kraken2 command-line arguments Optional kraken2_se memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional kraken2_se read2 File Internal component, do not modify Optional kraken2_se unclassified_out String Allows user to rename unclassified FASTQ files output. Must include .fastq as the suffix unclassified#.fastq Optional krona cpu Int Number of CPUs to allocate to the task 2 Optional krona disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional krona docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/krona:2.8.1 Optional krona memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status kraken2_ont_wf kraken2_db File A Kraken2 database in .tar.gz format Required kraken2_ont_wf read1 File Forward read in FASTQ file format (compression optional) Required kraken2_ont_wf samplename String The name of the sample being analyzed Required kraken2_recalculate_abundances cpu Int Number of CPUs to allocate to the task 4 Optional kraken2_recalculate_abundances disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional kraken2_recalculate_abundances docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-08-28-v4 Optional kraken2_recalculate_abundances memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional kraken2_recalculate_abundances target_organism String Target organism for the kraken2 abundance to be exported to the data table Optional kraken2_se classified_out String Allows user to rename the classified FASTQ files output. Must include .fastq as the suffix classified#.fastq Optional kraken2_se cpu Int Number of CPUs to allocate to the task 4 Optional kraken2_se disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional kraken2_se docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Optional kraken2_se kraken2_args String Allows a user to supply additional kraken2 command-line arguments Optional kraken2_se memory Int Amount of memory/RAM (in GB) to allocate to the task 32 Optional kraken2_se read2 File Internal component, do not modify Optional kraken2_se unclassified_out String Allows user to rename unclassified FASTQ files output. Must include .fastq as the suffix unclassified#.fastq Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/standalone/kraken2/#workflow-tasks","title":"Workflow Tasks","text":"Kraken2 <p><code>Kraken2</code> is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>Database-dependent</p> <p>This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz</code>.</p> <p>This workflow is database dependent, and one is required to run this task. Please see above for a list of suggested databases to provide through the <code>kraken2_db</code> input variable.</p> <p>Kraken2 Technical Details</p> Links Task task_kraken2.wdl Software Source Code Kraken2 on GitHub Software Documentation Kraken2 Documentation Original Publication(s) Improved metagenomic analysis with Kraken 2"},{"location":"workflows/standalone/kraken2/#outputs","title":"Outputs","text":"Kraken_PEKraken_SEKraken_ONT Variable Type Description kraken2_classified_read1 File FASTQ file of classified forward/R1 reads kraken2_classified_read2 File FASTQ file of classified reverse/R2 reads (if PE) kraken2_classified_report File Standard Kraken2 output report. TXT filetype, but can be opened in Excel as a TSV file kraken2_docker String Docker image used to run kraken2 kraken2_pe_wf_analysis_date String Date the workflow was run kraken2_pe_wf_version String Workflow version kraken2_report File TXT document describing taxonomic prediction of every FASTQ record. This file is usually very large and cumbersome to open and view kraken2_unclassified_read1 File FASTQ file of unclassified forward/R1 reads kraken2_unclassified_read2 File FASTQ file of unclassified reverse/R2 reads (if PE) kraken2_version String The version of kraken2 used krona_docker String The docker image of Krona krona_html File HTML report of krona with visualisation of taxonomic classification of reads (if PE or SE) krona_version String The version of Krona Variable Type Description kraken2_classified_read1 File FASTQ file of classified forward/R1 reads kraken2_classified_report File Standard Kraken2 output report. TXT filetype, but can be opened in Excel as a TSV file kraken2_docker String Docker image used to run kraken2 kraken2_report File TXT document describing taxonomic prediction of every FASTQ record. This file is usually very large and cumbersome to open and view kraken2_se_wf_analysis_date String Date the workflow was run kraken2_se_wf_version String Workflow version kraken2_unclassified_read1 File FASTQ file of unclassified forward/R1 reads kraken2_version String The version of kraken2 used krona_docker String The docker image of Krona krona_html File HTML report of krona with visualisation of taxonomic classification of reads (if PE or SE) krona_version String The version of Krona Variable Type Description kraken2_classified_read1 File FASTQ file of classified forward/R1 reads kraken2_classified_report File Standard Kraken2 output report. TXT filetype, but can be opened in Excel as a TSV file kraken2_docker String Docker image used to run kraken2 kraken2_report File TXT document describing taxonomic prediction of every FASTQ record. This file is usually very large and cumbersome to open and view kraken2_se_wf_analysis_date String Date the workflow was run kraken2_se_wf_version String Workflow version kraken2_unclassified_read1 File FASTQ file of unclassified forward/R1 reads kraken2_version String The version of kraken2 used"},{"location":"workflows/standalone/kraken2/#interpretation-of-results","title":"Interpretation of results","text":"<p>The most important outputs of the Kraken2 workflows are the <code>kraken2_report</code> files. These will include a breakdown of the number of sequences assigned to a particular taxon, and the percentage of reads assigned. A complete description of the report format can be found here.</p> <p>When assessing the taxonomic identity of a single isolate's sequence, it is normal that a few reads are assigned to very closely rated taxa due to the shared sequence identity between them. \"Very closely related taxa\" may be genetically similar species in the same genus, or taxa with which the dominant species have undergone horizontal gene transfer. Unrelated taxa or a high abundance of these closely related taxa is indicative of contamination or sequencing of non-target taxa. Interpretation of the results is dependent on the biological context.</p> Example Kraken2 report <p>Below is an example <code>kraken2_report</code> for a Klebsiella pneumoniae sample. Only the first 30 lines are included here since rows near the bottom are often spurious results with only a few reads assigned to a non-target organism.</p> <p>From this report, we can see that 84.35 % of the reads were assigned at the species level (<code>S</code> in the 4th column) to \"Klebsiella pneumoniae\". Given almost 6 % of reads were \"unclassified\" and ~2 % of reads were assigned to very closely related taxa (in the Klebsiella genus), this suggests the reads are from Klebsiella pneumoniae with very little -if any- read contamination. </p> <pre><code> 5.98    108155 108155  U   0   unclassified\n 94.02  1699669 0   C   1   \n 94.02  1699669 1862    C1  131567    cellular organisms\n 93.91  1697788 2590    D   2       Bacteria\n 93.75  1694805 6312    P   1224          Proteobacteria\n 93.39  1688284 37464   C   1236            Gammaproteobacteria\n 91.31  1650648 35278   O   91347             Enterobacterales\n 89.31  1614639 43698   F   543             Enterobacteriaceae\n 86.40  1561902 22513   G   570               Klebsiella\n **84.35    1524918 1524918 S   573                 Klebsiella pneumoniae**\n  0.75  13596   13596   S   548                 Klebsiella aerogenes\n  0.03  600 600 S   244366                  Klebsiella variicola\n  0.01  253 253 S   571                 Klebsiella oxytoca\n  0.00  17  17  S   1134687                 Klebsiella michiganensis\n  0.00  3   0   G1  2608929                 unclassified Klebsiella\n  0.00  3   3   S   1972757                   Klebsiella sp. PO552\n  0.00  2   2   S   1463165                 Klebsiella quasipneumoniae\n  0.17  3035    129 G   590               Salmonella\n  0.15  2728    909 S   28901                   Salmonella enterica\n  0.03  582 582 S1  9000010                   Salmonella enterica subsp. IIa\n  0.02  306 306 S1  59201                     Salmonella enterica subsp. enterica\n  0.01  230 230 S1  9000014                   Salmonella enterica subsp. IIIa\n  0.01  221 221 S1  9000015                   Salmonella enterica subsp. IIIb\n  0.01  136 136 S1  9000016                   Salmonella enterica subsp. IX\n  0.01  132 132 S1  9000011                   Salmonella enterica subsp. IIb\n  0.01  122 122 S1  59208                     Salmonella enterica subsp. VII\n  0.00  41  41  S1  59207                     Salmonella enterica subsp. indica\n  0.00  25  25  S1  9000017                   Salmonella enterica subsp. X\n  0.00  24  24  S1  9000009                   Salmonella enterica subsp. VIII\n  0.01  178 178 S   54736                   Salmonella bongori\n</code></pre>"},{"location":"workflows/standalone/kraken2/#krona-visualisation-of-kraken2-report","title":"Krona visualisation of Kraken2 report","text":"<p>Krona produces an interactive report that allows hierarchical data, such as the one from Kraken2, to be explored with zooming, multi-layered pie charts. These pie charts are intuitive and highly responsive.</p> Example Krona report <p>Below is an example of the <code>krona_html</code> for a bacterial sample. Taxonomic rank is organised from the centre of the pie chart to the edge, with each slice representing the relative abundance of a given taxa in the sample.</p> <p></p> <p>Kraken2 Technical Details</p> Links Software Source Code Kraken2 on GitHub Software Documentation https://github.com/DerrickWood/kraken2/blob/master/docs/MANUAL.markdown Original Publication(s) Improved metagenomic analysis with Kraken 2"},{"location":"workflows/standalone/ncbi_amrfinderplus/","title":"NCBI-AMRFinderPlus","text":""},{"location":"workflows/standalone/ncbi_amrfinderplus/#ncbi-amrfinderplus","title":"NCBI-AMRFinderPlus","text":""},{"location":"workflows/standalone/ncbi_amrfinderplus/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Standalone Bacteria, Mycotics v3.0.1 Yes Sample-level NCBI-AMRFinderPlus_PHB"},{"location":"workflows/standalone/ncbi_amrfinderplus/#ncbiamrfinderplus_phb","title":"NCBIAMRFinderPlus_PHB","text":"<p>AMRFinderPlus identifies acquired antimicrobial resistance (AMR) genes, virulence genes, and stress genes.  Such AMR genes confer resistance to antibiotics, metals, biocides, heat, or acid. For some taxa (see here), AMRFinderPlus will provide taxa-specific results including filtering out genes that are almost ubiquitous in the taxa (intrinsic genes) and identifying resistance-associated point mutations.  In TheiaProk, the taxon used by AMRFinderPlus is specified based on the <code>gambit_predicted_taxon</code> or a user-provided <code>expected_taxon</code>.</p> <p>You can check if a gene or point mutation is in the AMRFinderPlus database here, find the sequences of reference genes here, and search the query Hidden Markov Models (HMMs) used by AMRFinderPlus to identify AMR genes and some stress and virulence proteins (here). The AMRFinderPlus database is updated frequently. You can ensure you are using the most up-to-date version by specifying the docker image as a workflow input. You might like to save this docker image as a workspace data element to make this easier.</p>"},{"location":"workflows/standalone/ncbi_amrfinderplus/#use-cases","title":"\ud83d\udccb Use Cases","text":"<ul> <li>To run ONLY AMRFinderPlus software instead of running the entire TheiaProk workflow. This workflow will run much faster than the TheiaProk workflows.</li> <li>To update AMRFinderPlus results when a new version of the software and/or its database are released by the NCBI developers.</li> </ul>"},{"location":"workflows/standalone/ncbi_amrfinderplus/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status amrfinderplus_wf assembly File The assembly file for your sample in FASTA format Required amrfinderplus_wf samplename String The name of the sample being analyzed Required amrfinderplus_nuc annotation_assembly File Assembly file from annotation software such as Prokka or Bakta, used for utilizing protein fasta and GFF files. Optional amrfinderplus_nuc annotation_format String The format of the annotation files Optional amrfinderplus_nuc cpu Int Number of CPUs to allocate to the task 2 Optional amrfinderplus_nuc detailed_drug_class Boolean If set to true, amrfinderplus_amr_classes and amrfinderplus_amr_subclasses outputs will be created FALSE Optional amrfinderplus_nuc disk_size Int Amount of storage (in GB) to allocate to the task 50 Optional amrfinderplus_nuc docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/ncbi-amrfinderplus:4.0.23-2025-07-16.1 Optional amrfinderplus_nuc gff File GFF file provided by Prokka or Bakta when amrfinder_use_gff is set to true. This file is used to determine the location of AMR genes in the genome. Optional amrfinderplus_nuc hide_point_mutations Boolean If set to true, the output File amrfinderplus_all_report will not include any POINT mutations identified by AMRFinderPlus. FALSE Optional amrfinderplus_nuc memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional amrfinderplus_nuc min_percent_coverage Float Minimum proportion of reference gene covered for a BLAST-based hit (Methods BLAST or PARTIAL). Attribute should be a float ranging from 0-1, such as 0.6 (equal to 60% coverage) 0.5 Optional amrfinderplus_nuc min_percent_identity Float Minimum identity for a blast-based hit hit (Methods BLAST or PARTIAL). -1 means use a curated threshold if it exists and 0.9 otherwise. Setting this value to something other than -1 will override any curated similarity cutoffs. Attribute should be a float ranging from 0-1, such as 0.95 (equal to 95% identity) 0.9 Optional amrfinderplus_nuc organism String If provided, this input will override the taxonomic assignment made by GAMBIT and launch the relevant taxon-specific submodules. It will also modify the organism flag used by AMRFinderPlus. Example format: \"Salmonella enterica\" Optional amrfinderplus_nuc protein_fasta File Protein FASTA from annotation software such as Prokka or Bakta. Utilized when amrfinder_use_gff is set to true Optional amrfinderplus_nuc separate_betalactam_genes Boolean Report beta-Lactam AMR genes separated out by all beta-lactam and the respective beta-lactam subclasses FALSE Optional amrfinderplus_nuc use_gff Boolean Whether or not to use the GFF and protein FASTA files for AMRFinderPlus FALSE Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/standalone/ncbi_amrfinderplus/#outputs","title":"Outputs","text":"Variable Type Description amrfinderplus_all_report File Output TSV file from AMRFinderPlus (described https://github.com/ncbi/amr/wiki/Running-AMRFinderPlus#fields) amrfinderplus_amr_classes String AMRFinderPlus predictions for classes of drugs that genes found in the reads are known to confer resistance to amrfinderplus_amr_core_genes String AMR genes identified by AMRFinderPlus where the scope is \"core\" amrfinderplus_amr_plus_genes String AMR genes identified by AMRFinderPlus where the scope is \"plus\" amrfinderplus_amr_report File TSV file detailing AMR genes only, from the amrfinderplus_all_report amrfinderplus_amr_subclasses String More specificity about the drugs that genes identified in the reads confer resistance to amrfinderplus_db_version String AMRFinderPlus database version used amrfinderplus_stress_genes String Stress genes identified by AMRFinderPlus amrfinderplus_stress_report File TSV file detailing stress genes only, from the amrfinderplus_all_report amrfinderplus_version String AMRFinderPlus version used amrfinderplus_virulence_genes String Virulence genes identified by AMRFinderPlus amrfinderplus_virulence_report File TSV file detailing virulence genes only, from the amrfinderplus_all_report amrfinderplus_wf_analysis_date String Date of analysis amrfinderplus_wf_version String Version of PHB used for the analysis"},{"location":"workflows/standalone/ncbi_amrfinderplus/#references","title":"References","text":"<p>Feldgarden M, Brover V, Gonzalez-Escalona N, Frye JG, Haendiges J, Haft DH, Hoffmann M, Pettengill JB, Prasad AB, Tillman GE, Tyson GH, Klimke W. AMRFinderPlus and the Reference Gene Catalog facilitate examination of the genomic links among antimicrobial resistance, stress response, and virulence. Sci Rep. 2021 Jun 16;11(1):12728. doi: 10.1038/s41598-021-91456-0. PMID: 34135355; PMCID: PMC8208984. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8208984/</p> <p>https://github.com/ncbi/amr</p>"},{"location":"workflows/standalone/ncbi_scrub/","title":"NCBI-Scrub","text":""},{"location":"workflows/standalone/ncbi_scrub/#ncbi_scrub","title":"NCBI_Scrub","text":""},{"location":"workflows/standalone/ncbi_scrub/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Standalone Any taxa v2.2.1 Yes Sample-level NCBI_Scrub_PE_PHB, NCBI_Scrub_SE_PHB"},{"location":"workflows/standalone/ncbi_scrub/#ncbi-scrub-workflows","title":"NCBI Scrub Workflows","text":"<p>NCBI Scrub, also known as the human read removal tool (HRRT), is based on the SRA Taxonomy Analysis Tool that will take as input a FASTQ file, and produce as output a FASTQ file in which all reads identified as potentially of human origin are either removed (default) or masked with 'N'. There are three Kraken2 workflows:</p> <ul> <li><code>NCBI_Scrub_PE</code> is compatible with Illumina paired-end data</li> <li><code>NCBI_Scrub_SE</code> is compatible with Illumina single-end data</li> </ul>"},{"location":"workflows/standalone/ncbi_scrub/#inputs","title":"Inputs","text":"NCBI_Scrub_PENCBI_Scrub_SE Terra Task Name Variable Type Description Default Value Terra Status dehost_pe read1 File FASTQ file containing read1 sequences Required dehost_pe read2 File FASTQ file containing read2 sequences Required dehost_pe samplename String The name of the sample being analyzed Required dehost_pe target_organism String Target organism for Kraken2 reporting Severe acute respiratory syndrome coronavirus 2 Optional kraken2 cpu Int Number of CPUs to allocate to the task 4 Optional kraken2 disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional kraken2 docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Optional kraken2 kraken2_db File The database used to run Kraken2 gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz Optional kraken2 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional ncbi_scrub_pe cpu Int Number of CPUs to allocate to the task 4 Optional ncbi_scrub_pe disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ncbi_scrub_pe docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ncbi/sra-human-scrubber:2.2.1 Optional ncbi_scrub_pe memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional Terra Task Name Variable Type Description Default Value Terra Status dehost_se read1 File FASTQ file containing read1 sequences Required dehost_se samplename String The name of the sample being analyzed Required dehost_se target_organism String Target organism for Kraken2 reporting Severe acute respiratory syndrome coronavirus 2 Optional kraken2 cpu Int Number of CPUs to allocate to the task 4 Optional kraken2 disk_size Int Amount of storage (in GB) to allocate to the task. Increase this when using large (&gt;30GB kraken2 databases such as the \"k2_standard\" database) 100 Optional kraken2 docker_image String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/kraken2:2.1.2-no-db Optional kraken2 kraken2_db File The database used to run Kraken2 gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz Optional kraken2 memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional kraken2 read2 File Internal component, do not modify Optional ncbi_scrub_se cpu Int Number of CPUs to allocate to the task 4 Optional ncbi_scrub_se disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional ncbi_scrub_se docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ncbi/sra-human-scrubber:2.2.1 Optional ncbi_scrub_se memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/standalone/ncbi_scrub/#workflow-tasks","title":"Workflow Tasks","text":"<p>This workflow is composed of two tasks, one to dehost the input reads and another to screen the clean reads with kraken2 and the viral+human database.</p> <code>HRRT</code>: Human Host Sequence Removal <p>All reads of human origin are removed, including their mates, by using NCBI's human read removal tool (HRRT). </p> <p>HRRT is based on the SRA Taxonomy Analysis Tool and employs a k-mer database constructed of k-mers from Eukaryota derived from all human RefSeq records with any k-mers found in non-Eukaryota RefSeq records subtracted from the database.</p> <p>NCBI-Scrub Technical Details</p> Links Task task_ncbi_scrub.wdl Software Source Code HRRT on GitHub Software Documentation HRRT on NCBI <code>Kraken2</code>: Read Identification <p><code>Kraken2</code> is a bioinformatics tool originally designed for metagenomic applications. It has additionally proven valuable for validating taxonomic assignments and checking contamination of single-species (e.g. bacterial isolate, eukaryotic isolate, viral isolate, etc.) whole genome sequence data.</p> <p>Kraken2 is run on both the raw and clean reads.</p> <p>Database-dependent</p> <p>This workflow automatically uses a viral-specific Kraken2 database. This database was generated in-house from RefSeq's viral sequence collection and human genome GRCh38. It's available at <code>gs://theiagen-public-resources-rp/reference_data/databases/kraken2/kraken2_humanGRCh38_viralRefSeq_20240828.tar.gz</code>.</p> <p>Kraken2 Technical Details</p> Links Task task_kraken2.wdl Software Source Code Kraken2 on GitHub Software Documentation Kraken2 Documentation Original Publication(s) Improved metagenomic analysis with Kraken 2"},{"location":"workflows/standalone/ncbi_scrub/#outputs","title":"Outputs","text":"NCBI_Scrub_PENCBI_Scrub_SE Variable Type Description kraken_human_dehosted Float Percent of human read data detected using the Kraken2 software after host removal kraken_report_dehosted File Full Kraken report after host removal kraken_sc2_dehosted String Percent of SARS-CoV-2 read data detected using the Kraken2 software after host removal kraken_version_dehosted String Version of Kraken2 software used ncbi_scrub_docker String The Docker image for NCBI's HRRT (human read removal tool) ncbi_scrub_human_spots_removed Int Number of spots removed (or masked) ncbi_scrub_pe_analysis_date String Date of analysis ncbi_scrub_pe_version String Version of HRRT software used read1_dehosted File The dehosted forward reads file; suggested read file for SRA submission read2_dehosted File The dehosted reverse reads file; suggested read file for SRA submission Variable Type Description kraken_human_dehosted Float Percent of human read data detected using the Kraken2 software after host removal kraken_report_dehosted File Full Kraken report after host removal kraken_sc2_dehosted String Percent of SARS-CoV-2 read data detected using the Kraken2 software after host removal kraken_version_dehosted String Version of Kraken2 software used ncbi_scrub_docker String The Docker image for NCBI's HRRT (human read removal tool) ncbi_scrub_human_spots_removed Int Number of spots removed (or masked) ncbi_scrub_se_analysis_date String Date of analysis ncbi_scrub_se_version String Version of HRRT software used read1_dehosted File The dehosted forward reads file; suggested read file for SRA submission"},{"location":"workflows/standalone/phylocompare/","title":"PhyloCompare","text":""},{"location":"workflows/standalone/phylocompare/#phylocompare","title":"PhyloCompare","text":""},{"location":"workflows/standalone/phylocompare/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Standalone Any taxa vX.X.X Yes Sample-level Phylocompare_PHB"},{"location":"workflows/standalone/phylocompare/#phylocompare_phb","title":"PhyloCompare_PHB","text":"<p>PhyloCompare will generate a cophylogeny plot and calculate the distance between two newick-formatted phylogenies as a measure of the difference in their topologies (tip and branch arrangement). The cophylogeny plot is a visual of the topological differences between two phylogenies. A distance of 0 indicates the phylogenies have the same topology. PhyloCompare will validate if the phylogenies exceed an inputted maximum distance. The maximum distance is 0 by default and the phylogenies must have the same tips.</p> <p>It is difficult to conceptualize what a non-0 distance indicates, so please see the following citations for their interpretation. For unrooted phylogenies, PhyloCompare calculates the Lin-Rajan-Moret distance, and for rooted phylogenies, PhyloCompare calculates the matching cluster distance. The Robinson-Foulds distance is also calculated, though it is disregarded in validation (see citations for criticism).</p> <p>PhyloCompare can automatically root upon an outgroup tip or the midpoint.</p> Tree rooting <p>If no rooting options are supplied PhyloCompare will determine if the trees are rooted or unrooted. </p> <p><code>outgroups</code> and <code>midpoint</code> are incompatible options and the <code>outgroups</code> input will take precedence.</p> <code>phylocompare_flag</code> errors <p>The <code>phylocompare_flag</code> flags information that may confound distance calculation; e.g. \"polytomy\" can confound tree comparison if there are non-0 length branches descending from a polytomy, which may lead to erroneous distances if tips are reported in different order. In other words, phylogenies with the same topology may be reported with a non-0 distance if the tips within a polytomy are rearranged within the tree file.</p> <p>If flags are accompanied by a \"&gt;0\" <code>phylocompare_distance</code>, then this indicates no distance was calculated; e.g. the \"edge_count_mismatch\" flag is raised when the number of edges differs between trees and a distance could not be calculated.  </p>"},{"location":"workflows/standalone/phylocompare/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status phylocompare tree1 File Path to a newick-formatted phylogenetic tree in an accessible bucket Required phylocompare tree2 File Path to a newick-formatted phylogenetic tree in an accessible bucket Required phylovalidate_task memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional root_tree1_task memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional root_tree2_task memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional phylocompare max_distance Float Maximum tolerable distance in validation 0.0 Optional phylocompare midpoint Boolean Root phylogenies at their midpoint FALSE Optional phylocompare outgroups String Comma-delimited list of outgroup tip(s) to root upon. Multiple outgroup tips will root on the branch descended from their most recent common ancestor Optional phylovalidate_task cpu Int Number of CPUs to allocate to the task 1 Optional phylovalidate_task disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional phylovalidate_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/theiaphylo:0.1.8 Optional root_tree1_task cpu Int Number of CPUs to allocate to the task 1 Optional root_tree1_task disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional root_tree1_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/theiaphylo:0.1.8 Optional root_tree2_task cpu Int Number of CPUs to allocate to the task 1 Optional root_tree2_task disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional root_tree2_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/theiaphylo:0.1.8 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/standalone/phylocompare/#workflow-tasks","title":"Workflow Tasks","text":"<code>root_phylo</code> <p>Root_Phylo returns a rooted phylogeny from inputted outgroup(s) or by finding the midpoint root. Outgroups must be tip names (case-sensitive) that exist within the tree, and multiple outgroups must be comma-delimited. Up to two outgroup tips can be supplied, and the most-recent common ancestor (MRCA) of the these outgroups will be used as the rooting branch. It is important to note that rooting on the MRCA of two outgroups is relative to the topology of the tree prior to rooting - if one of the samples is at that base of the phylogeny prior to rooting, then a random tip will be selected to allow for rooting upon the MRCA of the two inputted outgroups.</p> <p>Root_Phylo Technical Details</p> Links Task task_root_phylo.wdl Software Source Code https://github.com/theiagen/theiaphylo Software Documentation TheiaPhylo <code>phylocompare</code> <p>PhyloCompare will clean two phylogenies and validate if the distance between these two phylogenies' topologies is less than an inputted <code>max_distance</code> float (0 by default). Phylogenies are cleaned by converting 0 branch length nodes into polytomies, and any detected polytomies are reported as a flag. Polytomies may arbitrarily yield a non-0 distance, though if a 0 distance is reported with a polytomy then it indicates that the polytomy did not confound distance calculation.</p> <p>For unrooted phylogenies, PhyloCompare calculates the Lin-Rajan-Moret distance, and for rooted phylogenies, PhyloCompare calculates the matching cluster distance. The Robinson-Foulds distance is also calculated, though it is disregarded in validation (see citations for criticism).</p> <p>PhyloCompare Technical Details</p> Links Task task_phylocompare.wdl Software Source Code https://github.com/theiagen/theiaphylo Software Documentation TheiaPhylo"},{"location":"workflows/standalone/phylocompare/#outputs","title":"Outputs","text":"Variable Type Description phylocompare_cophylo_plot File PDF cophylogeny plot depicting the topological difference between two phylogenies phylocompare_distance String Distance between the phylogenies, or \"None\"/\"&gt;0\" if distance was unable to be calculated phylocompare_flag String Flags raised that may confound distance calculation phylocompare_phb_version String The version of the Public Health Bioinformatics (PHB) repository used phylocompare_report File Text file of the calculated distances phylocompare_tree1_clean File Cleaned newick file for the first tree phylocompare_tree2_clean File Cleaned newick file for the second tree phylocompare_validation String PASS if distance &lt; <code>max_distance</code> and \"FAIL\" if distance &gt; <code>max_distance</code> or could not be calculated phylocompare_version String Version of PhyloCompare python script"},{"location":"workflows/standalone/phylocompare/#references","title":"References","text":"<ul> <li> <p>Lin, Y., Rajan, V., Moret, B. M. E. (2012). A metric for phylogenetic trees based on matching. IEEE/ACM Transactions on Computational Biology and Bioinformatics, 9(4), 1014-22, https://doi.org/10.1109/tcbb.2011.157</p> </li> <li> <p>Moon, J. &amp; Eulenstein, O. (2018). Cluster Matching Distance for Rooted Phylogenetic Trees. Lecture Notes in Computer Science, 10847, https://doi.org/10.1007/978-3-319-94968-0_31</p> </li> <li> <p>Cogent3 Python Library https://github.com/cogent3/cogent3</p> </li> </ul>"},{"location":"workflows/standalone/rasusa/","title":"RASUSA","text":""},{"location":"workflows/standalone/rasusa/#rasusa","title":"RASUSA","text":""},{"location":"workflows/standalone/rasusa/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Standalone Any taxa v3.0.0 Yes Sample-level RASUSA_PHB"},{"location":"workflows/standalone/rasusa/#rasusa_phb","title":"RASUSA_PHB","text":"<p>RASUSA functions to randomly downsample the number of raw reads to a user-defined threshold.</p>"},{"location":"workflows/standalone/rasusa/#use-cases","title":"\ud83d\udccb Use Cases","text":"<ul> <li>to reduce computing resources when samples end up with drastically more data than needed to perform analyses</li> <li>to perform limit of detection (LOD) studies to identify appropriate minimum coverage thresholds required to perform downstream analyses</li> </ul>"},{"location":"workflows/standalone/rasusa/#desired-size-may-be-specified-by-inputting-any-one-of-the-following","title":"\ud83d\udd27 Desired size may be specified by inputting any one of the following","text":"<ul> <li>coverage (e.g. 20X)</li> <li>number of bases (e.g. \"5m\" for 5 megabases)</li> <li>number of reads (e.g. 100000 total reads)</li> <li>fraction of reads (e.g. 0.5 samples half the reads)</li> </ul> <p>Call-caching disabled</p> <p>If using RASUSA_PHB workflow version v2.0.0 or higher, the call-caching feature of Terra has been DISABLED to ensure that the workflow is run from the beginning and data is downloaded fresh. Call-caching will not be enabled, even if the user checks the box \u2705 in the Terra workflow interface.</p>"},{"location":"workflows/standalone/rasusa/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status rasusa_workflow coverage Float Use to specify the desired coverage of reads after downsampling; actual coverage of subsampled reads will not be exact and may be slightly higher; always check the estimated clean coverage after performing downstream workflows to verify coverage values, when necessary Required rasusa_workflow genome_length String Input the approximate genome size expected in quotations; this is used to determine the number of bases required to achieve the desired coverage; acceptable metric suffixes include: b, k, m, g, and t for base, kilo, mega, giga, and tera, respectively Required rasusa_workflow read1 File FASTQ file containing read1 sequences Required rasusa_workflow samplename String The name of the sample being analyzed Required rasusa_task bases String Explicitly set the number of bases required e.g., 4.3kb, 7Tb, 9000, 4.1MB. If this option is given, --coverage and --genome-size are ignored Optional rasusa_task cpu Int Number of CPUs to allocate to the task 4 Optional rasusa_task disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional rasusa_task docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/rasusa:2.1.0 Optional rasusa_task frac Float Explicitly define the fraction of reads to keep in the subsample; when used, genome size and coverage are ignored; acceptable inputs include whole numbers and decimals, e.g. 50.0 will leave 50% of the reads in the subsample Optional rasusa_task memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional rasusa_task num Int Optional: explicitly define the number of reads in the subsample; when used, genome size and coverage are ignored; acceptable metric suffixes include: b, k, m, g, and t for base, kilo, mega, giga, and tera, respectively Optional rasusa_task seed Int Use to assign a name to the \"random seed\" that is used by the subsampler; i.e. this allows the exact same subsample to be produced from the same input file/s in subsequent runs when providing the seed identifier; do not input values for random downsampling Optional rasusa_workflow read2 File FASTQ file containing read2 sequences Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/standalone/rasusa/#outputs","title":"Outputs","text":"Variable Type Description rasusa_version String Version of RASUSA used for the analysis rasusa_wf_analysis_date String Date of analysis rasusa_wf_version String Version of PHB used for the analysis read1_subsampled File Read1 FASTQ files downsampled to desired coverage read2_subsampled File Read2 FASTQ files downsampled to desired coverage <p>Don't Forget!</p> <p>Remember to use the subsampled reads in downstream analyses with <code>this.read1_subsampled</code> and <code>this.read2_subsampled</code> inputs.</p> <p>Verify</p> <p>Confirm reads were successfully subsampled before downstream analyses by comparing read file size/s to the original read file size/s</p> <p>View file sizes by clicking on the read file listed in the Terra data table and looking at the file size</p>"},{"location":"workflows/standalone/rasusa/#references","title":"References","text":"<p>Hall, M. B., (2022). Rasusa: Randomly subsample sequencing reads to a specified coverage. Journal of Open Source Software, 7(69), 3941,\u00a0https://doi.org/10.21105/joss.03941</p>"},{"location":"workflows/standalone/rename_fastq/","title":"Rename_FASTQ","text":""},{"location":"workflows/standalone/rename_fastq/#rename_fastq","title":"Rename_FASTQ","text":""},{"location":"workflows/standalone/rename_fastq/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Standalone Any taxa v2.1.0 Yes Sample-level Rename_FASTQ_PHB"},{"location":"workflows/standalone/rename_fastq/#rename_fastq_phb","title":"Rename_FASTQ_PHB","text":"<p>This sample-level workflow receives a read file or a pair of read files (FASTQ), compressed or uncompressed, and returns a new, renamed and compressed FASTQ file.</p>"},{"location":"workflows/standalone/rename_fastq/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status rename_fastq_files new_filename String New name for the FASTQ file(s) Required rename_fastq_files read1 File FASTQ file containing read1 sequences Required rename_PE_files cpu Int Number of CPUs to allocate to the task 2 Optional rename_PE_files disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional rename_PE_files docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ubuntu/ubuntu:jammy-20230816 Optional rename_PE_files memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional rename_SE_files cpu Int Number of CPUs to allocate to the task 2 Optional rename_SE_files disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional rename_SE_files docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/ubuntu/ubuntu:jammy-20230816 Optional rename_SE_files memory Int Amount of memory/RAM (in GB) to allocate to the task 2 Optional rename_fastq_files read2 File FASTQ file containing read2 sequences Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/standalone/rename_fastq/#outputs","title":"Outputs","text":"<p>If a reverse read (<code>read2</code>) is provided, the files get renamed to the provided\u00a0<code>new_filename</code>\u00a0input with the notation\u00a0<code>&lt;new_filename&gt;_R1.fastq.gz</code>\u00a0and\u00a0<code>&lt;new_filename&gt;_R2.fastq.gz</code>. If only\u00a0<code>read1</code>\u00a0is provided, the file is renamed to\u00a0<code>&lt;new_filename&gt;.fastq.gz</code>.</p> Variable Type Description read1_renamed File New read1 FASTQ file renamed to desired filename read2_renamed File New read2 FASTQ file renamed to desired filename rename_fastq_files_analysis_date String Date of analysis rename_fastq_files_version String Version of PHB used for the analysis"},{"location":"workflows/standalone/tbprofiler_tngs/","title":"TBProfiler_tNGS","text":""},{"location":"workflows/standalone/tbprofiler_tngs/#tbprofiler_tngs","title":"TBProfiler_tNGS","text":""},{"location":"workflows/standalone/tbprofiler_tngs/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Standalone Bacteria, TB vX.X.X Yes Sample-level TBProfiler_tNGS_PHB"},{"location":"workflows/standalone/tbprofiler_tngs/#tbprofiler_tngs_phb","title":"TBProfiler_tNGS_PHB","text":"<p>This workflow is still in experimental research stages. Documentation is minimal as changes may occur in the code; it will be fleshed out when a stable state has been achieved.</p>"},{"location":"workflows/standalone/tbprofiler_tngs/#inputs","title":"Inputs","text":"Terra Task Name Variable Type Description Default Value Terra Status tbprofiler_tngs read1 File Illumina forward read file in FASTQ file format (compression optional) Required tbprofiler_tngs read2 File Illumina reverse read file in FASTQ file format (compression optional) Required tbprofiler_tngs samplename String The name of the sample being analyzed Required tbp_parser add_cycloserine_lims Boolean Set to true add cycloserine results to the LIMS report FALSE Optional tbp_parser config File The configuration file to use, in YAML format (overrides all other arguments except input_json and input_bam) Optional tbp_parser coverage_regions_bed File A file that contains the regions to perform coverage analysis on Optional tbp_parser cpu Int Number of CPUs to allocate to the task 1 Optional tbp_parser disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional tbp_parser docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/tbp-parser:2.6.0 Optional tbp_parser etha237_frequency Float Minimum frequency for a mutation in ethA at protein position 237 to pass QC in tbp-parser 0.1 Optional tbp_parser expert_rule_regions_bed File A file that contains the regions where R mutations and expert rules are applied Optional tbp_parser memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional tbp_parser min_depth Int Minimum depth for a variant to pass QC in tbp_parser 10 Optional tbp_parser min_frequency Float Minimum allele frequency for a variant to pass QC in tbp-parser 0.1 Optional tbp_parser min_percent_coverage Float The minimum percentage of a region to exceed the minimum depth for a region to pass QC in tbp_parser 100 Optional tbp_parser min_read_support Int Minimum read support for a variant to pass QC in tbp-parser 10 Optional tbp_parser operator String Fills the \"operator\" field in the tbp_parser output files Optional tbp_parser rpob449_frequency Float Minimum frequency for a mutation at protein position 449 to pass QC in tbp-parser 0.1 Optional tbp_parser rrl_frequency Float Minimum frequency for a mutation in rrl to pass QC in tbp-parser 0.1 Optional tbp_parser rrl_read_support Int Minimum read support for a mutation in rrl to pass QC in tbp-parser 10 Optional tbp_parser rrs_frequency Float Minimum frequency for a mutation in rrs to pass QC in tbp-parser 0.1 Optional tbp_parser rrs_read_support Int Minimum read support for a mutation in rrs to pass QC in tbp-parser 10 Optional tbp_parser sequencing_method String Fills out the \"seq_method\" field in the tbp_parser output files Optional tbp_parser tbp_parser_debug Boolean Activate the debug mode on tbp_parser; increases logging outputs TRUE Optional tbprofiler additional_parameters String Additional parameters for TBProfiler Optional tbprofiler cpu Int Number of CPUs to allocate to the task 8 Optional tbprofiler disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional tbprofiler docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/tbprofiler:6.6.3 Optional tbprofiler mapper String The mapping tool used in TBProfiler to align the reads to the reference genome; see TBProfiler's original documentation for available options. bwa Optional tbprofiler memory Int Amount of memory/RAM (in GB) to allocate to the task 16 Optional tbprofiler min_af Float The minimum allele frequency to call a variant 0.1 Optional tbprofiler min_depth Int The minimum depth for a variant to be called. 10 Optional tbprofiler ont_data Boolean Specifies nanopore specific tbprofiler parameters FALSE Optional tbprofiler tbprofiler_custom_db File TBProfiler uses by default the TBDB database; if you have a custom database you wish to use, you must provide a custom database in this field and set tbprofiler_run_custom_db to true Optional tbprofiler tbprofiler_run_cdph_db Boolean TBProfiler uses by default the TBDB database; set this value to \"true\" to use the WHO v2 database with customizations for CDPH FALSE Optional tbprofiler tbprofiler_run_custom_db Boolean Set to true to use your own custom database. The <code>tbprofiler_custom_db</code> variable MUST be filled if this value is set to true FALSE Optional tbprofiler variant_caller String Select a different variant caller for TBProfiler to use by writing it in this block; see TBProfiler's original documentation for available options. gatk Optional tbprofiler variant_calling_params String Enter additional variant calling parameters in this free text input to customize how the variant caller works in TBProfiler Optional tbprofiler_tngs bases_to_crop Int Indicate the number of bases to remove from the start and end of the read 0 Optional trimmomatic_pe cpu Int Number of CPUs to allocate to the task 4 Optional trimmomatic_pe disk_size Int Amount of storage (in GB) to allocate to the task 100 Optional trimmomatic_pe docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/staphb/trimmomatic:0.39 Optional trimmomatic_pe memory Int Amount of memory/RAM (in GB) to allocate to the task 8 Optional trimmomatic_pe trimmomatic_args String Additional arguments to pass to trimmomatic. \"-phred33\" specifies the Phred Q score encoding which is almost always phred33 with modern sequence data. -phred33 Optional trimmomatic_pe trimmomatic_min_length Int Specifies minimum length of each read after trimming to be kept 75 Optional trimmomatic_pe trimmomatic_quality_trim_score Int The trimming quality score 30 Optional trimmomatic_pe trimmomatic_window_size Int The window size for trimming 4 Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional"},{"location":"workflows/standalone/tbprofiler_tngs/#terra-outputs","title":"Terra Outputs","text":"Variable Type Description tbp_parser_average_genome_depth Float The mean depth of coverage across all target regions included in the analysis tbp_parser_coverage_report File A file containing the breadth of coverage across each target loci tbp_parser_docker String The docker image and version tag for the tbp_parser tool tbp_parser_genome_percent_coverage Float The percent breadth of coverage across the entire genome tbp_parser_laboratorian_report_csv File An output file containing information regarding each mutation and its associated drug resistance profile in a CSV file. This file also contains two interpretation fields -- \"Looker\" and \"MDL\" which are generated using the CDC's expert rules for interpreting the severity of potential drug resistance mutations. tbp_parser_lims_report_csv File An output file formatted specifically for STAR LIMS. This CSV report summarizes the highest severity mutations for each antimicrobial and lists the relevant mutations for each gene. tbp_parser_looker_report_csv File An output file that contains condensed information suitable for generating a dashboard in Google's Looker studio. tbp_parser_version String The version number of tbp_parser tbprofiler_dr_type String The drug resistance category as determined by TBProfiler (sensitive, Pre-MDR, MDR, Pre-XDR, XDR) tbprofiler_main_lineage String The Mycobacterium tuberculosis lineage assignment as made by TBProfiler tbprofiler_median_depth Float The median depth of the H37Rv TB reference genome covered by the sample tbprofiler_num_dr_variants String The total number of drug resistance conferring variants detected by TBProfiler tbprofiler_num_other_variants String The total number of non-drug resistance conferring variants detected by TBProfiler tbprofiler_output_alignment_bai File The index file associated with the binary alignment map of the input reads against the H37Rv genome tbprofiler_output_alignment_bam File The binary alignment map of the input reads against the H37Rv genome tbprofiler_pct_reads_mapped Float The percentage of reads that successfully mapped to the H37Rv genome tbprofiler_report_csv File The raw output file from TBProfiler tbprofiler_report_json File The json output file from TBProfiler tbprofiler_report_tsv File The TSV output file from TBProfiler tbprofiler_resistance_genes String The genes in which a mutation was detected that may be resistance conferring, in the format of <code>&lt;gene target&gt; &lt;variant detected&gt; (&lt;estimated fraction of reads that support the variant&gt;)</code> tbprofiler_sub_lineage String The Mycobacterium tuberculosis sub-lineage assignment as made by TBProfiler tbprofiler_tngs_wf_analysis_date String The date on which the workflow was run tbprofiler_tngs_wf_version String The version of the tbprofiler_tngs workflow used for this analysis tbprofiler_version String The version of TBProfiler used for this analysis trimmomatic_docker String The docker image used for the trimmomatic module in this workflow trimmomatic_read1_trimmed File The read1 file post trimming trimmomatic_read2_trimmed File The read2 file post trimming trimmomatic_stats File The read trimming statistics trimmomatic_version String The version of Trimmomatic used"},{"location":"workflows/standalone/theiavalidate/","title":"TheiaValidate","text":""},{"location":"workflows/standalone/theiavalidate/#theiavalidate","title":"TheiaValidate","text":""},{"location":"workflows/standalone/theiavalidate/#quick-facts","title":"Quick Facts","text":"Workflow Type Applicable Kingdom Last Known Changes Command-line Compatibility Workflow Level Dockstore Standalone Any taxa v3.0.0 No TheiaValidate_PHB"},{"location":"workflows/standalone/theiavalidate/#theiavalidate_phb","title":"TheiaValidate_PHB","text":"<p>Command-line incompatible</p> <p>This workflow is not compatible with command-line use, but the underlying tool (<code>theiavalidate</code>) is. If you want to run TheiaValidate on the command-line, please see the tool's README for more details.</p> <p>TheiaValidate Workflow Diagram</p> <p></p> <p>TheiaValidate performs basic comparisons between user-designated columns in two separate tables. We anticipate this workflow being run to determine if any differences exist between version releases or two workflows, such as TheiaProk_ONT vs TheiaProk_Illumina_PE. A summary PDF report is produced in addition to a Excel spreadsheet that lists the values for any columns that do not have matching content for a sample.</p> <p>Warning</p> <p>The two tables being compared must have both identical sample names and an equal number of samples. If not, validation will not work or (in the case of unequal number of samples) not be attempted.</p> <p>In order to enable this workflow to function for different workflow series, we require users to provide a list of columns they want to compare between the two tables. Feel free to use the information below that Theiagen uses to compare versions of the three main workflow series as a starting point for your own validations:</p> <p>Validation Starting Points</p> <p>Please ensure that you adjust these values to make sense for your own validation. Please see the theiavalidate README for more information as well.</p> Workflow Series Validation Criteria TSV Columns to Compare TheiaCoV Workflows TheiaCov Validation Criteria abricate_flu_subtype,abricate_flu_type,assembly_length_unambiguous,assembly_mean_coverage,irma_subtype,irma_type,kraken_human,kraken_human_dehosted,kraken_sc2,kraken_sc2_dehosted,kraken_target_org,kraken_target_org_dehosted,nextclade_aa_dels,nextclade_aa_subs,nextclade_clade,nextclade_lineage,nextclade_tamiflu_resistance_aa_subs,num_reads_clean1,num_reads_clean2,number_N,pango_lineage,percent_reference_coverage,vadr_num_alerts TheiaEuk Workflows TheiaEuk Validation Criteria assembly_length,busco_results,clade_type,est_coverage_clean,est_coverage_raw,gambit_predicted_taxon,n50_value,num_reads_clean1,num_reads_clean2,number_contigs,quast_gc_percent,theiaeuk_snippy_variants_hits TheiaProk Workflows TheiaProk Validation Criteria abricate_abaum_plasmid_type_genes,agrvate_agr_group,amrfinderplus_amr_core_genes,amrfinderplus_amr_plus_genes,amrfinderplus_stress_genes,amrfinderplus_virulence_genes,ani_highest_percent,ani_top_species_match,assembly_length,busco_results,ectyper_predicted_serotype,emmtypingtool_emm_type,est_coverage_clean,est_coverage_raw,gambit_predicted_taxon,genotyphi_final_genotype,hicap_genes,hicap_serotype,kaptive_k_type,kleborate_genomic_resistance_mutations,kleborate_key_resistance_genes,kleborate_mlst_sequence_type,legsta_predicted_sbt,lissero_serotype,meningotype_serogroup,midas_primary_genus,midas_secondary_genus,midas_secondary_genus_abundance,n50_value,ngmaster_ngmast_sequence_type,ngmaster_ngstar_sequence_type,num_reads_clean1,num_reads_clean2,number_contigs,pasty_serogroup,pbptyper_predicted_1A_2B_2X,plasmidfinder_plasmids,poppunk_gps_cluster,seqsero2_predicted_serotype,seroba_ariba_serotype,seroba_serotype,serotypefinder_serotype,shigatyper_ipaB_presence_absence,shigatyper_predicted_serotype,shigeifinder_cluster,shigeifinder_serotype,sistr_predicted_serotype,sonneityping_final_genotype,spatyper_type,srst2_vibrio_serogroup,staphopiasccmec_types_and_mecA_presence,tbprofiler_main_lineage,tbprofiler_resistance_genes,ts_mlst_predicted_st,virulencefinder_hits <p>If additional validation metrics are desired, the user has the ability to provide a <code>validation_criteria_tsv</code> file that specifies what type of comparison should be performed. There are several options for additional validation checks:</p> <ul> <li>EXACT performs an exact string match and counts the number of exact match failures/differences</li> <li>IGNORE does not check the values and says there are 0 failures</li> <li>SET checks list items (such as <code>amrfinder_plus_genes</code> which is a comma-delimited list of genes) for identical content \u2014 order does not matter; that is, <code>mdsA,mdsB</code> is determined to be same as <code>mdsB,mdsA</code>. The EXACT match does not consider these to be the same, but the SET match does.</li> <li>&lt;PERCENT_DIFF&gt;, which is an actual decimal value such as 0.02, calculates the percent difference between numerical columns. If the columns are not numerical, this function will not work and will lead to workflow failure. For example, if the decimal percentage is 0.02, the test will indicate a failure if the values in the two columns are more than 2% different.</li> <li>&lt;RANGE&gt;, which is an actual integer value such as 10, calculates the numerical difference between numerical columns. If the columns are not numerical, this function will not work and will lead to workflow failure. For example, if the range is 10, the test will indicate a failure if the values in the two columns are more than 10 apart (units ignored).</li> <li>CRITERIA1,CRITERIA2,... checks the values for the two columns with CRITERIA1 (which must be one of the above) and then with CRITERIA2, etc.; values will pass if at least one criteria is met; the separate criteria must be comma-delimited.</li> <li>Dates and object-type values are ignored and indicate 0 failures.</li> </ul>"},{"location":"workflows/standalone/theiavalidate/#file-comparisons","title":"File Comparisons","text":"<p>If a column consists of only GCP URIs (Google Cloud file paths), the files will be localized and compared with either an EXACT match or a SET match. In the SET match, the lines in the file are ordered before comparison. Results are returned to the summary table as expected. The results of each file comparison can be found in the <code>theiavalidate_diffs</code>  output column.</p>"},{"location":"workflows/standalone/theiavalidate/#inputs","title":"Inputs","text":"<p>Please note that all string inputs must be enclosed in quotation marks; for example, \"column1,column2\" or \"workspace1\"</p> Terra Task Name Variable Type Description Default Value Terra Status theiavalidate columns_to_compare String A comma-separated list of the columns the user wants to compare. Do not include whitespace. Required theiavalidate output_prefix String The prefix for the output files Required theiavalidate table1_name String The name of the first table Required theiavalidate table2_name String The name of the second table Required theiavalidate terra_project1_name String The name of the Terra project where table1_name can be found Required theiavalidate terra_workspace1_name String The name of the Terra workspace where table1_name can be found Required compare_two_tsvs cpu Int Number of CPUs to allocate to the task 2 Optional compare_two_tsvs debug_output Boolean Set to true to enable more outputs; useful when debugging FALSE Optional compare_two_tsvs disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional compare_two_tsvs docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/theiavalidate:1.1.2 Optional compare_two_tsvs memory Int Amount of memory/RAM (in GB) to allocate to the task 4 Optional compare_two_tsvs na_values String If the user knows a particular value in either table that they would like to be considered N/A, they can indicate those values in a comma-separated list here. Any changes here will overwrite the default and not append to the default list. Do not include whitespace. -1.#IND,1.#QNAN,1.#IND,-1.#QNAN,#N/A,N/A,n/a,,#NA,NULL,null,NaN,-NaN,nan,-nan,None Optional export_two_tsvs cpu Int Number of CPUs to allocate to the task 1 Optional export_two_tsvs disk_size Int Amount of storage (in GB) to allocate to the task 10 Optional export_two_tsvs docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/terra-tools:2023-03-16 Optional export_two_tsvs memory Int Amount of memory/RAM (in GB) to allocate to the task 1 Optional theiavalidate column_translation_tsv File If the user wants to link two columns of different names, they may supply a TSV file that provides a \"column translation\" between the two files (see the section below this table). Optional theiavalidate terra_project2_name String If the table2_name is located in a different Terra project, indicate it here. Otherwise, the workflow will look for table2_name in the Terra project indicated in terra_project1_name. value for terra_project1_name Optional theiavalidate terra_workspace2_name String If the table2_name is located in a different Terra workspace, indicate it here. Otherwise, the workflow will look for table2_name in the Terra workspace indicated in terra_workspace1_name. value for terra_workspace1_name Optional theiavalidate validation_criteria_tsv File If the user wants to specify a different comparison than the default exact string match, they may supply a TSV file that indicates the different options (see the section below this table). Optional version_capture docker String The Docker container to use for the task us-docker.pkg.dev/general-theiagen/theiagen/alpine-plus-bash:3.20.0 Optional version_capture timezone String Set the time zone to get an accurate date of analysis (uses UTC by default) Optional <p>The optional <code>validation_criteria_tsv</code> file takes the following format (tab-delimited; a header line is required):</p> <pre><code>column_name criteria\ncolumnB SET\ncolumnC IGNORE\ncolumnD 0.01\ncolumnE EXACT\n</code></pre> <p>Please see above for a description of all available criteria options (EXACT, IGNORE, SET, ).</p> <p>The optional <code>column_translation_tsv</code> file takes the following format (tab-delimited; a header line is required):</p> <pre><code>old_name    new_name\ncolumn_name_in_table1   column_name_in_table2\ncolumn_name_in_table2   column_name_in_table1\ninternal_column_name    display_column_name\n</code></pre> <p>Please note that the name in the second column will be displayed and used in all output files.</p> <p>Call Caching Disabled</p> <p>If using TheiaValidate workflow version 1.3.0 or higher, the call-caching feature of Terra has been DISABLED to ensure that the workflow is run from the beginning and data is compared fresh. Call-caching will not be enabled, even if the user checks the box \u2705 in the Terra workflow interface.</p>"},{"location":"workflows/standalone/theiavalidate/#outputs","title":"Outputs","text":"Variable Type Description theiavalidate_criteria_differences File A TSV file that lists only the differences that fail to meet the validation criteria theiavalidate_date String The date the analysis was run theiavalidate_diffs Array[File] An array of files with a single file for each file comparison performed; only has values if a column with files is compared theiavalidate_exact_differences File A TSV file that lists all exact string match differences between samples theiavalidate_filtered_input_table1 File The first data table used for validation after removing unexamined columns and translating column names theiavalidate_filtered_input_table2 File The second data table used for validation after removing unexamined columns and translating column names theiavalidate_report File A PDF summary report theiavalidate_status String Indicates whether or not validation was attempted theiavalidate_version String The version of the TheiaValidate Python Docker theiavalidate_wf_version String The version of the PHB repository"},{"location":"workflows/standalone/theiavalidate/#example-data-and-outputs","title":"Example Data and Outputs","text":"<p>To help demonstrate how TheiaValidate works, please observe the following example and outputs:</p> Table1 entity:example_table1_id columnA-string columnB-set columnC-ignore columnD-float columnE-missing sample1 option1 item1,item2,item3 cheese 1000 present sample2 option1 item1,item3,item2 cheesecake 12 present sample3 option2 item1,item2,item3 cake 14 present sample4 option1 item2,item1 cakebatter 3492 sample5 option2 item1,item2 batter 3 present Table2 entity:example_table2_id columnA-string columnB-set columnC-ignore columnD-float missing sample1 option1 item1,item3,item2 cheesecake 999 present sample2 option2 item1,item2,item3 batter 12 present sample3 option1 item1,item2 cheese 24 sample4 option1 item1,item2 cakebatter 728 sample5 option2 item1,item2,item3 batter 4 present Validation Criteria column criteria columnB-set SET columnC-ignore IGNORE columnD-float 0.01 columnE-missing EXACT Column Translation missing columnE-missing columnA-string columnA-string <p>Note: the second row translating <code>columnA-string</code> to itself is included to prevent the known bug explained above.</p> <p>If the above inputs are provided, then the following output files will be generated:</p> <p>filtered_example_table1.tsv</p> <p>filtered_example_table2.tsv</p> <p>example_summary.pdf</p> <p>example_exact_differences.tsv</p> <p>example_validation_criteria_differences.tsv</p>"},{"location":"workflows_overview/workflows_alphabetically/","title":"Alphabetical Workflows","text":"<p>Sort by Workflow Type | Sort by Kingdom</p> Name Description Applicable Kingdom Workflow Type Workflow Level Command-line Compatibility Last Known Changes Dockstore AMR_Search Perform AMR profiling on microbial assemblies mimicing Pathogenwatch Any taxa Standalone Sample-level Yes v3.0.1 AMR_Search_PHB Assembly_Fetch Download assemblies from NCBI, after optionally identifying the closest RefSeq reference genome to your own draft assembly Any taxa Data Import Sample-level Yes v3.1.0 Assembly_Fetch_PHB Augur Phylogenetic analysis for viral pathogens Viral Phylogenetic Construction Sample-level, Set-level Yes v3.0.0 Augur_Prep_PHB, Augur_PHB BaseSpace_Fetch Import data from BaseSpace into Terra Any taxa Data Import Sample-level Yes v3.1.0 BaseSpace_Fetch_PHB CZGenEpi_Prep Prepare metadata and fasta files for easy upload to the CZ GEN EPI platform. Monkeypox virus, SARS-CoV-2, Viral Phylogenetic Construction Set-level Yes v1.3.0 CZGenEpi_Prep_PHB Cauris_CladeTyper C. auris clade assignment Mycotics Standalone Sample-level Yes vX.X.X Cauris_CladeTyper_PHB Clair3_Variants ONT Variant Caller Any taxa Phylogenetic Construction Sample-level Yes v3.0.0 Clair3_Variants_ONT_PHB Concatenate_Column_Content Concatenate contents of a specified Terra data table column for many samples (\"entities\") Any taxa Exporting Data from Terra Set-level Yes v2.1.0 Concatenate_Column_Content_PHB Concatenate_Illumina_Lanes Concatenate Illumina lanes for a single sample Any taxa Standalone Sample-level Yes v2.3.0 Concatenate_Illumina_Lanes_PHB Core_Gene_SNP Pangenome analysis Bacteria Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 Core_Gene_SNP_PHB Create_Terra_Table Upload data to Terra and then run this workflow to have the table automatically created Any taxa Data Import No v2.2.0 Create_Terra_Table_PHB Dorado_Basecalling GPU-accelerated basecalling of Oxford Nanopore sequencing data Any taxa Standalone Sample-level No v3.0.1 Dorado_Basecalling_PHB Fetch_SRR_Accession Provided a BioSample accession, identify any associated SRR accession(s) Any taxa Data Import Sample-level Yes v2.3.0 Fetch_SRR_Accession_PHB Find_Shared_Variants Combines and reshapes variant data from Snippy_Variants to illustrate variants shared across multiple samples Bacteria, Mycotics Phylogenetic Construction Set-level Yes v2.0.0 Find_Shared_Variants_PHB Freyja Workflow Series Recovers relative lineage abundances from mixed sample data and generates visualizations SARS-CoV-2, Viral Genomic Characterization Sample-level, Set-level Yes v3.1.0 Freyja_FASTQ_PHB, Freyja_Plot_PHB, Freyja_Dashboard_PHB, Freyja_Update_PHB GAMBIT_Query Taxon identification of genome assembly using GAMBIT Bacteria, Mycotics Standalone Sample-level Yes v2.0.0 Gambit_Query_PHB Kraken2 Taxa identification from reads Any taxa Standalone Sample-level Yes v3.1.0 Kraken2_PE_PHB, Kraken2_SE_PHB, Kraken2_ONT_PHB Lyve_SET Alignment of reads to a reference genome, SNP calling, curation of high quality SNPs, phylogenetic analysis Bacteria Phylogenetic Construction Set-level Yes v2.1.0 Lyve_SET_PHB MashTree_FASTA Mash-distance based phylogenetic analysis from assemblies Bacteria, Mycotics, Viral Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 MashTree_FASTA_PHB Mercury_Prep_N_Batch Prepare metadata and sequence data for submission to NCBI and GISAID Influenza, Monkeypox virus, SARS-CoV-2, Viral Public Data Sharing Set-level No vX.X.X Mercury_Prep_N_Batch_PHB NCBI-AMRFinderPlus Runs NCBI's AMRFinderPlus on genome assemblies (bacterial and fungal) Bacteria, Mycotics Standalone Sample-level Yes v3.0.1 NCBI-AMRFinderPlus_PHB NCBI_Scrub Runs NCBI's HRRT on Illumina FASTQs Any taxa Standalone Sample-level Yes v2.2.1 NCBI_Scrub_PE_PHB, NCBI_Scrub_SE_PHB Nextclade_Batch Use Nextclade to rapidly and accurately place your samples on any existing phylogenetic tree Monkeypox virus, SARS-CoV-2, Viral Phylogenetic Placement Set-level Yes vX.X.X Nextclade_Batch_PHB ONT_Barcode_Concatenation Creates a Terra table after concatenating barcodes from ONT data Any taxa Data Import No vX.X.X ONT_Barcode_Concatenation_PHB Pangolin_Update Update Pangolin assignments SARS-CoV-2, Viral Genomic Characterization Sample-level Yes v3.0.1 Pangolin_Update_PHB PhyloCompare Quantify the difference between two phylogenetic trees with the same tips Any taxa Standalone Sample-level Yes vX.X.X Phylocompare_PHB RASUSA Randomly subsample sequencing reads to a specified coverage Any taxa Standalone Sample-level Yes v3.0.0 RASUSA_PHB Rename_FASTQ Rename paired-end or single-end read files in a Terra data table in a non-destructive way Any taxa Standalone Sample-level Yes v2.1.0 Rename_FASTQ_PHB SRA_Fetch Import publicly available reads from SRA using SRR#, ERR# or DRR# Any taxa Data Import Sample-level Yes v2.2.0 SRA_Fetch_PHB Snippy_Streamline Implementation of Snippy workflows for phylogenetic analysis from reads, with optional dynamic reference selection Bacteria Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 Snippy_Streamline_PHB Snippy_Streamline_FASTA Implementation of Snippy workflows for phylogenetic analysis from assembled genomes (in FASTA format), with optional dynamic reference selection Bacteria Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 Snippy_Streamline_FASTA_PHB Snippy_Tree SNP-based phylogenetic analysis from reads, with option to mask recombination Bacteria Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 Snippy_Tree_PHB Snippy_Variants Alignment of reads to a reference genome, then SNP calling Bacteria, Mycotics, Viral Phylogenetic Construction Sample-level Yes v2.3.0 Snippy_Variants_PHB TBProfiler_tNGS Performs in silico antimicrobial susceptibility testing on Mycobacterium tuberculosis targeted-NGS samples with TBProfiler and tbp-parser Bacteria, TB Standalone Sample-level Yes vX.X.X TBProfiler_tNGS_PHB Terra_2_ENA Upload of sequence data to ENA Bacteria, Viral Public Data Sharing Set-level No v3.1.0 Terra_2_ENA_PHB Terra_2_GISAID Upload of assembly data to GISAID SARS-CoV-2, Viral Public Data Sharing Set-level Yes v1.2.1 Terra_2_GISAID_PHB Terra_2_NCBI Upload of sequence data to NCBI Bacteria, Mycotics, Viral Public Data Sharing Set-level No vX.X.X Terra_2_NCBI_PHB TheiaCov Workflow Series Viral genome assembly, QC and characterization from amplicon sequencing HIV, Influenza, Monkeypox virus, RSV-A, RSV-B, SARS-CoV-2, Viral, WNV Genomic Characterization Sample-level, Set-level Some optional features incompatible, Yes vX.X.X TheiaCoV_Illumina_PE_PHB, TheiaCoV_Illumina_SE_PHB, TheiaCoV_ONT_PHB, TheiaCoV_ClearLabs_PHB, TheiaCoV_FASTA_PHB, TheiaCoV_FASTA_Batch_PHB TheiaEuk Workflow Series Mycotic genome assembly, QC and characterization from WGS data Mycotics Genomic Characterization Sample-level Some optional features incompatible, Yes vX.X.X TheiaEuk_Illumina_PE_PHB, TheiaEuk_ONT_PHB TheiaMeta Genome assembly and QC from metagenomic sequencing Any taxa Genomic Characterization Sample-level Yes v3.0.0 TheiaMeta_Illumina_PE_PHB TheiaProk Workflow Series Bacterial genome assembly, QC and characterization from WGS data Bacteria Genomic Characterization Sample-level Some optional features incompatible, Yes vX.X.X TheiaProk_Illumina_PE_PHB, TheiaProk_Illumina_SE_PHB, TheiaProk_ONT_PHB, TheiaProk_FASTA_PHB TheiaValidate This workflow performs basic comparisons between user-designated columns in two separate tables. Any taxa Standalone No v3.0.0 TheiaValidate_PHB TheiaViral Viral genome assembly, QC, and characterization from WGS data. Viral Genomic Characterization Sample-level Yes vX.X.X TheiaViral_Illumina_PE_PHB, TheiaViral_ONT_PHB Transfer_Column_Content Transfer contents of a specified Terra data table column for many samples (\"entities\") to a GCP storage bucket location Any taxa Exporting Data from Terra Set-level Yes v1.3.0 Transfer_Column_Content_PHB Usher Use UShER to rapidly and accurately place your samples on any existing phylogenetic tree Monkeypox virus, SARS-CoV-2, Viral Phylogenetic Placement Sample-level, Set-level Yes v2.1.0 Usher_PHB VADR_Update Update VADR assignments HAV, Influenza, Monkeypox virus, RSV-A, RSV-B, SARS-CoV-2, Viral, WNV Genomic Characterization Sample-level Yes vX.X.X VADR_Update_PHB Zip_Column_Content Zip contents of a specified Terra data table column for many samples (\"entities\") Any taxa Exporting Data from Terra Set-level Yes v2.1.0 Zip_Column_Content_PHB kSNP3 SNP-based phylogenetic analysis from assemblies Bacteria, Mycotics, Viral Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 kSNP3_PHB kSNP4 SNP-based phylogenetic analysis from assemblies Bacteria, Mycotics, Viral Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 kSNP4_PHB"},{"location":"workflows_overview/workflows_kingdom/","title":"Workflows by Kingdom","text":"<p>Sort by Type | Sort Alphabetically</p>"},{"location":"workflows_overview/workflows_kingdom/#any-taxa","title":"Any Taxa","text":"Name Description Workflow Type Workflow Level Command-line Compatibility Last Known Changes Dockstore AMR_Search Perform AMR profiling on microbial assemblies mimicing Pathogenwatch Standalone Sample-level Yes v3.0.1 AMR_Search_PHB Assembly_Fetch Download assemblies from NCBI, after optionally identifying the closest RefSeq reference genome to your own draft assembly Data Import Sample-level Yes v3.1.0 Assembly_Fetch_PHB BaseSpace_Fetch Import data from BaseSpace into Terra Data Import Sample-level Yes v3.1.0 BaseSpace_Fetch_PHB Clair3_Variants ONT Variant Caller Phylogenetic Construction Sample-level Yes v3.0.0 Clair3_Variants_ONT_PHB Concatenate_Column_Content Concatenate contents of a specified Terra data table column for many samples (\"entities\") Exporting Data from Terra Set-level Yes v2.1.0 Concatenate_Column_Content_PHB Concatenate_Illumina_Lanes Concatenate Illumina lanes for a single sample Standalone Sample-level Yes v2.3.0 Concatenate_Illumina_Lanes_PHB Create_Terra_Table Upload data to Terra and then run this workflow to have the table automatically created Data Import No v2.2.0 Create_Terra_Table_PHB Dorado_Basecalling GPU-accelerated basecalling of Oxford Nanopore sequencing data Standalone Sample-level No v3.0.1 Dorado_Basecalling_PHB Fetch_SRR_Accession Provided a BioSample accession, identify any associated SRR accession(s) Data Import Sample-level Yes v2.3.0 Fetch_SRR_Accession_PHB Kraken2 Taxa identification from reads Standalone Sample-level Yes v3.1.0 Kraken2_PE_PHB, Kraken2_SE_PHB, Kraken2_ONT_PHB NCBI_Scrub Runs NCBI's HRRT on Illumina FASTQs Standalone Sample-level Yes v2.2.1 NCBI_Scrub_PE_PHB, NCBI_Scrub_SE_PHB ONT_Barcode_Concatenation Creates a Terra table after concatenating barcodes from ONT data Data Import No vX.X.X ONT_Barcode_Concatenation_PHB RASUSA Randomly subsample sequencing reads to a specified coverage Standalone Sample-level Yes v3.0.0 RASUSA_PHB Rename_FASTQ Rename paired-end or single-end read files in a Terra data table in a non-destructive way Standalone Sample-level Yes v2.1.0 Rename_FASTQ_PHB SRA_Fetch Import publicly available reads from SRA using SRR#, ERR# or DRR# Data Import Sample-level Yes v2.2.0 SRA_Fetch_PHB TheiaMeta Genome assembly and QC from metagenomic sequencing Genomic Characterization Sample-level Yes v3.0.0 TheiaMeta_Illumina_PE_PHB TheiaValidate This workflow performs basic comparisons between user-designated columns in two separate tables. Standalone No v3.0.0 TheiaValidate_PHB Transfer_Column_Content Transfer contents of a specified Terra data table column for many samples (\"entities\") to a GCP storage bucket location Exporting Data from Terra Set-level Yes v1.3.0 Transfer_Column_Content_PHB Zip_Column_Content Zip contents of a specified Terra data table column for many samples (\"entities\") Exporting Data from Terra Set-level Yes v2.1.0 Zip_Column_Content_PHB"},{"location":"workflows_overview/workflows_kingdom/#bacteria","title":"Bacteria","text":"Name Description Workflow Type Workflow Level Command-line Compatibility Last Known Changes Dockstore Core_Gene_SNP Pangenome analysis Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 Core_Gene_SNP_PHB Find_Shared_Variants Combines and reshapes variant data from Snippy_Variants to illustrate variants shared across multiple samples Phylogenetic Construction Set-level Yes v2.0.0 Find_Shared_Variants_PHB GAMBIT_Query Taxon identification of genome assembly using GAMBIT Standalone Sample-level Yes v2.0.0 Gambit_Query_PHB Lyve_SET Alignment of reads to a reference genome, SNP calling, curation of high quality SNPs, phylogenetic analysis Phylogenetic Construction Set-level Yes v2.1.0 Lyve_SET_PHB MashTree_FASTA Mash-distance based phylogenetic analysis from assemblies Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 MashTree_FASTA_PHB NCBI-AMRFinderPlus Runs NCBI's AMRFinderPlus on genome assemblies (bacterial and fungal) Standalone Sample-level Yes v3.0.1 NCBI-AMRFinderPlus_PHB Snippy_Streamline Implementation of Snippy workflows for phylogenetic analysis from reads, with optional dynamic reference selection Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 Snippy_Streamline_PHB Snippy_Streamline_FASTA Implementation of Snippy workflows for phylogenetic analysis from assembled genomes (in FASTA format), with optional dynamic reference selection Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 Snippy_Streamline_FASTA_PHB Snippy_Tree SNP-based phylogenetic analysis from reads, with option to mask recombination Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 Snippy_Tree_PHB Snippy_Variants Alignment of reads to a reference genome, then SNP calling Phylogenetic Construction Sample-level Yes v2.3.0 Snippy_Variants_PHB TBProfiler_tNGS Performs in silico antimicrobial susceptibility testing on Mycobacterium tuberculosis targeted-NGS samples with TBProfiler and tbp-parser Standalone Sample-level Yes vX.X.X TBProfiler_tNGS_PHB Terra_2_ENA Upload of sequence data to ENA Public Data Sharing Set-level No v3.1.0 Terra_2_ENA_PHB Terra_2_NCBI Upload of sequence data to NCBI Public Data Sharing Set-level No vX.X.X Terra_2_NCBI_PHB TheiaProk Workflow Series Bacterial genome assembly, QC and characterization from WGS data Genomic Characterization Sample-level Some optional features incompatible, Yes vX.X.X TheiaProk_Illumina_PE_PHB, TheiaProk_Illumina_SE_PHB, TheiaProk_ONT_PHB, TheiaProk_FASTA_PHB kSNP3 SNP-based phylogenetic analysis from assemblies Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 kSNP3_PHB kSNP4 SNP-based phylogenetic analysis from assemblies Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 kSNP4_PHB"},{"location":"workflows_overview/workflows_kingdom/#mycotics","title":"Mycotics","text":"Name Description Workflow Type Workflow Level Command-line Compatibility Last Known Changes Dockstore Cauris_CladeTyper C. auris clade assignment Standalone Sample-level Yes vX.X.X Cauris_CladeTyper_PHB Find_Shared_Variants Combines and reshapes variant data from Snippy_Variants to illustrate variants shared across multiple samples Phylogenetic Construction Set-level Yes v2.0.0 Find_Shared_Variants_PHB GAMBIT_Query Taxon identification of genome assembly using GAMBIT Standalone Sample-level Yes v2.0.0 Gambit_Query_PHB MashTree_FASTA Mash-distance based phylogenetic analysis from assemblies Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 MashTree_FASTA_PHB NCBI-AMRFinderPlus Runs NCBI's AMRFinderPlus on genome assemblies (bacterial and fungal) Standalone Sample-level Yes v3.0.1 NCBI-AMRFinderPlus_PHB Snippy_Variants Alignment of reads to a reference genome, then SNP calling Phylogenetic Construction Sample-level Yes v2.3.0 Snippy_Variants_PHB Terra_2_NCBI Upload of sequence data to NCBI Public Data Sharing Set-level No vX.X.X Terra_2_NCBI_PHB TheiaEuk Workflow Series Mycotic genome assembly, QC and characterization from WGS data Genomic Characterization Sample-level Some optional features incompatible, Yes vX.X.X TheiaEuk_Illumina_PE_PHB, TheiaEuk_ONT_PHB kSNP3 SNP-based phylogenetic analysis from assemblies Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 kSNP3_PHB kSNP4 SNP-based phylogenetic analysis from assemblies Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 kSNP4_PHB"},{"location":"workflows_overview/workflows_kingdom/#viral","title":"Viral","text":"Name Description Workflow Type Workflow Level Command-line Compatibility Last Known Changes Dockstore Augur Phylogenetic analysis for viral pathogens Phylogenetic Construction Sample-level, Set-level Yes v3.0.0 Augur_Prep_PHB, Augur_PHB CZGenEpi_Prep Prepare metadata and fasta files for easy upload to the CZ GEN EPI platform. Phylogenetic Construction Set-level Yes v1.3.0 CZGenEpi_Prep_PHB Freyja Workflow Series Recovers relative lineage abundances from mixed sample data and generates visualizations Genomic Characterization Sample-level, Set-level Yes v3.1.0 Freyja_FASTQ_PHB, Freyja_Plot_PHB, Freyja_Dashboard_PHB, Freyja_Update_PHB MashTree_FASTA Mash-distance based phylogenetic analysis from assemblies Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 MashTree_FASTA_PHB Mercury_Prep_N_Batch Prepare metadata and sequence data for submission to NCBI and GISAID Public Data Sharing Set-level No vX.X.X Mercury_Prep_N_Batch_PHB Nextclade_Batch Use Nextclade to rapidly and accurately place your samples on any existing phylogenetic tree Phylogenetic Placement Set-level Yes vX.X.X Nextclade_Batch_PHB Pangolin_Update Update Pangolin assignments Genomic Characterization Sample-level Yes v3.0.1 Pangolin_Update_PHB Snippy_Variants Alignment of reads to a reference genome, then SNP calling Phylogenetic Construction Sample-level Yes v2.3.0 Snippy_Variants_PHB Terra_2_ENA Upload of sequence data to ENA Public Data Sharing Set-level No v3.1.0 Terra_2_ENA_PHB Terra_2_GISAID Upload of assembly data to GISAID Public Data Sharing Set-level Yes v1.2.1 Terra_2_GISAID_PHB Terra_2_NCBI Upload of sequence data to NCBI Public Data Sharing Set-level No vX.X.X Terra_2_NCBI_PHB TheiaCov Workflow Series Viral genome assembly, QC and characterization from amplicon sequencing Genomic Characterization Sample-level, Set-level Some optional features incompatible, Yes vX.X.X TheiaCoV_Illumina_PE_PHB, TheiaCoV_Illumina_SE_PHB, TheiaCoV_ONT_PHB, TheiaCoV_ClearLabs_PHB, TheiaCoV_FASTA_PHB, TheiaCoV_FASTA_Batch_PHB TheiaViral Viral genome assembly, QC, and characterization from WGS data. Genomic Characterization Sample-level Yes vX.X.X TheiaViral_Illumina_PE_PHB, TheiaViral_ONT_PHB Usher Use UShER to rapidly and accurately place your samples on any existing phylogenetic tree Phylogenetic Placement Sample-level, Set-level Yes v2.1.0 Usher_PHB VADR_Update Update VADR assignments Genomic Characterization Sample-level Yes vX.X.X VADR_Update_PHB kSNP3 SNP-based phylogenetic analysis from assemblies Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 kSNP3_PHB kSNP4 SNP-based phylogenetic analysis from assemblies Phylogenetic Construction Set-level Some optional features incompatible, Yes v3.0.0 kSNP4_PHB"},{"location":"workflows_overview/workflows_type/","title":"Workflows by Type","text":"<p>Sort by Kingdom | Sort Alphabetically</p>"},{"location":"workflows_overview/workflows_type/#data-import","title":"Data Import","text":"Name Description Applicable Kingdom Workflow Level Command-line Compatibility Last Known Changes Dockstore Assembly_Fetch Download assemblies from NCBI, after optionally identifying the closest RefSeq reference genome to your own draft assembly Any taxa Sample-level Yes v3.1.0 Assembly_Fetch_PHB BaseSpace_Fetch Import data from BaseSpace into Terra Any taxa Sample-level Yes v3.1.0 BaseSpace_Fetch_PHB Create_Terra_Table Upload data to Terra and then run this workflow to have the table automatically created Any taxa No v2.2.0 Create_Terra_Table_PHB Fetch_SRR_Accession Provided a BioSample accession, identify any associated SRR accession(s) Any taxa Sample-level Yes v2.3.0 Fetch_SRR_Accession_PHB ONT_Barcode_Concatenation Creates a Terra table after concatenating barcodes from ONT data Any taxa No vX.X.X ONT_Barcode_Concatenation_PHB SRA_Fetch Import publicly available reads from SRA using SRR#, ERR# or DRR# Any taxa Sample-level Yes v2.2.0 SRA_Fetch_PHB"},{"location":"workflows_overview/workflows_type/#genomic-characterization","title":"Genomic Characterization","text":"Name Description Applicable Kingdom Workflow Level Command-line Compatibility Last Known Changes Dockstore Freyja Workflow Series Recovers relative lineage abundances from mixed sample data and generates visualizations SARS-CoV-2, Viral Sample-level, Set-level Yes v3.1.0 Freyja_FASTQ_PHB, Freyja_Plot_PHB, Freyja_Dashboard_PHB, Freyja_Update_PHB Pangolin_Update Update Pangolin assignments SARS-CoV-2, Viral Sample-level Yes v3.0.1 Pangolin_Update_PHB TheiaCov Workflow Series Viral genome assembly, QC and characterization from amplicon sequencing HIV, Influenza, Monkeypox virus, RSV-A, RSV-B, SARS-CoV-2, Viral, WNV Sample-level, Set-level Some optional features incompatible, Yes vX.X.X TheiaCoV_Illumina_PE_PHB, TheiaCoV_Illumina_SE_PHB, TheiaCoV_ONT_PHB, TheiaCoV_ClearLabs_PHB, TheiaCoV_FASTA_PHB, TheiaCoV_FASTA_Batch_PHB TheiaEuk Workflow Series Mycotic genome assembly, QC and characterization from WGS data Mycotics Sample-level Some optional features incompatible, Yes vX.X.X TheiaEuk_Illumina_PE_PHB, TheiaEuk_ONT_PHB TheiaMeta Genome assembly and QC from metagenomic sequencing Any taxa Sample-level Yes v3.0.0 TheiaMeta_Illumina_PE_PHB TheiaProk Workflow Series Bacterial genome assembly, QC and characterization from WGS data Bacteria Sample-level Some optional features incompatible, Yes vX.X.X TheiaProk_Illumina_PE_PHB, TheiaProk_Illumina_SE_PHB, TheiaProk_ONT_PHB, TheiaProk_FASTA_PHB TheiaViral Viral genome assembly, QC, and characterization from WGS data. Viral Sample-level Yes vX.X.X TheiaViral_Illumina_PE_PHB, TheiaViral_ONT_PHB VADR_Update Update VADR assignments HAV, Influenza, Monkeypox virus, RSV-A, RSV-B, SARS-CoV-2, Viral, WNV Sample-level Yes vX.X.X VADR_Update_PHB"},{"location":"workflows_overview/workflows_type/#phylogenetic-construction","title":"Phylogenetic Construction","text":"Name Description Applicable Kingdom Workflow Level Command-line Compatibility Last Known Changes Dockstore Augur Phylogenetic analysis for viral pathogens Viral Sample-level, Set-level Yes v3.0.0 Augur_Prep_PHB, Augur_PHB CZGenEpi_Prep Prepare metadata and fasta files for easy upload to the CZ GEN EPI platform. Monkeypox virus, SARS-CoV-2, Viral Set-level Yes v1.3.0 CZGenEpi_Prep_PHB Clair3_Variants ONT Variant Caller Any taxa Sample-level Yes v3.0.0 Clair3_Variants_ONT_PHB Core_Gene_SNP Pangenome analysis Bacteria Set-level Some optional features incompatible, Yes v3.0.0 Core_Gene_SNP_PHB Find_Shared_Variants Combines and reshapes variant data from Snippy_Variants to illustrate variants shared across multiple samples Bacteria, Mycotics Set-level Yes v2.0.0 Find_Shared_Variants_PHB Lyve_SET Alignment of reads to a reference genome, SNP calling, curation of high quality SNPs, phylogenetic analysis Bacteria Set-level Yes v2.1.0 Lyve_SET_PHB MashTree_FASTA Mash-distance based phylogenetic analysis from assemblies Bacteria, Mycotics, Viral Set-level Some optional features incompatible, Yes v3.0.0 MashTree_FASTA_PHB Snippy_Streamline Implementation of Snippy workflows for phylogenetic analysis from reads, with optional dynamic reference selection Bacteria Set-level Some optional features incompatible, Yes v3.0.0 Snippy_Streamline_PHB Snippy_Streamline_FASTA Implementation of Snippy workflows for phylogenetic analysis from assembled genomes (in FASTA format), with optional dynamic reference selection Bacteria Set-level Some optional features incompatible, Yes v3.0.0 Snippy_Streamline_FASTA_PHB Snippy_Tree SNP-based phylogenetic analysis from reads, with option to mask recombination Bacteria Set-level Some optional features incompatible, Yes v3.0.0 Snippy_Tree_PHB Snippy_Variants Alignment of reads to a reference genome, then SNP calling Bacteria, Mycotics, Viral Sample-level Yes v2.3.0 Snippy_Variants_PHB kSNP3 SNP-based phylogenetic analysis from assemblies Bacteria, Mycotics, Viral Set-level Some optional features incompatible, Yes v3.0.0 kSNP3_PHB kSNP4 SNP-based phylogenetic analysis from assemblies Bacteria, Mycotics, Viral Set-level Some optional features incompatible, Yes v3.0.0 kSNP4_PHB"},{"location":"workflows_overview/workflows_type/#phylogenetic-placement","title":"Phylogenetic Placement","text":"Name Description Applicable Kingdom Workflow Level Command-line Compatibility Last Known Changes Dockstore Nextclade_Batch Use Nextclade to rapidly and accurately place your samples on any existing phylogenetic tree Monkeypox virus, SARS-CoV-2, Viral Set-level Yes vX.X.X Nextclade_Batch_PHB Usher Use UShER to rapidly and accurately place your samples on any existing phylogenetic tree Monkeypox virus, SARS-CoV-2, Viral Sample-level, Set-level Yes v2.1.0 Usher_PHB"},{"location":"workflows_overview/workflows_type/#public-data-sharing","title":"Public Data Sharing","text":"Name Description Applicable Kingdom Workflow Level Command-line Compatibility Last Known Changes Dockstore Mercury_Prep_N_Batch Prepare metadata and sequence data for submission to NCBI and GISAID Influenza, Monkeypox virus, SARS-CoV-2, Viral Set-level No vX.X.X Mercury_Prep_N_Batch_PHB Terra_2_GISAID Upload of assembly data to GISAID SARS-CoV-2, Viral Set-level Yes v1.2.1 Terra_2_GISAID_PHB Terra_2_NCBI Upload of sequence data to NCBI Bacteria, Mycotics, Viral Set-level No vX.X.X Terra_2_NCBI_PHB"},{"location":"workflows_overview/workflows_type/#exporting-data-from-terra","title":"Exporting Data from Terra","text":"Name Description Applicable Kingdom Workflow Level Command-line Compatibility Last Known Changes Dockstore Concatenate_Column_Content Concatenate contents of a specified Terra data table column for many samples (\"entities\") Any taxa Set-level Yes v2.1.0 Concatenate_Column_Content_PHB Transfer_Column_Content Transfer contents of a specified Terra data table column for many samples (\"entities\") to a GCP storage bucket location Any taxa Set-level Yes v1.3.0 Transfer_Column_Content_PHB Zip_Column_Content Zip contents of a specified Terra data table column for many samples (\"entities\") Any taxa Set-level Yes v2.1.0 Zip_Column_Content_PHB"},{"location":"workflows_overview/workflows_type/#standalone","title":"Standalone","text":"Name Description Applicable Kingdom Workflow Level Command-line Compatibility Last Known Changes Dockstore AMR_Search Perform AMR profiling on microbial assemblies mimicing Pathogenwatch Any taxa Sample-level Yes v3.0.1 AMR_Search_PHB Cauris_CladeTyper C. auris clade assignment Mycotics Sample-level Yes vX.X.X Cauris_CladeTyper_PHB Concatenate_Illumina_Lanes Concatenate Illumina lanes for a single sample Any taxa Sample-level Yes v2.3.0 Concatenate_Illumina_Lanes_PHB Dorado_Basecalling GPU-accelerated basecalling of Oxford Nanopore sequencing data Any taxa Sample-level No v3.0.1 Dorado_Basecalling_PHB GAMBIT_Query Taxon identification of genome assembly using GAMBIT Bacteria, Mycotics Sample-level Yes v2.0.0 Gambit_Query_PHB Kraken2 Taxa identification from reads Any taxa Sample-level Yes v3.1.0 Kraken2_PE_PHB, Kraken2_SE_PHB, Kraken2_ONT_PHB NCBI-AMRFinderPlus Runs NCBI's AMRFinderPlus on genome assemblies (bacterial and fungal) Bacteria, Mycotics Sample-level Yes v3.0.1 NCBI-AMRFinderPlus_PHB NCBI_Scrub Runs NCBI's HRRT on Illumina FASTQs Any taxa Sample-level Yes v2.2.1 NCBI_Scrub_PE_PHB, NCBI_Scrub_SE_PHB RASUSA Randomly subsample sequencing reads to a specified coverage Any taxa Sample-level Yes v3.0.0 RASUSA_PHB Rename_FASTQ Rename paired-end or single-end read files in a Terra data table in a non-destructive way Any taxa Sample-level Yes v2.1.0 Rename_FASTQ_PHB TBProfiler_tNGS Performs in silico antimicrobial susceptibility testing on Mycobacterium tuberculosis targeted-NGS samples with TBProfiler and tbp-parser Bacteria, TB Sample-level Yes vX.X.X TBProfiler_tNGS_PHB TheiaValidate This workflow performs basic comparisons between user-designated columns in two separate tables. Any taxa No v3.0.0 TheiaValidate_PHB"}]}