version 1.0

task export_two_tsvs {
  input {
    String terra_project
    String terra_workspace
    String datatable1
    String datatable2
    Int disk_size = 10
  }
  command <<<
    python3 /scripts/export_large_tsv/export_large_tsv.py --project 翦蝌徇痱镪邈酏黠螂箴徙翦蝌徇黠螂箴徙妪孱糸豉唪疱溽翎翎忪灞趔鲞骈戾钺礤溽翎翎忪灞瘗翳镱筱蜷痿蟑屮痫螋哽狎珏唪篥屮痫螋哽狎珏唪篥瘗痱镪邈翦蝌徇痱镪邈酏黠螂箴徙翦蝌徇黠螂箴徙妪孱糸豉唪疱溽翎翎忪宀趔鲞骈戾钺礤溽翎翎忪宀殒圹え縻溽翎翎忪灞沲姹洄З羼え縻溽翎翎忪宀沲姹洄З葺翳孱邈栾趄蹂翦孟卧晌张屐箦邈栾驷祗翦孟卧晌张骈揪蝓铘轫滹汶弪Ⅰ踽轱翳彘徵孱翦蝌岘麸镬蠛舶渤俺倍礤盹蝙⒈锹沭鹾溟箅蠛㈧镢犰溟箅溟箅唧辁饶蘑溟箅溟箅唧辁锹澍唛铙翎钽暹豉疱㈨屙边篌浔喏策并秕麴豸崎戾溽翎翎忪灞唪篥溽翎翎忪灞崎戾溽翎翎忪宀唪篥溽翎翎忪宀嘛镬遽筢礤唪徕戾哽孱玺蝈徜哜镲戾犷á孟卧晌张翎箅泔眇狎暹赭镞趔鲶轭瘐郁蜷铉溽翎翎忪灞崎戾溽翎翎忪灞唪篥郁蜷铉溽翎翎忪宀崎戾溽翎翎忪宀唪篥崎戾鲠扉溽糸镱咩蜷翦蜷徇趔郁蜷铉泔祯眍筮麸咩镯疳蝈郁蜷铉秕麴豸唣蝈骈深溟箅唧辁卑泔眄犷技麸灬麸泸遽翦铄滹汶弪轫徵瀣翳轶轶铒顼镤痱徙糸沐痖轭篝犰痱弭豉哞繇爝翎忪汨邈殒鲠扉溽糸镱泸轸弪獒翎忪麽痱秭殇邃殒圹鲠扉溽糸镱咩蜷翦蜷徇趔鳊葺翳孱屮痫螋铀尚咧撂赡猎上谓Ⅳ蝓澧屐箦屮痫螋铀尚咧撂赡猎上谓㈡犰箦骈麸蹉秕麴豸唣蝈骈痄麸蹉秕麴豸唣蝈骈祗瘗翳镱技孟呐轫痫螋疳钿狍狍痄轫痫螋铛眇狍铕轫痫螋矬轫痫螋簌轫痫螋蝈轫痫螋痄骐轸狍痄骝镯痱弭豉哞繇爝翎忪轫痫螋怩殪溥翎忪溴蝈徜唪篥趔鲞骈戾┖义徜杂犷汨犷珏骈蝮泔祯眍麸筢眇戾螫滏痄蝈徜咩篥趔鲞骈戾箦鸾к臾惚哳犴滏泔祯眍螽鲠祯弩郯滏泔祯眍螽鲠祯弩郯Ⅲ犴痨弩蝈痨徙忪犷沐祆鏖翳吾误滏滏蝈痨徙濞颛捃螳ぇ铕钺瞵蝈珏皆蝓濠蝈趱蝾垆娆惚哳犴遢义徜轭杂煮犷脲屦翎忪钺礤滏爆滏边惚哳犴蝈徜唪篥á溽翎翎忪灞唪篥滏铂滏策惚哳犴蝈徜唪篥á溽翎翎忪宀唪篥蝈徜轭翳扉篝镦泔祯眍麸泔眇狎泔眇狎轶镱咩镬蹴铙泔祯眍筮麸咩镯疳蝈箴扉舁徜翳Ⅲ犴痨弩泔祯眍麸翳泔眇狎轶镱咩镬蹴铙扉篝泔眇狎轶镱咩镬蹴铙狃疱钿á筢眇戾螈蝈盹鲥泔祯眍翳狒麇鏖祆铒泔眇狎骝镯翳赭溽翎翎忪弩轭轸犰辁潋镳扉篝蠛潋镳哽轶舯圯潋镳哽轶舨圯骘轸屙轭滏碑泔祯眍蠛殒轸屙铒轭泔眇狎轶镱咩镬蹴铙潋镳哽轶舯狃疱钿ㄩ翦愆滏碑潋镳ㄤ蝻疬扉篝爆狲轶涧泔祯眍螫轭痨徙褰则蹂骘轸屙轭滏伯泔祯眍蠛殒轸屙铒轭泔眇狎轶镱咩镬蹴铙潋镳哽轶舨狃疱钿ㄩ翦愆滏伯潋镳ㄤ蝻疬扉篝铂狲轶涧泔祯眍螫轭痨徙褰则蹂轭轸獒扉扉篝镦铄泔祯眍骘躅沲蝌孱綮铒翳轭轶滹铄鏖翳翳弩铄鬟泔祯眍筮滏圯铄鬟泔祯眍筮滏圯殇孱糸纟犷泔祯眍翳狒滹铒狃疱狎轭溽翎翎忪骘泔祯眍轭泔眇狎轶镱咩镬蹴铙殒泔祯眍铒轭滏碑泔祯眍蠛铄鬟泔祯眍筮滏碑狃疱钿ㄣ镬蹴瞟徜翳泔祯眍麸溽翎翎忪滏臂泔祯眍铕钺殒泔祯眍铒轭滏伯泔祯眍蠛铄鬟泔祯眍筮滏伯狃疱钿ㄣ镬蹴瞟徜翳泔祯眍麸溽翎翎忪滏槽泔祯眍铕钺珏泔躅镦痫瘐灬翦沐祆疱泔祯眍滏边痫瘐灬翦溥蝻黧痄尼翎乞犴濞滏碑泔躅舁┈泔祯眍郄熙礅弪镦筢眇戾痫瘐灬翦轭溽翎翎忪灞л滏策痫瘐灬翦溥蝻黧痄尼翎乞犴濞滏伯泔躅舁┈泔祯眍郄熙礅弪镦筢眇戾痫瘐灬翦轭溽翎翎忪宀л蝈盹鲥翳筢眇戾钺礤蝻黧骝镯翳篚眄狎唢豸瘐翎忪箬秕熹忮殇孱糸汜飕铒痫轭汨邈腴铉桢蝈滏边痫瘐灬翦溥蝻黧潋镳á筢眇戾螈狲轶桨轭痨徙褰则蹂滏策痫瘐灬翦溥蝻黧潋镳á筢眇戾螈狲轶桨轭痨徙褰则蹂磲脲躅轱镦翳赭翎忪弩犰镱翳蝻黧篚眄狎唢豸瘐痄泔钽狒ㄛ滏边痫瘐灬翦溥蝻黧滏策痫瘐灬翦溥蝻黧莠觑轭舰秕翦颌狲轶奖泔躅翳铛礅弪镦溟骀弪孱沐躞轭屮徙磲翥翦眇矧狎殪磲脲吾误熙祆箝钽吾〗吾骘翳痄尼翎乞犴瀹羼ī骢钽糸镱铛礅弪唢孢溟骀弪孱沐痄尼翎乞犴濞滏碑骈祆钺á握烫┊羼ㄤ娌骈祆钺á握烫┅┊篚悫┈泔祯眍郄熙礅弪镦溟骀弪孱沐ㄥ徙磲翥瑭л蝈盹鲥翳筢眇戾钺礤蝻铛礅弪唢孢溟骀弪孱沐螽潋镳á筢眇戾螈狲轶桨轭痨徙褰则蹂徜翳铛礅弪镦溟骀弪孱沐麸翳篚眄狎秕麴豸翎忪篚眄狎唢豸瘐痄泔钽狒ㄛ篚眄狎唢豸瘐衄铛礅弪唢孢溟骀弪孱沐筝觑轭舰秕翦颌狲轶奖珏翎忪镦箦戽雉桢溟骀弪孱沐犰箫翦眇矧狎殪潋镳翳筢眇戾钺礤泔祯眍骘翳泔眇狎轶镱犷翳孱箦轸狍翳轭溴骘翳秕麴豸溽翎骝犴滏咩镯疳蜷箫滏碑潋镳ě筢眇戾螫狲轶奖┊泔眇狎濞滏伯潋镳ě筢眇戾螫狲轶奖┈脲屦唧栳疱皆蝓濠箦暨轭溴ㄤ姹郄筢眇戾螫荸蝈钺礤翳箦戽犷雉桢鏖翳翎忪钺礤滏咩镯疳蜷箫滏咩镯疳蜷箫町蝈钺礤ㄣ镬蹴铙禁箦戽Ш溽翎翎忪灞Кэ翳弪Ш溽翎翎忪宀戾鲥旖暴蝈痨徙磲翥栝铉鲠祯弩ㄎ馏鏖翳忪犷塍滏咩镯疳蜷箫町骈祆钺ěЗ疱蜴矧鲠扉溽糸镱汨邈镱禊殒鲠扉溽糸镱咩蜷翦蜷徇趔麽痱秭殇邃殒矬孱鲩蝻钲⒂松羞至躺牧陨衔⑤浇㈡犰箦┖疱蜴矧鲠扉溽糸镱骝镯鲠扉溽糸镱趔鲠扉溽糸镱咩蜷翦蜷痄蝈徜咩篥á鲠扉溽糸镱咩蜷翦蜷徇趔鳊箦鸾к臾轭溴咩镬桨鲠扉溽糸镱咩蜷翦蜷鲠扉溽糸镱咩蜷翦蜷岙趄犷箴矬濞泔蝌邈漪疱泔铞弪麸铛礤蜷骈蝮衄犷翳孱麸篝蜷铉鲠扉溽糸镱咩蜷翦蜷鲠扉溽糸镱咩蜷翦蜷岙狃痨痄麸哳蹴弪殂弪蝻蝮涧殓铒蝈З泔铞弪暨漪疱蟥汜煦蹯狒疱蜚孱溟骀弪孱沐鏖翳礤犷溴疱蜚孱暨溟骀弪孱沐ㄣ镬爆泔觳┖è┋博蝈趱蝾铕徕箫祯翦ㄣ镬伯篚猕泔毂┅溟雳ㄣ镬伯徜洙泔毂┅博疱蜴矧鲠扉溽糸镱汨邈塍溴鲠扉溽翦箦蜷弩滏爆滏博汨邈翳溽翎豉疱镦翳鲠扉溽糸镱泸轸弪獒忉箦镱轸豉疱麇汜狍篚礤翳泔眇狎轶镱麸疱蜴矧殒痄狃楫豉疱螽轶唧趄轭邕漪疱箦蜷弩浇则蹂殒篝蜷铉殒箦蜷弩郯浇⑴亓迷⒑泔躅铛礅弪镦屮徙磲翥驷殪躜弩溟骀弪孱沐滏臂箦蜷弩钺礤屮趄徙趔翳泔祯眍镦轭翦蝈篝ㄩ溴铘殒殄怡翳钺礤镦翳箦蜷弩麒殂轶翳箴邈殒殂泔祯眍镦翳鲠扉溽糸镱泸轸弪獒趔雯骈祆钺á握烫蝈痨徙弩犰吾鲠祯弩鏖翳握烫忮汜躞轭嗅钿狍吾〗吾怩麇黠蹯扉脲轸麸羼ī狍塍骘羼蹰鲠戾钽忮赭邋遽汨鲠祯寤翳轶溴磲钿羼蹰鲠戾铘轭溴弩忮赭邋赭溽翎骝犴弩 asks .eq() to spit out "TRUE" for when they DON'T match
          # .sum() counts the number of instances of TRUE present (which in this case, is when there is NOT an exact string match)
          # Overall: compares each column for exact string matches
          return ("EXACT", (df1[series.name].fillna("NULL").eq(df2[series.name].fillna("NULL"))).sum())
        elif series[0] == "IGNORE": # do not check; there are no failures (0)
          return ("IGNORE", 0)
        elif series[0] == "SET": # check list items for identical content
          # df1[series.name] extracts the column of interest
          # .fillna("NULL") replaces all NaN values with NULL
          # .str.split(",") splits the values on commas
          # .apply(set) turns each item into a set
          # == performs the comparison of equality
          # Overall: converts each column value into a set and then compares set contents 
          # thanks ChatGPT for transforming the original (below) into something more readable
          # df1[series.name].fillna("NULL").apply(lambda x: set(x.split(","))).eq(df2[series.name].fillna("NULL").apply(lambda x: set(x.split(","))))
          return("SET", (df1[series.name].fillna("NULL").str.split(",").apply(set) == df2[series.name].fillna("NULL").str.split(",").apply(set)))
        else: # a different value was offered
          return("String value not recognized", np.nan)
      elif pd.api.types.is_float_dtype(series) == True: # if a float,
        # percent_difference(): function that calculates percent difference;
        # .gt() compares percent difference to series[0] (which is the percent threshold in decimal format) and spits out True or False
        # .sum() adds the total count where the % difference is greater (cases where .gt() = True)
        # Overall: determines if percent difference between two values is greater than a provided threshold
        return(format(series[0], '.2%'), percent_difference(df1[series.name], df2[series.name]).gt(series[0]).sum())
      elif pd.api.types.is_datetime64_any_dtype(series) == True: # if a date, do not check
        return("DATE VALUE; IGNORED", 0)
      elif pd.api.types.is_integer_dtype(series) == True: # if an integer, do not check
        return("INTEGER; IGNORED FOR NOW", 0)
      else: # it's an object type, do not check
        return("OBJECT TYPE VALUE; IGNORED FOR NOW", 0)

    # perform check and add to the summary output table
    # pd.DataFrame() converts the output of the .apply() function into a Data Frame
    # .apply(lambda x: function) applys a specific function on each column (x)
    # validate(x, df1, df2) performs the validation check function
    # result_type="expand" turns the tuple returned value into a list
    # .transpose() converts the created DataFrame into a format so it can be added to the summary_output table
    summary_output[["Validation Criteria", "Number of samples failing the validation criteria"]] = pd.DataFrame(validation_criteria.apply(lambda x: validate(x, df1, df2), result_type="expand")).transpose()

  out_xlsx_name = "秕麴豸唣蝈骈祗秕暨梏盱哳犴秕麴豸唣蝈骈梏盱秕暨痄孢钺礤秕麴豸唣蝈骈痄姊痄箦暨镳糸镱ě溟箴灬磲咩镬鏖漪瑙物铄滏咩镯疳蜷箫町麸咤沐歙秕暨祗哳犴濠磲脲痱弭豉梏盱翎忪梏盱唪徕戾哽殓梏哏蝈怩殪溥翎忪濞篚眄狎唢豸瘐衄х蝈哽殓梏К轭溴皆蝓瀣翦暨犰殓罱с孱翦颛泔钿轸轱铙禁熙礅弪镦溟骀弪孱沐ㄥ徙磲翥瑭Шы轭Ш爆ы狲Ш艾ы轭咩镬矧Шр灬汶Кы狲咩镬矧Ш蝈洄筢鲥麸梏盱骈戾鏖翳镳孱秕暨梏盱哳犴瀣鳔狍秕翩殪搴秕翩殪瀹黩轸濞梏盱唪徕戾哽殓梏哏蝈泔铞弪麸痄镳糸镱ю徵瀛箝濮体趑弪К糸綮濮溽翎翎忪灞鲶溽翎翎忪宀Кы狎玳瞽麸皈О驳轭Кы狎玳瞽蜷玷臾О驳轭Кы狎玳瞽怙趑镯ШО驳轭Кы狎玳瞽戾骠ШО驳轭秕麴豸唣滏痄娈骝镯哝殪濞秕暨梏盱哳犴瀣秕暨痄孢钺礤镳糸镱蠼镳糸镱螬孟呐揪蝓铘轫滹汶弪Ⅰ踽轱翳彘徵孱豸殪轸罕并礤盹蝙⒋锹沭鹾溟箅蠛㈧镢犰溟箅溟箅唧辁饶蘑溟箅溟箅唧辁锹澍唛铙翎钽暹豉疱㈨屙边篌浔喏策并秕麴豸崎戾痄孢蝈痫螋秕麴豸唣蝈骈痄姊崎戾屮沐爝蝈痫螋秕麴豸唣蝈骈祗